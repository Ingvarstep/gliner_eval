{
  "0": [
    {
      "answer": "France",
      "score": 0.9928568601608276
    }
  ],
  "1": [
    {
      "answer": "10th",
      "score": 0.9773081541061401
    },
    {
      "answer": "10th century",
      "score": 0.6186399459838867
    }
  ],
  "2": [
    {
      "answer": "Denmark",
      "score": 0.9902995824813843
    },
    {
      "answer": "Iceland",
      "score": 0.9856152534484863
    },
    {
      "answer": "Norway",
      "score": 0.9817140102386475
    }
  ],
  "3": [
    {
      "answer": "Rollo",
      "score": 0.9961976408958435
    }
  ],
  "4": [
    {
      "answer": "10th",
      "score": 0.7312455773353577
    },
    {
      "answer": "10th",
      "score": 0.99240642786026
    }
  ],
  "5": [],
  "6": [
    {
      "answer": "Normans",
      "score": 0.5780496001243591
    },
    {
      "answer": "Normandy",
      "score": 0.5651973485946655
    }
  ],
  "7": [
    {
      "answer": "Normans",
      "score": 0.7762840986251831
    },
    {
      "answer": "King Charles III of West Francia",
      "score": 0.5660308599472046
    },
    {
      "answer": "Normans",
      "score": 0.6661635637283325
    }
  ],
  "8": [
    {
      "answer": "10th century",
      "score": 0.9791744947433472
    }
  ],
  "9": [
    {
      "answer": "William the Conqueror",
      "score": 0.9917402267456055
    }
  ],
  "10": [],
  "11": [
    {
      "answer": "Catholic",
      "score": 0.9423629641532898
    }
  ],
  "12": [
    {
      "answer": "political, cultural and military impact",
      "score": 0.8078534603118896
    }
  ],
  "13": [
    {
      "answer": "Normans",
      "score": 0.9199742078781128
    }
  ],
  "14": [],
  "15": [
    {
      "answer": "Richard I of Normandy",
      "score": 0.933341920375824
    }
  ],
  "16": [
    {
      "answer": "Kingdom of Sicily",
      "score": 0.9549006223678589
    }
  ],
  "17": [
    {
      "answer": "Norseman, Viking",
      "score": 0.9211126565933228
    }
  ],
  "18": [
    {
      "answer": "9th century",
      "score": 0.9919692873954773
    }
  ],
  "19": [
    {
      "answer": "Normans",
      "score": 0.9837693572044373
    },
    {
      "answer": "Normans",
      "score": 0.8779423832893372
    },
    {
      "answer": "Normanz",
      "score": 0.798936665058136
    }
  ],
  "20": [
    {
      "answer": "9th century",
      "score": 0.9870600700378418
    }
  ],
  "21": [
    {
      "answer": "911",
      "score": 0.9922605156898499
    }
  ],
  "22": [
    {
      "answer": "King Charles III of West Francia",
      "score": 0.9485284686088562
    }
  ],
  "23": [
    {
      "answer": "Epte",
      "score": 0.9610072374343872
    }
  ],
  "24": [
    {
      "answer": "10th century",
      "score": 0.98250412940979
    }
  ],
  "25": [
    {
      "answer": "Saint-Clair-sur-Epte",
      "score": 0.9635069966316223
    }
  ],
  "26": [
    {
      "answer": "Rollo",
      "score": 0.8391030430793762
    }
  ],
  "27": [
    {
      "answer": "Viking incursions",
      "score": 0.9696108102798462
    }
  ],
  "28": [
    {
      "answer": "Rollo",
      "score": 0.722067654132843
    },
    {
      "answer": "Rollo",
      "score": 0.6502575278282166
    }
  ],
  "29": [
    {
      "answer": "880s",
      "score": 0.9877724051475525
    }
  ],
  "30": [
    {
      "answer": "Danes",
      "score": 0.906228244304657
    },
    {
      "answer": "Norwegians",
      "score": 0.9237391352653503
    },
    {
      "answer": "Norse\u2013Gaels",
      "score": 0.9176101684570312
    },
    {
      "answer": "Orkney Vikings",
      "score": 0.9779976010322571
    },
    {
      "answer": "Swedes",
      "score": 0.9101488590240479
    },
    {
      "answer": "Anglo-Danes",
      "score": 0.7243770956993103
    }
  ],
  "31": [
    {
      "answer": "Catholicism",
      "score": 0.8660063147544861
    }
  ],
  "32": [
    {
      "answer": "north",
      "score": 0.9923182725906372
    }
  ],
  "33": [
    {
      "answer": "Catholicism (Christianity)",
      "score": 0.8873913884162903
    }
  ],
  "34": [
    {
      "answer": "Gallo-Romance language",
      "score": 0.8891899585723877
    }
  ],
  "35": [
    {
      "answer": "Norman",
      "score": 0.9205542802810669
    },
    {
      "answer": "Norman",
      "score": 0.8668322563171387
    }
  ],
  "36": [
    {
      "answer": "fighting horsemen",
      "score": 0.98863285779953
    }
  ],
  "37": [
    {
      "answer": "France",
      "score": 0.7977287173271179
    }
  ],
  "38": [
    {
      "answer": "fighting horsemen",
      "score": 0.9560298919677734
    }
  ],
  "39": [
    {
      "answer": "Normans",
      "score": 0.9078587889671326
    },
    {
      "answer": "Italy",
      "score": 0.9280961155891418
    }
  ],
  "40": [
    {
      "answer": "Pechenegs",
      "score": 0.8524606227874756
    }
  ],
  "41": [
    {
      "answer": "Normans",
      "score": 0.9866234660148621
    },
    {
      "answer": "Normans",
      "score": 0.8162944912910461
    },
    {
      "answer": "Normans",
      "score": 0.7053033113479614
    }
  ],
  "42": [
    {
      "answer": "Pechenegs",
      "score": 0.9811850190162659
    },
    {
      "answer": "Bulgars",
      "score": 0.9768728017807007
    },
    {
      "answer": "Seljuk Turks",
      "score": 0.9768474102020264
    }
  ],
  "43": [
    {
      "answer": "Lombards",
      "score": 0.992137610912323
    }
  ],
  "44": [
    {
      "answer": "Sicilian campaign of George Maniaces",
      "score": 0.9422837495803833
    }
  ],
  "45": [
    {
      "answer": "1050s",
      "score": 0.9907838106155396
    }
  ],
  "46": [
    {
      "answer": "1060s",
      "score": 0.991820216178894
    }
  ],
  "47": [
    {
      "answer": "Alexius Komnenos",
      "score": 0.9827369451522827
    }
  ],
  "48": [
    {
      "answer": "Herv\u00e9",
      "score": 0.9915701150894165
    }
  ],
  "49": [
    {
      "answer": "1050s",
      "score": 0.9904311299324036
    }
  ],
  "50": [
    {
      "answer": "Roussel de Bailleul",
      "score": 0.9544330835342407
    }
  ],
  "51": [
    {
      "answer": "1060s",
      "score": 0.9804020524024963
    }
  ],
  "52": [
    {
      "answer": "Afranji",
      "score": 0.9904778003692627
    }
  ],
  "53": [
    {
      "answer": "Oursel",
      "score": 0.9869171380996704
    },
    {
      "answer": "Oursel",
      "score": 0.8866358399391174
    }
  ],
  "54": [
    {
      "answer": "Turkish forces",
      "score": 0.9941762685775757
    }
  ],
  "55": [
    {
      "answer": "Normans",
      "score": 0.9682366847991943
    }
  ],
  "56": [
    {
      "answer": "Armenian state",
      "score": 0.8706053495407104
    }
  ],
  "57": [
    {
      "answer": "Oursel",
      "score": 0.9900975227355957
    },
    {
      "answer": "Oursel",
      "score": 0.8488857746124268
    }
  ],
  "58": [
    {
      "answer": "upper Euphrates valley in northern Syria",
      "score": 0.978104293346405
    }
  ],
  "59": [
    {
      "answer": "descended from an Italo-Norman named Raoul",
      "score": 0.9126462936401367
    }
  ],
  "60": [
    {
      "answer": "Byzantine Greece",
      "score": 0.9956912994384766
    }
  ],
  "61": [
    {
      "answer": "George Maniaces",
      "score": 0.9955810308456421
    }
  ],
  "62": [
    {
      "answer": "Sicilian",
      "score": 0.9832472205162048
    }
  ],
  "63": [
    {
      "answer": "Robert Guiscard",
      "score": 0.8211796283721924
    }
  ],
  "64": [
    {
      "answer": "February 1082",
      "score": 0.9615738391876221
    }
  ],
  "65": [
    {
      "answer": "30,000",
      "score": 0.9883370399475098
    }
  ],
  "66": [
    {
      "answer": "Robert Guiscard",
      "score": 0.9960706233978271
    }
  ],
  "67": [
    {
      "answer": "Gregory VII",
      "score": 0.9944051504135132
    }
  ],
  "68": [
    {
      "answer": "They lost Dyrrachium, Valona, and Butrint",
      "score": 0.8951992988586426
    }
  ],
  "69": [
    {
      "answer": "30,000",
      "score": 0.9847328066825867
    }
  ],
  "70": [
    {
      "answer": "Deabolis",
      "score": 0.9020883440971375
    },
    {
      "answer": "Deabolis",
      "score": 0.9917763471603394
    }
  ],
  "71": [
    {
      "answer": "Bohemond",
      "score": 0.9783873558044434
    },
    {
      "answer": "Bohemond",
      "score": 0.6266934871673584
    }
  ],
  "72": [
    {
      "answer": "Deabolis",
      "score": 0.9796199202537537
    },
    {
      "answer": "Deabolis",
      "score": 0.7406188249588013
    }
  ],
  "73": [
    {
      "answer": "Dyrrachium",
      "score": 0.9842233061790466
    }
  ],
  "74": [
    {
      "answer": "Normans",
      "score": 0.9918699264526367
    },
    {
      "answer": "Normans",
      "score": 0.8502883315086365
    },
    {
      "answer": "Normans",
      "score": 0.7787001132965088
    }
  ],
  "75": [
    {
      "answer": "Robert",
      "score": 0.9841800928115845
    }
  ],
  "76": [
    {
      "answer": "1185",
      "score": 0.994211733341217
    }
  ],
  "77": [
    {
      "answer": "Dyrrachium",
      "score": 0.8476638793945312
    },
    {
      "answer": "Dyrrachium",
      "score": 0.9176978468894958
    }
  ],
  "78": [
    {
      "answer": "Adriatic",
      "score": 0.9802170991897583
    }
  ],
  "79": [
    {
      "answer": "Norman",
      "score": 0.9938051700592041
    }
  ],
  "80": [
    {
      "answer": "high Byzantine officials",
      "score": 0.9953180551528931
    }
  ],
  "81": [
    {
      "answer": "Dyrrachium",
      "score": 0.9011750817298889
    },
    {
      "answer": "Dyrrachium",
      "score": 0.9020400643348694
    }
  ],
  "82": [
    {
      "answer": "King Ethelred II",
      "score": 0.9659382104873657
    }
  ],
  "83": [
    {
      "answer": "Duke Richard II",
      "score": 0.9834123849868774
    }
  ],
  "84": [
    {
      "answer": "Normandy",
      "score": 0.9606513977050781
    },
    {
      "answer": "Normandy",
      "score": 0.988906979560852
    },
    {
      "answer": "Normandy",
      "score": 0.9520754218101501
    },
    {
      "answer": "Normandy",
      "score": 0.9363179206848145
    }
  ],
  "85": [
    {
      "answer": "Sweyn Forkbeard",
      "score": 0.9972598552703857
    }
  ],
  "86": [
    {
      "answer": "Emma",
      "score": 0.9912660717964172
    },
    {
      "answer": "Emma",
      "score": 0.887242317199707
    }
  ],
  "87": [
    {
      "answer": "1013",
      "score": 0.9869377613067627
    }
  ],
  "88": [
    {
      "answer": "Normans",
      "score": 0.9644778966903687
    }
  ],
  "89": [
    {
      "answer": "Harthacnut",
      "score": 0.9935221076011658
    }
  ],
  "90": [
    {
      "answer": "1041",
      "score": 0.9942305088043213
    }
  ],
  "91": [
    {
      "answer": "Robert of Jumi\u00e8ges",
      "score": 0.995315670967102
    }
  ],
  "92": [
    {
      "answer": "1041",
      "score": 0.9887499809265137
    }
  ],
  "93": [
    {
      "answer": "English cavalry",
      "score": 0.991348147392273
    }
  ],
  "94": [
    {
      "answer": "Edward the Confessor",
      "score": 0.9378033876419067
    }
  ],
  "95": [
    {
      "answer": "England",
      "score": 0.7279418110847473
    },
    {
      "answer": "England",
      "score": 0.7591871619224548
    },
    {
      "answer": "England",
      "score": 0.7113950252532959
    },
    {
      "answer": "England",
      "score": 0.7762165665626526
    },
    {
      "answer": "England",
      "score": 0.6443628668785095
    }
  ],
  "96": [
    {
      "answer": "Duke William II",
      "score": 0.9865984320640564
    }
  ],
  "97": [
    {
      "answer": "1066",
      "score": 0.9744186997413635
    }
  ],
  "98": [
    {
      "answer": "Anglo-Saxons",
      "score": 0.9762070775032043
    }
  ],
  "99": [
    {
      "answer": "1066",
      "score": 0.9732294082641602
    }
  ],
  "100": [
    {
      "answer": "Battle of Hastings",
      "score": 0.9838091731071472
    }
  ],
  "101": [
    {
      "answer": "Normans",
      "score": 0.6494523286819458
    },
    {
      "answer": "Anglo-Saxons",
      "score": 0.9207640290260315
    }
  ],
  "102": [
    {
      "answer": "Norman kings",
      "score": 0.9638087749481201
    }
  ],
  "103": [
    {
      "answer": "absorbed into the Anglo-Saxon language",
      "score": 0.7191109657287598
    },
    {
      "answer": "Modern English",
      "score": 0.9175924062728882
    }
  ],
  "104": [
    {
      "answer": "Norman aristocracy",
      "score": 0.9810546636581421
    }
  ],
  "105": [
    {
      "answer": "Anglo-Saxon language",
      "score": 0.9487258791923523
    }
  ],
  "106": [
    {
      "answer": "Geoffrey Chaucer",
      "score": 0.9973776340484619
    }
  ],
  "107": [
    {
      "answer": "1169",
      "score": 0.986729085445404
    }
  ],
  "108": [
    {
      "answer": "Ireland",
      "score": 0.8417028784751892
    },
    {
      "answer": "Ireland",
      "score": 0.8756707310676575
    }
  ],
  "109": [
    {
      "answer": "Irish culture",
      "score": 0.7906565070152283
    },
    {
      "answer": "Irish culture",
      "score": 0.9278591275215149
    }
  ],
  "110": [
    {
      "answer": "Bannow Bay",
      "score": 0.9956575632095337
    }
  ],
  "111": [
    {
      "answer": "Normans",
      "score": 0.9799545407295227
    },
    {
      "answer": "Normans",
      "score": 0.829646646976471
    },
    {
      "answer": "Normans",
      "score": 0.8105638027191162
    }
  ],
  "112": [
    {
      "answer": "Trim Castle",
      "score": 0.972140908241272
    },
    {
      "answer": "Dublin Castle",
      "score": 0.9768173694610596
    }
  ],
  "113": [
    {
      "answer": "Edgar Atheling",
      "score": 0.9382250308990479
    },
    {
      "answer": "Edgar",
      "score": 0.56025630235672
    }
  ],
  "114": [
    {
      "answer": "Malcolm III",
      "score": 0.9878618121147156
    }
  ],
  "115": [
    {
      "answer": "1072",
      "score": 0.9946494698524475
    }
  ],
  "116": [
    {
      "answer": "Duncan",
      "score": 0.9939706325531006
    }
  ],
  "117": [
    {
      "answer": "Margaret",
      "score": 0.9755761027336121
    }
  ],
  "118": [
    {
      "answer": "William",
      "score": 0.8105905055999756
    },
    {
      "answer": "William",
      "score": 0.9873515367507935
    },
    {
      "answer": "William",
      "score": 0.7117776870727539
    }
  ],
  "119": [
    {
      "answer": "Duncan",
      "score": 0.9931465983390808
    }
  ],
  "120": [
    {
      "answer": "Sybilla of Normandy",
      "score": 0.9934386014938354
    }
  ],
  "121": [
    {
      "answer": "Norman",
      "score": 0.9823110103607178
    }
  ],
  "122": [
    {
      "answer": "Sybilla of Normandy",
      "score": 0.9330970644950867
    }
  ],
  "123": [
    {
      "answer": "Normans and Norman culture",
      "score": 0.7057642936706543
    }
  ],
  "124": [
    {
      "answer": "Hereford",
      "score": 0.9945158362388611
    }
  ],
  "125": [
    {
      "answer": "Welsh",
      "score": 0.9896715879440308
    }
  ],
  "126": [
    {
      "answer": "Edward the Confessor",
      "score": 0.9987992644309998
    }
  ],
  "127": [
    {
      "answer": "Normans",
      "score": 0.9563183188438416
    },
    {
      "answer": "Normans",
      "score": 0.8094606995582581
    }
  ],
  "128": [
    {
      "answer": "Edward the Confessor",
      "score": 0.9728816747665405
    }
  ],
  "129": [
    {
      "answer": "Wales",
      "score": 0.992391049861908
    }
  ],
  "130": [
    {
      "answer": "Marches",
      "score": 0.9804292917251587
    }
  ],
  "131": [
    {
      "answer": "Bernard de Neufmarch\u00e9",
      "score": 0.7790679335594177
    },
    {
      "answer": "Roger of Montgomery",
      "score": 0.8076688647270203
    },
    {
      "answer": "Hugh Lupus",
      "score": 0.8548184633255005
    }
  ],
  "132": [
    {
      "answer": "1018",
      "score": 0.9905568361282349
    }
  ],
  "133": [
    {
      "answer": "William of Montreuil",
      "score": 0.9961735010147095
    }
  ],
  "134": [
    {
      "answer": "Iberian Peninsula",
      "score": 0.902920126914978
    }
  ],
  "135": [
    {
      "answer": "Reconquista",
      "score": 0.9715340733528137
    }
  ],
  "136": [
    {
      "answer": "Roger de Tosny",
      "score": 0.9971019625663757
    }
  ],
  "137": [
    {
      "answer": "Reconquista",
      "score": 0.6263161301612854
    },
    {
      "answer": "War of Barbastro",
      "score": 0.8958775401115417
    }
  ],
  "138": [
    {
      "answer": "1097",
      "score": 0.9920207858085632
    }
  ],
  "139": [
    {
      "answer": "Tancred",
      "score": 0.9860073924064636
    },
    {
      "answer": "Tancred",
      "score": 0.8568347692489624
    }
  ],
  "140": [
    {
      "answer": "Jerusalem",
      "score": 0.9760620594024658
    }
  ],
  "141": [
    {
      "answer": "1097",
      "score": 0.987659752368927
    }
  ],
  "142": [
    {
      "answer": "Tancred",
      "score": 0.8283475637435913
    },
    {
      "answer": "Tancred",
      "score": 0.7321695685386658
    }
  ],
  "143": [
    {
      "answer": "380",
      "score": 0.9944673776626587
    }
  ],
  "144": [
    {
      "answer": "Cyprus",
      "score": 0.9747910499572754
    }
  ],
  "145": [
    {
      "answer": "Anglo-Norman",
      "score": 0.9835432767868042
    }
  ],
  "146": [
    {
      "answer": "a storm",
      "score": 0.991070032119751
    }
  ],
  "147": [
    {
      "answer": "Berengaria",
      "score": 0.9802163243293762
    }
  ],
  "148": [
    {
      "answer": "1191",
      "score": 0.9595017433166504
    },
    {
      "answer": "1191",
      "score": 0.9262613654136658
    }
  ],
  "149": [
    {
      "answer": "Isaac Komnenos",
      "score": 0.9960686564445496
    }
  ],
  "150": [
    {
      "answer": "Richard the Lion-hearted",
      "score": 0.9760910272598267
    }
  ],
  "151": [
    {
      "answer": "1191",
      "score": 0.9459238648414612
    },
    {
      "answer": "1191",
      "score": 0.9066348075866699
    }
  ],
  "152": [
    {
      "answer": "Isaac Komnenos",
      "score": 0.9941200017929077
    }
  ],
  "153": [
    {
      "answer": "Conrad of Montferrat",
      "score": 0.9978457689285278
    }
  ],
  "154": [
    {
      "answer": "silver",
      "score": 0.9934379458427429
    }
  ],
  "155": [
    {
      "answer": "Guy de Lusignan",
      "score": 0.9167160987854004
    },
    {
      "answer": "Guy de Lusignan",
      "score": 0.983162522315979
    }
  ],
  "156": [
    {
      "answer": "Isaac",
      "score": 0.7275711894035339
    }
  ],
  "157": [
    {
      "answer": "Guy de Lusignan",
      "score": 0.8190469741821289
    },
    {
      "answer": "Guy de Lusignan",
      "score": 0.8614380359649658
    }
  ],
  "158": [
    {
      "answer": "Guy de Lusignan",
      "score": 0.5906214118003845
    },
    {
      "answer": "Guy de Lusignan",
      "score": 0.6684349775314331
    }
  ],
  "159": [
    {
      "answer": "Africa",
      "score": 0.981058657169342
    }
  ],
  "160": [
    {
      "answer": "Jean de Bethencourt",
      "score": 0.9844412803649902
    }
  ],
  "161": [
    {
      "answer": "Lanzarote",
      "score": 0.7128669023513794
    },
    {
      "answer": "Fuerteventura",
      "score": 0.7019046545028687
    }
  ],
  "162": [
    {
      "answer": "Bethencourt",
      "score": 0.9411837458610535
    },
    {
      "answer": "Bethencourt",
      "score": 0.6875972151756287
    }
  ],
  "163": [
    {
      "answer": "Enrique P\u00e9rez de Guzm\u00e1n, 2nd Count de Niebla",
      "score": 0.9798052310943604
    }
  ],
  "164": [
    {
      "answer": "Maciot de Bethencourt",
      "score": 0.9704500436782837
    }
  ],
  "165": [
    {
      "answer": "King",
      "score": 0.973490297794342
    }
  ],
  "166": [
    {
      "answer": "Maciot de Bethencourt",
      "score": 0.9421460032463074
    }
  ],
  "167": [],
  "168": [
    {
      "answer": "two",
      "score": 0.9819951057434082
    },
    {
      "answer": "two",
      "score": 0.696865439414978
    }
  ],
  "169": [
    {
      "answer": "customary law of Normandy",
      "score": 0.8311618566513062
    }
  ],
  "170": [
    {
      "answer": "Normandy",
      "score": 0.8497586250305176
    },
    {
      "answer": "Normandy",
      "score": 0.5962976217269897
    }
  ],
  "171": [
    {
      "answer": "Tr\u00e8s ancien coutumier",
      "score": 0.9799070358276367
    }
  ],
  "172": [
    {
      "answer": "Romanesque",
      "score": 0.9068362712860107
    },
    {
      "answer": "rounded arches",
      "score": 0.612330973148346
    }
  ],
  "173": [
    {
      "answer": "rounded",
      "score": 0.9909045100212097
    }
  ],
  "174": [
    {
      "answer": "rounded arches",
      "score": 0.904259204864502
    }
  ],
  "175": [
    {
      "answer": "Anglo-Saxon",
      "score": 0.9198094606399536
    }
  ],
  "176": [
    {
      "answer": "Anglo-Saxon",
      "score": 0.967985212802887
    }
  ],
  "177": [
    {
      "answer": "southern Italy",
      "score": 0.7049807906150818
    },
    {
      "answer": "Kingdom of Sicily",
      "score": 0.8496949672698975
    }
  ],
  "178": [
    {
      "answer": "Norman",
      "score": 0.9711405038833618
    }
  ],
  "179": [
    {
      "answer": "Norman",
      "score": 0.9017410278320312
    }
  ],
  "180": [
    {
      "answer": "Normans",
      "score": 0.9876256585121155
    }
  ],
  "181": [
    {
      "answer": "early 11th century",
      "score": 0.9687576293945312
    }
  ],
  "182": [
    {
      "answer": "dukes",
      "score": 0.679996907711029
    },
    {
      "answer": "dukes",
      "score": 0.9254902005195618
    }
  ],
  "183": [],
  "184": [],
  "185": [
    {
      "answer": "Normans",
      "score": 0.7652532458305359
    }
  ],
  "186": [],
  "187": [
    {
      "answer": "16th century",
      "score": 0.9659336805343628
    }
  ],
  "188": [
    {
      "answer": "French Wars of Religion",
      "score": 0.8944875001907349
    },
    {
      "answer": "French Revolution",
      "score": 0.5813179016113281
    }
  ],
  "189": [],
  "190": [
    {
      "answer": "embroidery",
      "score": 0.988074004650116
    }
  ],
  "191": [
    {
      "answer": "Bayeux Tapestry",
      "score": 0.9933120012283325
    }
  ],
  "192": [
    {
      "answer": "Odo",
      "score": 0.9892420172691345
    }
  ],
  "193": [
    {
      "answer": "Bayeux Tapestry",
      "score": 0.9279528260231018
    }
  ],
  "194": [
    {
      "answer": "Odo",
      "score": 0.9873121976852417
    }
  ],
  "195": [
    {
      "answer": "mosaics",
      "score": 0.9795476198196411
    }
  ],
  "196": [
    {
      "answer": "stonework or metalwork",
      "score": 0.6886588335037231
    }
  ],
  "197": [
    {
      "answer": "sculptured",
      "score": 0.9330571293830872
    },
    {
      "answer": "mosaics",
      "score": 0.8031933903694153
    }
  ],
  "198": [
    {
      "answer": "Salerno",
      "score": 0.9891893863677979
    }
  ],
  "199": [
    {
      "answer": "11th",
      "score": 0.9880564212799072
    },
    {
      "answer": "11th century",
      "score": 0.9374105930328369
    }
  ],
  "200": [
    {
      "answer": "William of Volpiano",
      "score": 0.9863032698631287
    },
    {
      "answer": "John of Ravenna",
      "score": 0.980904757976532
    }
  ],
  "201": [
    {
      "answer": "several important developments in the history of classical music",
      "score": 0.7059421539306641
    },
    {
      "answer": "the system of denoting notes by letters",
      "score": 0.7438427805900574
    }
  ],
  "202": [
    {
      "answer": "musical production and education",
      "score": 0.956640362739563
    }
  ],
  "203": [
    {
      "answer": "southern Italy",
      "score": 0.9959018230438232
    }
  ],
  "204": [
    {
      "answer": "Sant'Eufemia",
      "score": 0.7564420700073242
    }
  ],
  "205": [
    {
      "answer": "Robert Guiscard",
      "score": 0.9973416924476624
    }
  ],
  "206": [
    {
      "answer": "singing",
      "score": 0.8714746236801147
    }
  ],
  "207": [
    {
      "answer": "Robert de Grantmesnil",
      "score": 0.9627379179000854
    }
  ],
  "208": [
    {
      "answer": "Computational complexity theory",
      "score": 0.9950761795043945
    }
  ],
  "209": [
    {
      "answer": "inherent difficulty",
      "score": 0.9846120476722717
    }
  ],
  "210": [
    {
      "answer": "computational problem",
      "score": 0.9385226964950562
    }
  ],
  "211": [
    {
      "answer": "amenable to being solved by a computer",
      "score": 0.9409917593002319
    }
  ],
  "212": [
    {
      "answer": "Computational complexity theory",
      "score": 0.9945873022079468
    }
  ],
  "213": [
    {
      "answer": "computational problems",
      "score": 0.5590530633926392
    },
    {
      "answer": "computational problem",
      "score": 0.8961078524589539
    }
  ],
  "214": [
    {
      "answer": "algorithm",
      "score": 0.9527981281280518
    }
  ],
  "215": [
    {
      "answer": "algorithm",
      "score": 0.9429514408111572
    }
  ],
  "216": [
    {
      "answer": "significant resources",
      "score": 0.6048982739448547
    },
    {
      "answer": "time",
      "score": 0.7856139540672302
    }
  ],
  "217": [
    {
      "answer": "mathematical models",
      "score": 0.8079937100410461
    }
  ],
  "218": [
    {
      "answer": "time",
      "score": 0.9948059916496277
    }
  ],
  "219": [
    {
      "answer": "time",
      "score": 0.6616989970207214
    },
    {
      "answer": "number of gates",
      "score": 0.8218274116516113
    }
  ],
  "220": [
    {
      "answer": "determine the practical limits on what computers can and cannot do",
      "score": 0.9552521705627441
    }
  ],
  "221": [
    {
      "answer": "time",
      "score": 0.8118113875389099
    }
  ],
  "222": [],
  "223": [
    {
      "answer": "time",
      "score": 0.9918795228004456
    }
  ],
  "224": [
    {
      "answer": "time",
      "score": 0.8883645534515381
    }
  ],
  "225": [],
  "226": [
    {
      "answer": "analysis of algorithms",
      "score": 0.9934078454971313
    },
    {
      "answer": "computability theory",
      "score": 0.967572808265686
    },
    {
      "answer": "analysis of algorithms",
      "score": 0.9827401638031006
    }
  ],
  "227": [
    {
      "answer": "analysis of algorithms",
      "score": 0.5871948003768921
    },
    {
      "answer": "analysis of algorithms",
      "score": 0.9717609286308289
    },
    {
      "answer": "computational complexity theory",
      "score": 0.6482922434806824
    }
  ],
  "228": [
    {
      "answer": "analysis of algorithms",
      "score": 0.936665952205658
    },
    {
      "answer": "computational complexity theory",
      "score": 0.8677014112472534
    }
  ],
  "229": [
    {
      "answer": "analysis of algorithms",
      "score": 0.6031227111816406
    },
    {
      "answer": "analysis of algorithms",
      "score": 0.932266116142273
    }
  ],
  "230": [
    {
      "answer": "analysis of algorithms",
      "score": 0.9919652938842773
    },
    {
      "answer": "computability theory",
      "score": 0.9575768113136292
    },
    {
      "answer": "analysis of algorithms",
      "score": 0.9754574298858643
    }
  ],
  "231": [
    {
      "answer": "the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem",
      "score": 0.9397554993629456
    }
  ],
  "232": [
    {
      "answer": "the former",
      "score": 0.7388733625411987
    }
  ],
  "233": [
    {
      "answer": "computational complexity theory",
      "score": 0.5708496570587158
    },
    {
      "answer": "the latter",
      "score": 0.8482503890991211
    }
  ],
  "234": [],
  "235": [
    {
      "answer": "problem instance",
      "score": 0.9823073148727417
    }
  ],
  "236": [
    {
      "answer": "problem",
      "score": 0.8717382550239563
    },
    {
      "answer": "problem",
      "score": 0.9081335067749023
    },
    {
      "answer": "problem",
      "score": 0.8309133052825928
    },
    {
      "answer": "problem",
      "score": 0.8443946838378906
    },
    {
      "answer": "problem",
      "score": 0.9202378988265991
    },
    {
      "answer": "problem",
      "score": 0.8811277747154236
    },
    {
      "answer": "problem",
      "score": 0.8579075336456299
    },
    {
      "answer": "problem",
      "score": 0.8956241011619568
    },
    {
      "answer": "problem",
      "score": 0.9181357622146606
    }
  ],
  "237": [
    {
      "answer": "concrete utterance",
      "score": 0.8677682876586914
    }
  ],
  "238": [
    {
      "answer": "problem instance",
      "score": 0.9085550904273987
    }
  ],
  "239": [
    {
      "answer": "solution",
      "score": 0.8181867003440857
    },
    {
      "answer": "solution",
      "score": 0.9697750210762024
    }
  ],
  "240": [
    {
      "answer": "computational problem",
      "score": 0.9864234924316406
    }
  ],
  "241": [
    {
      "answer": "problem instance",
      "score": 0.9815529584884644
    }
  ],
  "242": [
    {
      "answer": "problem",
      "score": 0.7092800140380859
    },
    {
      "answer": "problem",
      "score": 0.7806968688964844
    },
    {
      "answer": "problem",
      "score": 0.5678464770317078
    },
    {
      "answer": "problem",
      "score": 0.59424889087677
    },
    {
      "answer": "problem",
      "score": 0.5711247324943542
    },
    {
      "answer": "problem",
      "score": 0.743459165096283
    },
    {
      "answer": "problem",
      "score": 0.7791553735733032
    },
    {
      "answer": "problem",
      "score": 0.7426837086677551
    },
    {
      "answer": "problem",
      "score": 0.8316755294799805
    }
  ],
  "243": [
    {
      "answer": "solution",
      "score": 0.6224212646484375
    },
    {
      "answer": "solution",
      "score": 0.9508929252624512
    }
  ],
  "244": [
    {
      "answer": "instance",
      "score": 0.5266508460044861
    },
    {
      "answer": "instance",
      "score": 0.5961675047874451
    },
    {
      "answer": "instance",
      "score": 0.684624433517456
    },
    {
      "answer": "instance",
      "score": 0.5371752977371216
    },
    {
      "answer": "instance",
      "score": 0.7995607256889343
    }
  ],
  "245": [
    {
      "answer": "2000 kilometres",
      "score": 0.9329643249511719
    }
  ],
  "246": [],
  "247": [
    {
      "answer": "computational problems",
      "score": 0.9796888828277588
    }
  ],
  "248": [],
  "249": [],
  "250": [],
  "251": [
    {
      "answer": "computational problems",
      "score": 0.960950493812561
    }
  ],
  "252": [
    {
      "answer": "problem instance",
      "score": 0.9865661263465881
    }
  ],
  "253": [
    {
      "answer": "binary alphabet",
      "score": 0.9731190800666809
    }
  ],
  "254": [
    {
      "answer": "bitstrings",
      "score": 0.6495335698127747
    }
  ],
  "255": [
    {
      "answer": "binary notation",
      "score": 0.9085274934768677
    }
  ],
  "256": [
    {
      "answer": "adjacency matrices",
      "score": 0.8256950378417969
    },
    {
      "answer": "encoding their adjacency lists in binary",
      "score": 0.711174488067627
    }
  ],
  "257": [
    {
      "answer": "alphabet",
      "score": 0.892504870891571
    }
  ],
  "258": [
    {
      "answer": "binary alphabet",
      "score": 0.9478802680969238
    }
  ],
  "259": [
    {
      "answer": "bitstrings",
      "score": 0.6051761507987976
    },
    {
      "answer": "bitstrings",
      "score": 0.5316575765609741
    }
  ],
  "260": [
    {
      "answer": "integers",
      "score": 0.9728394746780396
    }
  ],
  "261": [
    {
      "answer": "adjacency matrices",
      "score": 0.8958160877227783
    }
  ],
  "262": [
    {
      "answer": "Decision problems",
      "score": 0.9785957336425781
    },
    {
      "answer": "decision problem",
      "score": 0.7240101099014282
    },
    {
      "answer": "decision problem",
      "score": 0.7158322334289551
    }
  ],
  "263": [
    {
      "answer": "answer",
      "score": 0.8328915238380432
    },
    {
      "answer": "yes",
      "score": 0.9125232100486755
    },
    {
      "answer": "no",
      "score": 0.9595543146133423
    },
    {
      "answer": "yes",
      "score": 0.7840040922164917
    },
    {
      "answer": "no",
      "score": 0.8163602948188782
    },
    {
      "answer": "answer",
      "score": 0.6999353766441345
    },
    {
      "answer": "yes",
      "score": 0.730029821395874
    }
  ],
  "264": [
    {
      "answer": "1",
      "score": 0.9633673429489136
    },
    {
      "answer": "0",
      "score": 0.9488853812217712
    }
  ],
  "265": [
    {
      "answer": "yes",
      "score": 0.8079124093055725
    },
    {
      "answer": "yes",
      "score": 0.9819969534873962
    },
    {
      "answer": "yes",
      "score": 0.7588422298431396
    }
  ],
  "266": [
    {
      "answer": "yes",
      "score": 0.7927191257476807
    },
    {
      "answer": "yes",
      "score": 0.7946268916130066
    },
    {
      "answer": "yes",
      "score": 0.9921276569366455
    }
  ],
  "267": [
    {
      "answer": "Decision problems",
      "score": 0.981738805770874
    },
    {
      "answer": "decision problem",
      "score": 0.8177943229675293
    },
    {
      "answer": "decision problem",
      "score": 0.8072460889816284
    }
  ],
  "268": [
    {
      "answer": "decision problem",
      "score": 0.9710581302642822
    },
    {
      "answer": "decision problem",
      "score": 0.950196385383606
    }
  ],
  "269": [
    {
      "answer": "decision problem",
      "score": 0.8971882462501526
    },
    {
      "answer": "decision problem",
      "score": 0.9741233587265015
    }
  ],
  "270": [
    {
      "answer": "1",
      "score": 0.9521130323410034
    },
    {
      "answer": "0",
      "score": 0.9344884157180786
    }
  ],
  "271": [
    {
      "answer": "yes",
      "score": 0.7899896502494812
    },
    {
      "answer": "yes",
      "score": 0.7429513335227966
    },
    {
      "answer": "yes",
      "score": 0.9891449809074402
    }
  ],
  "272": [
    {
      "answer": "arbitrary graph",
      "score": 0.9696693420410156
    }
  ],
  "273": [
    {
      "answer": "formal language",
      "score": 0.9768019318580627
    }
  ],
  "274": [
    {
      "answer": "how graphs are encoded as binary strings",
      "score": 0.9032708406448364
    }
  ],
  "275": [
    {
      "answer": "arbitrary graph",
      "score": 0.9358227252960205
    }
  ],
  "276": [
    {
      "answer": "formal language",
      "score": 0.9708734750747681
    }
  ],
  "277": [
    {
      "answer": "how graphs are encoded as binary strings",
      "score": 0.9019128680229187
    }
  ],
  "278": [
    {
      "answer": "one has to decide how graphs are encoded as binary strings",
      "score": 0.9335474967956543
    }
  ],
  "279": [
    {
      "answer": "computational problem",
      "score": 0.8502202033996582
    }
  ],
  "280": [
    {
      "answer": "single",
      "score": 0.9898978471755981
    }
  ],
  "281": [
    {
      "answer": "function",
      "score": 0.9823154807090759
    }
  ],
  "282": [
    {
      "answer": "integer factorization problem",
      "score": 0.9874283075332642
    }
  ],
  "283": [
    {
      "answer": "more complex",
      "score": 0.9471672773361206
    }
  ],
  "284": [
    {
      "answer": "function problem",
      "score": 0.9634113311767578
    }
  ],
  "285": [
    {
      "answer": "single output",
      "score": 0.7784751653671265
    }
  ],
  "286": [
    {
      "answer": "traveling salesman problem",
      "score": 0.8910374641418457
    },
    {
      "answer": "integer factorization problem",
      "score": 0.7332022190093994
    }
  ],
  "287": [
    {
      "answer": "traveling salesman problem",
      "score": 0.9739106893539429
    },
    {
      "answer": "integer factorization problem",
      "score": 0.9475461840629578
    }
  ],
  "288": [
    {
      "answer": "more complex",
      "score": 0.9223950505256653
    }
  ],
  "289": [
    {
      "answer": "decision problems",
      "score": 0.9779990911483765
    }
  ],
  "290": [
    {
      "answer": "triples (a, b, c)",
      "score": 0.74684739112854
    }
  ],
  "291": [
    {
      "answer": "function problems",
      "score": 0.8490664958953857
    }
  ],
  "292": [
    {
      "answer": "set of triples (a, b, c)",
      "score": 0.8684232831001282
    }
  ],
  "293": [
    {
      "answer": "Deciding whether a given triple is a member of this set",
      "score": 0.9535188674926758
    }
  ],
  "294": [
    {
      "answer": "size of the input in bits",
      "score": 0.8537898063659668
    }
  ],
  "295": [
    {
      "answer": "instance",
      "score": 0.9810017943382263
    },
    {
      "answer": "instance",
      "score": 0.5956168174743652
    }
  ],
  "296": [],
  "297": [
    {
      "answer": "bits",
      "score": 0.9902055859565735
    }
  ],
  "298": [
    {
      "answer": "input size",
      "score": 0.9653639197349548
    }
  ],
  "299": [
    {
      "answer": "how much time the best algorithm requires to solve the problem",
      "score": 0.7114612460136414
    }
  ],
  "300": [
    {
      "answer": "instance",
      "score": 0.9259185194969177
    }
  ],
  "301": [],
  "302": [
    {
      "answer": "Complexity theory",
      "score": 0.9936995506286621
    }
  ],
  "303": [
    {
      "answer": "a function of the size of the instance",
      "score": 0.9395701289176941
    }
  ],
  "304": [
    {
      "answer": "Cobham",
      "score": 0.9949583411216736
    }
  ],
  "305": [
    {
      "answer": "time taken",
      "score": 0.6861192584037781
    }
  ],
  "306": [
    {
      "answer": "worst-case time complexity",
      "score": 0.9292833805084229
    }
  ],
  "307": [],
  "308": [],
  "309": [
    {
      "answer": "polynomial",
      "score": 0.6598934531211853
    }
  ],
  "310": [
    {
      "answer": "Cobham",
      "score": 0.9923321008682251
    }
  ],
  "311": [],
  "312": [],
  "313": [],
  "314": [
    {
      "answer": "Turing machine",
      "score": 0.9468480348587036
    },
    {
      "answer": "Turing machine",
      "score": 0.8739383220672607
    },
    {
      "answer": "Turing machine",
      "score": 0.8708983659744263
    },
    {
      "answer": "Turing machine",
      "score": 0.875731348991394
    }
  ],
  "315": [
    {
      "answer": "algorithm",
      "score": 0.9681413769721985
    }
  ],
  "316": [
    {
      "answer": "Turing machine",
      "score": 0.9293926954269409
    },
    {
      "answer": "Turing machine",
      "score": 0.873966634273529
    },
    {
      "answer": "Turing machine",
      "score": 0.914543092250824
    },
    {
      "answer": "Turing machine",
      "score": 0.9627999663352966
    }
  ],
  "317": [
    {
      "answer": "symbols",
      "score": 0.9828417301177979
    }
  ],
  "318": [
    {
      "answer": "Turing machine",
      "score": 0.9640505313873291
    },
    {
      "answer": "Turing machine",
      "score": 0.8740803003311157
    },
    {
      "answer": "Turing machine",
      "score": 0.896316409111023
    },
    {
      "answer": "Turing machine",
      "score": 0.9043575525283813
    }
  ],
  "319": [
    {
      "answer": "Turing machine",
      "score": 0.9703842401504517
    },
    {
      "answer": "Turing machine",
      "score": 0.9012163281440735
    },
    {
      "answer": "Turing machine",
      "score": 0.9071944952011108
    },
    {
      "answer": "Turing machine",
      "score": 0.9015982747077942
    }
  ],
  "320": [
    {
      "answer": "Turing machines",
      "score": 0.7181365489959717
    },
    {
      "answer": "Turing machine",
      "score": 0.581863522529602
    }
  ],
  "321": [
    {
      "answer": "Turing machine",
      "score": 0.7516641616821289
    },
    {
      "answer": "Turing machine",
      "score": 0.9649269580841064
    },
    {
      "answer": "Turing machine",
      "score": 0.8199273347854614
    },
    {
      "answer": "Turing machine",
      "score": 0.8039848804473877
    }
  ],
  "322": [
    {
      "answer": "deterministic",
      "score": 0.9872897267341614
    }
  ],
  "323": [
    {
      "answer": "rules",
      "score": 0.9527356624603271
    }
  ],
  "324": [
    {
      "answer": "probabilistic Turing machine",
      "score": 0.950403094291687
    }
  ],
  "325": [
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.9838685989379883
    }
  ],
  "326": [
    {
      "answer": "randomized algorithms",
      "score": 0.9662739038467407
    }
  ],
  "327": [
    {
      "answer": "deterministic Turing machine",
      "score": 0.7789546847343445
    }
  ],
  "328": [
    {
      "answer": "probabilistic Turing machine",
      "score": 0.9626889228820801
    }
  ],
  "329": [
    {
      "answer": "probabilistic decisions",
      "score": 0.9160770773887634
    }
  ],
  "330": [
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.9750649929046631
    }
  ],
  "331": [
    {
      "answer": "that the Turing machine branches into many possible computational paths at each step, and if it solves the problem in any of these branches, it is said to have solved the problem",
      "score": 0.9146474003791809
    }
  ],
  "332": [
    {
      "answer": "complexity classes",
      "score": 0.9732793569564819
    },
    {
      "answer": "deterministic Turing machines",
      "score": 0.5846648216247559
    },
    {
      "answer": "probabilistic Turing machines",
      "score": 0.5326017737388611
    },
    {
      "answer": "non-deterministic Turing machines",
      "score": 0.578392744064331
    },
    {
      "answer": "quantum Turing machines",
      "score": 0.5353289842605591
    }
  ],
  "333": [
    {
      "answer": "time or space",
      "score": 0.8878829479217529
    }
  ],
  "334": [
    {
      "answer": "deterministic Turing machines",
      "score": 0.9451985359191895
    },
    {
      "answer": "probabilistic Turing machines",
      "score": 0.8934943675994873
    },
    {
      "answer": "non-deterministic Turing machines",
      "score": 0.8870627284049988
    },
    {
      "answer": "quantum Turing machines",
      "score": 0.8350879549980164
    },
    {
      "answer": "symmetric Turing machines",
      "score": 0.8123677968978882
    },
    {
      "answer": "alternating Turing machines",
      "score": 0.7171787023544312
    }
  ],
  "335": [
    {
      "answer": "complexity classes",
      "score": 0.8720038533210754
    },
    {
      "answer": "deterministic Turing machines",
      "score": 0.6620013117790222
    },
    {
      "answer": "probabilistic Turing machines",
      "score": 0.6307637095451355
    },
    {
      "answer": "non-deterministic Turing machines",
      "score": 0.6745271682739258
    },
    {
      "answer": "quantum Turing machines",
      "score": 0.6717495918273926
    },
    {
      "answer": "symmetric Turing machines",
      "score": 0.598874032497406
    },
    {
      "answer": "alternating Turing machines",
      "score": 0.6053783297538757
    }
  ],
  "336": [
    {
      "answer": "time or space",
      "score": 0.8770505785942078
    }
  ],
  "337": [
    {
      "answer": "deterministic Turing machines",
      "score": 0.9268798232078552
    },
    {
      "answer": "probabilistic Turing machines",
      "score": 0.884376049041748
    },
    {
      "answer": "non-deterministic Turing machines",
      "score": 0.9301590919494629
    },
    {
      "answer": "quantum Turing machines",
      "score": 0.9378003478050232
    },
    {
      "answer": "symmetric Turing machines",
      "score": 0.9436972141265869
    },
    {
      "answer": "alternating Turing machines",
      "score": 0.9539004564285278
    }
  ],
  "338": [
    {
      "answer": "Turing machines",
      "score": 0.6291047930717468
    },
    {
      "answer": "Turing machines",
      "score": 0.6039783954620361
    },
    {
      "answer": "Turing machines",
      "score": 0.5695890188217163
    },
    {
      "answer": "Turing machines",
      "score": 0.5936576128005981
    },
    {
      "answer": "Turing machines",
      "score": 0.6866370439529419
    }
  ],
  "339": [
    {
      "answer": "random access machines",
      "score": 0.994422435760498
    }
  ],
  "340": [
    {
      "answer": "computational power",
      "score": 0.965103268623352
    }
  ],
  "341": [
    {
      "answer": "time",
      "score": 0.9832472205162048
    },
    {
      "answer": "memory",
      "score": 0.981549859046936
    }
  ],
  "342": [
    {
      "answer": "the machines operate deterministically",
      "score": 0.812069833278656
    }
  ],
  "343": [
    {
      "answer": "random access machines",
      "score": 0.989134669303894
    }
  ],
  "344": [
    {
      "answer": "time",
      "score": 0.974259614944458
    }
  ],
  "345": [
    {
      "answer": "time",
      "score": 0.9838986992835999
    },
    {
      "answer": "memory",
      "score": 0.9813982844352722
    }
  ],
  "346": [
    {
      "answer": "operate deterministically",
      "score": 0.9086005687713623
    }
  ],
  "347": [
    {
      "answer": "non-deterministic",
      "score": 0.9843310713768005
    },
    {
      "answer": "non-deterministic",
      "score": 0.6401991844177246
    }
  ],
  "348": [
    {
      "answer": "non-deterministic time",
      "score": 0.9480572938919067
    }
  ],
  "349": [
    {
      "answer": "non-deterministic time",
      "score": 0.9337104558944702
    }
  ],
  "350": [
    {
      "answer": "non-deterministic time",
      "score": 0.9893628358840942
    }
  ],
  "351": [
    {
      "answer": "computational problems",
      "score": 0.5785009264945984
    },
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.66484534740448
    },
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.6498255729675293
    }
  ],
  "352": [
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.9434924125671387
    },
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.805370032787323
    }
  ],
  "353": [
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.7021609544754028
    },
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.9606322050094604
    }
  ],
  "354": [
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.7950299978256226
    },
    {
      "answer": "non-deterministic Turing machine",
      "score": 0.8737048506736755
    }
  ],
  "355": [
    {
      "answer": "non-deterministic time",
      "score": 0.9703218936920166
    }
  ],
  "356": [
    {
      "answer": "the total number of state transitions, or steps, the machine makes before it halts and outputs the answer (\"yes\" or \"no\")",
      "score": 0.6999790668487549
    }
  ],
  "357": [
    {
      "answer": "difficulty",
      "score": 0.9961259961128235
    }
  ],
  "358": [
    {
      "answer": "DTIME",
      "score": 0.9707226157188416
    }
  ],
  "359": [
    {
      "answer": "time",
      "score": 0.7054976224899292
    },
    {
      "answer": "time",
      "score": 0.7343254685401917
    },
    {
      "answer": "time",
      "score": 0.6180517077445984
    },
    {
      "answer": "time",
      "score": 0.6286293864250183
    },
    {
      "answer": "time",
      "score": 0.5117462873458862
    },
    {
      "answer": "time",
      "score": 0.6000756621360779
    }
  ],
  "360": [
    {
      "answer": "deterministic Turing machine",
      "score": 0.8321722745895386
    },
    {
      "answer": "deterministic Turing machine",
      "score": 0.7315529584884644
    },
    {
      "answer": "deterministic Turing machine",
      "score": 0.8272048830986023
    }
  ],
  "361": [
    {
      "answer": "within time f(n)",
      "score": 0.9225263595581055
    }
  ],
  "362": [
    {
      "answer": "DTIME",
      "score": 0.9647728204727173
    }
  ],
  "363": [
    {
      "answer": "time",
      "score": 0.6655954122543335
    },
    {
      "answer": "time",
      "score": 0.7730472087860107
    },
    {
      "answer": "time",
      "score": 0.6656376719474792
    },
    {
      "answer": "time",
      "score": 0.6859343647956848
    },
    {
      "answer": "time",
      "score": 0.5656462907791138
    },
    {
      "answer": "time",
      "score": 0.6530690789222717
    }
  ],
  "364": [
    {
      "answer": "there exists a Turing machine operating in time f(n) that solves the problem",
      "score": 0.9704138040542603
    }
  ],
  "365": [
    {
      "answer": "complexity",
      "score": 0.890948474407196
    }
  ],
  "366": [],
  "367": [
    {
      "answer": "Blum complexity axioms",
      "score": 0.9842356443405151
    }
  ],
  "368": [
    {
      "answer": "complexity",
      "score": 0.8797925114631653
    }
  ],
  "369": [
    {
      "answer": "complexity",
      "score": 0.9678032398223877
    }
  ],
  "370": [
    {
      "answer": "Analogous definitions",
      "score": 0.9119267463684082
    }
  ],
  "371": [
    {
      "answer": "space",
      "score": 0.9296528100967407
    }
  ],
  "372": [
    {
      "answer": "Blum complexity axioms",
      "score": 0.9812614321708679
    }
  ],
  "373": [
    {
      "answer": "communication complexity",
      "score": 0.9634253978729248
    },
    {
      "answer": "circuit complexity",
      "score": 0.9415470361709595
    },
    {
      "answer": "decision tree complexity",
      "score": 0.9599573016166687
    }
  ],
  "374": [],
  "375": [
    {
      "answer": "best",
      "score": 0.9581683874130249
    },
    {
      "answer": "worst",
      "score": 0.9531304836273193
    },
    {
      "answer": "average",
      "score": 0.9165636897087097
    }
  ],
  "376": [],
  "377": [
    {
      "answer": "average case complexity",
      "score": 0.8203198313713074
    }
  ],
  "378": [
    {
      "answer": "time complexity",
      "score": 0.5492749214172363
    }
  ],
  "379": [
    {
      "answer": "best",
      "score": 0.9343720078468323
    },
    {
      "answer": "worst",
      "score": 0.9353880882263184
    },
    {
      "answer": "average",
      "score": 0.8891654014587402
    }
  ],
  "380": [
    {
      "answer": "best, worst and average case complexity",
      "score": 0.9804536700248718
    }
  ],
  "381": [
    {
      "answer": "average case complexity",
      "score": 0.8613988757133484
    }
  ],
  "382": [
    {
      "answer": "time",
      "score": 0.9548822641372681
    }
  ],
  "383": [
    {
      "answer": "quicksort",
      "score": 0.9928265810012817
    }
  ],
  "384": [
    {
      "answer": "O(n2)",
      "score": 0.8452701568603516
    }
  ],
  "385": [
    {
      "answer": "O(n2)",
      "score": 0.9642969369888306
    }
  ],
  "386": [
    {
      "answer": "quicksort",
      "score": 0.8897483348846436
    }
  ],
  "387": [
    {
      "answer": "solves the problem of sorting a list of integers",
      "score": 0.9674618244171143
    }
  ],
  "388": [
    {
      "answer": "O(n2)",
      "score": 0.8555153012275696
    },
    {
      "answer": "O(n log n)",
      "score": 0.5693800449371338
    }
  ],
  "389": [
    {
      "answer": "O(n2)",
      "score": 0.9204931855201721
    }
  ],
  "390": [
    {
      "answer": "best",
      "score": 0.926209568977356
    }
  ],
  "391": [
    {
      "answer": "most efficient algorithm",
      "score": 0.9690257906913757
    }
  ],
  "392": [
    {
      "answer": "algorithms",
      "score": 0.962063193321228
    }
  ],
  "393": [
    {
      "answer": "lower bounds",
      "score": 0.9556035995483398
    }
  ],
  "394": [],
  "395": [
    {
      "answer": "all possible algorithms",
      "score": 0.9660267233848572
    }
  ],
  "396": [],
  "397": [
    {
      "answer": "worst-case",
      "score": 0.9932010769844055
    }
  ],
  "398": [],
  "399": [
    {
      "answer": "To show a lower bound of T(n) for a problem requires showing that no algorithm can have time complexity lower than T(n)",
      "score": 0.6693962216377258
    }
  ],
  "400": [],
  "401": [
    {
      "answer": "big O notation",
      "score": 0.988656759262085
    },
    {
      "answer": "big O notation",
      "score": 0.7998654842376709
    }
  ],
  "402": [
    {
      "answer": "constant factors",
      "score": 0.9929631948471069
    }
  ],
  "403": [
    {
      "answer": "O(n2)",
      "score": 0.9780528545379639
    }
  ],
  "404": [
    {
      "answer": "computational model",
      "score": 0.9852989912033081
    }
  ],
  "405": [
    {
      "answer": "Upper and lower bounds",
      "score": 0.9715873599052429
    }
  ],
  "406": [
    {
      "answer": "big O notation",
      "score": 0.9909667372703552
    },
    {
      "answer": "big O notation",
      "score": 0.8492215871810913
    }
  ],
  "407": [
    {
      "answer": "big O notation",
      "score": 0.9900003671646118
    },
    {
      "answer": "big O notation",
      "score": 0.6153399348258972
    }
  ],
  "408": [
    {
      "answer": "O(n2)",
      "score": 0.9165229797363281
    }
  ],
  "409": [
    {
      "answer": "complexity classes",
      "score": 0.9868514537811279
    }
  ],
  "410": [],
  "411": [],
  "412": [],
  "413": [
    {
      "answer": "complexity classes",
      "score": 0.9731168746948242
    }
  ],
  "414": [
    {
      "answer": "framework",
      "score": 0.8880848288536072
    }
  ],
  "415": [],
  "416": [
    {
      "answer": "machine model",
      "score": 0.9862164258956909
    }
  ],
  "417": [
    {
      "answer": "quadratic time",
      "score": 0.9644497036933899
    }
  ],
  "418": [
    {
      "answer": "single-tape Turing machines",
      "score": 0.7571448683738708
    }
  ],
  "419": [
    {
      "answer": "Cobham-Edmonds",
      "score": 0.9936898946762085
    }
  ],
  "420": [
    {
      "answer": "P",
      "score": 0.9914293885231018
    }
  ],
  "421": [
    {
      "answer": "bounding the computation time",
      "score": 0.9407030344009399
    }
  ],
  "422": [
    {
      "answer": "function f(n)",
      "score": 0.7402915954589844
    }
  ],
  "423": [
    {
      "answer": "the language {xx | x is any binary string}",
      "score": 0.8146042823791504
    }
  ],
  "424": [
    {
      "answer": "quadratic time",
      "score": 0.598624587059021
    }
  ],
  "425": [
    {
      "answer": "Cobham-Edmonds",
      "score": 0.9872698783874512
    }
  ],
  "426": [
    {
      "answer": "time",
      "score": 0.9806016683578491
    },
    {
      "answer": "space",
      "score": 0.9731540083885193
    }
  ],
  "427": [
    {
      "answer": "bounding",
      "score": 0.8779197931289673
    }
  ],
  "428": [
    {
      "answer": "complexity classes",
      "score": 0.9333622455596924
    }
  ],
  "429": [
    {
      "answer": "complexity classes",
      "score": 0.777616024017334
    }
  ],
  "430": [
    {
      "answer": "time",
      "score": 0.9710964560508728
    },
    {
      "answer": "space",
      "score": 0.9641432166099548
    }
  ],
  "431": [
    {
      "answer": "bounding the time or space",
      "score": 0.7106755375862122
    }
  ],
  "432": [
    {
      "answer": "time",
      "score": 0.9649975895881653
    }
  ],
  "433": [
    {
      "answer": "BPP",
      "score": 0.9582940340042114
    },
    {
      "answer": "ZPP and RP",
      "score": 0.8037256002426147
    }
  ],
  "434": [
    {
      "answer": "Boolean circuits",
      "score": 0.959700345993042
    }
  ],
  "435": [
    {
      "answer": "quantum",
      "score": 0.9887730479240417
    }
  ],
  "436": [
    {
      "answer": "#P",
      "score": 0.9476194381713867
    }
  ],
  "437": [
    {
      "answer": "Interactive",
      "score": 0.9973245859146118
    }
  ],
  "438": [
    {
      "answer": "BPP, ZPP and RP",
      "score": 0.9830093383789062
    },
    {
      "answer": "AC and NC",
      "score": 0.9724768400192261
    },
    {
      "answer": "BQP and QMA",
      "score": 0.9722548723220825
    }
  ],
  "439": [
    {
      "answer": "probabilistic Turing machines",
      "score": 0.9599361419677734
    }
  ],
  "440": [
    {
      "answer": "probabilistic Turing machines",
      "score": 0.6142226457595825
    },
    {
      "answer": "quantum Turing machines",
      "score": 0.9285266399383545
    }
  ],
  "441": [
    {
      "answer": "#P",
      "score": 0.9739025831222534
    }
  ],
  "442": [
    {
      "answer": "Interactive proof systems",
      "score": 0.9550161361694336
    }
  ],
  "443": [
    {
      "answer": "computation time",
      "score": 0.9623006582260132
    }
  ],
  "444": [],
  "445": [
    {
      "answer": "time and space hierarchy theorems",
      "score": 0.9856948256492615
    }
  ],
  "446": [
    {
      "answer": "a proper hierarchy",
      "score": 0.7293816804885864
    }
  ],
  "447": [
    {
      "answer": "hierarchy theorems",
      "score": 0.8009862303733826
    }
  ],
  "448": [
    {
      "answer": "computation time",
      "score": 0.640404462814331
    }
  ],
  "449": [
    {
      "answer": "computation time",
      "score": 0.9164215326309204
    }
  ],
  "450": [],
  "451": [
    {
      "answer": "hierarchy theorems",
      "score": 0.7068890929222107
    },
    {
      "answer": "hierarchy theorems",
      "score": 0.7758334875106812
    }
  ],
  "452": [
    {
      "answer": "hierarchy theorems",
      "score": 0.7861366271972656
    }
  ],
  "453": [
    {
      "answer": "time and space hierarchy theorems",
      "score": 0.9701531529426575
    },
    {
      "answer": "time hierarchy theorem",
      "score": 0.5800883769989014
    }
  ],
  "454": [
    {
      "answer": "time hierarchy theorem",
      "score": 0.7981857657432556
    },
    {
      "answer": "space hierarchy theorem",
      "score": 0.8167640566825867
    }
  ],
  "455": [
    {
      "answer": "PSPACE",
      "score": 0.9820324778556824
    }
  ],
  "456": [
    {
      "answer": "time and space hierarchy theorems",
      "score": 0.7768678069114685
    }
  ],
  "457": [
    {
      "answer": "separation results of complexity classes",
      "score": 0.9645307660102844
    }
  ],
  "458": [
    {
      "answer": "P",
      "score": 0.9538445472717285
    }
  ],
  "459": [
    {
      "answer": "L",
      "score": 0.972505509853363
    }
  ],
  "460": [
    {
      "answer": "reduction",
      "score": 0.9765239357948303
    }
  ],
  "461": [
    {
      "answer": "another problem",
      "score": 0.9707496166229248
    }
  ],
  "462": [],
  "463": [
    {
      "answer": "Cook reductions",
      "score": 0.9877580404281616
    },
    {
      "answer": "Karp reductions",
      "score": 0.9817970395088196
    },
    {
      "answer": "Levin reductions",
      "score": 0.9736415147781372
    }
  ],
  "464": [
    {
      "answer": "bound on the complexity of reductions",
      "score": 0.6378607749938965
    },
    {
      "answer": "log-space reductions",
      "score": 0.5823819637298584
    }
  ],
  "465": [
    {
      "answer": "reduction",
      "score": 0.9509443044662476
    }
  ],
  "466": [
    {
      "answer": "complexity classes",
      "score": 0.7552657127380371
    }
  ],
  "467": [
    {
      "answer": "reduction",
      "score": 0.6363070011138916
    },
    {
      "answer": "reduction",
      "score": 0.8046359419822693
    }
  ],
  "468": [
    {
      "answer": "reduction",
      "score": 0.915367066860199
    },
    {
      "answer": "reduction",
      "score": 0.8949446678161621
    }
  ],
  "469": [
    {
      "answer": "Cook reductions",
      "score": 0.9896199703216553
    },
    {
      "answer": "Karp reductions",
      "score": 0.9866406321525574
    },
    {
      "answer": "Levin reductions",
      "score": 0.9795486927032471
    }
  ],
  "470": [
    {
      "answer": "polynomial-time reduction",
      "score": 0.9903450012207031
    }
  ],
  "471": [
    {
      "answer": "multiplying two integers",
      "score": 0.712421178817749
    },
    {
      "answer": "multiplication",
      "score": 0.6499479413032532
    }
  ],
  "472": [
    {
      "answer": "polynomial time",
      "score": 0.9313701391220093
    }
  ],
  "473": [
    {
      "answer": "same input",
      "score": 0.881501317024231
    }
  ],
  "474": [
    {
      "answer": "multiplying",
      "score": 0.9023803472518921
    },
    {
      "answer": "multiplication",
      "score": 0.5838435888290405
    }
  ],
  "475": [
    {
      "answer": "polynomial-time reduction",
      "score": 0.9547132253646851
    }
  ],
  "476": [
    {
      "answer": "the reduction process takes polynomial time",
      "score": 0.9441196322441101
    }
  ],
  "477": [
    {
      "answer": "multiplying two integers",
      "score": 0.9478785395622253
    }
  ],
  "478": [],
  "479": [
    {
      "answer": "squaring",
      "score": 0.5501972436904907
    },
    {
      "answer": "squaring",
      "score": 0.9466651082038879
    }
  ],
  "480": [
    {
      "answer": "type of reduction",
      "score": 0.8013133406639099
    },
    {
      "answer": "polynomial-time reductions",
      "score": 0.643372654914856
    }
  ],
  "481": [],
  "482": [
    {
      "answer": "solve any problem in C",
      "score": 0.9487310647964478
    }
  ],
  "483": [
    {
      "answer": "every problem in C can be reduced to X",
      "score": 0.7461122870445251
    }
  ],
  "484": [],
  "485": [
    {
      "answer": "no problem in C is harder than X",
      "score": 0.8142255544662476
    }
  ],
  "486": [
    {
      "answer": "no",
      "score": 0.9158486127853394
    }
  ],
  "487": [
    {
      "answer": "NP-hard problems",
      "score": 0.9055799245834351
    }
  ],
  "488": [
    {
      "answer": "NP-complete problems",
      "score": 0.9465495347976685
    }
  ],
  "489": [],
  "490": [
    {
      "answer": "no known polynomial-time solution for \u03a01",
      "score": 0.9288604259490967
    }
  ],
  "491": [
    {
      "answer": "P = NP",
      "score": 0.8623062968254089
    }
  ],
  "492": [
    {
      "answer": "X is said to be complete for C",
      "score": 0.9520220756530762
    }
  ],
  "493": [],
  "494": [
    {
      "answer": "NP-complete problems",
      "score": 0.9798724055290222
    }
  ],
  "495": [
    {
      "answer": "being able to reduce a known NP-complete problem, \u03a02, to another problem, \u03a01",
      "score": 0.9537731409072876
    }
  ],
  "496": [
    {
      "answer": "P",
      "score": 0.9612272381782532
    },
    {
      "answer": "P",
      "score": 0.7766377925872803
    }
  ],
  "497": [
    {
      "answer": "Cobham\u2013Edmonds thesis",
      "score": 0.996404767036438
    }
  ],
  "498": [
    {
      "answer": "NP",
      "score": 0.9595590233802795
    },
    {
      "answer": "NP",
      "score": 0.7524571418762207
    }
  ],
  "499": [
    {
      "answer": "Boolean satisfiability problem",
      "score": 0.9831544160842896
    },
    {
      "answer": "Hamiltonian path problem",
      "score": 0.9743868708610535
    },
    {
      "answer": "vertex cover problem",
      "score": 0.9557415843009949
    }
  ],
  "500": [
    {
      "answer": "deterministic Turing machines",
      "score": 0.9407228231430054
    }
  ],
  "501": [
    {
      "answer": "complexity class P",
      "score": 0.9371070265769958
    }
  ],
  "502": [
    {
      "answer": "Cobham\u2013Edmonds thesis",
      "score": 0.7036933302879333
    }
  ],
  "503": [
    {
      "answer": "NP",
      "score": 0.9391815662384033
    },
    {
      "answer": "NP",
      "score": 0.697828471660614
    }
  ],
  "504": [
    {
      "answer": "Boolean satisfiability problem",
      "score": 0.960969865322113
    },
    {
      "answer": "Hamiltonian path problem",
      "score": 0.9506109952926636
    },
    {
      "answer": "vertex cover problem",
      "score": 0.9115869402885437
    }
  ],
  "505": [],
  "506": [
    {
      "answer": "many important problems can be shown to have more efficient solutions",
      "score": 0.9297048449516296
    }
  ],
  "507": [
    {
      "answer": "protein structure prediction",
      "score": 0.993884265422821
    }
  ],
  "508": [
    {
      "answer": "US$1,000,000",
      "score": 0.9873862862586975
    }
  ],
  "509": [
    {
      "answer": "The question of whether P equals NP",
      "score": 0.8915888071060181
    }
  ],
  "510": [
    {
      "answer": "many important problems can be shown to have more efficient solutions",
      "score": 0.9898191094398499
    }
  ],
  "511": [
    {
      "answer": "protein structure prediction in biology",
      "score": 0.9318389892578125
    }
  ],
  "512": [
    {
      "answer": "P versus NP",
      "score": 0.9853350520133972
    }
  ],
  "513": [
    {
      "answer": "US$1,000,000",
      "score": 0.982877254486084
    }
  ],
  "514": [
    {
      "answer": "Ladner",
      "score": 0.9954451322555542
    }
  ],
  "515": [
    {
      "answer": "NP-intermediate problems",
      "score": 0.9598489999771118
    }
  ],
  "516": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.9719561338424683
    },
    {
      "answer": "discrete logarithm problem",
      "score": 0.9663516283035278
    },
    {
      "answer": "integer factorization problem",
      "score": 0.9266805648803711
    }
  ],
  "517": [
    {
      "answer": "Ladner",
      "score": 0.9958513975143433
    }
  ],
  "518": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.9800940752029419
    },
    {
      "answer": "discrete logarithm problem",
      "score": 0.9491662979125977
    },
    {
      "answer": "integer factorization problem",
      "score": 0.8444237112998962
    }
  ],
  "519": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.9802564382553101
    },
    {
      "answer": "discrete logarithm problem",
      "score": 0.9683035612106323
    },
    {
      "answer": "integer factorization problem",
      "score": 0.9477941393852234
    }
  ],
  "520": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.995222806930542
    },
    {
      "answer": "discrete logarithm problem",
      "score": 0.9944065809249878
    },
    {
      "answer": "integer factorization problem",
      "score": 0.9882998466491699
    }
  ],
  "521": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.9360570907592773
    },
    {
      "answer": "graph isomorphism problem",
      "score": 0.9382134675979614
    }
  ],
  "522": [
    {
      "answer": "not NP-complete",
      "score": 0.6332741975784302
    },
    {
      "answer": "not NP-complete",
      "score": 0.5920425057411194
    }
  ],
  "523": [
    {
      "answer": "polynomial time",
      "score": 0.9934953451156616
    }
  ],
  "524": [
    {
      "answer": "second",
      "score": 0.9827247262001038
    }
  ],
  "525": [
    {
      "answer": "Laszlo Babai",
      "score": 0.9883250594139099
    },
    {
      "answer": "Eugene Luks",
      "score": 0.952228844165802
    }
  ],
  "526": [
    {
      "answer": "the computational problem of determining whether two finite graphs are isomorphic",
      "score": 0.7669230699539185
    }
  ],
  "527": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.9021213054656982
    },
    {
      "answer": "graph isomorphism problem",
      "score": 0.9150083065032959
    }
  ],
  "528": [
    {
      "answer": "graph isomorphism problem",
      "score": 0.7869848608970642
    }
  ],
  "529": [
    {
      "answer": "polynomial time",
      "score": 0.9829963445663452
    }
  ],
  "530": [
    {
      "answer": "to its second level",
      "score": 0.9075964689254761
    }
  ],
  "531": [
    {
      "answer": "integer factorization problem",
      "score": 0.9382156133651733
    },
    {
      "answer": "integer factorization problem",
      "score": 0.9084916114807129
    }
  ],
  "532": [
    {
      "answer": "k",
      "score": 0.7201306819915771
    }
  ],
  "533": [
    {
      "answer": "RSA algorithm",
      "score": 0.9874968528747559
    }
  ],
  "534": [
    {
      "answer": "general number field sieve",
      "score": 0.9797070026397705
    }
  ],
  "535": [],
  "536": [
    {
      "answer": "integer factorization problem",
      "score": 0.8563691973686218
    },
    {
      "answer": "integer factorization problem",
      "score": 0.8701448440551758
    }
  ],
  "537": [
    {
      "answer": "decision problem",
      "score": 0.8522589802742004
    }
  ],
  "538": [
    {
      "answer": "integer factorization problem",
      "score": 0.8819946646690369
    },
    {
      "answer": "integer factorization problem",
      "score": 0.9518668055534363
    }
  ],
  "539": [
    {
      "answer": "general number field sieve",
      "score": 0.7405456304550171
    }
  ],
  "540": [
    {
      "answer": "unequal",
      "score": 0.842506468296051
    }
  ],
  "541": [
    {
      "answer": "If P is not equal to NP, then P is not equal to PSPACE either.",
      "score": 0.7631828188896179
    }
  ],
  "542": [
    {
      "answer": "between P and PSPACE",
      "score": 0.6417489051818848
    }
  ],
  "543": [
    {
      "answer": "Proving that any of these classes are unequal",
      "score": 0.9027142524719238
    }
  ],
  "544": [],
  "545": [],
  "546": [
    {
      "answer": "between P and PSPACE",
      "score": 0.6386005878448486
    }
  ],
  "547": [
    {
      "answer": "all these complexity classes collapse to one class",
      "score": 0.9173932671546936
    }
  ],
  "548": [
    {
      "answer": "Proving that any of these classes are unequal",
      "score": 0.9559339284896851
    }
  ],
  "549": [
    {
      "answer": "co-NP",
      "score": 0.9704199433326721
    },
    {
      "answer": "co-NP",
      "score": 0.8146247863769531
    }
  ],
  "550": [
    {
      "answer": "reversed",
      "score": 0.9769679307937622
    }
  ],
  "551": [
    {
      "answer": "NP is not equal to co-NP",
      "score": 0.7307378649711609
    },
    {
      "answer": "not equal to NP",
      "score": 0.7267405986785889
    }
  ],
  "552": [
    {
      "answer": "P is not equal to NP",
      "score": 0.8680912852287292
    }
  ],
  "553": [
    {
      "answer": "co-NP",
      "score": 0.952481210231781
    },
    {
      "answer": "co-NP",
      "score": 0.8304242491722107
    }
  ],
  "554": [],
  "555": [
    {
      "answer": "NP is not equal to co-NP",
      "score": 0.8823922872543335
    }
  ],
  "556": [
    {
      "answer": "not equal to NP",
      "score": 0.7629266381263733
    }
  ],
  "557": [],
  "558": [],
  "559": [
    {
      "answer": "there are many complexity classes",
      "score": 0.8934003710746765
    }
  ],
  "560": [
    {
      "answer": "NL",
      "score": 0.9872690439224243
    },
    {
      "answer": "NC",
      "score": 0.9759228229522705
    }
  ],
  "561": [
    {
      "answer": "NL and NC",
      "score": 0.9275343418121338
    },
    {
      "answer": "not known if they are distinct or equal classes",
      "score": 0.7510769367218018
    }
  ],
  "562": [],
  "563": [
    {
      "answer": "logarithmic space",
      "score": 0.5458908081054688
    }
  ],
  "564": [
    {
      "answer": "complexity classes",
      "score": 0.7801965475082397
    },
    {
      "answer": "NL and NC",
      "score": 0.5974637269973755
    }
  ],
  "565": [
    {
      "answer": "NL",
      "score": 0.9812198877334595
    },
    {
      "answer": "NC",
      "score": 0.9703342914581299
    }
  ],
  "566": [
    {
      "answer": "there are many complexity classes between the two, such as NL and NC",
      "score": 0.8245816826820374
    }
  ],
  "567": [
    {
      "answer": "intractable",
      "score": 0.9902324676513672
    }
  ],
  "568": [],
  "569": [
    {
      "answer": "NP-complete problems",
      "score": 0.978681743144989
    }
  ],
  "570": [
    {
      "answer": "intractable problems",
      "score": 0.9220786094665527
    }
  ],
  "571": [
    {
      "answer": "EXPTIME-hard",
      "score": 0.9095975756645203
    }
  ],
  "572": [
    {
      "answer": "Cobham\u2013Edmonds thesis",
      "score": 0.9918714761734009
    }
  ],
  "573": [
    {
      "answer": "Even with a much faster computer, the program would only be useful for very small instances",
      "score": 0.8084561228752136
    }
  ],
  "574": [
    {
      "answer": "polynomial time",
      "score": 0.9720275402069092
    }
  ],
  "575": [
    {
      "answer": "Presburger",
      "score": 0.9971215128898621
    }
  ],
  "576": [
    {
      "answer": "algorithms have been written that solve the problem in reasonable times in most cases",
      "score": 0.83210688829422
    }
  ],
  "577": [
    {
      "answer": "decision problem",
      "score": 0.9637707471847534
    }
  ],
  "578": [
    {
      "answer": "less than quadratic time",
      "score": 0.9555199146270752
    }
  ],
  "579": [
    {
      "answer": "NP-complete Boolean satisfiability problem",
      "score": 0.8688287138938904
    }
  ],
  "580": [
    {
      "answer": "Presburger",
      "score": 0.9965766072273254
    }
  ],
  "581": [
    {
      "answer": "algorithms have been written that solve the problem in reasonable times in most cases",
      "score": 0.7385631799697876
    }
  ],
  "582": [
    {
      "answer": "algorithms",
      "score": 0.9606287479400635
    }
  ],
  "583": [
    {
      "answer": "decision problem",
      "score": 0.8520753383636475
    },
    {
      "answer": "NP-complete Boolean satisfiability problem",
      "score": 0.8478351831436157
    }
  ],
  "584": [
    {
      "answer": "numerous foundations were laid out",
      "score": 0.8447198867797852
    }
  ],
  "585": [
    {
      "answer": "Alan Turing",
      "score": 0.9963034391403198
    }
  ],
  "586": [
    {
      "answer": "Turing machines",
      "score": 0.9888774156570435
    }
  ],
  "587": [
    {
      "answer": "1936",
      "score": 0.99553382396698
    }
  ],
  "588": [
    {
      "answer": "computer",
      "score": 0.9857288599014282
    }
  ],
  "589": [
    {
      "answer": "numerous foundations",
      "score": 0.9485875368118286
    }
  ],
  "590": [],
  "591": [
    {
      "answer": "Alan Turing",
      "score": 0.9873515367507935
    }
  ],
  "592": [
    {
      "answer": "Turing machines",
      "score": 0.7289072275161743
    }
  ],
  "593": [
    {
      "answer": "computer",
      "score": 0.8689593076705933
    }
  ],
  "594": [
    {
      "answer": "On the Computational Complexity of Algorithms",
      "score": 0.9934482574462891
    }
  ],
  "595": [
    {
      "answer": "Juris Hartmanis",
      "score": 0.9926689863204956
    },
    {
      "answer": "Richard Stearns",
      "score": 0.9907357692718506
    }
  ],
  "596": [
    {
      "answer": "1965",
      "score": 0.9919490814208984
    },
    {
      "answer": "1965",
      "score": 0.9023436307907104
    }
  ],
  "597": [
    {
      "answer": "time",
      "score": 0.937381386756897
    },
    {
      "answer": "space",
      "score": 0.8974703550338745
    },
    {
      "answer": "time",
      "score": 0.6760561466217041
    }
  ],
  "598": [
    {
      "answer": "1965",
      "score": 0.8689163327217102
    },
    {
      "answer": "1965",
      "score": 0.9895883798599243
    }
  ],
  "599": [
    {
      "answer": "On the Computational Complexity of Algorithms",
      "score": 0.9929665923118591
    }
  ],
  "600": [
    {
      "answer": "Juris Hartmanis",
      "score": 0.9935035705566406
    },
    {
      "answer": "Richard Stearns",
      "score": 0.9876298904418945
    }
  ],
  "601": [
    {
      "answer": "On the Computational Complexity of Algorithms",
      "score": 0.9911969900131226
    }
  ],
  "602": [
    {
      "answer": "time",
      "score": 0.8575493693351746
    },
    {
      "answer": "space complexity",
      "score": 0.7851628065109253
    },
    {
      "answer": "time",
      "score": 0.702878475189209
    }
  ],
  "603": [
    {
      "answer": "John Myhill",
      "score": 0.9900319576263428
    }
  ],
  "604": [
    {
      "answer": "1961",
      "score": 0.9941430687904358
    }
  ],
  "605": [
    {
      "answer": "Hisao Yamada",
      "score": 0.9936681985855103
    }
  ],
  "606": [
    {
      "answer": "John Myhill",
      "score": 0.7904777526855469
    },
    {
      "answer": "Raymond Smullyan",
      "score": 0.8549274802207947
    },
    {
      "answer": "Hisao Yamada",
      "score": 0.9208986759185791
    }
  ],
  "607": [
    {
      "answer": "John Myhill",
      "score": 0.9924185276031494
    }
  ],
  "608": [
    {
      "answer": "1961",
      "score": 0.9934483170509338
    }
  ],
  "609": [
    {
      "answer": "Hisao Yamada",
      "score": 0.9849147796630859
    }
  ],
  "610": [
    {
      "answer": "Boris Trakhtenbrot",
      "score": 0.9942916631698608
    }
  ],
  "611": [
    {
      "answer": "input encoding",
      "score": 0.9875109195709229
    }
  ],
  "612": [
    {
      "answer": "choice of encoding",
      "score": 0.9657976627349854
    }
  ],
  "613": [
    {
      "answer": "independent of the choice of encoding",
      "score": 0.7155451774597168
    }
  ],
  "614": [
    {
      "answer": "independent of the choice of encoding",
      "score": 0.8829379081726074
    }
  ],
  "615": [
    {
      "answer": "abstract enough to be independent of the choice of encoding",
      "score": 0.6271271705627441
    }
  ],
  "616": [
    {
      "answer": "input encoding",
      "score": 0.6260281801223755
    },
    {
      "answer": "encoding",
      "score": 0.9545950293540955
    }
  ],
  "617": [
    {
      "answer": "Manuel Blum",
      "score": 0.9979679584503174
    }
  ],
  "618": [
    {
      "answer": "speed-up theorem",
      "score": 0.9799860119819641
    }
  ],
  "619": [
    {
      "answer": "Reducibility Among Combinatorial Problems",
      "score": 0.9923584461212158
    }
  ],
  "620": [
    {
      "answer": "21",
      "score": 0.994174063205719
    }
  ],
  "621": [
    {
      "answer": "Manuel Blum",
      "score": 0.9940129518508911
    }
  ],
  "622": [
    {
      "answer": "Manuel Blum",
      "score": 0.9959220886230469
    }
  ],
  "623": [
    {
      "answer": "Stephen Cook",
      "score": 0.9779505729675293
    },
    {
      "answer": "Leonid Levin",
      "score": 0.614811897277832
    }
  ],
  "624": [
    {
      "answer": "Richard Karp",
      "score": 0.9966530799865723
    }
  ],
  "625": [
    {
      "answer": "Reducibility Among Combinatorial Problems",
      "score": 0.9881154298782349
    }
  ],
  "626": [
    {
      "answer": "SoCal",
      "score": 0.9857127666473389
    }
  ],
  "627": [
    {
      "answer": "10",
      "score": 0.8650403022766113
    },
    {
      "answer": "10-county",
      "score": 0.58303302526474
    }
  ],
  "628": [
    {
      "answer": "major economic center",
      "score": 0.9825414419174194
    }
  ],
  "629": [
    {
      "answer": "economic ties",
      "score": 0.9742927551269531
    }
  ],
  "630": [
    {
      "answer": "demographics and economic ties",
      "score": 0.8525285720825195
    }
  ],
  "631": [
    {
      "answer": "Kern and San Luis Obispo",
      "score": 0.9306840896606445
    }
  ],
  "632": [
    {
      "answer": "Kern and San Luis Obispo",
      "score": 0.957916259765625
    }
  ],
  "633": [
    {
      "answer": "Southern California",
      "score": 0.898104727268219
    },
    {
      "answer": "Southern California",
      "score": 0.9829403162002563
    }
  ],
  "634": [
    {
      "answer": "greater Southern California Megaregion",
      "score": 0.9665887355804443
    }
  ],
  "635": [
    {
      "answer": "11",
      "score": 0.9961407780647278
    }
  ],
  "636": [
    {
      "answer": "Nevada",
      "score": 0.9260826706886292
    }
  ],
  "637": [
    {
      "answer": "Mexican",
      "score": 0.9887595176696777
    }
  ],
  "638": [
    {
      "answer": "Tijuana",
      "score": 0.9762969613075256
    }
  ],
  "639": [
    {
      "answer": "Southern California Megaregion",
      "score": 0.9690467715263367
    }
  ],
  "640": [
    {
      "answer": "Las Vegas, Nevada",
      "score": 0.9472324252128601
    },
    {
      "answer": "south across the Mexican border into Tijuana",
      "score": 0.8943257331848145
    }
  ],
  "641": [
    {
      "answer": "Southern California Megaregion",
      "score": 0.9270089864730835
    }
  ],
  "642": [
    {
      "answer": "Pacific",
      "score": 0.9939153790473938
    }
  ],
  "643": [
    {
      "answer": "seven",
      "score": 0.9930804371833801
    }
  ],
  "644": [
    {
      "answer": "12 million",
      "score": 0.9692155122756958
    }
  ],
  "645": [
    {
      "answer": "Riverside-San Bernardino area",
      "score": 0.8166991472244263
    },
    {
      "answer": "San Diego area",
      "score": 0.9283689856529236
    }
  ],
  "646": [
    {
      "answer": "17.5 million",
      "score": 0.9721518754959106
    }
  ],
  "647": [
    {
      "answer": "60",
      "score": 0.9946840405464172
    }
  ],
  "648": [
    {
      "answer": "MSAs",
      "score": 0.7025973796844482
    }
  ],
  "649": [
    {
      "answer": "four million",
      "score": 0.9524728059768677
    }
  ],
  "650": [],
  "651": [
    {
      "answer": "Colorado River",
      "score": 0.8747286796569824
    }
  ],
  "652": [
    {
      "answer": "Colorado Desert",
      "score": 0.9002401232719421
    }
  ],
  "653": [
    {
      "answer": "Mojave Desert",
      "score": 0.9414117336273193
    }
  ],
  "654": [
    {
      "answer": "Mexico\u2013United States border",
      "score": 0.9749428629875183
    }
  ],
  "655": [
    {
      "answer": "Mexico\u2013United States border",
      "score": 0.9385735392570496
    }
  ],
  "656": [
    {
      "answer": "Mojave Desert",
      "score": 0.9052591919898987
    }
  ],
  "657": [
    {
      "answer": "south",
      "score": 0.9877733588218689
    }
  ],
  "658": [
    {
      "answer": "California",
      "score": 0.876462996006012
    },
    {
      "answer": "California",
      "score": 0.6048662066459656
    }
  ],
  "659": [
    {
      "answer": "3,792,621",
      "score": 0.9938065409660339
    }
  ],
  "660": [
    {
      "answer": "Los Angeles",
      "score": 0.9383984208106995
    },
    {
      "answer": "Los Angeles",
      "score": 0.9945207834243774
    }
  ],
  "661": [
    {
      "answer": "San Diego",
      "score": 0.862406849861145
    },
    {
      "answer": "San Diego",
      "score": 0.9849408268928528
    }
  ],
  "662": [
    {
      "answer": "south",
      "score": 0.9527340531349182
    }
  ],
  "663": [
    {
      "answer": "Los Angeles",
      "score": 0.9056499600410461
    },
    {
      "answer": "San Diego",
      "score": 0.8596980571746826
    },
    {
      "answer": "Los Angeles",
      "score": 0.6490445137023926
    },
    {
      "answer": "San Diego",
      "score": 0.6134930849075317
    }
  ],
  "664": [
    {
      "answer": "Los Angeles",
      "score": 0.8948038816452026
    },
    {
      "answer": "Los Angeles",
      "score": 0.9622759819030762
    }
  ],
  "665": [
    {
      "answer": "San Diego",
      "score": 0.8805174231529236
    },
    {
      "answer": "San Diego",
      "score": 0.9864815473556519
    }
  ],
  "666": [
    {
      "answer": "San Diego",
      "score": 0.8453240394592285
    },
    {
      "answer": "San Diego",
      "score": 0.8942049741744995
    }
  ],
  "667": [],
  "668": [
    {
      "answer": "United States",
      "score": 0.9971461296081543
    }
  ],
  "669": [
    {
      "answer": "the five most populous in the state",
      "score": 0.9479870796203613
    }
  ],
  "670": [
    {
      "answer": "top 15",
      "score": 0.8700056076049805
    }
  ],
  "671": [],
  "672": [
    {
      "answer": "Los Angeles, Orange, San Diego, San Bernardino, and Riverside",
      "score": 0.8381336331367493
    }
  ],
  "673": [],
  "674": [],
  "675": [
    {
      "answer": "Hollywood",
      "score": 0.9747352004051208
    }
  ],
  "676": [
    {
      "answer": "Los Angeles",
      "score": 0.9695892333984375
    },
    {
      "answer": "Los Angeles",
      "score": 0.9709826707839966
    }
  ],
  "677": [
    {
      "answer": "The Walt Disney Company",
      "score": 0.9892985820770264
    }
  ],
  "678": [],
  "679": [
    {
      "answer": "Sony",
      "score": 0.6609697937965393
    },
    {
      "answer": "Sony",
      "score": 0.8956124186515808
    }
  ],
  "680": [
    {
      "answer": "The Walt Disney Company",
      "score": 0.9893763661384583
    }
  ],
  "681": [
    {
      "answer": "motion picture, television",
      "score": 0.9406565427780151
    }
  ],
  "682": [
    {
      "answer": "southern California",
      "score": 0.9133393168449402
    },
    {
      "answer": "southern California",
      "score": 0.797921895980835
    }
  ],
  "683": [
    {
      "answer": "The Walt Disney Company",
      "score": 0.9114932417869568
    },
    {
      "answer": "Sony Pictures",
      "score": 0.9026052951812744
    },
    {
      "answer": "Universal",
      "score": 0.8228428363800049
    },
    {
      "answer": "MGM",
      "score": 0.8535609245300293
    },
    {
      "answer": "Paramount Pictures",
      "score": 0.9136402606964111
    },
    {
      "answer": "20th Century Fox",
      "score": 0.8860432505607605
    },
    {
      "answer": "Warner Brothers",
      "score": 0.921097993850708
    }
  ],
  "684": [
    {
      "answer": "skateboard culture",
      "score": 0.9209470748901367
    }
  ],
  "685": [
    {
      "answer": "Tony Hawk",
      "score": 0.9297188520431519
    }
  ],
  "686": [
    {
      "answer": "Shaun White",
      "score": 0.9165527820587158
    }
  ],
  "687": [
    {
      "answer": "Oahu",
      "score": 0.9946503043174744
    }
  ],
  "688": [
    {
      "answer": "Transpac",
      "score": 0.6992150545120239
    }
  ],
  "689": [
    {
      "answer": "Southern California",
      "score": 0.9186075925827026
    },
    {
      "answer": "southern California",
      "score": 0.7298753261566162
    },
    {
      "answer": "southern California",
      "score": 0.6339350938796997
    },
    {
      "answer": "southern California",
      "score": 0.7266167402267456
    },
    {
      "answer": "Southern California",
      "score": 0.7495843172073364
    }
  ],
  "690": [],
  "691": [
    {
      "answer": "Southern California",
      "score": 0.7896982431411743
    },
    {
      "answer": "southern California",
      "score": 0.9164776802062988
    },
    {
      "answer": "southern California",
      "score": 0.7305766344070435
    },
    {
      "answer": "southern California",
      "score": 0.7738844156265259
    },
    {
      "answer": "Southern California",
      "score": 0.688825249671936
    }
  ],
  "692": [
    {
      "answer": "Rincon",
      "score": 0.7488146424293518
    },
    {
      "answer": "The Wedge",
      "score": 0.844107985496521
    },
    {
      "answer": "Huntington Beach",
      "score": 0.8433169722557068
    }
  ],
  "693": [
    {
      "answer": "America's Cup",
      "score": 0.9629342555999756
    }
  ],
  "694": [
    {
      "answer": "Palm Springs",
      "score": 0.6925240755081177
    }
  ],
  "695": [
    {
      "answer": "popular beaches",
      "score": 0.9500811100006104
    }
  ],
  "696": [
    {
      "answer": "southern California",
      "score": 0.871544361114502
    }
  ],
  "697": [
    {
      "answer": "resort feel",
      "score": 0.6491222977638245
    },
    {
      "answer": "nearby open spaces",
      "score": 0.8562238216400146
    }
  ],
  "698": [
    {
      "answer": "locals",
      "score": 0.9438595175743103
    },
    {
      "answer": "tourists",
      "score": 0.9684907793998718
    }
  ],
  "699": [
    {
      "answer": "beaches",
      "score": 0.7346103191375732
    },
    {
      "answer": "resort feel",
      "score": 0.8170421123504639
    }
  ],
  "700": [
    {
      "answer": "southern California",
      "score": 0.9503306150436401
    }
  ],
  "701": [
    {
      "answer": "37\u00b0 9' 58.23\" latitude, around 11 miles (18 km) south of San Jose",
      "score": 0.8883305788040161
    }
  ],
  "702": [
    {
      "answer": "11",
      "score": 0.9900025129318237
    }
  ],
  "703": [
    {
      "answer": "ten",
      "score": 0.9936005473136902
    }
  ],
  "704": [
    {
      "answer": "Tehachapi Mountains",
      "score": 0.9441666603088379
    }
  ],
  "705": [
    {
      "answer": "Tehachapi Mountains",
      "score": 0.8581486344337463
    },
    {
      "answer": "northern",
      "score": 0.5588271021842957
    }
  ],
  "706": [
    {
      "answer": "California's north-south midway point",
      "score": 0.8946737051010132
    }
  ],
  "707": [],
  "708": [
    {
      "answer": "northern borders of San Luis Obispo, Kern, and San Bernardino counties",
      "score": 0.9373554587364197
    }
  ],
  "709": [
    {
      "answer": "southern California",
      "score": 0.6620597243309021
    },
    {
      "answer": "southern California",
      "score": 0.9266707897186279
    }
  ],
  "710": [
    {
      "answer": "Mexico",
      "score": 0.9968456625938416
    }
  ],
  "711": [
    {
      "answer": "Alta California",
      "score": 0.990183413028717
    },
    {
      "answer": "Alta California",
      "score": 0.8449801206588745
    }
  ],
  "712": [
    {
      "answer": "Monterey",
      "score": 0.9884300231933594
    }
  ],
  "713": [
    {
      "answer": "Compromise of 1850",
      "score": 0.9058932662010193
    }
  ],
  "714": [
    {
      "answer": "free",
      "score": 0.9933171272277832
    }
  ],
  "715": [
    {
      "answer": "Mexico",
      "score": 0.9945776462554932
    }
  ],
  "716": [
    {
      "answer": "Californios of Monterey",
      "score": 0.9454106092453003
    }
  ],
  "717": [
    {
      "answer": "the Missouri Compromise",
      "score": 0.9783663749694824
    }
  ],
  "718": [
    {
      "answer": "Compromise of 1850",
      "score": 0.9923958778381348
    }
  ],
  "719": [
    {
      "answer": "inequitable taxes",
      "score": 0.9871120452880859
    },
    {
      "answer": "land laws",
      "score": 0.7520363330841064
    }
  ],
  "720": [
    {
      "answer": "Cow Counties",
      "score": 0.9730688333511353
    }
  ],
  "721": [
    {
      "answer": "three",
      "score": 0.9932130575180054
    }
  ],
  "722": [
    {
      "answer": "75%",
      "score": 0.9755518436431885
    }
  ],
  "723": [
    {
      "answer": "Milton Latham",
      "score": 0.9966332912445068
    }
  ],
  "724": [
    {
      "answer": "Californios",
      "score": 0.843856930732727
    }
  ],
  "725": [
    {
      "answer": "Pico Act of 1859",
      "score": 0.9502218961715698
    }
  ],
  "726": [
    {
      "answer": "John B. Weller",
      "score": 0.9931474924087524
    }
  ],
  "727": [
    {
      "answer": "Abraham Lincoln",
      "score": 0.9317142963409424
    }
  ],
  "728": [
    {
      "answer": "Senator",
      "score": 0.9858788847923279
    }
  ],
  "729": [
    {
      "answer": "Los Angeles Times",
      "score": 0.9975172281265259
    }
  ],
  "730": [
    {
      "answer": "1900",
      "score": 0.992743730545044
    }
  ],
  "731": [
    {
      "answer": "1999",
      "score": 0.9939841628074646
    }
  ],
  "732": [
    {
      "answer": "Imperial",
      "score": 0.9922176599502563
    }
  ],
  "733": [
    {
      "answer": "seven",
      "score": 0.992581844329834
    }
  ],
  "734": [
    {
      "answer": "the seven counties of Los Angeles, San Bernardino, Orange, Riverside, San Diego, Ventura and Santa Barbara",
      "score": 0.9629011750221252
    }
  ],
  "735": [
    {
      "answer": "Imperial",
      "score": 0.9800028800964355
    }
  ],
  "736": [
    {
      "answer": "southern California",
      "score": 0.9288065433502197
    }
  ],
  "737": [
    {
      "answer": "regional tourism groups",
      "score": 0.7523959875106812
    },
    {
      "answer": "California State Automobile Association",
      "score": 0.8975163698196411
    },
    {
      "answer": "Automobile Club of Southern California",
      "score": 0.8712957501411438
    }
  ],
  "738": [
    {
      "answer": "California State Automobile Association",
      "score": 0.976345419883728
    }
  ],
  "739": [
    {
      "answer": "three-region",
      "score": 0.9638097882270813
    }
  ],
  "740": [
    {
      "answer": "Tehachapis",
      "score": 0.9850009679794312
    }
  ],
  "741": [
    {
      "answer": "southern California",
      "score": 0.9762251377105713
    }
  ],
  "742": [
    {
      "answer": "AAA Auto Clubs",
      "score": 0.975653886795044
    }
  ],
  "743": [
    {
      "answer": "AAA Auto Clubs",
      "score": 0.9434354305267334
    }
  ],
  "744": [],
  "745": [
    {
      "answer": "regional tourism",
      "score": 0.9780393838882446
    }
  ],
  "746": [
    {
      "answer": "third most populated megalopolis in the United States",
      "score": 0.8070622682571411
    }
  ],
  "747": [
    {
      "answer": "vast",
      "score": 0.9810035228729248
    }
  ],
  "748": [
    {
      "answer": "suburban",
      "score": 0.951135516166687
    },
    {
      "answer": "use of automobiles and highways",
      "score": 0.6946132779121399
    }
  ],
  "749": [
    {
      "answer": "automobiles",
      "score": 0.8627216219902039
    },
    {
      "answer": "highways",
      "score": 0.9613467454910278
    }
  ],
  "750": [
    {
      "answer": "heavily developed urban environment",
      "score": 0.8855239152908325
    }
  ],
  "751": [
    {
      "answer": "Great Lakes Megalopolis",
      "score": 0.9297139048576355
    },
    {
      "answer": "Northeastern megalopolis",
      "score": 0.8854433298110962
    }
  ],
  "752": [
    {
      "answer": "Orange County, San Diego, and Riverside-San Bernardino",
      "score": 0.9310262799263
    }
  ],
  "753": [
    {
      "answer": "San Diego\u2013Tijuana",
      "score": 0.990842342376709
    }
  ],
  "754": [
    {
      "answer": "Camp Pendleton",
      "score": 0.9969581365585327
    }
  ],
  "755": [
    {
      "answer": "Inland Empire",
      "score": 0.9865366816520691
    }
  ],
  "756": [
    {
      "answer": "United States Census Bureau",
      "score": 0.9954119920730591
    }
  ],
  "757": [
    {
      "answer": "Orange Counties",
      "score": 0.9390869140625
    }
  ],
  "758": [
    {
      "answer": "1980s",
      "score": 0.9624283313751221
    },
    {
      "answer": "1990s",
      "score": 0.9811262488365173
    }
  ],
  "759": [
    {
      "answer": "San Bernardino and Riverside Counties",
      "score": 0.9491111040115356
    }
  ],
  "760": [
    {
      "answer": "L.A. and Orange Counties",
      "score": 0.9565874934196472
    }
  ],
  "761": [
    {
      "answer": "exurbs",
      "score": 0.9792810678482056
    }
  ],
  "762": [
    {
      "answer": "Bakersfield-Kern County",
      "score": 0.7234437465667725
    },
    {
      "answer": "Santa Maria",
      "score": 0.7307665348052979
    },
    {
      "answer": "San Luis Obispo",
      "score": 0.8308717608451843
    }
  ],
  "763": [
    {
      "answer": "Mediterranean",
      "score": 0.9829633235931396
    },
    {
      "answer": "Mediterranean",
      "score": 0.9256204962730408
    }
  ],
  "764": [
    {
      "answer": "Mediterranean",
      "score": 0.961492657661438
    }
  ],
  "765": [
    {
      "answer": "90-60",
      "score": 0.9401715397834778
    }
  ],
  "766": [
    {
      "answer": "very rare",
      "score": 0.9917653799057007
    }
  ],
  "767": [
    {
      "answer": "70-50's",
      "score": 0.8212935328483582
    }
  ],
  "768": [
    {
      "answer": "Mediterranean",
      "score": 0.9793669581413269
    },
    {
      "answer": "Mediterranean",
      "score": 0.9333648085594177
    }
  ],
  "769": [
    {
      "answer": "Southern California",
      "score": 0.8013188242912292
    }
  ],
  "770": [
    {
      "answer": "Southern California",
      "score": 0.6971466541290283
    }
  ],
  "771": [
    {
      "answer": "snow",
      "score": 0.9744402170181274
    }
  ],
  "772": [
    {
      "answer": "geologic, topographic, and natural ecosystem",
      "score": 0.8936589956283569
    }
  ],
  "773": [
    {
      "answer": "Pacific Ocean",
      "score": 0.996165931224823
    }
  ],
  "774": [
    {
      "answer": "Pacific Ocean islands",
      "score": 0.8522536754608154
    },
    {
      "answer": "shorelines",
      "score": 0.7091876864433289
    },
    {
      "answer": "beaches",
      "score": 0.6947952508926392
    },
    {
      "answer": "coastal plains",
      "score": 0.8109837770462036
    },
    {
      "answer": "interior valleys",
      "score": 0.643100917339325
    },
    {
      "answer": "deserts",
      "score": 0.8282358646392822
    }
  ],
  "775": [
    {
      "answer": "Peninsular Ranges",
      "score": 0.9244537353515625
    }
  ],
  "776": [
    {
      "answer": "interior valleys",
      "score": 0.7842670679092407
    },
    {
      "answer": "deserts",
      "score": 0.8040164709091187
    }
  ],
  "777": [
    {
      "answer": "topographic",
      "score": 0.9288068413734436
    },
    {
      "answer": "natural ecosystem landscapes",
      "score": 0.9064644575119019
    }
  ],
  "778": [
    {
      "answer": "Pacific Ocean",
      "score": 0.9815238118171692
    }
  ],
  "779": [
    {
      "answer": "Pacific",
      "score": 0.9970664381980896
    }
  ],
  "780": [
    {
      "answer": "Southern California",
      "score": 0.9767919182777405
    }
  ],
  "781": [
    {
      "answer": "10,000",
      "score": 0.99038165807724
    }
  ],
  "782": [
    {
      "answer": "so small",
      "score": 0.7325359582901001
    }
  ],
  "783": [
    {
      "answer": "6.7",
      "score": 0.9925258159637451
    }
  ],
  "784": [
    {
      "answer": "property damage",
      "score": 0.9823633432388306
    }
  ],
  "785": [
    {
      "answer": "$20 billion",
      "score": 0.9837383031845093
    }
  ],
  "786": [
    {
      "answer": "1994",
      "score": 0.9823334217071533
    }
  ],
  "787": [
    {
      "answer": "Northridge",
      "score": 0.9901822209358215
    }
  ],
  "788": [
    {
      "answer": "10,000",
      "score": 0.9900984168052673
    }
  ],
  "789": [
    {
      "answer": "15\u201320",
      "score": 0.9805936217308044
    }
  ],
  "790": [
    {
      "answer": "San Andreas Fault",
      "score": 0.9906798601150513
    }
  ],
  "791": [
    {
      "answer": "6.7+",
      "score": 0.9782792329788208
    }
  ],
  "792": [
    {
      "answer": "Puente Hills Fault",
      "score": 0.8674894571304321
    }
  ],
  "793": [
    {
      "answer": "USGS",
      "score": 0.9956375956535339
    }
  ],
  "794": [
    {
      "answer": "San Andreas Fault",
      "score": 0.8388633728027344
    },
    {
      "answer": "San Jacinto Fault",
      "score": 0.6796263456344604
    },
    {
      "answer": "Puente Hills Fault",
      "score": 0.6394557952880859
    },
    {
      "answer": "Elsinore Fault Zone",
      "score": 0.6853331923484802
    }
  ],
  "795": [
    {
      "answer": "San Andreas Fault",
      "score": 0.9905636310577393
    }
  ],
  "796": [
    {
      "answer": "San Jacinto Fault",
      "score": 0.9699709415435791
    },
    {
      "answer": "Puente Hills Fault",
      "score": 0.9654332995414734
    },
    {
      "answer": "Elsinore Fault Zone",
      "score": 0.9058324098587036
    }
  ],
  "797": [
    {
      "answer": "California Earthquake forecast",
      "score": 0.9950083494186401
    }
  ],
  "798": [
    {
      "answer": "Earthquake occurrence in California",
      "score": 0.9707528352737427
    }
  ],
  "799": [
    {
      "answer": "distinctive regions",
      "score": 0.7858273983001709
    }
  ],
  "800": [
    {
      "answer": "global",
      "score": 0.9910445213317871
    }
  ],
  "801": [
    {
      "answer": "economic",
      "score": 0.9919044971466064
    }
  ],
  "802": [
    {
      "answer": "city",
      "score": 0.9598855972290039
    }
  ],
  "803": [
    {
      "answer": "hub of economic activity",
      "score": 0.7831342220306396
    },
    {
      "answer": "home to many tourist destinations",
      "score": 0.7379068732261658
    }
  ],
  "804": [
    {
      "answer": "distinctive regions",
      "score": 0.9523850083351135
    }
  ],
  "805": [
    {
      "answer": "2010",
      "score": 0.9854471683502197
    }
  ],
  "806": [
    {
      "answer": "high growth rates",
      "score": 0.9937548041343689
    }
  ],
  "807": [
    {
      "answer": "10.0%",
      "score": 0.9938880205154419
    }
  ],
  "808": [
    {
      "answer": "tech-oriented",
      "score": 0.9850495457649231
    }
  ],
  "809": [
    {
      "answer": "northern part of the state",
      "score": 0.792422890663147
    },
    {
      "answer": "Greater Sacramento region",
      "score": 0.639394998550415
    }
  ],
  "810": [
    {
      "answer": "2010",
      "score": 0.9492670893669128
    }
  ],
  "811": [
    {
      "answer": "less than the state average of 10.0%",
      "score": 0.7929784655570984
    }
  ],
  "812": [
    {
      "answer": "tech-oriented",
      "score": 0.9847990870475769
    }
  ],
  "813": [],
  "814": [
    {
      "answer": "Metropolitan Statistical Areas",
      "score": 0.8954843878746033
    }
  ],
  "815": [
    {
      "answer": "two",
      "score": 0.7884921431541443
    }
  ],
  "816": [
    {
      "answer": "five million",
      "score": 0.9665098786354065
    }
  ],
  "817": [
    {
      "answer": "Southern Border Region",
      "score": 0.9796212911605835
    }
  ],
  "818": [
    {
      "answer": "17,786,419",
      "score": 0.9691886901855469
    }
  ],
  "819": [
    {
      "answer": "Southern California",
      "score": 0.8984681367874146
    }
  ],
  "820": [
    {
      "answer": "Southern California",
      "score": 0.9302045702934265
    }
  ],
  "821": [
    {
      "answer": "Greater Los Angeles",
      "score": 0.9861612319946289
    }
  ],
  "822": [
    {
      "answer": "Greater Los Angeles Area",
      "score": 0.7026578187942505
    },
    {
      "answer": "San Diego\u2013Tijuana",
      "score": 0.9615984559059143
    }
  ],
  "823": [
    {
      "answer": "Bakersfield",
      "score": 0.8674917817115784
    }
  ],
  "824": [
    {
      "answer": "Los Angeles",
      "score": 0.82790207862854
    },
    {
      "answer": "San Diego",
      "score": 0.6381710171699524
    }
  ],
  "825": [
    {
      "answer": "1.3 million",
      "score": 0.9909942746162415
    }
  ],
  "826": [
    {
      "answer": "twelve",
      "score": 0.99224853515625
    }
  ],
  "827": [
    {
      "answer": "100,000",
      "score": 0.9891518354415894
    }
  ],
  "828": [
    {
      "answer": "Riverside",
      "score": 0.9410209655761719
    }
  ],
  "829": [
    {
      "answer": "Los Angeles",
      "score": 0.9375271797180176
    },
    {
      "answer": "San Diego",
      "score": 0.8270058035850525
    }
  ],
  "830": [
    {
      "answer": "southern California",
      "score": 0.7362998723983765
    },
    {
      "answer": "southern California",
      "score": 0.9824719429016113
    },
    {
      "answer": "southern California",
      "score": 0.6664553880691528
    }
  ],
  "831": [
    {
      "answer": "southern California",
      "score": 0.757282018661499
    },
    {
      "answer": "southern California",
      "score": 0.9853317141532898
    },
    {
      "answer": "southern California",
      "score": 0.6610221862792969
    }
  ],
  "832": [
    {
      "answer": "Los Angeles",
      "score": 0.9415260553359985
    },
    {
      "answer": "San Diego",
      "score": 0.5318408012390137
    }
  ],
  "833": [
    {
      "answer": "Los Angeles",
      "score": 0.8814259767532349
    },
    {
      "answer": "San Diego",
      "score": 0.7536225318908691
    }
  ],
  "834": [
    {
      "answer": "petroleum",
      "score": 0.9855474233627319
    }
  ],
  "835": [
    {
      "answer": "Hollywood",
      "score": 0.9900240302085876
    }
  ],
  "836": [
    {
      "answer": "housing bubble",
      "score": 0.988770604133606
    }
  ],
  "837": [
    {
      "answer": "diverse",
      "score": 0.9694668054580688
    }
  ],
  "838": [
    {
      "answer": "heavily impacted",
      "score": 0.9406330585479736
    }
  ],
  "839": [
    {
      "answer": "Southern California",
      "score": 0.8100370764732361
    }
  ],
  "840": [
    {
      "answer": "housing bubble",
      "score": 0.9548619389533997
    }
  ],
  "841": [
    {
      "answer": "petroleum",
      "score": 0.9854257106781006
    }
  ],
  "842": [
    {
      "answer": "Southern California",
      "score": 0.6982978582382202
    }
  ],
  "843": [
    {
      "answer": "1920s",
      "score": 0.9959954023361206
    }
  ],
  "844": [
    {
      "answer": "richest",
      "score": 0.9603523015975952
    }
  ],
  "845": [
    {
      "answer": "cattle",
      "score": 0.9749489426612854
    }
  ],
  "846": [
    {
      "answer": "motion pictures",
      "score": 0.8805851936340332
    },
    {
      "answer": "petroleum",
      "score": 0.7889337539672852
    },
    {
      "answer": "aircraft manufacturing",
      "score": 0.9030330777168274
    }
  ],
  "847": [
    {
      "answer": "aerospace",
      "score": 0.9949073195457458
    }
  ],
  "848": [
    {
      "answer": "motion pictures",
      "score": 0.6936187744140625
    },
    {
      "answer": "aircraft manufacturing",
      "score": 0.7736857533454895
    }
  ],
  "849": [
    {
      "answer": "cattle and citrus",
      "score": 0.9688801765441895
    }
  ],
  "850": [
    {
      "answer": "aerospace",
      "score": 0.9525256752967834
    }
  ],
  "851": [
    {
      "answer": "1920s",
      "score": 0.9832726716995239
    }
  ],
  "852": [
    {
      "answer": "major business districts",
      "score": 0.8191876411437988
    },
    {
      "answer": "Central business districts",
      "score": 0.7786256670951843
    }
  ],
  "853": [
    {
      "answer": "Central business districts",
      "score": 0.9870755076408386
    }
  ],
  "854": [],
  "855": [
    {
      "answer": "Central business districts",
      "score": 0.9511942863464355
    }
  ],
  "856": [
    {
      "answer": "Downtown Los Angeles",
      "score": 0.9711920022964478
    },
    {
      "answer": "Downtown San Diego",
      "score": 0.9800624251365662
    },
    {
      "answer": "Downtown San Bernardino",
      "score": 0.9814600348472595
    },
    {
      "answer": "Downtown Bakersfield",
      "score": 0.9743189811706543
    },
    {
      "answer": "South Coast Metro",
      "score": 0.9575307369232178
    },
    {
      "answer": "Downtown Riverside",
      "score": 0.9624001979827881
    }
  ],
  "857": [
    {
      "answer": "Central business districts",
      "score": 0.9213383197784424
    }
  ],
  "858": [
    {
      "answer": "business districts",
      "score": 0.9544150829315186
    }
  ],
  "859": [
    {
      "answer": "Los Angeles Area",
      "score": 0.9851363897323608
    }
  ],
  "860": [
    {
      "answer": "San Fernando Valley",
      "score": 0.9800254702568054
    }
  ],
  "861": [
    {
      "answer": "San Fernando Valley",
      "score": 0.8704122304916382
    }
  ],
  "862": [
    {
      "answer": "Downtown Burbank",
      "score": 0.9316283464431763
    },
    {
      "answer": "Downtown Santa Monica",
      "score": 0.9371755123138428
    },
    {
      "answer": "Downtown Glendale",
      "score": 0.9285353422164917
    },
    {
      "answer": "Downtown Long Beach",
      "score": 0.9128315448760986
    }
  ],
  "863": [
    {
      "answer": "Downtown Los Angeles",
      "score": 0.9485827684402466
    }
  ],
  "864": [
    {
      "answer": "Century City, Westwood and Warner Center",
      "score": 0.797329843044281
    }
  ],
  "865": [
    {
      "answer": "business districts",
      "score": 0.8416867256164551
    },
    {
      "answer": "Downtown San Bernardino",
      "score": 0.7627593278884888
    },
    {
      "answer": "Hospitality Business/Financial Centre",
      "score": 0.6727399826049805
    }
  ],
  "866": [
    {
      "answer": "Riverside",
      "score": 0.9640616774559021
    }
  ],
  "867": [
    {
      "answer": "Hospitality Business/Financial Centre",
      "score": 0.9843623042106628
    }
  ],
  "868": [
    {
      "answer": "Downtown San Bernardino",
      "score": 0.9019129276275635
    },
    {
      "answer": "Hospitality Business/Financial Centre",
      "score": 0.9222864508628845
    },
    {
      "answer": "University Town",
      "score": 0.8756100535392761
    }
  ],
  "869": [
    {
      "answer": "Downtown San Bernardino",
      "score": 0.9303137063980103
    },
    {
      "answer": "Hospitality Business/Financial Centre",
      "score": 0.9359123110771179
    },
    {
      "answer": "University Town",
      "score": 0.890282154083252
    },
    {
      "answer": "Downtown Riverside",
      "score": 0.5759402513504028
    }
  ],
  "870": [
    {
      "answer": "Orange",
      "score": 0.988089382648468
    }
  ],
  "871": [
    {
      "answer": "University of California, Irvine",
      "score": 0.9562891125679016
    }
  ],
  "872": [
    {
      "answer": "West Irvine",
      "score": 0.7708017826080322
    },
    {
      "answer": "West Irvine",
      "score": 0.8728749752044678
    }
  ],
  "873": [
    {
      "answer": "The Irvine Spectrum",
      "score": 0.6276074647903442
    },
    {
      "answer": "West Irvine",
      "score": 0.8066596984863281
    },
    {
      "answer": "West Irvine",
      "score": 0.6417629718780518
    }
  ],
  "874": [
    {
      "answer": "rapidly",
      "score": 0.9451968669891357
    }
  ],
  "875": [
    {
      "answer": "Orange County",
      "score": 0.9370866417884827
    }
  ],
  "876": [
    {
      "answer": "Downtown Santa Ana",
      "score": 0.7165035009384155
    },
    {
      "answer": "South Coast Metro",
      "score": 0.9097884893417358
    }
  ],
  "877": [
    {
      "answer": "Irvine business centers of The Irvine Spectrum",
      "score": 0.5934002995491028
    },
    {
      "answer": "West Irvine",
      "score": 0.6630635261535645
    }
  ],
  "878": [
    {
      "answer": "West Irvine",
      "score": 0.7179023027420044
    },
    {
      "answer": "West Irvine",
      "score": 0.9780542850494385
    }
  ],
  "879": [
    {
      "answer": "Downtown San Diego",
      "score": 0.9679243564605713
    }
  ],
  "880": [
    {
      "answer": "Northern San Diego",
      "score": 0.9816749095916748
    },
    {
      "answer": "North County regions",
      "score": 0.8326455950737
    }
  ],
  "881": [
    {
      "answer": "North County",
      "score": 0.9957811832427979
    }
  ],
  "882": [
    {
      "answer": "San Diego",
      "score": 0.8184638023376465
    },
    {
      "answer": "San Diego",
      "score": 0.873852014541626
    },
    {
      "answer": "San Diego",
      "score": 0.8434746265411377
    }
  ],
  "883": [
    {
      "answer": "Downtown San Diego",
      "score": 0.8469178676605225
    }
  ],
  "884": [
    {
      "answer": "Carmel Valley",
      "score": 0.7096351385116577
    },
    {
      "answer": "Del Mar Heights",
      "score": 0.6884767413139343
    }
  ],
  "885": [
    {
      "answer": "Carmel Valley",
      "score": 0.9300480484962463
    },
    {
      "answer": "Del Mar Heights",
      "score": 0.8995661735534668
    },
    {
      "answer": "Mission Valley",
      "score": 0.9038649797439575
    },
    {
      "answer": "Rancho Bernardo",
      "score": 0.862531840801239
    },
    {
      "answer": "Sorrento Mesa",
      "score": 0.8894768953323364
    },
    {
      "answer": "University City",
      "score": 0.8253425359725952
    }
  ],
  "886": [
    {
      "answer": "Los Angeles International Airport",
      "score": 0.9871352910995483
    }
  ],
  "887": [
    {
      "answer": "passenger volume",
      "score": 0.9793022871017456
    },
    {
      "answer": "passenger traffic",
      "score": 0.6232504844665527
    },
    {
      "answer": "passenger volume",
      "score": 0.8424936532974243
    },
    {
      "answer": "passenger traffic",
      "score": 0.8754416704177856
    }
  ],
  "888": [
    {
      "answer": "third",
      "score": 0.9855889678001404
    }
  ],
  "889": [
    {
      "answer": "San Diego International Airport",
      "score": 0.9872596859931946
    }
  ],
  "890": [
    {
      "answer": "Van Nuys Airport",
      "score": 0.9830553531646729
    }
  ],
  "891": [
    {
      "answer": "Los Angeles International Airport",
      "score": 0.9662221670150757
    }
  ],
  "892": [
    {
      "answer": "San Diego International Airport",
      "score": 0.9702448844909668
    }
  ],
  "893": [
    {
      "answer": "Van Nuys Airport",
      "score": 0.9787091016769409
    }
  ],
  "894": [
    {
      "answer": "Orange County, Bakersfield, Ontario, Burbank and Long Beach",
      "score": 0.8593198657035828
    }
  ],
  "895": [
    {
      "answer": "Metrolink",
      "score": 0.9368965029716492
    }
  ],
  "896": [
    {
      "answer": "seven",
      "score": 0.9793750643730164
    }
  ],
  "897": [
    {
      "answer": "Six",
      "score": 0.9676854610443115
    }
  ],
  "898": [
    {
      "answer": "Orange",
      "score": 0.9570180773735046
    }
  ],
  "899": [
    {
      "answer": "Downtown Los Angeles",
      "score": 0.9890940189361572
    }
  ],
  "900": [
    {
      "answer": "Metrolink",
      "score": 0.9480798840522766
    }
  ],
  "901": [
    {
      "answer": "Orange",
      "score": 0.6649470925331116
    },
    {
      "answer": "Orange",
      "score": 0.6821325421333313
    }
  ],
  "902": [
    {
      "answer": "Port of Los Angeles",
      "score": 0.9893843531608582
    }
  ],
  "903": [
    {
      "answer": "Port of Long Beach",
      "score": 0.9794442653656006
    }
  ],
  "904": [
    {
      "answer": "Southern California",
      "score": 0.932105541229248
    }
  ],
  "905": [
    {
      "answer": "Port of Los Angeles",
      "score": 0.9197753667831421
    }
  ],
  "906": [
    {
      "answer": "Port of Los Angeles",
      "score": 0.9863578677177429
    }
  ],
  "907": [
    {
      "answer": "Port of Long Beach",
      "score": 0.8520337343215942
    }
  ],
  "908": [
    {
      "answer": "Port of Long Beach",
      "score": 0.9870749711990356
    }
  ],
  "909": [
    {
      "answer": "Tech Coast",
      "score": 0.9580240249633789
    }
  ],
  "910": [
    {
      "answer": "prestigious and world-renowned research universities",
      "score": 0.9626025557518005
    }
  ],
  "911": [
    {
      "answer": "private",
      "score": 0.9905603528022766
    }
  ],
  "912": [
    {
      "answer": "5",
      "score": 0.9923416376113892
    }
  ],
  "913": [
    {
      "answer": "12",
      "score": 0.9952312111854553
    }
  ],
  "914": [
    {
      "answer": "Irvine, Los Angeles, Riverside, Santa Barbara, and San Diego",
      "score": 0.8932970762252808
    },
    {
      "answer": "San Diego",
      "score": 0.5769220590591431
    }
  ],
  "915": [
    {
      "answer": "5",
      "score": 0.9932335019111633
    }
  ],
  "916": [
    {
      "answer": "12",
      "score": 0.9894835352897644
    }
  ],
  "917": [],
  "918": [],
  "919": [
    {
      "answer": "NFL",
      "score": 0.9873314499855042
    }
  ],
  "920": [
    {
      "answer": "NBA",
      "score": 0.9879492521286011
    }
  ],
  "921": [
    {
      "answer": "MLB",
      "score": 0.9909635782241821
    }
  ],
  "922": [
    {
      "answer": "Los Angeles Kings",
      "score": 0.9934751987457275
    }
  ],
  "923": [
    {
      "answer": "LA Galaxy",
      "score": 0.9937620162963867
    }
  ],
  "924": [
    {
      "answer": "Los Angeles Kings",
      "score": 0.8661962747573853
    },
    {
      "answer": "Anaheim Ducks",
      "score": 0.8780325055122375
    }
  ],
  "925": [
    {
      "answer": "Los Angeles Lakers",
      "score": 0.9444187879562378
    },
    {
      "answer": "Los Angeles Clippers",
      "score": 0.9751021862030029
    }
  ],
  "926": [
    {
      "answer": "Los Angeles Dodgers",
      "score": 0.8943492770195007
    },
    {
      "answer": "Los Angeles Angels of Anaheim",
      "score": 0.9272071719169617
    }
  ],
  "927": [
    {
      "answer": "Anaheim Ducks",
      "score": 0.749248206615448
    }
  ],
  "928": [
    {
      "answer": "LA Galaxy",
      "score": 0.9936849474906921
    }
  ],
  "929": [
    {
      "answer": "Chivas USA",
      "score": 0.8706978559494019
    }
  ],
  "930": [
    {
      "answer": "two",
      "score": 0.9819482564926147
    }
  ],
  "931": [
    {
      "answer": "2014",
      "score": 0.8895727396011353
    },
    {
      "answer": "2014",
      "score": 0.988347589969635
    }
  ],
  "932": [
    {
      "answer": "StubHub Center",
      "score": 0.9699647426605225
    }
  ],
  "933": [
    {
      "answer": "2018",
      "score": 0.9903505444526672
    }
  ],
  "934": [
    {
      "answer": "two",
      "score": 0.9895280003547668
    }
  ],
  "935": [
    {
      "answer": "LA Galaxy",
      "score": 0.9639252424240112
    },
    {
      "answer": "Chivas USA",
      "score": 0.9616134166717529
    }
  ],
  "936": [
    {
      "answer": "2014",
      "score": 0.72628253698349
    },
    {
      "answer": "2014",
      "score": 0.9516381025314331
    }
  ],
  "937": [
    {
      "answer": "2018",
      "score": 0.9890719652175903
    }
  ],
  "938": [
    {
      "answer": "College sports",
      "score": 0.9701743125915527
    }
  ],
  "939": [
    {
      "answer": "UCLA",
      "score": 0.9808608889579773
    }
  ],
  "940": [
    {
      "answer": "USC Trojans",
      "score": 0.8830286264419556
    }
  ],
  "941": [
    {
      "answer": "Pac-12",
      "score": 0.9940806031227112
    }
  ],
  "942": [
    {
      "answer": "NCAA Division I",
      "score": 0.9800130724906921
    }
  ],
  "943": [
    {
      "answer": "UCLA Bruins",
      "score": 0.9345732927322388
    }
  ],
  "944": [
    {
      "answer": "USC Trojans",
      "score": 0.9310766458511353
    }
  ],
  "945": [
    {
      "answer": "Pac-12",
      "score": 0.9894071221351624
    }
  ],
  "946": [
    {
      "answer": "Rugby",
      "score": 0.8909369707107544
    }
  ],
  "947": [
    {
      "answer": "high school",
      "score": 0.9962804317474365
    }
  ],
  "948": [
    {
      "answer": "an official school sport",
      "score": 0.9191833138465881
    }
  ],
  "949": [
    {
      "answer": "Rugby",
      "score": 0.8481891751289368
    }
  ],
  "950": [
    {
      "answer": "BSkyB",
      "score": 0.84173583984375
    },
    {
      "answer": "BSkyB",
      "score": 0.6412865519523621
    }
  ],
  "951": [
    {
      "answer": "BSkyB",
      "score": 0.9514445662498474
    },
    {
      "answer": "BSkyB",
      "score": 0.5555257797241211
    }
  ],
  "952": [
    {
      "answer": "2014",
      "score": 0.9845162630081177
    },
    {
      "answer": "2014",
      "score": 0.9097411036491394
    }
  ],
  "953": [
    {
      "answer": "British Sky Broadcasting Group plc",
      "score": 0.9454751014709473
    }
  ],
  "954": [
    {
      "answer": "Sky UK Limited",
      "score": 0.8892335295677185
    }
  ],
  "955": [
    {
      "answer": "BSkyB",
      "score": 0.6411890387535095
    },
    {
      "answer": "BSkyB",
      "score": 0.680911660194397
    }
  ],
  "956": [
    {
      "answer": "BSkyB",
      "score": 0.7179858088493347
    },
    {
      "answer": "BSkyB",
      "score": 0.6973816156387329
    }
  ],
  "957": [
    {
      "answer": "2014",
      "score": 0.9839296340942383
    },
    {
      "answer": "2014",
      "score": 0.9244056940078735
    }
  ],
  "958": [
    {
      "answer": "November 1990",
      "score": 0.9735314249992371
    }
  ],
  "959": [
    {
      "answer": "British Sky Broadcasting Group plc",
      "score": 0.8259205222129822
    },
    {
      "answer": "Sky plc",
      "score": 0.6877797842025757
    }
  ],
  "960": [
    {
      "answer": "2006",
      "score": 0.9904807209968567
    }
  ],
  "961": [
    {
      "answer": "two",
      "score": 0.9886369109153748
    }
  ],
  "962": [
    {
      "answer": "Sky",
      "score": 0.9645692706108093
    },
    {
      "answer": "Sky",
      "score": 0.6910050511360168
    },
    {
      "answer": "Sky",
      "score": 0.6145938634872437
    }
  ],
  "963": [
    {
      "answer": "\u00a31.3bn",
      "score": 0.9809700846672058
    }
  ],
  "964": [
    {
      "answer": "BSkyB",
      "score": 0.9811758399009705
    }
  ],
  "965": [
    {
      "answer": "two",
      "score": 0.9868918061256409
    }
  ],
  "966": [
    {
      "answer": "two",
      "score": 0.9013779163360596
    }
  ],
  "967": [
    {
      "answer": "\u00a31.3bn",
      "score": 0.9728406071662903
    }
  ],
  "968": [
    {
      "answer": "3D",
      "score": 0.900513768196106
    }
  ],
  "969": [
    {
      "answer": "ONdigital",
      "score": 0.9934040904045105
    }
  ],
  "970": [
    {
      "answer": "BBC",
      "score": 0.8265798091888428
    },
    {
      "answer": "ITV",
      "score": 0.8000307679176331
    },
    {
      "answer": "Channel 4",
      "score": 0.8252302408218384
    },
    {
      "answer": "National Grid Wireless",
      "score": 0.8346247673034668
    }
  ],
  "971": [
    {
      "answer": "three",
      "score": 0.9858652353286743
    }
  ],
  "972": [
    {
      "answer": "Sky Three",
      "score": 0.9107431769371033
    },
    {
      "answer": "Sky Three",
      "score": 0.9894380569458008
    }
  ],
  "973": [
    {
      "answer": "Pick TV",
      "score": 0.9870599508285522
    }
  ],
  "974": [
    {
      "answer": "Freeview",
      "score": 0.9313671588897705
    }
  ],
  "975": [
    {
      "answer": "Pick TV",
      "score": 0.7519882321357727
    }
  ],
  "976": [
    {
      "answer": "Sky Three",
      "score": 0.8667836785316467
    },
    {
      "answer": "Sky Three",
      "score": 0.920536994934082
    }
  ],
  "977": [
    {
      "answer": "BBC",
      "score": 0.8703619241714478
    },
    {
      "answer": "ITV",
      "score": 0.8160556554794312
    },
    {
      "answer": "Channel 4",
      "score": 0.846121072769165
    },
    {
      "answer": "National Grid Wireless",
      "score": 0.8363208770751953
    }
  ],
  "978": [],
  "979": [
    {
      "answer": "Sky+ PVR",
      "score": 0.8340646624565125
    }
  ],
  "980": [
    {
      "answer": "September 2007",
      "score": 0.9773510694503784
    }
  ],
  "981": [
    {
      "answer": "pay a monthly fee",
      "score": 0.948708176612854
    }
  ],
  "982": [
    {
      "answer": "January 2010",
      "score": 0.9758204221725464
    }
  ],
  "983": [
    {
      "answer": "Sky+HD Box",
      "score": 0.9825437664985657
    }
  ],
  "984": [
    {
      "answer": "Sky+",
      "score": 0.6164183020591736
    }
  ],
  "985": [
    {
      "answer": "September 2007",
      "score": 0.9743567705154419
    }
  ],
  "986": [
    {
      "answer": "pay a monthly fee",
      "score": 0.9088813662528992
    }
  ],
  "987": [
    {
      "answer": "January 2010",
      "score": 0.9392592906951904
    }
  ],
  "988": [
    {
      "answer": "Sky+HD Box",
      "score": 0.9020463228225708
    }
  ],
  "989": [],
  "990": [
    {
      "answer": "Cisco Systems",
      "score": 0.9529668092727661
    }
  ],
  "991": [
    {
      "answer": "Cisco Systems",
      "score": 0.9925004243850708
    }
  ],
  "992": [
    {
      "answer": "BSkyB",
      "score": 0.7384157776832581
    },
    {
      "answer": "BSkyB",
      "score": 0.9540392756462097
    }
  ],
  "993": [
    {
      "answer": "Sky+",
      "score": 0.739937424659729
    }
  ],
  "994": [],
  "995": [
    {
      "answer": "BSkyB",
      "score": 0.7894161343574524
    }
  ],
  "996": [
    {
      "answer": "VideoGuard decoders",
      "score": 0.9618042707443237
    }
  ],
  "997": [
    {
      "answer": "Cisco Systems",
      "score": 0.975105345249176
    }
  ],
  "998": [
    {
      "answer": "Sky+",
      "score": 0.9204753637313843
    }
  ],
  "999": [
    {
      "answer": "2007",
      "score": 0.8786532282829285
    },
    {
      "answer": "2007",
      "score": 0.813607931137085
    }
  ],
  "1000": [
    {
      "answer": "basic channels",
      "score": 0.7887619137763977
    }
  ],
  "1001": [
    {
      "answer": "substantially increased the asking price for the channels",
      "score": 0.8863221406936646
    }
  ],
  "1002": [
    {
      "answer": "Video On Demand",
      "score": 0.9476747512817383
    }
  ],
  "1003": [
    {
      "answer": "HD channels",
      "score": 0.9631292819976807
    }
  ],
  "1004": [
    {
      "answer": "2007",
      "score": 0.8635455965995789
    },
    {
      "answer": "2007",
      "score": 0.8320426940917969
    }
  ],
  "1005": [
    {
      "answer": "Sky channels",
      "score": 0.5612719058990479
    }
  ],
  "1006": [
    {
      "answer": "Video On Demand",
      "score": 0.9377340078353882
    }
  ],
  "1007": [],
  "1008": [
    {
      "answer": "2007",
      "score": 0.5635080337524414
    },
    {
      "answer": "2007",
      "score": 0.8673338890075684
    }
  ],
  "1009": [
    {
      "answer": "July 2013",
      "score": 0.9857468605041504
    },
    {
      "answer": "July 2013",
      "score": 0.9224774837493896
    }
  ],
  "1010": [
    {
      "answer": "2013",
      "score": 0.9233565926551819
    },
    {
      "answer": "2013",
      "score": 0.9587982296943665
    }
  ],
  "1011": [
    {
      "answer": "OneDrive",
      "score": 0.9737393856048584
    }
  ],
  "1012": [
    {
      "answer": "OneDrive for Business",
      "score": 0.965370774269104
    }
  ],
  "1013": [
    {
      "answer": "cloud storage",
      "score": 0.9909110069274902
    }
  ],
  "1014": [
    {
      "answer": "July 2013",
      "score": 0.9605057239532471
    },
    {
      "answer": "July 2013",
      "score": 0.9239359498023987
    }
  ],
  "1015": [
    {
      "answer": "July 2013",
      "score": 0.9644349217414856
    }
  ],
  "1016": [
    {
      "answer": "OneDrive",
      "score": 0.8963102698326111
    }
  ],
  "1017": [
    {
      "answer": "OneDrive",
      "score": 0.7632094025611877
    },
    {
      "answer": "OneDrive",
      "score": 0.7457362413406372
    }
  ],
  "1018": [
    {
      "answer": "27 January 2014",
      "score": 0.9914621114730835
    }
  ],
  "1019": [
    {
      "answer": "Sam Chisholm",
      "score": 0.9938578605651855
    }
  ],
  "1020": [
    {
      "answer": "Astra",
      "score": 0.9900256395339966
    }
  ],
  "1021": [
    {
      "answer": "27 September 2001",
      "score": 0.9928346872329712
    }
  ],
  "1022": [
    {
      "answer": "Sky Digital",
      "score": 0.994513750076294
    }
  ],
  "1023": [
    {
      "answer": "3.5 million",
      "score": 0.9880502820014954
    }
  ],
  "1024": [
    {
      "answer": "Sky Digital",
      "score": 0.9931090474128723
    }
  ],
  "1025": [
    {
      "answer": "Astra",
      "score": 0.9573442339897156
    }
  ],
  "1026": [
    {
      "answer": "400,000",
      "score": 0.9500095844268799
    }
  ],
  "1027": [
    {
      "answer": "Michael Grade",
      "score": 0.9932847023010254
    }
  ],
  "1028": [
    {
      "answer": "BSkyB",
      "score": 0.964503824710846
    },
    {
      "answer": "BSkyB",
      "score": 0.8369162082672119
    },
    {
      "answer": "BSkyB",
      "score": 0.8541877269744873
    }
  ],
  "1029": [
    {
      "answer": "British Sky Broadcasting",
      "score": 0.9636712074279785
    }
  ],
  "1030": [
    {
      "answer": "British telecommunications",
      "score": 0.9593100547790527
    }
  ],
  "1031": [
    {
      "answer": "11 million",
      "score": 0.9746406078338623
    }
  ],
  "1032": [
    {
      "answer": "Freeview",
      "score": 0.9805371165275574
    }
  ],
  "1033": [],
  "1034": [
    {
      "answer": "Freeview",
      "score": 0.8622117638587952
    }
  ],
  "1035": [
    {
      "answer": "11 million",
      "score": 0.9629417657852173
    }
  ],
  "1036": [
    {
      "answer": "Freeview",
      "score": 0.7144318222999573
    }
  ],
  "1037": [
    {
      "answer": "Isleworth",
      "score": 0.9888555407524109
    }
  ],
  "1038": [
    {
      "answer": "Sky Q Hub",
      "score": 0.9545283317565918
    }
  ],
  "1039": [
    {
      "answer": "Sky Q Silver set top boxes",
      "score": 0.9336541891098022
    }
  ],
  "1040": [
    {
      "answer": "all set top boxes in a household to share recordings and other media",
      "score": 0.889724612236023
    }
  ],
  "1041": [
    {
      "answer": "2016",
      "score": 0.6736287474632263
    },
    {
      "answer": "2016",
      "score": 0.9737642407417297
    }
  ],
  "1042": [
    {
      "answer": "2016",
      "score": 0.9714959263801575
    },
    {
      "answer": "2016",
      "score": 0.870124101638794
    }
  ],
  "1043": [
    {
      "answer": "Sky Q Hub",
      "score": 0.9342465400695801
    }
  ],
  "1044": [
    {
      "answer": "Sky Q Silver set top boxes",
      "score": 0.9368165731430054
    }
  ],
  "1045": [
    {
      "answer": "all set top boxes in a household to share recordings and other media",
      "score": 0.8658463954925537
    }
  ],
  "1046": [
    {
      "answer": "Sky Q Silver",
      "score": 0.6144231557846069
    },
    {
      "answer": "Sky Q Silver",
      "score": 0.5911101698875427
    },
    {
      "answer": "Sky Q Silver",
      "score": 0.893578052520752
    }
  ],
  "1047": [
    {
      "answer": "DVB-compliant MPEG-2",
      "score": 0.834551215171814
    }
  ],
  "1048": [
    {
      "answer": "Dolby Digital",
      "score": 0.9943124055862427
    }
  ],
  "1049": [
    {
      "answer": "MPEG-4",
      "score": 0.9824429750442505
    }
  ],
  "1050": [
    {
      "answer": "OpenTV",
      "score": 0.9811108708381653
    }
  ],
  "1051": [
    {
      "answer": "DVB-S2",
      "score": 0.9916468858718872
    }
  ],
  "1052": [
    {
      "answer": "Sky+",
      "score": 0.9939678907394409
    }
  ],
  "1053": [
    {
      "answer": "OpenTV",
      "score": 0.988899827003479
    }
  ],
  "1054": [
    {
      "answer": "Sky News",
      "score": 0.8865753412246704
    }
  ],
  "1055": [
    {
      "answer": "Dolby Digital",
      "score": 0.989183247089386
    }
  ],
  "1056": [
    {
      "answer": "1998",
      "score": 0.9029366374015808
    }
  ],
  "1057": [
    {
      "answer": "Astra 2A",
      "score": 0.9372354745864868
    }
  ],
  "1058": [
    {
      "answer": "Astra 2A",
      "score": 0.6881709098815918
    },
    {
      "answer": "Eurobird 1",
      "score": 0.7664053440093994
    }
  ],
  "1059": [
    {
      "answer": "hundreds",
      "score": 0.9739668369293213
    }
  ],
  "1060": [
    {
      "answer": "28.5\u00b0E",
      "score": 0.8724564909934998
    },
    {
      "answer": "28.5\u00b0E",
      "score": 0.7858640551567078
    },
    {
      "answer": "28.5\u00b0E",
      "score": 0.9588629007339478
    }
  ],
  "1061": [
    {
      "answer": "Sky Digital",
      "score": 0.9193234443664551
    }
  ],
  "1062": [
    {
      "answer": "Astra 2A",
      "score": 0.9853171110153198
    }
  ],
  "1063": [
    {
      "answer": "hundreds",
      "score": 0.9279939532279968
    }
  ],
  "1064": [
    {
      "answer": "1998",
      "score": 0.9731047749519348
    }
  ],
  "1065": [
    {
      "answer": "22 May 2006",
      "score": 0.9640702605247498
    }
  ],
  "1066": [
    {
      "answer": "40,000",
      "score": 0.984521746635437
    }
  ],
  "1067": [
    {
      "answer": "Thomson",
      "score": 0.9625959396362305
    }
  ],
  "1068": [
    {
      "answer": "17,000",
      "score": 0.9670004844665527
    }
  ],
  "1069": [
    {
      "answer": "4,222,000",
      "score": 0.9626582264900208
    }
  ],
  "1070": [
    {
      "answer": "18 May 2006",
      "score": 0.8355809450149536
    }
  ],
  "1071": [
    {
      "answer": "Thomson",
      "score": 0.9883395433425903
    }
  ],
  "1072": [
    {
      "answer": "17,000",
      "score": 0.978816032409668
    }
  ],
  "1073": [
    {
      "answer": "BBC",
      "score": 0.9809980988502502
    }
  ],
  "1074": [
    {
      "answer": "31 March 2012",
      "score": 0.9924898147583008
    }
  ],
  "1075": [
    {
      "answer": "8 February 2007",
      "score": 0.9536957144737244
    }
  ],
  "1076": [
    {
      "answer": "March",
      "score": 0.9822339415550232
    }
  ],
  "1077": [
    {
      "answer": "digital terrestrial",
      "score": 0.7364605665206909
    },
    {
      "answer": "digital terrestrial",
      "score": 0.9726853966712952
    }
  ],
  "1078": [
    {
      "answer": "Virgin Media",
      "score": 0.9922439455986023
    }
  ],
  "1079": [
    {
      "answer": "English Premier League Football",
      "score": 0.9813575148582458
    }
  ],
  "1080": [
    {
      "answer": "8 February 2007",
      "score": 0.9714509844779968
    }
  ],
  "1081": [
    {
      "answer": "March",
      "score": 0.9832583665847778
    }
  ],
  "1082": [
    {
      "answer": "Freeview",
      "score": 0.9889974594116211
    }
  ],
  "1083": [
    {
      "answer": "Virgin Media",
      "score": 0.782966136932373
    }
  ],
  "1084": [
    {
      "answer": "BSkyB",
      "score": 0.6454057097434998
    },
    {
      "answer": "BSkyB",
      "score": 0.6734973788261414
    },
    {
      "answer": "BSkyB",
      "score": 0.9275631904602051
    }
  ],
  "1085": [
    {
      "answer": "free-to-view",
      "score": 0.7975626587867737
    }
  ],
  "1086": [
    {
      "answer": "VideoGuard UK equipped receiver",
      "score": 0.9300702214241028
    }
  ],
  "1087": [
    {
      "answer": "VideoGuard UK",
      "score": 0.9829772710800171
    }
  ],
  "1088": [
    {
      "answer": "Ku band",
      "score": 0.7430940866470337
    },
    {
      "answer": "9.75/10.600 GHz",
      "score": 0.9462099671363831
    }
  ],
  "1089": [
    {
      "answer": "Sky",
      "score": 0.9574465751647949
    }
  ],
  "1090": [
    {
      "answer": "monthly subscription",
      "score": 0.9822821617126465
    }
  ],
  "1091": [
    {
      "answer": "VideoGuard UK",
      "score": 0.9796139001846313
    }
  ],
  "1092": [
    {
      "answer": "Ku band",
      "score": 0.5518040657043457
    },
    {
      "answer": "9.75/10.600 GHz",
      "score": 0.9397399425506592
    }
  ],
  "1093": [
    {
      "answer": "Sky",
      "score": 0.9394903779029846
    }
  ],
  "1094": [
    {
      "answer": "Ku band",
      "score": 0.8814699649810791
    },
    {
      "answer": "9.75/10.600 GHz",
      "score": 0.8227914571762085
    }
  ],
  "1095": [
    {
      "answer": "autumn of 1991",
      "score": 0.7387056350708008
    }
  ],
  "1096": [
    {
      "answer": "ITV",
      "score": 0.9399383068084717
    }
  ],
  "1097": [
    {
      "answer": "\u00a334m",
      "score": 0.9821057915687561
    }
  ],
  "1098": [
    {
      "answer": "BBC",
      "score": 0.9879932403564453
    }
  ],
  "1099": [
    {
      "answer": "\u00a3304m",
      "score": 0.9688231945037842
    }
  ],
  "1100": [
    {
      "answer": "BSkyB",
      "score": 0.7742447853088379
    },
    {
      "answer": "BSkyB",
      "score": 0.6774148941040039
    }
  ],
  "1101": [
    {
      "answer": "\u00a3304m",
      "score": 0.9837268590927124
    }
  ],
  "1102": [
    {
      "answer": "BSkyB",
      "score": 0.6606814861297607
    },
    {
      "answer": "BBC",
      "score": 0.6869487762451172
    },
    {
      "answer": "BBC",
      "score": 0.7495968341827393
    }
  ],
  "1103": [
    {
      "answer": "ITV",
      "score": 0.9700304269790649
    }
  ],
  "1104": [
    {
      "answer": "Ofcom",
      "score": 0.9895511269569397
    }
  ],
  "1105": [
    {
      "answer": "\u00a315\u2013100,000",
      "score": 0.9858267307281494
    }
  ],
  "1106": [
    {
      "answer": "no",
      "score": 0.9749295711517334
    }
  ],
  "1107": [
    {
      "answer": "BSkyB does not",
      "score": 0.8720871210098267
    }
  ],
  "1108": [
    {
      "answer": "BSkyB does not",
      "score": 0.8523921370506287
    }
  ],
  "1109": [
    {
      "answer": "Ofcom",
      "score": 0.9940804839134216
    }
  ],
  "1110": [
    {
      "answer": "BSkyB",
      "score": 0.9369701743125916
    },
    {
      "answer": "BSkyB",
      "score": 0.830222487449646
    },
    {
      "answer": "BSkyB",
      "score": 0.8184587359428406
    },
    {
      "answer": "BSkyB",
      "score": 0.861110270023346
    }
  ],
  "1111": [
    {
      "answer": "EPG",
      "score": 0.9624837636947632
    }
  ],
  "1112": [
    {
      "answer": "open access",
      "score": 0.7104416489601135
    }
  ],
  "1113": [
    {
      "answer": "1 October 1998",
      "score": 0.8110434412956238
    }
  ],
  "1114": [],
  "1115": [
    {
      "answer": "Sky Active",
      "score": 0.9410642385482788
    }
  ],
  "1116": [
    {
      "answer": "ONdigital",
      "score": 0.9027899503707886
    }
  ],
  "1117": [
    {
      "answer": "100,000",
      "score": 0.9824690222740173
    }
  ],
  "1118": [
    {
      "answer": "1 October 1998",
      "score": 0.5457075834274292
    }
  ],
  "1119": [
    {
      "answer": "100,000 digiboxes",
      "score": 0.7828567028045654
    }
  ],
  "1120": [
    {
      "answer": "100,000",
      "score": 0.9831012487411499
    }
  ],
  "1121": [
    {
      "answer": "May 1999",
      "score": 0.9337714910507202
    }
  ],
  "1122": [
    {
      "answer": "2007",
      "score": 0.9807677865028381
    }
  ],
  "1123": [
    {
      "answer": "Virgin Media",
      "score": 0.9781770706176758
    },
    {
      "answer": "Virgin Media",
      "score": 0.9074525833129883
    },
    {
      "answer": "Virgin Media",
      "score": 0.9326545000076294
    },
    {
      "answer": "Virgin Media",
      "score": 0.9231864213943481
    },
    {
      "answer": "Virgin Media",
      "score": 0.9180521368980408
    }
  ],
  "1124": [
    {
      "answer": "Video On Demand service",
      "score": 0.9899722337722778
    }
  ],
  "1125": [
    {
      "answer": "BBC HD",
      "score": 0.93089759349823
    }
  ],
  "1126": [
    {
      "answer": "Channel 4 HD",
      "score": 0.9741579294204712
    }
  ],
  "1127": [
    {
      "answer": "2007",
      "score": 0.9819155931472778
    }
  ],
  "1128": [
    {
      "answer": "Channel 4 HD",
      "score": 0.717498779296875
    }
  ],
  "1129": [
    {
      "answer": "BBC HD",
      "score": 0.9443176984786987
    }
  ],
  "1130": [
    {
      "answer": "Channel 4 HD",
      "score": 0.7269104719161987
    }
  ],
  "1131": [
    {
      "answer": "10 million",
      "score": 0.9761053323745728
    }
  ],
  "1132": [
    {
      "answer": "more than 25m people",
      "score": 0.9497531652450562
    }
  ],
  "1133": [
    {
      "answer": "August 2004",
      "score": 0.9914414882659912
    }
  ],
  "1134": [
    {
      "answer": "36%",
      "score": 0.9854848384857178
    }
  ],
  "1135": [
    {
      "answer": "flattened",
      "score": 0.9863046407699585
    }
  ],
  "1136": [
    {
      "answer": "10 million",
      "score": 0.9703103303909302
    }
  ],
  "1137": [
    {
      "answer": "25m people",
      "score": 0.8622457981109619
    }
  ],
  "1138": [
    {
      "answer": "36%",
      "score": 0.9800664186477661
    }
  ],
  "1139": [
    {
      "answer": "BSkyB's direct-to-home satellite service",
      "score": 0.8107759356498718
    }
  ],
  "1140": [
    {
      "answer": "Welfare Cash Card",
      "score": 0.985041081905365
    }
  ],
  "1141": [
    {
      "answer": "essentials",
      "score": 0.9724595546722412
    }
  ],
  "1142": [
    {
      "answer": "often damaging",
      "score": 0.9867152571678162
    }
  ],
  "1143": [
    {
      "answer": "Sky TV bills",
      "score": 0.9115095138549805
    }
  ],
  "1144": [
    {
      "answer": "betray a man's presence in the household",
      "score": 0.9581165313720703
    }
  ],
  "1145": [
    {
      "answer": "Welfare Cash Card",
      "score": 0.9627541303634644
    }
  ],
  "1146": [
    {
      "answer": "essentials",
      "score": 0.8991856575012207
    }
  ],
  "1147": [
    {
      "answer": "often damaging",
      "score": 0.9713190793991089
    }
  ],
  "1148": [
    {
      "answer": "subscription to sports channels would betray a man's presence in the household",
      "score": 0.7298509478569031
    }
  ],
  "1149": [
    {
      "answer": "Sky TV",
      "score": 0.9519836902618408
    }
  ],
  "1150": [
    {
      "answer": "\u00a330m",
      "score": 0.9795615673065186
    }
  ],
  "1151": [
    {
      "answer": "no indication",
      "score": 0.940711498260498
    }
  ],
  "1152": [
    {
      "answer": "Virgin Media",
      "score": 0.9907525777816772
    }
  ],
  "1153": [
    {
      "answer": "BSkyB",
      "score": 0.7353746891021729
    },
    {
      "answer": "BSkyB",
      "score": 0.968185305595398
    }
  ],
  "1154": [
    {
      "answer": "carriage of their respective basic channels",
      "score": 0.9571730494499207
    }
  ],
  "1155": [
    {
      "answer": "\u00a330m",
      "score": 0.9031158685684204
    }
  ],
  "1156": [
    {
      "answer": "Virgin Media",
      "score": 0.9889496564865112
    }
  ],
  "1157": [
    {
      "answer": "carriage of their respective basic channels",
      "score": 0.9564424753189087
    }
  ],
  "1158": [
    {
      "answer": "BSkyB",
      "score": 0.8620242476463318
    },
    {
      "answer": "Virgin Media",
      "score": 0.9604559540748596
    }
  ],
  "1159": [
    {
      "answer": "BSkyB",
      "score": 0.9927034378051758
    },
    {
      "answer": "BSkyB",
      "score": 0.8666110634803772
    }
  ],
  "1160": [
    {
      "answer": "highly diversified",
      "score": 0.9580208659172058
    }
  ],
  "1161": [
    {
      "answer": "second",
      "score": 0.9870500564575195
    }
  ],
  "1162": [
    {
      "answer": "fourth",
      "score": 0.9856477975845337
    }
  ],
  "1163": [
    {
      "answer": "Melbourne",
      "score": 0.9840596914291382
    },
    {
      "answer": "Melbourne",
      "score": 0.7959465384483337
    },
    {
      "answer": "Melbourne",
      "score": 0.8925107717514038
    }
  ],
  "1164": [
    {
      "answer": "Melbourne Cricket Ground",
      "score": 0.994412899017334
    }
  ],
  "1165": [
    {
      "answer": "public universities",
      "score": 0.9425647258758545
    }
  ],
  "1166": [
    {
      "answer": "second",
      "score": 0.9737430214881897
    }
  ],
  "1167": [
    {
      "answer": "second",
      "score": 0.9778101444244385
    }
  ],
  "1168": [
    {
      "answer": "Melbourne",
      "score": 0.561109721660614
    },
    {
      "answer": "Melbourne",
      "score": 0.9572803974151611
    },
    {
      "answer": "Melbourne",
      "score": 0.5632655024528503
    }
  ],
  "1169": [
    {
      "answer": "eight",
      "score": 0.9938265681266785
    }
  ],
  "1170": [
    {
      "answer": "Bendigo",
      "score": 0.9957029223442078
    }
  ],
  "1171": [
    {
      "answer": "New South Wales",
      "score": 0.9829511642456055
    }
  ],
  "1172": [
    {
      "answer": "Buckland Valley",
      "score": 0.991909384727478
    },
    {
      "answer": "Buckland Valley",
      "score": 0.884401798248291
    }
  ],
  "1173": [
    {
      "answer": "1,000",
      "score": 0.9889923334121704
    }
  ],
  "1174": [
    {
      "answer": "cramped and unsanitary",
      "score": 0.96463942527771
    }
  ],
  "1175": [
    {
      "answer": "Bendigo",
      "score": 0.9948400855064392
    }
  ],
  "1176": [
    {
      "answer": "Buckland Valley near Bright",
      "score": 0.938961386680603
    },
    {
      "answer": "Buckland Valley",
      "score": 0.6397236585617065
    }
  ],
  "1177": [
    {
      "answer": "Buckland Valley",
      "score": 0.9255658388137817
    },
    {
      "answer": "Buckland Valley",
      "score": 0.7289183139801025
    }
  ],
  "1178": [
    {
      "answer": "1,000",
      "score": 0.9807747602462769
    }
  ],
  "1179": [
    {
      "answer": "cramped and unsanitary",
      "score": 0.9747719764709473
    }
  ],
  "1180": [
    {
      "answer": "multi-member proportional representation",
      "score": 0.9854890704154968
    }
  ],
  "1181": [
    {
      "answer": "eight",
      "score": 0.9917451739311218
    }
  ],
  "1182": [
    {
      "answer": "five",
      "score": 0.9942677021026611
    }
  ],
  "1183": [
    {
      "answer": "four years",
      "score": 0.9860197305679321
    },
    {
      "answer": "four years",
      "score": 0.8934429883956909
    }
  ],
  "1184": [
    {
      "answer": "four years",
      "score": 0.7300724983215332
    },
    {
      "answer": "four years",
      "score": 0.9790964126586914
    }
  ],
  "1185": [
    {
      "answer": "eight",
      "score": 0.9396286606788635
    }
  ],
  "1186": [
    {
      "answer": "five",
      "score": 0.9910286068916321
    }
  ],
  "1187": [
    {
      "answer": "four years",
      "score": 0.939810037612915
    },
    {
      "answer": "four years",
      "score": 0.9030610918998718
    }
  ],
  "1188": [
    {
      "answer": "November",
      "score": 0.899341881275177
    },
    {
      "answer": "November",
      "score": 0.9475314617156982
    }
  ],
  "1189": [
    {
      "answer": "Labor",
      "score": 0.8573770523071289
    },
    {
      "answer": "Labor",
      "score": 0.9764155745506287
    }
  ],
  "1190": [
    {
      "answer": "The Liberals",
      "score": 0.7995718121528625
    },
    {
      "answer": "The Greens",
      "score": 0.6387326121330261
    }
  ],
  "1191": [
    {
      "answer": "Nationals",
      "score": 0.9972314238548279
    }
  ],
  "1192": [
    {
      "answer": "Greens",
      "score": 0.989277720451355
    }
  ],
  "1193": [
    {
      "answer": "Labor",
      "score": 0.6939716339111328
    },
    {
      "answer": "Labor",
      "score": 0.7690325379371643
    },
    {
      "answer": "The Nationals",
      "score": 0.6576907634735107
    }
  ],
  "1194": [
    {
      "answer": "Nationals",
      "score": 0.8824520111083984
    }
  ],
  "1195": [
    {
      "answer": "Greens",
      "score": 0.9903372526168823
    }
  ],
  "1196": [
    {
      "answer": "Nationals",
      "score": 0.9879563450813293
    }
  ],
  "1197": [
    {
      "answer": "Greens",
      "score": 0.9771626591682434
    }
  ],
  "1198": [
    {
      "answer": "Nationals",
      "score": 0.9962884187698364
    }
  ],
  "1199": [
    {
      "answer": "61.1%",
      "score": 0.9909772276878357
    }
  ],
  "1200": [
    {
      "answer": "61.1%",
      "score": 0.9312978982925415
    }
  ],
  "1201": [
    {
      "answer": "Buddhism",
      "score": 0.9940527081489563
    }
  ],
  "1202": [
    {
      "answer": "168,637",
      "score": 0.9866229295730591
    }
  ],
  "1203": [
    {
      "answer": "20%",
      "score": 0.9542433023452759
    }
  ],
  "1204": [
    {
      "answer": "61.1%",
      "score": 0.9254665374755859
    }
  ],
  "1205": [],
  "1206": [
    {
      "answer": "Christian",
      "score": 0.9506486058235168
    }
  ],
  "1207": [
    {
      "answer": "168,637",
      "score": 0.8868789076805115
    }
  ],
  "1208": [
    {
      "answer": "152,775",
      "score": 0.9767948389053345
    }
  ],
  "1209": [
    {
      "answer": "south-east",
      "score": 0.9347254037857056
    }
  ],
  "1210": [
    {
      "answer": "most densely populated state",
      "score": 0.9420236349105835
    }
  ],
  "1211": [
    {
      "answer": "second-most populous state overall",
      "score": 0.8596941232681274
    }
  ],
  "1212": [
    {
      "answer": "Melbourne",
      "score": 0.980599582195282
    }
  ],
  "1213": [],
  "1214": [],
  "1215": [
    {
      "answer": "second-largest city",
      "score": 0.9337852001190186
    }
  ],
  "1216": [],
  "1217": [
    {
      "answer": "Melbourne",
      "score": 0.9836663007736206
    }
  ],
  "1218": [],
  "1219": [
    {
      "answer": "Koori",
      "score": 0.9865662455558777
    }
  ],
  "1220": [
    {
      "answer": "1788",
      "score": 0.9919813275337219
    }
  ],
  "1221": [
    {
      "answer": "Sullivan Bay",
      "score": 0.9926623106002808
    }
  ],
  "1222": [
    {
      "answer": "Sullivan Bay",
      "score": 0.9968328475952148
    }
  ],
  "1223": [
    {
      "answer": "1803",
      "score": 0.988135576248169
    }
  ],
  "1224": [
    {
      "answer": "Koori",
      "score": 0.9680877327919006
    }
  ],
  "1225": [
    {
      "answer": "1788",
      "score": 0.9845151901245117
    }
  ],
  "1226": [
    {
      "answer": "Sullivan Bay",
      "score": 0.9384123086929321
    }
  ],
  "1227": [
    {
      "answer": "Sullivan Bay",
      "score": 0.9862605333328247
    }
  ],
  "1228": [
    {
      "answer": "1927",
      "score": 0.9751136302947998
    }
  ],
  "1229": [
    {
      "answer": "26,000 square kilometres",
      "score": 0.9695929884910583
    }
  ],
  "1230": [
    {
      "answer": "50%",
      "score": 0.9742643237113953
    }
  ],
  "1231": [
    {
      "answer": "6,000 square kilometres",
      "score": 0.9769408106803894
    }
  ],
  "1232": [
    {
      "answer": "121,200 tonnes",
      "score": 0.9824080467224121
    }
  ],
  "1233": [
    {
      "answer": "270,000",
      "score": 0.9796778559684753
    }
  ],
  "1234": [
    {
      "answer": "6,000 square kilometres",
      "score": 0.9214932322502136
    }
  ],
  "1235": [
    {
      "answer": "More than 50%",
      "score": 0.7179763317108154
    }
  ],
  "1236": [
    {
      "answer": "More than 26,000 square kilometres",
      "score": 0.7974895238876343
    }
  ],
  "1237": [
    {
      "answer": "90%",
      "score": 0.7539012432098389
    },
    {
      "answer": "121,200 tonnes",
      "score": 0.6870532035827637
    }
  ],
  "1238": [
    {
      "answer": "270,000",
      "score": 0.9526473879814148
    }
  ],
  "1239": [
    {
      "answer": "1975",
      "score": 0.9861335158348083
    }
  ],
  "1240": [
    {
      "answer": "1855 colonial constitution",
      "score": 0.9854690432548523
    }
  ],
  "1241": [
    {
      "answer": "Parliament of Victoria",
      "score": 0.9852192401885986
    }
  ],
  "1242": [
    {
      "answer": "certain \"entrenched\" provisions",
      "score": 0.8685159683227539
    }
  ],
  "1243": [
    {
      "answer": "Victoria Constitution Act 1855",
      "score": 0.962395966053009
    }
  ],
  "1244": [
    {
      "answer": "1855",
      "score": 0.7691425085067749
    },
    {
      "answer": "1855",
      "score": 0.7743738889694214
    }
  ],
  "1245": [
    {
      "answer": "1855 colonial constitution",
      "score": 0.9773073196411133
    }
  ],
  "1246": [
    {
      "answer": "Parliament of Victoria",
      "score": 0.9211599826812744
    }
  ],
  "1247": [
    {
      "answer": "certain \"entrenched\" provisions",
      "score": 0.9119212031364441
    }
  ],
  "1248": [
    {
      "answer": "Victoria Constitution Act 1855",
      "score": 0.9367872476577759
    }
  ],
  "1249": [
    {
      "answer": "hot winds",
      "score": 0.8451405763626099
    }
  ],
  "1250": [
    {
      "answer": "32 \u00b0C",
      "score": 0.986712634563446
    }
  ],
  "1251": [
    {
      "answer": "32 \u00b0C (90 \u00b0F)",
      "score": 0.7684284448623657
    },
    {
      "answer": "15 \u00b0C (59 \u00b0F)",
      "score": 0.8494184613227844
    }
  ],
  "1252": [
    {
      "answer": "48.8 \u00b0C",
      "score": 0.9772585034370422
    }
  ],
  "1253": [
    {
      "answer": "7 February 2009",
      "score": 0.9746135473251343
    }
  ],
  "1254": [
    {
      "answer": "cool",
      "score": 0.8031514286994934
    }
  ],
  "1255": [
    {
      "answer": "15 \u00b0C",
      "score": 0.9732179641723633
    }
  ],
  "1256": [
    {
      "answer": "32 \u00b0C",
      "score": 0.945467472076416
    }
  ],
  "1257": [
    {
      "answer": "32 \u00b0C",
      "score": 0.7343677878379822
    }
  ],
  "1258": [
    {
      "answer": "7 February 2009",
      "score": 0.9694535732269287
    }
  ],
  "1259": [],
  "1260": [
    {
      "answer": "Victoria Department of Education",
      "score": 0.9947087168693542
    }
  ],
  "1261": [
    {
      "answer": "some extra costs",
      "score": 0.9762365221977234
    }
  ],
  "1262": [
    {
      "answer": "Roman Catholic",
      "score": 0.996219277381897
    }
  ],
  "1263": [
    {
      "answer": "government-set curriculum standards",
      "score": 0.9786021709442139
    }
  ],
  "1264": [],
  "1265": [
    {
      "answer": "Victoria Department of Education",
      "score": 0.6682133674621582
    }
  ],
  "1266": [
    {
      "answer": "some extra costs are levied",
      "score": 0.8984633684158325
    }
  ],
  "1267": [
    {
      "answer": "Roman Catholic",
      "score": 0.9755572080612183
    }
  ],
  "1268": [
    {
      "answer": "curriculum standards",
      "score": 0.9455658197402954
    }
  ],
  "1269": [
    {
      "answer": "car",
      "score": 0.6267933249473572
    }
  ],
  "1270": [
    {
      "answer": "February 2014",
      "score": 0.9559134244918823
    }
  ],
  "1271": [
    {
      "answer": "May 2013",
      "score": 0.9862641096115112
    }
  ],
  "1272": [
    {
      "answer": "October 2016",
      "score": 0.9777852892875671
    }
  ],
  "1273": [
    {
      "answer": "Ford",
      "score": 0.8231474161148071
    }
  ],
  "1274": [],
  "1275": [
    {
      "answer": "February 2014",
      "score": 0.9892644882202148
    }
  ],
  "1276": [
    {
      "answer": "May 2013",
      "score": 0.9882874488830566
    }
  ],
  "1277": [
    {
      "answer": "2017",
      "score": 0.9188533425331116
    }
  ],
  "1278": [
    {
      "answer": "Ford",
      "score": 0.8290180563926697
    }
  ],
  "1279": [
    {
      "answer": "2,000 m",
      "score": 0.9838278293609619
    }
  ],
  "1280": [
    {
      "answer": "Mount Bogong",
      "score": 0.9946552515029907
    }
  ],
  "1281": [
    {
      "answer": "1,986 m",
      "score": 0.9873909950256348
    }
  ],
  "1282": [
    {
      "answer": "wet, temperate climate of Gippsland",
      "score": 0.7095610499382019
    },
    {
      "answer": "snow-covered Victorian alpine areas",
      "score": 0.8339619040489197
    },
    {
      "answer": "semi-arid plains",
      "score": 0.8686599731445312
    }
  ],
  "1283": [
    {
      "answer": "helmeted honeyeater",
      "score": 0.9735424518585205
    }
  ],
  "1284": [
    {
      "answer": "2,000 m",
      "score": 0.9744385480880737
    }
  ],
  "1285": [
    {
      "answer": "Mount Bogong",
      "score": 0.9914358854293823
    }
  ],
  "1286": [
    {
      "answer": "1,986 m",
      "score": 0.9801990985870361
    }
  ],
  "1287": [],
  "1288": [
    {
      "answer": "Victorian",
      "score": 0.6892242431640625
    }
  ],
  "1289": [
    {
      "answer": "Victorian Alps in the northeast",
      "score": 0.9315943717956543
    }
  ],
  "1290": [
    {
      "answer": "Great Dividing Range",
      "score": 0.995717465877533
    }
  ],
  "1291": [
    {
      "answer": "east-west",
      "score": 0.9924957752227783
    }
  ],
  "1292": [
    {
      "answer": "0 \u00b0C",
      "score": 0.9669169187545776
    }
  ],
  "1293": [
    {
      "answer": "\u221211.7 \u00b0C",
      "score": 0.9804961085319519
    }
  ],
  "1294": [
    {
      "answer": "northeast",
      "score": 0.9266493320465088
    }
  ],
  "1295": [
    {
      "answer": "Great Dividing Range",
      "score": 0.9903358221054077
    }
  ],
  "1296": [
    {
      "answer": "east-west",
      "score": 0.7805231809616089
    }
  ],
  "1297": [
    {
      "answer": "less than 9 \u00b0C",
      "score": 0.8356795310974121
    }
  ],
  "1298": [
    {
      "answer": "\u221211.7 \u00b0C (10.9 \u00b0F)",
      "score": 0.8730157017707825
    }
  ],
  "1299": [
    {
      "answer": "government-owned",
      "score": 0.8749569654464722
    },
    {
      "answer": "Victorian Government",
      "score": 0.6617470979690552
    }
  ],
  "1300": [
    {
      "answer": "Metro Trains Melbourne",
      "score": 0.7713533639907837
    },
    {
      "answer": "The Overland Melbourne\u2014Adelaide",
      "score": 0.8334956169128418
    }
  ],
  "1301": [
    {
      "answer": "Victorian Government",
      "score": 0.9962480068206787
    }
  ],
  "1302": [
    {
      "answer": "freight",
      "score": 0.9846523404121399
    }
  ],
  "1303": [
    {
      "answer": "electrified",
      "score": 0.9736968874931335
    }
  ],
  "1304": [
    {
      "answer": "V/Line",
      "score": 0.5593830943107605
    },
    {
      "answer": "Victorian Government",
      "score": 0.830936074256897
    }
  ],
  "1305": [
    {
      "answer": "The Overland Melbourne\u2014Adelaide",
      "score": 0.8306525349617004
    }
  ],
  "1306": [],
  "1307": [
    {
      "answer": "Pacific National",
      "score": 0.9769425392150879
    },
    {
      "answer": "CFCL Australia",
      "score": 0.8989957571029663
    }
  ],
  "1308": [
    {
      "answer": "Metro Trains Melbourne",
      "score": 0.8926945924758911
    },
    {
      "answer": "V/Line",
      "score": 0.7209276556968689
    },
    {
      "answer": "Great Southern Rail",
      "score": 0.5799148082733154
    }
  ],
  "1309": [
    {
      "answer": "37",
      "score": 0.9937993884086609
    }
  ],
  "1310": [
    {
      "answer": "12",
      "score": 0.9933944344520569
    }
  ],
  "1311": [
    {
      "answer": "Legislative Assembly",
      "score": 0.9946937561035156
    }
  ],
  "1312": [
    {
      "answer": "Legislative Council",
      "score": 0.9960048198699951
    }
  ],
  "1313": [
    {
      "answer": "Linda Dessau",
      "score": 0.9949795007705688
    }
  ],
  "1314": [
    {
      "answer": "37",
      "score": 0.9943986535072327
    }
  ],
  "1315": [
    {
      "answer": "12",
      "score": 0.994025707244873
    }
  ],
  "1316": [
    {
      "answer": "Legislative Assembly",
      "score": 0.9860811233520508
    }
  ],
  "1317": [
    {
      "answer": "Legislative Council",
      "score": 0.9935787916183472
    }
  ],
  "1318": [
    {
      "answer": "Linda Dessau",
      "score": 0.980736494064331
    }
  ],
  "1319": [
    {
      "answer": "1 July 1851",
      "score": 0.987606406211853
    }
  ],
  "1320": [
    {
      "answer": "1851",
      "score": 0.7850620746612549
    },
    {
      "answer": "1851",
      "score": 0.9237863421440125
    },
    {
      "answer": "1851",
      "score": 0.8055012822151184
    }
  ],
  "1321": [
    {
      "answer": "triggered one of the largest gold rushes the world has ever seen",
      "score": 0.9401912093162537
    }
  ],
  "1322": [
    {
      "answer": "540,000",
      "score": 0.8968539237976074
    }
  ],
  "1323": [
    {
      "answer": "20 million ounces",
      "score": 0.9832522869110107
    }
  ],
  "1324": [
    {
      "answer": "1 July 1851",
      "score": 0.9714233875274658
    }
  ],
  "1325": [
    {
      "answer": "1851",
      "score": 0.8798574805259705
    },
    {
      "answer": "1851",
      "score": 0.7492696046829224
    },
    {
      "answer": "1851",
      "score": 0.8220415115356445
    }
  ],
  "1326": [
    {
      "answer": "one of the largest gold rushes",
      "score": 0.9253182411193848
    }
  ],
  "1327": [],
  "1328": [
    {
      "answer": "20 million ounces",
      "score": 0.9616340398788452
    }
  ],
  "1329": [
    {
      "answer": "1,548",
      "score": 0.9677318930625916
    }
  ],
  "1330": [
    {
      "answer": "489",
      "score": 0.9920873045921326
    }
  ],
  "1331": [
    {
      "answer": "540,800",
      "score": 0.9519495964050293
    }
  ],
  "1332": [
    {
      "answer": "63,519",
      "score": 0.9765686988830566
    }
  ],
  "1333": [
    {
      "answer": "61",
      "score": 0.9945853352546692
    }
  ],
  "1334": [
    {
      "answer": "1,548",
      "score": 0.9220878481864929
    }
  ],
  "1335": [
    {
      "answer": "489",
      "score": 0.9908932447433472
    }
  ],
  "1336": [
    {
      "answer": "540,800",
      "score": 0.9670445919036865
    }
  ],
  "1337": [
    {
      "answer": "63,519",
      "score": 0.8059026002883911
    }
  ],
  "1338": [
    {
      "answer": "61",
      "score": 0.9856091141700745
    }
  ],
  "1339": [
    {
      "answer": "Victoria",
      "score": 0.9576236605644226
    }
  ],
  "1340": [
    {
      "answer": "3 million",
      "score": 0.9882373809814453
    }
  ],
  "1341": [
    {
      "answer": "60%",
      "score": 0.9913302659988403
    }
  ],
  "1342": [
    {
      "answer": "6.4 billion litres",
      "score": 0.989672839641571
    }
  ],
  "1343": [
    {
      "answer": "Asia",
      "score": 0.9968745708465576
    }
  ],
  "1344": [
    {
      "answer": "Victoria",
      "score": 0.9561924934387207
    }
  ],
  "1345": [
    {
      "answer": "3 million",
      "score": 0.9794811010360718
    }
  ],
  "1346": [
    {
      "answer": "60%",
      "score": 0.9906046390533447
    }
  ],
  "1347": [
    {
      "answer": "60%",
      "score": 0.988654613494873
    }
  ],
  "1348": [
    {
      "answer": "Asia",
      "score": 0.9964572787284851
    }
  ],
  "1349": [
    {
      "answer": "1,600 mm (5 ft 3 in)",
      "score": 0.96050626039505
    }
  ],
  "1350": [
    {
      "answer": "standard gauge",
      "score": 0.9509270191192627
    }
  ],
  "1351": [
    {
      "answer": "narrow gauge",
      "score": 0.9633608460426331
    }
  ],
  "1352": [
    {
      "answer": "mountainous areas",
      "score": 0.8942254781723022
    }
  ],
  "1353": [
    {
      "answer": "five",
      "score": 0.9896027445793152
    }
  ],
  "1354": [
    {
      "answer": "1,600 mm (5 ft 3 in)",
      "score": 0.9563706517219543
    }
  ],
  "1355": [
    {
      "answer": "standard gauge",
      "score": 0.9640102386474609
    }
  ],
  "1356": [
    {
      "answer": "1,600 mm (5 ft 3 in) broad gauge",
      "score": 0.6544901728630066
    },
    {
      "answer": "760 mm (2 ft 6 in) narrow gauge",
      "score": 0.7812942862510681
    }
  ],
  "1357": [
    {
      "answer": "west",
      "score": 0.8380150198936462
    }
  ],
  "1358": [
    {
      "answer": "five",
      "score": 0.9861690998077393
    }
  ],
  "1359": [
    {
      "answer": "1788",
      "score": 0.96377032995224
    }
  ],
  "1360": [
    {
      "answer": "New South Wales",
      "score": 0.8816426992416382
    },
    {
      "answer": "New South Wales",
      "score": 0.9426158666610718
    }
  ],
  "1361": [
    {
      "answer": "New Holland",
      "score": 0.993919849395752
    }
  ],
  "1362": [
    {
      "answer": "Sydney",
      "score": 0.9860681295394897
    }
  ],
  "1363": [
    {
      "answer": "October 1803",
      "score": 0.986734926700592
    }
  ],
  "1364": [
    {
      "answer": "New Holland",
      "score": 0.9944589734077454
    }
  ],
  "1365": [
    {
      "answer": "Sydney",
      "score": 0.9883435964584351
    }
  ],
  "1366": [
    {
      "answer": "French",
      "score": 0.9931332468986511
    }
  ],
  "1367": [
    {
      "answer": "1854",
      "score": 0.9771839380264282
    }
  ],
  "1368": [
    {
      "answer": "Eureka Stockade",
      "score": 0.9812384843826294
    }
  ],
  "1369": [
    {
      "answer": "British troops",
      "score": 0.9910625219345093
    }
  ],
  "1370": [
    {
      "answer": "mining licence fees",
      "score": 0.9915558099746704
    }
  ],
  "1371": [
    {
      "answer": "Colony of Victoria Act 1855",
      "score": 0.993316650390625
    }
  ],
  "1372": [
    {
      "answer": "1854",
      "score": 0.9669567346572876
    }
  ],
  "1373": [
    {
      "answer": "miners",
      "score": 0.9663048982620239
    }
  ],
  "1374": [
    {
      "answer": "mining licence fees",
      "score": 0.9900340437889099
    }
  ],
  "1375": [
    {
      "answer": "members of the Victorian Parliament",
      "score": 0.9950920939445496
    }
  ],
  "1376": [
    {
      "answer": "miners",
      "score": 0.9899598360061646
    }
  ],
  "1377": [
    {
      "answer": "leader of the political party or coalition with the most seats",
      "score": 0.8972125053405762
    }
  ],
  "1378": [
    {
      "answer": "cabinet",
      "score": 0.8229442238807678
    },
    {
      "answer": "Cabinet",
      "score": 0.6054673194885254
    }
  ],
  "1379": [
    {
      "answer": "representatives elected to either house of parliament",
      "score": 0.8376327753067017
    }
  ],
  "1380": [
    {
      "answer": "Daniel Andrews",
      "score": 0.9933212995529175
    }
  ],
  "1381": [
    {
      "answer": "Cabinet consists of representatives elected to either house of parliament",
      "score": 0.9813410639762878
    }
  ],
  "1382": [],
  "1383": [
    {
      "answer": "cabinet",
      "score": 0.8466904163360596
    },
    {
      "answer": "Cabinet",
      "score": 0.605332612991333
    }
  ],
  "1384": [
    {
      "answer": "Daniel Andrews",
      "score": 0.9812079668045044
    }
  ],
  "1385": [
    {
      "answer": "Daniel Andrews",
      "score": 0.7258694171905518
    }
  ],
  "1386": [
    {
      "answer": "Cabinet consists of representatives elected to either house of parliament",
      "score": 0.9347448348999023
    }
  ],
  "1387": [
    {
      "answer": "$8.7 billion",
      "score": 0.9328118562698364
    }
  ],
  "1388": [
    {
      "answer": "17%",
      "score": 0.988484799861908
    }
  ],
  "1389": [
    {
      "answer": "32,463",
      "score": 0.9917689561843872
    }
  ],
  "1390": [
    {
      "answer": "136,000 square kilometres",
      "score": 0.9774923324584961
    }
  ],
  "1391": [
    {
      "answer": "60%",
      "score": 0.9747196435928345
    }
  ],
  "1392": [
    {
      "answer": "17%",
      "score": 0.8252658843994141
    },
    {
      "answer": "$8.7 billion",
      "score": 0.8561027646064758
    }
  ],
  "1393": [
    {
      "answer": "17%",
      "score": 0.9865565299987793
    }
  ],
  "1394": [
    {
      "answer": "32,463",
      "score": 0.9842528700828552
    }
  ],
  "1395": [
    {
      "answer": "A quarter",
      "score": 0.7731497287750244
    }
  ],
  "1396": [
    {
      "answer": "A quarter",
      "score": 0.9674043655395508
    }
  ],
  "1397": [
    {
      "answer": "cultural tourism",
      "score": 0.8908520340919495
    }
  ],
  "1398": [
    {
      "answer": "Australian Motorcycle Grand Prix",
      "score": 0.9230408668518066
    },
    {
      "answer": "Grand Annual Steeplechase at Warrnambool",
      "score": 0.7168486714363098
    },
    {
      "answer": "Australian International Airshow",
      "score": 0.8576271533966064
    }
  ],
  "1399": [
    {
      "answer": "Melbourne",
      "score": 0.9914235472679138
    }
  ],
  "1400": [
    {
      "answer": "Phillip Island",
      "score": 0.9087538719177246
    },
    {
      "answer": "Geelong",
      "score": 0.7921692132949829
    }
  ],
  "1401": [
    {
      "answer": "SurfClassic",
      "score": 0.9628732800483704
    }
  ],
  "1402": [],
  "1403": [
    {
      "answer": "V8 Supercars",
      "score": 0.9436748027801514
    }
  ],
  "1404": [
    {
      "answer": "Phillip Island",
      "score": 0.8579691648483276
    }
  ],
  "1405": [
    {
      "answer": "Phillip Island",
      "score": 0.93402498960495
    },
    {
      "answer": "Warrnambool",
      "score": 0.7020410299301147
    },
    {
      "answer": "Geelong",
      "score": 0.6792649626731873
    }
  ],
  "1406": [
    {
      "answer": "Port Fairy Folk Festival",
      "score": 0.7691608667373657
    }
  ],
  "1407": [
    {
      "answer": "southern and central parts of France",
      "score": 0.9522111415863037
    }
  ],
  "1408": [
    {
      "answer": "one-eighth",
      "score": 0.9830795526504517
    }
  ],
  "1409": [
    {
      "answer": "1562",
      "score": 0.9590920209884644
    },
    {
      "answer": "1598",
      "score": 0.9492304921150208
    }
  ],
  "1410": [
    {
      "answer": "Edict of Nantes",
      "score": 0.9951462149620056
    }
  ],
  "1411": [
    {
      "answer": "Edict of Nantes",
      "score": 0.6751601696014404
    },
    {
      "answer": "granted the Huguenots substantial religious, political and military autonomy",
      "score": 0.9450531005859375
    }
  ],
  "1412": [
    {
      "answer": "1562",
      "score": 0.9343324899673462
    },
    {
      "answer": "1562",
      "score": 0.9394640326499939
    }
  ],
  "1413": [
    {
      "answer": "southern and central parts",
      "score": 0.9659428596496582
    }
  ],
  "1414": [
    {
      "answer": "Catholic",
      "score": 0.8884766101837158
    }
  ],
  "1415": [
    {
      "answer": "two million",
      "score": 0.6780480146408081
    }
  ],
  "1416": [],
  "1417": [],
  "1418": [
    {
      "answer": "Besan\u00e7on Hugues",
      "score": 0.9885042905807495
    }
  ],
  "1419": [
    {
      "answer": "Geneva",
      "score": 0.9859746098518372
    },
    {
      "answer": "Geneva",
      "score": 0.8980966210365295
    },
    {
      "answer": "Geneva",
      "score": 0.8676402568817139
    }
  ],
  "1420": [
    {
      "answer": "Huguenot",
      "score": 0.5304441452026367
    },
    {
      "answer": "Huguenot",
      "score": 0.658535361289978
    },
    {
      "answer": "Amboise plot",
      "score": 0.8436554074287415
    },
    {
      "answer": "Huguenot",
      "score": 0.6005549430847168
    }
  ],
  "1421": [
    {
      "answer": "1560",
      "score": 0.9921543002128601
    }
  ],
  "1422": [
    {
      "answer": "1532",
      "score": 0.9935124516487122
    }
  ],
  "1423": [
    {
      "answer": "Huguenot",
      "score": 0.6469259262084961
    },
    {
      "answer": "Huguenot",
      "score": 0.6844092011451721
    },
    {
      "answer": "Huguenot",
      "score": 0.5737784504890442
    }
  ],
  "1424": [
    {
      "answer": "Geneva",
      "score": 0.9149250984191895
    },
    {
      "answer": "Geneva",
      "score": 0.877029299736023
    },
    {
      "answer": "Geneva",
      "score": 0.8863544464111328
    }
  ],
  "1425": [
    {
      "answer": "Huguenot",
      "score": 0.5838577151298523
    }
  ],
  "1426": [
    {
      "answer": "1560",
      "score": 0.9945144653320312
    }
  ],
  "1427": [
    {
      "answer": "availability of the Bible in vernacular languages",
      "score": 0.9712694883346558
    }
  ],
  "1428": [
    {
      "answer": "1294",
      "score": 0.9946432113647461
    }
  ],
  "1429": [
    {
      "answer": "Guyard de Moulin",
      "score": 0.6879331469535828
    },
    {
      "answer": "Jean de R\u00e9ly",
      "score": 0.9578256607055664
    }
  ],
  "1430": [
    {
      "answer": "1487",
      "score": 0.9947354197502136
    }
  ],
  "1431": [
    {
      "answer": "Paris",
      "score": 0.9968485236167908
    }
  ],
  "1432": [
    {
      "answer": "1294",
      "score": 0.9928780198097229
    }
  ],
  "1433": [
    {
      "answer": "France",
      "score": 0.9905647039413452
    }
  ],
  "1434": [
    {
      "answer": "1294",
      "score": 0.9918228983879089
    }
  ],
  "1435": [
    {
      "answer": "France",
      "score": 0.9374769926071167
    }
  ],
  "1436": [
    {
      "answer": "France",
      "score": 0.9330875277519226
    }
  ],
  "1437": [
    {
      "answer": "villes de s\u00fbret\u00e9",
      "score": 0.9583665132522583
    }
  ],
  "1438": [
    {
      "answer": "Montpellier",
      "score": 0.990532398223877
    }
  ],
  "1439": [
    {
      "answer": "1622",
      "score": 0.9954686164855957
    }
  ],
  "1440": [
    {
      "answer": "Edict of Al\u00e8s",
      "score": 0.9702174663543701
    }
  ],
  "1441": [
    {
      "answer": "1598",
      "score": 0.6499154567718506
    },
    {
      "answer": "1622",
      "score": 0.933266818523407
    }
  ],
  "1442": [
    {
      "answer": "The city's political institutions and the university were all handed over to the Huguenots",
      "score": 0.7831121683120728
    }
  ],
  "1443": [],
  "1444": [],
  "1445": [
    {
      "answer": "1622",
      "score": 0.9940351843833923
    }
  ],
  "1446": [
    {
      "answer": "1622",
      "score": 0.9951817393302917
    }
  ],
  "1447": [
    {
      "answer": "Cape of Good Hope",
      "score": 0.9157307147979736
    },
    {
      "answer": "Cape of Good Hope",
      "score": 0.9606105089187622
    },
    {
      "answer": "Cape of Good Hope",
      "score": 0.956337034702301
    }
  ],
  "1448": [
    {
      "answer": "Cape Town",
      "score": 0.9828858375549316
    }
  ],
  "1449": [
    {
      "answer": "Maria de la Queillerie",
      "score": 0.992766261100769
    }
  ],
  "1450": [
    {
      "answer": "Dutch East India Company",
      "score": 0.9908809661865234
    }
  ],
  "1451": [
    {
      "answer": "1700",
      "score": 0.9923089742660522
    }
  ],
  "1452": [
    {
      "answer": "1671",
      "score": 0.9641170501708984
    }
  ],
  "1453": [
    {
      "answer": "Walloon church minister",
      "score": 0.9479168653488159
    }
  ],
  "1454": [
    {
      "answer": "seven",
      "score": 0.7375934720039368
    }
  ],
  "1455": [
    {
      "answer": "Cape Town",
      "score": 0.9733352065086365
    }
  ],
  "1456": [
    {
      "answer": "Walloon church minister",
      "score": 0.9860658049583435
    }
  ],
  "1457": [
    {
      "answer": "1624",
      "score": 0.9921759963035583
    }
  ],
  "1458": [
    {
      "answer": "Jess\u00e9 de Forest",
      "score": 0.996691107749939
    }
  ],
  "1459": [
    {
      "answer": "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam",
      "score": 0.9680116176605225
    }
  ],
  "1460": [
    {
      "answer": "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam",
      "score": 0.7227733135223389
    },
    {
      "answer": "L'Eglise du Saint-Esprit",
      "score": 0.8373557329177856
    }
  ],
  "1461": [
    {
      "answer": "Brooklyn",
      "score": 0.9502661824226379
    }
  ],
  "1462": [
    {
      "answer": "New York and New Jersey",
      "score": 0.9216665625572205
    }
  ],
  "1463": [
    {
      "answer": "1624",
      "score": 0.776494026184082
    }
  ],
  "1464": [
    {
      "answer": "New France",
      "score": 0.8557045459747314
    },
    {
      "answer": "New Netherland",
      "score": 0.6048297882080078
    }
  ],
  "1465": [
    {
      "answer": "Nova Scotia",
      "score": 0.9684836864471436
    }
  ],
  "1466": [
    {
      "answer": "1624",
      "score": 0.9928624033927917
    }
  ],
  "1467": [
    {
      "answer": "Charleston",
      "score": 0.8623138666152954
    }
  ],
  "1468": [
    {
      "answer": "Charleston",
      "score": 0.6284342408180237
    },
    {
      "answer": "Charleston",
      "score": 0.9090748429298401
    }
  ],
  "1469": [
    {
      "answer": "1697",
      "score": 0.9883097410202026
    }
  ],
  "1470": [
    {
      "answer": "Edmund Bellinger",
      "score": 0.9838083982467651
    }
  ],
  "1471": [
    {
      "answer": "Pons",
      "score": 0.9895078539848328
    }
  ],
  "1472": [
    {
      "answer": "Orsement",
      "score": 0.9285361170768738
    }
  ],
  "1473": [
    {
      "answer": "Suffolk",
      "score": 0.9839562773704529
    }
  ],
  "1474": [
    {
      "answer": "1685",
      "score": 0.9850903749465942
    },
    {
      "answer": "1685",
      "score": 0.9171949625015259
    }
  ],
  "1475": [
    {
      "answer": "1685",
      "score": 0.9564398527145386
    },
    {
      "answer": "1685",
      "score": 0.9360409379005432
    }
  ],
  "1476": [
    {
      "answer": "1685",
      "score": 0.9816545248031616
    },
    {
      "answer": "1685",
      "score": 0.9255892634391785
    }
  ],
  "1477": [
    {
      "answer": "William III of Orange",
      "score": 0.9936949014663696
    }
  ],
  "1478": [
    {
      "answer": "King of England",
      "score": 0.9846868515014648
    }
  ],
  "1479": [
    {
      "answer": "League of Augsburg",
      "score": 0.9968435168266296
    }
  ],
  "1480": [
    {
      "answer": "Dutch Republic",
      "score": 0.9729727506637573
    },
    {
      "answer": "Dutch Republic",
      "score": 0.9914905428886414
    }
  ],
  "1481": [
    {
      "answer": "1672",
      "score": 0.9950569868087769
    }
  ],
  "1482": [
    {
      "answer": "1672",
      "score": 0.9932233095169067
    }
  ],
  "1483": [
    {
      "answer": "French",
      "score": 0.6947594285011292
    },
    {
      "answer": "French",
      "score": 0.8585036396980286
    },
    {
      "answer": "French-speaking",
      "score": 0.8811153173446655
    }
  ],
  "1484": [
    {
      "answer": "French",
      "score": 0.5734076499938965
    },
    {
      "answer": "French",
      "score": 0.7725591063499451
    },
    {
      "answer": "French-speaking",
      "score": 0.9127799272537231
    }
  ],
  "1485": [
    {
      "answer": "1672",
      "score": 0.9895150661468506
    }
  ],
  "1486": [
    {
      "answer": "Edict of Fontainebleau",
      "score": 0.9959167242050171
    }
  ],
  "1487": [
    {
      "answer": "1685",
      "score": 0.9824509024620056
    }
  ],
  "1488": [
    {
      "answer": "Louis XIV",
      "score": 0.9911612868309021
    }
  ],
  "1489": [
    {
      "answer": "500,000",
      "score": 0.9926960468292236
    }
  ],
  "1490": [
    {
      "answer": "1620s",
      "score": 0.9840853214263916
    }
  ],
  "1491": [
    {
      "answer": "500,000",
      "score": 0.8837565779685974
    }
  ],
  "1492": [
    {
      "answer": "Louis XIV",
      "score": 0.9967833757400513
    }
  ],
  "1493": [
    {
      "answer": "500,000",
      "score": 0.989348828792572
    }
  ],
  "1494": [
    {
      "answer": "Catholic Church",
      "score": 0.9841961860656738
    }
  ],
  "1495": [
    {
      "answer": "St. Bartholomew's Day massacre",
      "score": 0.9790626168251038
    }
  ],
  "1496": [
    {
      "answer": "5,000 to 30,000",
      "score": 0.9910319447517395
    }
  ],
  "1497": [
    {
      "answer": "the Huguenots had their own militia",
      "score": 0.8951465487480164
    }
  ],
  "1498": [
    {
      "answer": "political",
      "score": 0.8569232225418091
    }
  ],
  "1499": [
    {
      "answer": "5,000 to 30,000",
      "score": 0.9884847402572632
    }
  ],
  "1500": [
    {
      "answer": "5,000 to 30,000",
      "score": 0.8999371528625488
    }
  ],
  "1501": [
    {
      "answer": "5,000 to 30,000",
      "score": 0.9898574352264404
    }
  ],
  "1502": [
    {
      "answer": "5,000",
      "score": 0.9763903021812439
    }
  ],
  "1503": [
    {
      "answer": "Huguenot rebellions",
      "score": 0.9940446615219116
    }
  ],
  "1504": [
    {
      "answer": "southwestern France",
      "score": 0.9947010278701782
    }
  ],
  "1505": [
    {
      "answer": "1621",
      "score": 0.9927955269813538
    },
    {
      "answer": "1629",
      "score": 0.9649901390075684
    }
  ],
  "1506": [
    {
      "answer": "Henry IV",
      "score": 0.998073935508728
    }
  ],
  "1507": [
    {
      "answer": "Louis XIII",
      "score": 0.9982393980026245
    }
  ],
  "1508": [
    {
      "answer": "1621",
      "score": 0.9738934636116028
    },
    {
      "answer": "1629",
      "score": 0.9450674057006836
    }
  ],
  "1509": [
    {
      "answer": "1620",
      "score": 0.9191664457321167
    }
  ],
  "1510": [
    {
      "answer": "Italian",
      "score": 0.8165192008018494
    }
  ],
  "1511": [
    {
      "answer": "foreign powers",
      "score": 0.9564123749732971
    }
  ],
  "1512": [
    {
      "answer": "Catholicism",
      "score": 0.5282065272331238
    }
  ],
  "1513": [
    {
      "answer": "one million",
      "score": 0.9940062761306763
    }
  ],
  "1514": [
    {
      "answer": "2%",
      "score": 0.9862042665481567
    }
  ],
  "1515": [
    {
      "answer": "Alsace",
      "score": 0.9903634190559387
    }
  ],
  "1516": [
    {
      "answer": "C\u00e9vennes",
      "score": 0.9818127155303955
    }
  ],
  "1517": [
    {
      "answer": "France",
      "score": 0.9588819146156311
    },
    {
      "answer": "France",
      "score": 0.9303351640701294
    },
    {
      "answer": "Australia",
      "score": 0.7262575626373291
    }
  ],
  "1518": [
    {
      "answer": "one million",
      "score": 0.9809746146202087
    }
  ],
  "1519": [
    {
      "answer": "one million",
      "score": 0.9911355972290039
    }
  ],
  "1520": [
    {
      "answer": "Alsace",
      "score": 0.9798893332481384
    },
    {
      "answer": "C\u00e9vennes mountain region in the south",
      "score": 0.7543465495109558
    }
  ],
  "1521": [
    {
      "answer": "2%",
      "score": 0.9597510099411011
    }
  ],
  "1522": [
    {
      "answer": "one million",
      "score": 0.9722098112106323
    }
  ],
  "1523": [
    {
      "answer": "New Rochelle",
      "score": 0.9934729337692261
    }
  ],
  "1524": [
    {
      "answer": "New Paltz",
      "score": 0.9746510982513428
    },
    {
      "answer": "New Paltz",
      "score": 0.833153486251831
    }
  ],
  "1525": [
    {
      "answer": "Huguenot Street Historic District",
      "score": 0.9813267588615417
    }
  ],
  "1526": [
    {
      "answer": "Huguenot Street Historic District",
      "score": 0.9603764414787292
    }
  ],
  "1527": [
    {
      "answer": "Staten Island",
      "score": 0.976355791091919
    }
  ],
  "1528": [
    {
      "answer": "21 miles",
      "score": 0.9856758117675781
    }
  ],
  "1529": [
    {
      "answer": "21 miles",
      "score": 0.9906166791915894
    }
  ],
  "1530": [
    {
      "answer": "small",
      "score": 0.8911094069480896
    }
  ],
  "1531": [
    {
      "answer": "New York",
      "score": 0.9457625150680542
    },
    {
      "answer": "New York",
      "score": 0.8659671545028687
    },
    {
      "answer": "New Rochelle",
      "score": 0.7272218465805054
    },
    {
      "answer": "New Paltz",
      "score": 0.7992778420448303
    },
    {
      "answer": "New Paltz",
      "score": 0.5476694107055664
    },
    {
      "answer": "New York",
      "score": 0.8357225656509399
    }
  ],
  "1532": [
    {
      "answer": "south shore of Staten Island",
      "score": 0.8376059532165527
    },
    {
      "answer": "New York",
      "score": 0.811214804649353
    }
  ],
  "1533": [
    {
      "answer": "Dutch Republic",
      "score": 0.9926009178161621
    },
    {
      "answer": "Dutch Republic",
      "score": 0.9765917062759399
    },
    {
      "answer": "Dutch Republic",
      "score": 0.9475598335266113
    }
  ],
  "1534": [
    {
      "answer": "75,000",
      "score": 0.9915778040885925
    }
  ],
  "1535": [
    {
      "answer": "ca. 2 million",
      "score": 0.9454973340034485
    }
  ],
  "1536": [
    {
      "answer": "Amsterdam",
      "score": 0.7927249073982239
    },
    {
      "answer": "Amsterdam",
      "score": 0.9809865355491638
    }
  ],
  "1537": [
    {
      "answer": "Edict of Nantes",
      "score": 0.9779369235038757
    }
  ],
  "1538": [
    {
      "answer": "75,000",
      "score": 0.9667307734489441
    }
  ],
  "1539": [
    {
      "answer": "75,000",
      "score": 0.9811717867851257
    }
  ],
  "1540": [
    {
      "answer": "1705",
      "score": 0.5527449250221252
    }
  ],
  "1541": [
    {
      "answer": "200",
      "score": 0.9935715198516846
    }
  ],
  "1542": [
    {
      "answer": "Dutch Republic",
      "score": 0.8649507761001587
    },
    {
      "answer": "Dutch Republic",
      "score": 0.9136420488357544
    },
    {
      "answer": "Dutch Republic",
      "score": 0.8911101818084717
    }
  ],
  "1543": [
    {
      "answer": "Tours",
      "score": 0.9836254715919495
    }
  ],
  "1544": [
    {
      "answer": "Huguon",
      "score": 0.9560884237289429
    }
  ],
  "1545": [
    {
      "answer": "le roi Huguet",
      "score": 0.976019561290741
    }
  ],
  "1546": [
    {
      "answer": "pr\u00e9tendus r\u00e9form\u00e9s",
      "score": 0.9793831706047058
    }
  ],
  "1547": [
    {
      "answer": "night",
      "score": 0.9315524101257324
    },
    {
      "answer": "night",
      "score": 0.9756569862365723
    }
  ],
  "1548": [
    {
      "answer": "1560",
      "score": 0.9372992515563965
    }
  ],
  "1549": [
    {
      "answer": "1560",
      "score": 0.9940423369407654
    }
  ],
  "1550": [
    {
      "answer": "1560",
      "score": 0.9950012564659119
    }
  ],
  "1551": [
    {
      "answer": "1560",
      "score": 0.9953253269195557
    }
  ],
  "1552": [
    {
      "answer": "1560",
      "score": 0.8049603700637817
    }
  ],
  "1553": [
    {
      "answer": "Sandwich, Faversham and Maidstone",
      "score": 0.9487947821617126
    }
  ],
  "1554": [
    {
      "answer": "The Weavers",
      "score": 0.9477365016937256
    }
  ],
  "1555": [
    {
      "answer": "variety of occupations necessary to sustain the community",
      "score": 0.9415849447250366
    }
  ],
  "1556": [
    {
      "answer": "Sandwich",
      "score": 0.8803334832191467
    },
    {
      "answer": "Faversham",
      "score": 0.8864163160324097
    },
    {
      "answer": "Maidstone",
      "score": 0.9132511615753174
    }
  ],
  "1557": [
    {
      "answer": "restaurant",
      "score": 0.9787205457687378
    }
  ],
  "1558": [
    {
      "answer": "1830",
      "score": 0.9942960143089294
    }
  ],
  "1559": [
    {
      "answer": "Canterbury",
      "score": 0.976108729839325
    }
  ],
  "1560": [
    {
      "answer": "Canterbury",
      "score": 0.9752402305603027
    }
  ],
  "1561": [
    {
      "answer": "weavers",
      "score": 0.5303695201873779
    }
  ],
  "1562": [
    {
      "answer": "Sandwich",
      "score": 0.582938551902771
    },
    {
      "answer": "Faversham",
      "score": 0.7036892771720886
    },
    {
      "answer": "Maidstone",
      "score": 0.6971281170845032
    }
  ],
  "1563": [
    {
      "answer": "Dublin",
      "score": 0.9404276609420776
    },
    {
      "answer": "Cork",
      "score": 0.8994231820106506
    },
    {
      "answer": "Youghal",
      "score": 0.935519814491272
    },
    {
      "answer": "Waterford",
      "score": 0.9145845770835876
    },
    {
      "answer": "Cork",
      "score": 0.751907229423523
    },
    {
      "answer": "Dublin",
      "score": 0.7943706512451172
    }
  ],
  "1564": [
    {
      "answer": "Cork",
      "score": 0.9908341765403748
    }
  ],
  "1565": [
    {
      "answer": "Dublin",
      "score": 0.82345050573349
    },
    {
      "answer": "Dublin",
      "score": 0.989123523235321
    }
  ],
  "1566": [
    {
      "answer": "High Sheriff and one of the founders of the Bank of Ireland",
      "score": 0.9184198379516602
    }
  ],
  "1567": [
    {
      "answer": "1696",
      "score": 0.9970068335533142
    }
  ],
  "1568": [
    {
      "answer": "Dublin",
      "score": 0.5870218873023987
    },
    {
      "answer": "Cork",
      "score": 0.7923375368118286
    },
    {
      "answer": "Dublin",
      "score": 0.7482332587242126
    }
  ],
  "1569": [
    {
      "answer": "1696",
      "score": 0.9885645508766174
    }
  ],
  "1570": [
    {
      "answer": "1696",
      "score": 0.9847224354743958
    }
  ],
  "1571": [
    {
      "answer": "1696",
      "score": 0.9426721930503845
    }
  ],
  "1572": [
    {
      "answer": "D'Olier",
      "score": 0.6394307613372803
    }
  ],
  "1573": [
    {
      "answer": "brain drain",
      "score": 0.9876878261566162
    }
  ],
  "1574": [
    {
      "answer": "New France",
      "score": 0.9362612962722778
    },
    {
      "answer": "New France",
      "score": 0.929262638092041
    }
  ],
  "1575": [
    {
      "answer": "non-Catholics",
      "score": 0.9736117720603943
    }
  ],
  "1576": [
    {
      "answer": "Seven Years' War",
      "score": 0.9395568370819092
    }
  ],
  "1577": [
    {
      "answer": "1759-60",
      "score": 0.9935018420219421
    }
  ],
  "1578": [
    {
      "answer": "1759-60",
      "score": 0.9900280833244324
    }
  ],
  "1579": [
    {
      "answer": "non-Catholics",
      "score": 0.9862775206565857
    }
  ],
  "1580": [
    {
      "answer": "1759-60",
      "score": 0.9621719717979431
    }
  ],
  "1581": [
    {
      "answer": "British",
      "score": 0.8391165733337402
    },
    {
      "answer": "British",
      "score": 0.7755164504051208
    },
    {
      "answer": "British",
      "score": 0.8705479502677917
    }
  ],
  "1582": [
    {
      "answer": "Henry of Navarre",
      "score": 0.9532480239868164
    }
  ],
  "1583": [
    {
      "answer": "1598",
      "score": 0.9955968260765076
    }
  ],
  "1584": [
    {
      "answer": "granted the Protestants equality with Catholics under the throne and a degree of religious and political freedom within their domains",
      "score": 0.9560930132865906
    }
  ],
  "1585": [
    {
      "answer": "founding of new Protestant churches",
      "score": 0.9941810965538025
    }
  ],
  "1586": [
    {
      "answer": "Protestantism",
      "score": 0.9684585928916931
    },
    {
      "answer": "Roman Catholicism",
      "score": 0.8353358507156372
    }
  ],
  "1587": [
    {
      "answer": "1598",
      "score": 0.9765477776527405
    }
  ],
  "1588": [
    {
      "answer": "1598",
      "score": 0.9943622350692749
    }
  ],
  "1589": [
    {
      "answer": "1598",
      "score": 0.5445718169212341
    }
  ],
  "1590": [
    {
      "answer": "discouraging the founding of new Protestant churches",
      "score": 0.9609953165054321
    }
  ],
  "1591": [
    {
      "answer": "education of children as Catholics",
      "score": 0.9644346237182617
    }
  ],
  "1592": [
    {
      "answer": "required education of children as Catholics",
      "score": 0.7100895643234253
    },
    {
      "answer": "prohibited emigration",
      "score": 0.9448651075363159
    }
  ],
  "1593": [
    {
      "answer": "Four thousand",
      "score": 0.9965037107467651
    }
  ],
  "1594": [
    {
      "answer": "new converts",
      "score": 0.9264034032821655
    }
  ],
  "1595": [
    {
      "answer": "Britain",
      "score": 0.5483953356742859
    },
    {
      "answer": "Holland",
      "score": 0.7994335889816284
    },
    {
      "answer": "South Africa",
      "score": 0.9052881002426147
    },
    {
      "answer": "North American colonies",
      "score": 0.635117769241333
    },
    {
      "answer": "New York and Virginia",
      "score": 0.5979093909263611
    }
  ],
  "1596": [
    {
      "answer": "hundreds of thousands",
      "score": 0.9680999517440796
    }
  ],
  "1597": [
    {
      "answer": "English",
      "score": 0.9032078385353088
    }
  ],
  "1598": [
    {
      "answer": "France",
      "score": 0.7323315739631653
    },
    {
      "answer": "Britain",
      "score": 0.5701363682746887
    },
    {
      "answer": "France",
      "score": 0.6739271879196167
    }
  ],
  "1599": [],
  "1600": [],
  "1601": [
    {
      "answer": "Switzerland",
      "score": 0.980069637298584
    },
    {
      "answer": "Netherlands",
      "score": 0.9734598398208618
    }
  ],
  "1602": [
    {
      "answer": "1555",
      "score": 0.9949243068695068
    }
  ],
  "1603": [
    {
      "answer": "France Antarctique",
      "score": 0.976934015750885
    }
  ],
  "1604": [
    {
      "answer": "1560",
      "score": 0.9951289892196655
    }
  ],
  "1605": [
    {
      "answer": "Guanabara Confession of Faith",
      "score": 0.9938024878501892
    }
  ],
  "1606": [
    {
      "answer": "500",
      "score": 0.9726688265800476
    }
  ],
  "1607": [
    {
      "answer": "1555",
      "score": 0.974917471408844
    }
  ],
  "1608": [
    {
      "answer": "500",
      "score": 0.9747369885444641
    }
  ],
  "1609": [
    {
      "answer": "500",
      "score": 0.848014771938324
    }
  ],
  "1610": [
    {
      "answer": "Afrikaans-speaking",
      "score": 0.9952031373977661
    }
  ],
  "1611": [
    {
      "answer": "wine",
      "score": 0.9894785284996033
    }
  ],
  "1612": [
    {
      "answer": "Western Cape",
      "score": 0.9928922653198242
    }
  ],
  "1613": [
    {
      "answer": "surnames",
      "score": 0.8197417855262756
    },
    {
      "answer": "French Huguenot ancestry",
      "score": 0.6649791598320007
    }
  ],
  "1614": [
    {
      "answer": "Huguenots",
      "score": 0.9101220965385437
    }
  ],
  "1615": [
    {
      "answer": "Huguenots",
      "score": 0.9507402777671814
    }
  ],
  "1616": [
    {
      "answer": "Huguenots",
      "score": 0.8916634321212769
    }
  ],
  "1617": [
    {
      "answer": "Huguenots",
      "score": 0.7592546939849854
    }
  ],
  "1618": [
    {
      "answer": "Paul Revere",
      "score": 0.916273832321167
    },
    {
      "answer": "Jack Jouett",
      "score": 0.8013249635696411
    }
  ],
  "1619": [
    {
      "answer": "Henry Laurens",
      "score": 0.9767005443572998
    }
  ],
  "1620": [
    {
      "answer": "Charleston",
      "score": 0.9932394027709961
    }
  ],
  "1621": [
    {
      "answer": "Manakin Episcopal Church",
      "score": 0.9876396059989929
    }
  ],
  "1622": [
    {
      "answer": "Texas",
      "score": 0.9934458136558533
    }
  ],
  "1623": [
    {
      "answer": "1844",
      "score": 0.9938374161720276
    }
  ],
  "1624": [
    {
      "answer": "1844",
      "score": 0.9912585616111755
    }
  ],
  "1625": [
    {
      "answer": "a church that dates to 1844",
      "score": 0.7770049571990967
    }
  ],
  "1626": [
    {
      "answer": "Jack Jouett",
      "score": 0.913434624671936
    }
  ],
  "1627": [
    {
      "answer": "South Carolina",
      "score": 0.9832747578620911
    },
    {
      "answer": "South Carolina",
      "score": 0.9722402095794678
    }
  ],
  "1628": [
    {
      "answer": "British lace industry",
      "score": 0.9684289693832397
    }
  ],
  "1629": [
    {
      "answer": "Bucks Point",
      "score": 0.9896202087402344
    }
  ],
  "1630": [
    {
      "answer": "twenty-five widows who settled in Dover",
      "score": 0.9428867697715759
    }
  ],
  "1631": [
    {
      "answer": "first half of the eighteenth century",
      "score": 0.9893822073936462
    }
  ],
  "1632": [
    {
      "answer": "twenty-five",
      "score": 0.9674385190010071
    }
  ],
  "1633": [
    {
      "answer": "eighteenth century",
      "score": 0.8399449586868286
    }
  ],
  "1634": [
    {
      "answer": "Some",
      "score": 0.8896881341934204
    }
  ],
  "1635": [
    {
      "answer": "lace industry",
      "score": 0.8762340545654297
    }
  ],
  "1636": [
    {
      "answer": "Dorotheenstadt",
      "score": 0.9861688017845154
    },
    {
      "answer": "Friedrichstadt",
      "score": 0.9840361475944519
    }
  ],
  "1637": [
    {
      "answer": "one-fifth",
      "score": 0.9948908090591431
    }
  ],
  "1638": [
    {
      "answer": "protest against the occupation of Prussia by Napoleon",
      "score": 0.9902427196502686
    }
  ],
  "1639": [
    {
      "answer": "1806-07",
      "score": 0.9933215975761414
    }
  ],
  "1640": [
    {
      "answer": "Stockholm",
      "score": 0.9443541169166565
    },
    {
      "answer": "Hamburg",
      "score": 0.9219102263450623
    },
    {
      "answer": "Frankfurt",
      "score": 0.847184956073761
    },
    {
      "answer": "Helsinki",
      "score": 0.9394437670707703
    },
    {
      "answer": "Emden",
      "score": 0.834004819393158
    }
  ],
  "1641": [
    {
      "answer": "1806-07",
      "score": 0.9389058351516724
    }
  ],
  "1642": [
    {
      "answer": "Dorotheenstadt",
      "score": 0.5309234261512756
    }
  ],
  "1643": [
    {
      "answer": "Dorotheenstadt",
      "score": 0.7015634179115295
    },
    {
      "answer": "Friedrichstadt",
      "score": 0.5929122567176819
    }
  ],
  "1644": [
    {
      "answer": "1700",
      "score": 0.9535448551177979
    }
  ],
  "1645": [
    {
      "answer": "one-fifth",
      "score": 0.9931742548942566
    }
  ],
  "1646": [
    {
      "answer": "Prussia",
      "score": 0.989063560962677
    }
  ],
  "1647": [
    {
      "answer": "C\u00e9vennes region",
      "score": 0.9155809879302979
    }
  ],
  "1648": [
    {
      "answer": "Camisards",
      "score": 0.9926855564117432
    },
    {
      "answer": "Camisards",
      "score": 0.892532229423523
    }
  ],
  "1649": [
    {
      "answer": "Catholic Church",
      "score": 0.9941390156745911
    }
  ],
  "1650": [
    {
      "answer": "1702",
      "score": 0.9948063492774963
    },
    {
      "answer": "1709",
      "score": 0.9902498126029968
    }
  ],
  "1651": [
    {
      "answer": "1702",
      "score": 0.9861141443252563
    }
  ],
  "1652": [
    {
      "answer": "200,000",
      "score": 0.9849772453308105
    }
  ],
  "1653": [
    {
      "answer": "200,000",
      "score": 0.9596265554428101
    },
    {
      "answer": "1,000,000",
      "score": 0.9001945853233337
    }
  ],
  "1654": [
    {
      "answer": "1702",
      "score": 0.9564400911331177
    },
    {
      "answer": "1709",
      "score": 0.852689266204834
    }
  ],
  "1655": [
    {
      "answer": "18th century",
      "score": 0.9156973958015442
    }
  ],
  "1656": [
    {
      "answer": "Jacksonville",
      "score": 0.9772133827209473
    }
  ],
  "1657": [
    {
      "answer": "Jean Ribault",
      "score": 0.9954147338867188
    }
  ],
  "1658": [
    {
      "answer": "Fort Caroline",
      "score": 0.879056453704834
    },
    {
      "answer": "Fort Caroline",
      "score": 0.647009015083313
    }
  ],
  "1659": [
    {
      "answer": "Spanish",
      "score": 0.8885483145713806
    }
  ],
  "1660": [
    {
      "answer": "September 1565",
      "score": 0.9762310981750488
    }
  ],
  "1661": [
    {
      "answer": "1564",
      "score": 0.9855340719223022
    }
  ],
  "1662": [
    {
      "answer": "Hundreds",
      "score": 0.897230863571167
    }
  ],
  "1663": [
    {
      "answer": "small",
      "score": 0.8373648524284363
    }
  ],
  "1664": [
    {
      "answer": "St. Johns River",
      "score": 0.8371490240097046
    }
  ],
  "1665": [
    {
      "answer": "Charlesfort",
      "score": 0.8886441588401794
    }
  ],
  "1666": [
    {
      "answer": "Southeastern U.S.",
      "score": 0.8577032089233398
    }
  ],
  "1667": [
    {
      "answer": "Pedro Men\u00e9ndez de Avil\u00e9s",
      "score": 0.9891698956489563
    }
  ],
  "1668": [
    {
      "answer": "1562",
      "score": 0.9907989501953125
    }
  ],
  "1669": [
    {
      "answer": "Wars of Religion",
      "score": 0.9960066676139832
    }
  ],
  "1670": [
    {
      "answer": "1562",
      "score": 0.9832774996757507
    }
  ],
  "1671": [
    {
      "answer": "1564",
      "score": 0.9846877455711365
    }
  ],
  "1672": [
    {
      "answer": "1565",
      "score": 0.9621649384498596
    }
  ],
  "1673": [
    {
      "answer": "1564",
      "score": 0.990228533744812
    }
  ],
  "1674": [
    {
      "answer": "1562",
      "score": 0.9810361862182617
    }
  ],
  "1675": [
    {
      "answer": "Lower Norfolk County",
      "score": 0.8605145812034607
    }
  ],
  "1676": [
    {
      "answer": "Lower Norfolk County",
      "score": 0.9929298758506775
    }
  ],
  "1677": [
    {
      "answer": "Manakin Town",
      "score": 0.9589605331420898
    },
    {
      "answer": "Manakintown",
      "score": 0.5505646467208862
    },
    {
      "answer": "Manakintown",
      "score": 0.5802310705184937
    }
  ],
  "1678": [
    {
      "answer": "390",
      "score": 0.9946129322052002
    }
  ],
  "1679": [
    {
      "answer": "1705",
      "score": 0.9943411350250244
    }
  ],
  "1680": [
    {
      "answer": "148",
      "score": 0.6519070267677307
    }
  ],
  "1681": [
    {
      "answer": "148",
      "score": 0.847227156162262
    }
  ],
  "1682": [
    {
      "answer": "148",
      "score": 0.9708974957466125
    }
  ],
  "1683": [
    {
      "answer": "18th",
      "score": 0.7992088794708252
    },
    {
      "answer": "19th",
      "score": 0.75694340467453
    }
  ],
  "1684": [
    {
      "answer": "1700",
      "score": 0.978209912776947
    }
  ],
  "1685": [
    {
      "answer": "1568",
      "score": 0.9885110855102539
    },
    {
      "answer": "1609",
      "score": 0.9471037983894348
    }
  ],
  "1686": [
    {
      "answer": "Spain",
      "score": 0.9884457588195801
    },
    {
      "answer": "Spanish",
      "score": 0.5741056799888611
    }
  ],
  "1687": [
    {
      "answer": "\"Apologie\" of William the Silent",
      "score": 0.861250638961792
    }
  ],
  "1688": [
    {
      "answer": "William the Silent",
      "score": 0.9835049510002136
    },
    {
      "answer": "William the Silent",
      "score": 0.9499568343162537
    }
  ],
  "1689": [
    {
      "answer": "Calvinist",
      "score": 0.9878415465354919
    }
  ],
  "1690": [
    {
      "answer": "1568",
      "score": 0.9673384428024292
    },
    {
      "answer": "1609",
      "score": 0.8375600576400757
    }
  ],
  "1691": [
    {
      "answer": "Dutch",
      "score": 0.5560560822486877
    },
    {
      "answer": "Dutch",
      "score": 0.6900438666343689
    },
    {
      "answer": "Dutch",
      "score": 0.6667842864990234
    },
    {
      "answer": "Dutch",
      "score": 0.6878988742828369
    },
    {
      "answer": "Dutch",
      "score": 0.6319751143455505
    },
    {
      "answer": "Dutch",
      "score": 0.5915321707725525
    }
  ],
  "1692": [
    {
      "answer": "New Netherland",
      "score": 0.8944807648658752
    }
  ],
  "1693": [
    {
      "answer": "1568",
      "score": 0.8688009977340698
    },
    {
      "answer": "1609",
      "score": 0.7930041551589966
    }
  ],
  "1694": [
    {
      "answer": "Gaspard de Coligny",
      "score": 0.9115986824035645
    }
  ],
  "1695": [
    {
      "answer": "Foreign Protestants Naturalization Act",
      "score": 0.9964912533760071
    }
  ],
  "1696": [
    {
      "answer": "1708",
      "score": 0.9952334761619568
    }
  ],
  "1697": [
    {
      "answer": "50,000",
      "score": 0.9920966625213623
    }
  ],
  "1698": [
    {
      "answer": "Andrew Lortie",
      "score": 0.9960544109344482
    }
  ],
  "1699": [
    {
      "answer": "transubstantiation",
      "score": 0.9846157431602478
    }
  ],
  "1700": [
    {
      "answer": "50,000",
      "score": 0.989732027053833
    }
  ],
  "1701": [
    {
      "answer": "50,000",
      "score": 0.9881007075309753
    }
  ],
  "1702": [],
  "1703": [
    {
      "answer": "1708",
      "score": 0.9930250644683838
    }
  ],
  "1704": [
    {
      "answer": "50,000",
      "score": 0.9895517230033875
    }
  ],
  "1705": [
    {
      "answer": "Williamite war",
      "score": 0.9757446050643921
    }
  ],
  "1706": [
    {
      "answer": "William of Orange",
      "score": 0.9974576234817505
    }
  ],
  "1707": [
    {
      "answer": "Dublin",
      "score": 0.6832270622253418
    },
    {
      "answer": "Dublin",
      "score": 0.8767943382263184
    },
    {
      "answer": "Cork",
      "score": 0.9023427963256836
    },
    {
      "answer": "Portarlington",
      "score": 0.9071902632713318
    },
    {
      "answer": "Lisburn",
      "score": 0.8792725205421448
    },
    {
      "answer": "Waterford",
      "score": 0.9011659622192383
    },
    {
      "answer": "Youghal",
      "score": 0.8853358626365662
    }
  ],
  "1708": [
    {
      "answer": "flax",
      "score": 0.9896838665008545
    }
  ],
  "1709": [
    {
      "answer": "Irish linen",
      "score": 0.9129751324653625
    }
  ],
  "1710": [
    {
      "answer": "late 17th and early 18th centuries",
      "score": 0.9008002281188965
    }
  ],
  "1711": [
    {
      "answer": "Dublin",
      "score": 0.919964075088501
    },
    {
      "answer": "Dublin",
      "score": 0.8597874045372009
    }
  ],
  "1712": [
    {
      "answer": "Killeshandra",
      "score": 0.9813448190689087
    }
  ],
  "1713": [
    {
      "answer": "fought for William of Orange in the Williamite war in Ireland",
      "score": 0.9700626134872437
    }
  ],
  "1714": [
    {
      "answer": "expansion of flax cultivation",
      "score": 0.9020949006080627
    }
  ],
  "1715": [
    {
      "answer": "Prince Louis de Cond\u00e9",
      "score": 0.9839296340942383
    }
  ],
  "1716": [
    {
      "answer": "Ludwig von Nassau-Saarbr\u00fccken",
      "score": 0.9929417371749878
    }
  ],
  "1717": [
    {
      "answer": "glass-making",
      "score": 0.9877846240997314
    }
  ],
  "1718": [
    {
      "answer": "1890s",
      "score": 0.9958400726318359
    }
  ],
  "1719": [
    {
      "answer": "1604",
      "score": 0.9939915537834167
    }
  ],
  "1720": [
    {
      "answer": "1604",
      "score": 0.9921813011169434
    }
  ],
  "1721": [
    {
      "answer": "1604",
      "score": 0.9945387244224548
    }
  ],
  "1722": [
    {
      "answer": "Louis de Cond\u00e9",
      "score": 0.9903184771537781
    }
  ],
  "1723": [
    {
      "answer": "1604",
      "score": 0.991868257522583
    }
  ],
  "1724": [
    {
      "answer": "Electorate of Brandenburg",
      "score": 0.9160542488098145
    },
    {
      "answer": "Electorate of the Palatinate",
      "score": 0.9026418924331665
    }
  ],
  "1725": [
    {
      "answer": "Protestant",
      "score": 0.994767427444458
    }
  ],
  "1726": [
    {
      "answer": "Dutch Cape Colony",
      "score": 0.9791523814201355
    }
  ],
  "1727": [
    {
      "answer": "Quebec",
      "score": 0.969254732131958
    }
  ],
  "1728": [
    {
      "answer": "accepted and allowed to worship freely",
      "score": 0.9647355079650879
    }
  ],
  "1729": [
    {
      "answer": "England",
      "score": 0.8396965265274048
    },
    {
      "answer": "Scotland",
      "score": 0.6399016976356506
    },
    {
      "answer": "Denmark",
      "score": 0.8063436150550842
    },
    {
      "answer": "Sweden",
      "score": 0.8424226641654968
    },
    {
      "answer": "Switzerland",
      "score": 0.760698139667511
    },
    {
      "answer": "Dutch Republic",
      "score": 0.7864472270011902
    }
  ],
  "1730": [
    {
      "answer": "England",
      "score": 0.5670422911643982
    },
    {
      "answer": "Sweden",
      "score": 0.5571692585945129
    },
    {
      "answer": "Dutch Republic",
      "score": 0.613953173160553
    }
  ],
  "1731": [
    {
      "answer": "Huguenot",
      "score": 0.9485709071159363
    }
  ],
  "1732": [
    {
      "answer": "Huguenot",
      "score": 0.5751982927322388
    },
    {
      "answer": "Protestant",
      "score": 0.6729402542114258
    }
  ],
  "1733": [
    {
      "answer": "Huguenot",
      "score": 0.967990517616272
    }
  ],
  "1734": [
    {
      "answer": "Hugues Capet",
      "score": 0.9933805465698242
    }
  ],
  "1735": [
    {
      "answer": "Hugues hypothesis",
      "score": 0.9632167816162109
    }
  ],
  "1736": [
    {
      "answer": "Janet Gray",
      "score": 0.9790804982185364
    }
  ],
  "1737": [],
  "1738": [
    {
      "answer": "Hugues hypothesis",
      "score": 0.773666262626648
    }
  ],
  "1739": [
    {
      "answer": "Hugues Capet",
      "score": 0.9952999353408813
    }
  ],
  "1740": [
    {
      "answer": "Gallicans",
      "score": 0.9741498827934265
    },
    {
      "answer": "Protestants",
      "score": 0.9749284386634827
    }
  ],
  "1741": [
    {
      "answer": "Gallicans",
      "score": 0.8072537779808044
    },
    {
      "answer": "Protestants",
      "score": 0.9795646667480469
    }
  ],
  "1742": [
    {
      "answer": "Hugues Capet",
      "score": 0.792924165725708
    }
  ],
  "1743": [
    {
      "answer": "Jacques Lefevre",
      "score": 0.9942125082015991
    }
  ],
  "1744": [
    {
      "answer": "University of Paris",
      "score": 0.9967007637023926
    },
    {
      "answer": "University of Paris",
      "score": 0.9833124876022339
    }
  ],
  "1745": [
    {
      "answer": "1523",
      "score": 0.7893816232681274
    },
    {
      "answer": "1530",
      "score": 0.942289412021637
    }
  ],
  "1746": [
    {
      "answer": "William Farel",
      "score": 0.9944493770599365
    },
    {
      "answer": "William Farel",
      "score": 0.8926671147346497
    }
  ],
  "1747": [
    {
      "answer": "Jean Cauvin (John Calvin)",
      "score": 0.7871732711791992
    }
  ],
  "1748": [
    {
      "answer": "France",
      "score": 0.8614312410354614
    },
    {
      "answer": "France",
      "score": 0.8385042548179626
    }
  ],
  "1749": [
    {
      "answer": "Paris",
      "score": 0.9242138862609863
    },
    {
      "answer": "Paris",
      "score": 0.9033769965171814
    }
  ],
  "1750": [
    {
      "answer": "1455",
      "score": 0.7929626703262329
    }
  ],
  "1751": [
    {
      "answer": "1523",
      "score": 0.7682863473892212
    },
    {
      "answer": "1530",
      "score": 0.5501888990402222
    }
  ],
  "1752": [
    {
      "answer": "Jacques Lefevre",
      "score": 0.5830683708190918
    }
  ],
  "1753": [
    {
      "answer": "24 August",
      "score": 0.9122488498687744
    },
    {
      "answer": "3 October 1572",
      "score": 0.873831033706665
    }
  ],
  "1754": [
    {
      "answer": "Catholics",
      "score": 0.9931148886680603
    }
  ],
  "1755": [
    {
      "answer": "3,000",
      "score": 0.9752660989761353
    }
  ],
  "1756": [
    {
      "answer": "1573",
      "score": 0.9908599853515625
    }
  ],
  "1757": [
    {
      "answer": "25,000",
      "score": 0.9782010912895203
    }
  ],
  "1758": [
    {
      "answer": "3,000",
      "score": 0.9471143484115601
    }
  ],
  "1759": [
    {
      "answer": "Paris",
      "score": 0.8176392316818237
    },
    {
      "answer": "Paris",
      "score": 0.8748839497566223
    },
    {
      "answer": "Paris",
      "score": 0.7300767302513123
    },
    {
      "answer": "Paris",
      "score": 0.7623187899589539
    }
  ],
  "1760": [
    {
      "answer": "25,000",
      "score": 0.7307127714157104
    }
  ],
  "1761": [
    {
      "answer": "3,000",
      "score": 0.9729563593864441
    }
  ],
  "1762": [
    {
      "answer": "3,000",
      "score": 0.9761332869529724
    }
  ],
  "1763": [
    {
      "answer": "Louis XIV",
      "score": 0.9982438087463379
    }
  ],
  "1764": [
    {
      "answer": "acted increasingly aggressively to force the Huguenots to convert",
      "score": 0.7668337225914001
    }
  ],
  "1765": [
    {
      "answer": "sent missionaries",
      "score": 0.9719844460487366
    }
  ],
  "1766": [
    {
      "answer": "closed Huguenot schools",
      "score": 0.9667415618896484
    }
  ],
  "1767": [
    {
      "answer": "dragonnades",
      "score": 0.9971816539764404
    }
  ],
  "1768": [
    {
      "answer": "1685",
      "score": 0.9668117761611938
    }
  ],
  "1769": [
    {
      "answer": "1643",
      "score": 0.9838851690292358
    }
  ],
  "1770": [
    {
      "answer": "1643",
      "score": 0.9786020517349243
    }
  ],
  "1771": [
    {
      "answer": "1643",
      "score": 0.6966635584831238
    },
    {
      "answer": "1685",
      "score": 0.924301266670227
    }
  ],
  "1772": [
    {
      "answer": "1643",
      "score": 0.9887996912002563
    }
  ],
  "1773": [
    {
      "answer": "Westchester",
      "score": 0.9682933688163757
    }
  ],
  "1774": [
    {
      "answer": "Davenports Neck",
      "score": 0.9511450529098511
    }
  ],
  "1775": [
    {
      "answer": "John Pell, Lord of Pelham Manor",
      "score": 0.9832690358161926
    }
  ],
  "1776": [
    {
      "answer": "La Rochelle",
      "score": 0.984946608543396
    }
  ],
  "1777": [
    {
      "answer": "Trinity-St. Paul's Episcopal Church",
      "score": 0.9348225593566895
    }
  ],
  "1778": [
    {
      "answer": "John Pell",
      "score": 0.7763963937759399
    },
    {
      "answer": "Jacob Leisler",
      "score": 0.707034707069397
    }
  ],
  "1779": [
    {
      "answer": "six thousand one hundred acres",
      "score": 0.9907747507095337
    }
  ],
  "1780": [
    {
      "answer": "John Pell, Lord of Pelham Manor",
      "score": 0.8159584403038025
    }
  ],
  "1781": [
    {
      "answer": "twenty-three miles",
      "score": 0.9911055564880371
    }
  ],
  "1782": [
    {
      "answer": "A small wooden church",
      "score": 0.7407393455505371
    }
  ],
  "1783": [
    {
      "answer": "affiliated with other Protestant denominations with more numerous members",
      "score": 0.8113526105880737
    }
  ],
  "1784": [
    {
      "answer": "The Huguenots adapted quickly and often married outside their immediate French communities",
      "score": 0.9001449942588806
    }
  ],
  "1785": [
    {
      "answer": "E.I. du Pont",
      "score": 0.986774206161499
    }
  ],
  "1786": [
    {
      "answer": "well into the nineteenth century",
      "score": 0.9729313254356384
    }
  ],
  "1787": [
    {
      "answer": "Eleutherian",
      "score": 0.9817294478416443
    }
  ],
  "1788": [
    {
      "answer": "nineteenth",
      "score": 0.9875432252883911
    }
  ],
  "1789": [
    {
      "answer": "E.I. du Pont, a former student of Lavoisier, established the Eleutherian gunpowder mills",
      "score": 0.7047155499458313
    }
  ],
  "1790": [
    {
      "answer": "French",
      "score": 0.9535025954246521
    },
    {
      "answer": "French",
      "score": 0.8162006139755249
    },
    {
      "answer": "French",
      "score": 0.8632747530937195
    }
  ],
  "1791": [
    {
      "answer": "The Huguenots adapted quickly and often married outside their immediate French communities",
      "score": 0.8451291918754578
    }
  ],
  "1792": [
    {
      "answer": "Pierre Bayle",
      "score": 0.9970871806144714
    }
  ],
  "1793": [
    {
      "answer": "Rotterdam",
      "score": 0.997520387172699
    }
  ],
  "1794": [
    {
      "answer": "Historical and Critical Dictionary",
      "score": 0.9914602041244507
    }
  ],
  "1795": [
    {
      "answer": "US Library of Congress",
      "score": 0.9924185276031494
    }
  ],
  "1796": [
    {
      "answer": "Saint Nicolas",
      "score": 0.9453920125961304
    }
  ],
  "1797": [],
  "1798": [
    {
      "answer": "100",
      "score": 0.6535742878913879
    }
  ],
  "1799": [
    {
      "answer": "Sint Nicolaas (Sinterklaas)",
      "score": 0.8223283886909485
    }
  ],
  "1800": [
    {
      "answer": "multi-volume",
      "score": 0.9900486469268799
    }
  ],
  "1801": [
    {
      "answer": "French Protestant Church of London",
      "score": 0.9723858833312988
    }
  ],
  "1802": [
    {
      "answer": "1550",
      "score": 0.9929478168487549
    }
  ],
  "1803": [
    {
      "answer": "Soho Square",
      "score": 0.9903367757797241
    }
  ],
  "1804": [
    {
      "answer": "Shoreditch",
      "score": 0.9852989912033081
    }
  ],
  "1805": [
    {
      "answer": "1724",
      "score": 0.9926568865776062
    }
  ],
  "1806": [
    {
      "answer": "1550",
      "score": 0.9820107817649841
    }
  ],
  "1807": [
    {
      "answer": "1724",
      "score": 0.8760219216346741
    }
  ],
  "1808": [
    {
      "answer": "French Protestant Church of London",
      "score": 0.785150945186615
    }
  ],
  "1809": [
    {
      "answer": "a third",
      "score": 0.9831434488296509
    }
  ],
  "1810": [
    {
      "answer": "1550",
      "score": 0.9058645963668823
    }
  ],
  "1811": [
    {
      "answer": "Lutheran",
      "score": 0.9941492080688477
    },
    {
      "answer": "Reformed",
      "score": 0.9853335022926331
    }
  ],
  "1812": [
    {
      "answer": "Germany",
      "score": 0.8766798973083496
    },
    {
      "answer": "Scandinavia",
      "score": 0.8941172361373901
    }
  ],
  "1813": [
    {
      "answer": "Edict of Potsdam",
      "score": 0.9972902536392212
    }
  ],
  "1814": [
    {
      "answer": "Elector of Brandenburg",
      "score": 0.9912204742431641
    },
    {
      "answer": "Duke of Prussia",
      "score": 0.9877197742462158
    }
  ],
  "1815": [
    {
      "answer": "The Huguenots furnished two new regiments of his army: the Altpreu\u00dfische Infantry Regiments No. 13 (Regiment on foot Varenne) and 15 (Regiment on foot Wylich)",
      "score": 0.9274603724479675
    }
  ],
  "1816": [
    {
      "answer": "1685",
      "score": 0.9899569153785706
    }
  ],
  "1817": [
    {
      "answer": "1685",
      "score": 0.9865778684616089
    }
  ],
  "1818": [
    {
      "answer": "4,000",
      "score": 0.9634029269218445
    }
  ],
  "1819": [
    {
      "answer": "1,500",
      "score": 0.9827606081962585
    }
  ],
  "1820": [
    {
      "answer": "20,000",
      "score": 0.5330812931060791
    }
  ],
  "1821": [
    {
      "answer": "Frederick William, Elector of Brandenburg",
      "score": 0.9717990756034851
    }
  ],
  "1822": [
    {
      "answer": "Theodor Fontane",
      "score": 0.9951750040054321
    }
  ],
  "1823": [
    {
      "answer": "Adolf Galland",
      "score": 0.9840914011001587
    }
  ],
  "1824": [
    {
      "answer": "Lothar de Maizi\u00e8re",
      "score": 0.9940177798271179
    }
  ],
  "1825": [
    {
      "answer": "Federal Minister of the Interior",
      "score": 0.9605156779289246
    }
  ],
  "1826": [],
  "1827": [
    {
      "answer": "Thomas de Maizi\u00e8re",
      "score": 0.5592979788780212
    }
  ],
  "1828": [
    {
      "answer": "General Hermann von Fran\u00e7ois",
      "score": 0.9273433685302734
    }
  ],
  "1829": [
    {
      "answer": "Huguenot",
      "score": 0.846314013004303
    }
  ],
  "1830": [
    {
      "answer": "Frederick William, Elector of Brandenburg",
      "score": 0.5797160863876343
    },
    {
      "answer": "General Hermann von Fran\u00e7ois",
      "score": 0.7410584092140198
    }
  ],
  "1831": [
    {
      "answer": "solar power",
      "score": 0.9861945509910583
    },
    {
      "answer": "nuclear power",
      "score": 0.6241989135742188
    }
  ],
  "1832": [
    {
      "answer": "Rankine cycle",
      "score": 0.9826693534851074
    }
  ],
  "1833": [
    {
      "answer": "Steam",
      "score": 0.7639804482460022
    },
    {
      "answer": "steam",
      "score": 0.9904800057411194
    },
    {
      "answer": "steam",
      "score": 0.8485528230667114
    }
  ],
  "1834": [
    {
      "answer": "high",
      "score": 0.9771667122840881
    }
  ],
  "1835": [
    {
      "answer": "external combustion engines",
      "score": 0.918350875377655
    }
  ],
  "1836": [
    {
      "answer": "solar power",
      "score": 0.9894245862960815
    }
  ],
  "1837": [
    {
      "answer": "Rankine cycle",
      "score": 0.9833252429962158
    }
  ],
  "1838": [
    {
      "answer": "Steam",
      "score": 0.7336339354515076
    },
    {
      "answer": "steam",
      "score": 0.9787220358848572
    },
    {
      "answer": "steam",
      "score": 0.8002914190292358
    }
  ],
  "1839": [
    {
      "answer": "high",
      "score": 0.9506788849830627
    }
  ],
  "1840": [
    {
      "answer": "Steam engines",
      "score": 0.7480913400650024
    }
  ],
  "1841": [
    {
      "answer": "atmospheric engine",
      "score": 0.9932581186294556
    }
  ],
  "1842": [
    {
      "answer": "Thomas Newcomen",
      "score": 0.9886918067932129
    }
  ],
  "1843": [
    {
      "answer": "1712",
      "score": 0.9877921938896179
    }
  ],
  "1844": [
    {
      "answer": "steam pump",
      "score": 0.9757677316665649
    }
  ],
  "1845": [
    {
      "answer": "Papin",
      "score": 0.9919890761375427
    }
  ],
  "1846": [
    {
      "answer": "atmospheric engine",
      "score": 0.9924442768096924
    }
  ],
  "1847": [
    {
      "answer": "Thomas Newcomen",
      "score": 0.9821285009384155
    }
  ],
  "1848": [
    {
      "answer": "1712",
      "score": 0.9928529858589172
    }
  ],
  "1849": [
    {
      "answer": "atmospheric engine",
      "score": 0.7959802150726318
    }
  ],
  "1850": [
    {
      "answer": "Thomas Newcomen",
      "score": 0.9879395961761475
    }
  ],
  "1851": [
    {
      "answer": "United Kingdom",
      "score": 0.9721854329109192
    }
  ],
  "1852": [
    {
      "answer": "21 February 1804",
      "score": 0.9484526515007019
    }
  ],
  "1853": [
    {
      "answer": "Abercynon",
      "score": 0.973861038684845
    }
  ],
  "1854": [
    {
      "answer": "Wales",
      "score": 0.8894358277320862
    }
  ],
  "1855": [
    {
      "answer": "south Wales",
      "score": 0.8402272462844849
    }
  ],
  "1856": [
    {
      "answer": "United Kingdom",
      "score": 0.6822043657302856
    }
  ],
  "1857": [
    {
      "answer": "21 February 1804",
      "score": 0.9565030932426453
    }
  ],
  "1858": [
    {
      "answer": "Abercynon",
      "score": 0.9767664670944214
    }
  ],
  "1859": [],
  "1860": [
    {
      "answer": "north-east England",
      "score": 0.7547001242637634
    }
  ],
  "1861": [
    {
      "answer": "water pump",
      "score": 0.9462308287620544
    }
  ],
  "1862": [
    {
      "answer": "multi-stage centrifugal pumps",
      "score": 0.9715368747711182
    }
  ],
  "1863": [
    {
      "answer": "1850s",
      "score": 0.9942492246627808
    }
  ],
  "1864": [
    {
      "answer": "steam locomotives",
      "score": 0.9807358980178833
    }
  ],
  "1865": [
    {
      "answer": "lower-pressure boiler feed water",
      "score": 0.8507767915725708
    }
  ],
  "1866": [
    {
      "answer": "water pump",
      "score": 0.9507145881652832
    }
  ],
  "1867": [],
  "1868": [
    {
      "answer": "1850s",
      "score": 0.993699312210083
    }
  ],
  "1869": [
    {
      "answer": "steam locomotives",
      "score": 0.7230775356292725
    }
  ],
  "1870": [],
  "1871": [
    {
      "answer": "three",
      "score": 0.9812486171722412
    },
    {
      "answer": "four",
      "score": 0.6363727450370789
    }
  ],
  "1872": [
    {
      "answer": "quadruple expansion engines",
      "score": 0.9312447309494019
    }
  ],
  "1873": [
    {
      "answer": "19th",
      "score": 0.9932379722595215
    }
  ],
  "1874": [
    {
      "answer": "marine triple expansion engines",
      "score": 0.9268437623977661
    }
  ],
  "1875": [
    {
      "answer": "Olympic class",
      "score": 0.9898032546043396
    }
  ],
  "1876": [
    {
      "answer": "three",
      "score": 0.9750275015830994
    },
    {
      "answer": "four",
      "score": 0.7895647883415222
    }
  ],
  "1877": [
    {
      "answer": "quadruple expansion engines",
      "score": 0.9304701089859009
    }
  ],
  "1878": [
    {
      "answer": "19th",
      "score": 0.9923926591873169
    }
  ],
  "1879": [
    {
      "answer": "marine triple expansion engines",
      "score": 0.6075026988983154
    }
  ],
  "1880": [
    {
      "answer": "Olympic class",
      "score": 0.9877519607543945
    }
  ],
  "1881": [
    {
      "answer": "Corliss",
      "score": 0.9296721816062927
    }
  ],
  "1882": [
    {
      "answer": "Joy",
      "score": 0.9623442888259888
    }
  ],
  "1883": [
    {
      "answer": "lengthening rubbing surfaces of the valve",
      "score": 0.9413573145866394
    }
  ],
  "1884": [
    {
      "answer": "patent valve gears",
      "score": 0.5763105154037476
    },
    {
      "answer": "Corliss",
      "score": 0.651034951210022
    }
  ],
  "1885": [],
  "1886": [
    {
      "answer": "lengthening rubbing surfaces of the valve",
      "score": 0.9510811567306519
    }
  ],
  "1887": [
    {
      "answer": "1840s",
      "score": 0.9853933453559875
    }
  ],
  "1888": [
    {
      "answer": "Lead fusible plugs",
      "score": 0.9771393537521362
    }
  ],
  "1889": [
    {
      "answer": "the lead melts",
      "score": 0.9401669502258301
    }
  ],
  "1890": [
    {
      "answer": "the steam escapes",
      "score": 0.915357768535614
    }
  ],
  "1891": [
    {
      "answer": "manually suppress the fire",
      "score": 0.9819724559783936
    }
  ],
  "1892": [
    {
      "answer": "dampening the fire",
      "score": 0.9054317474365234
    }
  ],
  "1893": [
    {
      "answer": "Lead fusible plugs",
      "score": 0.9241639971733093
    }
  ],
  "1894": [
    {
      "answer": "the lead melts",
      "score": 0.939534068107605
    }
  ],
  "1895": [
    {
      "answer": "the lead melts and the steam escapes",
      "score": 0.7320489287376404
    }
  ],
  "1896": [
    {
      "answer": "manually suppress the fire",
      "score": 0.9800447225570679
    }
  ],
  "1897": [
    {
      "answer": "dampening the fire",
      "score": 0.9036003947257996
    }
  ],
  "1898": [
    {
      "answer": "James Watt",
      "score": 0.9895784854888916
    }
  ],
  "1899": [
    {
      "answer": "rotary",
      "score": 0.9646182656288147
    }
  ],
  "1900": [
    {
      "answer": "ten-horsepower",
      "score": 0.9832166433334351
    }
  ],
  "1901": [
    {
      "answer": "1883",
      "score": 0.9929075241088867
    }
  ],
  "1902": [
    {
      "answer": "Industrial Revolution",
      "score": 0.9758133888244629
    }
  ],
  "1903": [
    {
      "answer": "James Watt",
      "score": 0.9663589000701904
    }
  ],
  "1904": [
    {
      "answer": "rotary",
      "score": 0.9362820982933044
    }
  ],
  "1905": [
    {
      "answer": "ten-horsepower",
      "score": 0.9772489070892334
    }
  ],
  "1906": [
    {
      "answer": "1883",
      "score": 0.9911534190177917
    }
  ],
  "1907": [
    {
      "answer": "Industrial Revolution",
      "score": 0.9531710743904114
    }
  ],
  "1908": [
    {
      "answer": "first",
      "score": 0.9903871417045593
    }
  ],
  "1909": [
    {
      "answer": "Hero of Alexandria",
      "score": 0.9967422485351562
    }
  ],
  "1910": [
    {
      "answer": "Greek",
      "score": 0.9935790300369263
    }
  ],
  "1911": [
    {
      "answer": "Giovanni Branca",
      "score": 0.9909478425979614
    }
  ],
  "1912": [
    {
      "answer": "1606",
      "score": 0.9765609502792358
    }
  ],
  "1913": [
    {
      "answer": "first",
      "score": 0.9855578541755676
    }
  ],
  "1914": [
    {
      "answer": "Denis Papin",
      "score": 0.9926040172576904
    }
  ],
  "1915": [
    {
      "answer": "Greek",
      "score": 0.9932734966278076
    }
  ],
  "1916": [
    {
      "answer": "Denis Papin",
      "score": 0.9782520532608032
    }
  ],
  "1917": [
    {
      "answer": "1606",
      "score": 0.9797514081001282
    }
  ],
  "1918": [],
  "1919": [
    {
      "answer": "expansions",
      "score": 0.9066744446754456
    }
  ],
  "1920": [
    {
      "answer": "shipping",
      "score": 0.9650980234146118
    },
    {
      "answer": "shipping",
      "score": 0.5658446550369263
    }
  ],
  "1921": [
    {
      "answer": "coal",
      "score": 0.6898887753486633
    }
  ],
  "1922": [
    {
      "answer": "internal combustion engines",
      "score": 0.9087953567504883
    },
    {
      "answer": "steam turbine",
      "score": 0.8661513328552246
    }
  ],
  "1923": [
    {
      "answer": "compound engines",
      "score": 0.6043672561645508
    }
  ],
  "1924": [
    {
      "answer": "expansions",
      "score": 0.8951966762542725
    }
  ],
  "1925": [
    {
      "answer": "shipping",
      "score": 0.9775200486183167
    },
    {
      "answer": "shipping",
      "score": 0.6322424411773682
    }
  ],
  "1926": [
    {
      "answer": "coal",
      "score": 0.7092374563217163
    }
  ],
  "1927": [
    {
      "answer": "internal combustion engines",
      "score": 0.9085679054260254
    },
    {
      "answer": "steam turbine",
      "score": 0.8556379675865173
    }
  ],
  "1928": [
    {
      "answer": "steam turbines",
      "score": 0.9886983633041382
    },
    {
      "answer": "Steam turbines",
      "score": 0.8174651861190796
    },
    {
      "answer": "Steam turbines",
      "score": 0.8546444773674011
    },
    {
      "answer": "steam turbines",
      "score": 0.8874238729476929
    },
    {
      "answer": "Steam turbines",
      "score": 0.8581374287605286
    }
  ],
  "1929": [
    {
      "answer": "late",
      "score": 0.9822936654090881
    }
  ],
  "1930": [
    {
      "answer": "several hundred horsepower",
      "score": 0.9461717009544373
    }
  ],
  "1931": [
    {
      "answer": "90%",
      "score": 0.9859942197799683
    }
  ],
  "1932": [
    {
      "answer": "electric",
      "score": 0.9858546853065491
    }
  ],
  "1933": [
    {
      "answer": "steam turbines",
      "score": 0.9889771938323975
    },
    {
      "answer": "Steam turbines",
      "score": 0.8021143078804016
    },
    {
      "answer": "Steam turbines",
      "score": 0.8504701256752014
    },
    {
      "answer": "steam turbines",
      "score": 0.8793352246284485
    },
    {
      "answer": "Steam turbines",
      "score": 0.8504099249839783
    }
  ],
  "1934": [
    {
      "answer": "late",
      "score": 0.9682042598724365
    }
  ],
  "1935": [
    {
      "answer": "several hundred horsepower",
      "score": 0.9410216808319092
    }
  ],
  "1936": [
    {
      "answer": "90%",
      "score": 0.9862346649169922
    }
  ],
  "1937": [
    {
      "answer": "90% of the electric power",
      "score": 0.7484649419784546
    }
  ],
  "1938": [
    {
      "answer": "burning combustible materials",
      "score": 0.9827587604522705
    }
  ],
  "1939": [
    {
      "answer": "combustion chamber",
      "score": 0.9908612966537476
    }
  ],
  "1940": [
    {
      "answer": "solar energy",
      "score": 0.9728406667709351
    }
  ],
  "1941": [
    {
      "answer": "electric",
      "score": 0.9731225371360779
    }
  ],
  "1942": [
    {
      "answer": "burning combustible materials",
      "score": 0.9795002341270447
    }
  ],
  "1943": [
    {
      "answer": "combustion chamber",
      "score": 0.9901383519172668
    }
  ],
  "1944": [
    {
      "answer": "electric",
      "score": 0.973727285861969
    }
  ],
  "1945": [
    {
      "answer": "solar energy",
      "score": 0.984416663646698
    }
  ],
  "1946": [
    {
      "answer": "electric",
      "score": 0.984713613986969
    }
  ],
  "1947": [
    {
      "answer": "steam engine indicator",
      "score": 0.9334279894828796
    },
    {
      "answer": "steam engine indicator",
      "score": 0.7503623366355896
    }
  ],
  "1948": [
    {
      "answer": "1851",
      "score": 0.9927321076393127
    }
  ],
  "1949": [
    {
      "answer": "Charles Porter",
      "score": 0.7500068545341492
    },
    {
      "answer": "Charles Richard",
      "score": 0.8050065040588379
    }
  ],
  "1950": [
    {
      "answer": "Charles Richard",
      "score": 0.9880257844924927
    }
  ],
  "1951": [
    {
      "answer": "London Exhibition",
      "score": 0.9351944923400879
    }
  ],
  "1952": [
    {
      "answer": "steam engine indicator",
      "score": 0.9780097007751465
    },
    {
      "answer": "steam engine indicator",
      "score": 0.9405209422111511
    }
  ],
  "1953": [
    {
      "answer": "1851",
      "score": 0.9919468760490417
    }
  ],
  "1954": [
    {
      "answer": "Charles Porter",
      "score": 0.8348973989486694
    },
    {
      "answer": "Charles Richard",
      "score": 0.7596497535705566
    }
  ],
  "1955": [
    {
      "answer": "Charles Richard",
      "score": 0.9845706224441528
    }
  ],
  "1956": [
    {
      "answer": "London Exhibition",
      "score": 0.9712398648262024
    }
  ],
  "1957": [
    {
      "answer": "90\u00b0",
      "score": 0.9876943230628967
    },
    {
      "answer": "90\u00b0",
      "score": 0.9048417806625366
    },
    {
      "answer": "90\u00b0",
      "score": 0.927381157875061
    },
    {
      "answer": "90\u00b0",
      "score": 0.8292180299758911
    }
  ],
  "1958": [
    {
      "answer": "180\u00b0",
      "score": 0.9872767925262451
    }
  ],
  "1959": [
    {
      "answer": "90\u00b0",
      "score": 0.9664561152458191
    }
  ],
  "1960": [
    {
      "answer": "90\u00b0",
      "score": 0.9882515668869019
    },
    {
      "answer": "90\u00b0",
      "score": 0.8947573900222778
    },
    {
      "answer": "90\u00b0",
      "score": 0.9197479486465454
    },
    {
      "answer": "90\u00b0",
      "score": 0.8090616464614868
    }
  ],
  "1961": [
    {
      "answer": "180\u00b0",
      "score": 0.9866734743118286
    }
  ],
  "1962": [
    {
      "answer": "90\u00b0",
      "score": 0.9653357267379761
    }
  ],
  "1963": [
    {
      "answer": "the individual pistons within the group are usually balanced at 180\u00b0, the groups being set at 90\u00b0 to each other",
      "score": 0.9471861720085144
    }
  ],
  "1964": [
    {
      "answer": "the pistons worked in the same phase driving a common crosshead and crank, again set at 90\u00b0 as for a two-cylinder engine.",
      "score": 0.9315325617790222
    }
  ],
  "1965": [
    {
      "answer": "counterflow",
      "score": 0.9793798923492432
    }
  ],
  "1966": [
    {
      "answer": "two",
      "score": 0.9746877551078796
    }
  ],
  "1967": [
    {
      "answer": "one",
      "score": 0.9799270629882812
    }
  ],
  "1968": [
    {
      "answer": "four",
      "score": 0.98946613073349
    }
  ],
  "1969": [
    {
      "answer": "expansion",
      "score": 0.9615188837051392
    }
  ],
  "1970": [
    {
      "answer": "counterflow",
      "score": 0.9808552861213684
    }
  ],
  "1971": [
    {
      "answer": "two",
      "score": 0.9361597299575806
    }
  ],
  "1972": [
    {
      "answer": "one",
      "score": 0.979866087436676
    }
  ],
  "1973": [
    {
      "answer": "four",
      "score": 0.9898548126220703
    }
  ],
  "1974": [
    {
      "answer": "expansion",
      "score": 0.9509173631668091
    }
  ],
  "1975": [
    {
      "answer": "Quasiturbine",
      "score": 0.9503047466278076
    }
  ],
  "1976": [
    {
      "answer": "counterflow",
      "score": 0.9925703406333923
    }
  ],
  "1977": [
    {
      "answer": "piston",
      "score": 0.891693651676178
    }
  ],
  "1978": [
    {
      "answer": "Quasiturbine",
      "score": 0.9489691257476807
    }
  ],
  "1979": [
    {
      "answer": "counterflow",
      "score": 0.9866062998771667
    }
  ],
  "1980": [
    {
      "answer": "additional port uncovered by the piston at the end of each stroke",
      "score": 0.8097352981567383
    }
  ],
  "1981": [
    {
      "answer": "Uniflow engines",
      "score": 0.9482001066207886
    },
    {
      "answer": "uniflow engines",
      "score": 0.6590741872787476
    }
  ],
  "1982": [
    {
      "answer": "improve efficiency",
      "score": 0.9731605052947998
    }
  ],
  "1983": [
    {
      "answer": "oscillating cylinder",
      "score": 0.9811530709266663
    }
  ],
  "1984": [
    {
      "answer": "trunnion",
      "score": 0.985826313495636
    }
  ],
  "1985": [
    {
      "answer": "toys and models",
      "score": 0.9204128980636597
    }
  ],
  "1986": [
    {
      "answer": "ships",
      "score": 0.9882320761680603
    }
  ],
  "1987": [
    {
      "answer": "oscillating cylinder",
      "score": 0.9819023013114929
    }
  ],
  "1988": [
    {
      "answer": "pivot mounting",
      "score": 0.8513466119766235
    },
    {
      "answer": "trunnion",
      "score": 0.7135726809501648
    }
  ],
  "1989": [
    {
      "answer": "full size working engines",
      "score": 0.7115820050239563
    }
  ],
  "1990": [
    {
      "answer": "ships",
      "score": 0.9830910563468933
    }
  ],
  "1991": [
    {
      "answer": "oscillating cylinder steam engine",
      "score": 0.963555097579956
    }
  ],
  "1992": [
    {
      "answer": "the working fluid is recycled continuously",
      "score": 0.8197543025016785
    }
  ],
  "1993": [
    {
      "answer": "open loop",
      "score": 0.9427417516708374
    }
  ],
  "1994": [
    {
      "answer": "Mercury",
      "score": 0.9459307789802551
    },
    {
      "answer": "mercury",
      "score": 0.5398932695388794
    }
  ],
  "1995": [
    {
      "answer": "water",
      "score": 0.9158284664154053
    }
  ],
  "1996": [],
  "1997": [
    {
      "answer": "open loop",
      "score": 0.950282871723175
    }
  ],
  "1998": [
    {
      "answer": "Mercury",
      "score": 0.9242553114891052
    },
    {
      "answer": "mercury",
      "score": 0.6096947193145752
    }
  ],
  "1999": [
    {
      "answer": "Mercury",
      "score": 0.6787209510803223
    },
    {
      "answer": "mercury",
      "score": 0.6175674796104431
    }
  ],
  "2000": [
    {
      "answer": "closed loop system",
      "score": 0.9757186770439148
    }
  ],
  "2001": [
    {
      "answer": "working fluid",
      "score": 0.9871386885643005
    }
  ],
  "2002": [
    {
      "answer": "565 \u00b0C",
      "score": 0.9753031730651855
    }
  ],
  "2003": [
    {
      "answer": "stainless steel",
      "score": 0.9909533262252808
    }
  ],
  "2004": [
    {
      "answer": "30 \u00b0C",
      "score": 0.9706013202667236
    }
  ],
  "2005": [
    {
      "answer": "63%",
      "score": 0.9793704152107239
    }
  ],
  "2006": [
    {
      "answer": "working fluid",
      "score": 0.8998017907142639
    },
    {
      "answer": "working fluid",
      "score": 0.5862234830856323
    }
  ],
  "2007": [
    {
      "answer": "565 \u00b0C",
      "score": 0.9703842997550964
    }
  ],
  "2008": [
    {
      "answer": "stainless steel",
      "score": 0.9863242506980896
    }
  ],
  "2009": [
    {
      "answer": "30 \u00b0C",
      "score": 0.9732221961021423
    }
  ],
  "2010": [
    {
      "answer": "63%",
      "score": 0.9805651903152466
    }
  ],
  "2011": [
    {
      "answer": "Steam engines",
      "score": 0.9782390594482422
    }
  ],
  "2012": [
    {
      "answer": "steamboats",
      "score": 0.8829654455184937
    },
    {
      "answer": "road vehicles",
      "score": 0.7858436107635498
    }
  ],
  "2013": [
    {
      "answer": "Stanley Steamer",
      "score": 0.97076016664505
    }
  ],
  "2014": [
    {
      "answer": "factories",
      "score": 0.898136556148529
    }
  ],
  "2015": [
    {
      "answer": "increase in the land available for cultivation",
      "score": 0.976881206035614
    }
  ],
  "2016": [
    {
      "answer": "Steam engines",
      "score": 0.9810965061187744
    }
  ],
  "2017": [
    {
      "answer": "steamboats",
      "score": 0.8397889137268066
    },
    {
      "answer": "road vehicles",
      "score": 0.7920287847518921
    }
  ],
  "2018": [
    {
      "answer": "Stanley Steamer",
      "score": 0.9456784725189209
    }
  ],
  "2019": [],
  "2020": [
    {
      "answer": "an increase in the land available for cultivation",
      "score": 0.9276401996612549
    }
  ],
  "2021": [
    {
      "answer": "Catch Me Who Can",
      "score": 0.9381618499755859
    }
  ],
  "2022": [
    {
      "answer": "Matthew Murray",
      "score": 0.9967983365058899
    }
  ],
  "2023": [
    {
      "answer": "twin-cylinder",
      "score": 0.9889217615127563
    }
  ],
  "2024": [
    {
      "answer": "Middleton Railway",
      "score": 0.975421667098999
    }
  ],
  "2025": [
    {
      "answer": "Stockton and Darlington Railway",
      "score": 0.9912127256393433
    }
  ],
  "2026": [
    {
      "answer": "Locomotion",
      "score": 0.91045743227005
    }
  ],
  "2027": [
    {
      "answer": "Matthew Murray",
      "score": 0.9967983365058899
    }
  ],
  "2028": [
    {
      "answer": "Locomotion",
      "score": 0.5500245690345764
    }
  ],
  "2029": [
    {
      "answer": "Stockton and Darlington Railway",
      "score": 0.9485821723937988
    }
  ],
  "2030": [
    {
      "answer": "Middleton Railway",
      "score": 0.6024329662322998
    },
    {
      "answer": "Stockton and Darlington Railway",
      "score": 0.9622026681900024
    }
  ],
  "2031": [
    {
      "answer": "Arthur Woolf",
      "score": 0.9891616106033325
    }
  ],
  "2032": [
    {
      "answer": "British",
      "score": 0.9940418601036072
    }
  ],
  "2033": [
    {
      "answer": "torque",
      "score": 0.9328610301017761
    }
  ],
  "2034": [
    {
      "answer": "cylinder volume",
      "score": 0.9506808519363403
    }
  ],
  "2035": [
    {
      "answer": "Arthur Woolf",
      "score": 0.9894134998321533
    }
  ],
  "2036": [
    {
      "answer": "British",
      "score": 0.992676854133606
    }
  ],
  "2037": [
    {
      "answer": "torque",
      "score": 0.9382621645927429
    }
  ],
  "2038": [
    {
      "answer": "cylinder volume",
      "score": 0.9476488828659058
    }
  ],
  "2039": [
    {
      "answer": "Arthur Woolf",
      "score": 0.9857397079467773
    }
  ],
  "2040": [
    {
      "answer": "90%",
      "score": 0.9847735166549683
    }
  ],
  "2041": [
    {
      "answer": "reciprocating steam engines",
      "score": 0.6131996512413025
    },
    {
      "answer": "reciprocating Diesel engines",
      "score": 0.6302163600921631
    }
  ],
  "2042": [
    {
      "answer": "Diesel engines",
      "score": 0.8516235947608948
    },
    {
      "answer": "gas turbines",
      "score": 0.8951705694198608
    }
  ],
  "2043": [
    {
      "answer": "steam turbines",
      "score": 0.6226891279220581
    },
    {
      "answer": "steam turbines",
      "score": 0.6676996946334839
    },
    {
      "answer": "steam turbines",
      "score": 0.951804518699646
    }
  ],
  "2044": [
    {
      "answer": "reduction",
      "score": 0.9874749779701233
    }
  ],
  "2045": [
    {
      "answer": "90%",
      "score": 0.9850292205810547
    }
  ],
  "2046": [
    {
      "answer": "reciprocating steam engines",
      "score": 0.7172409892082214
    }
  ],
  "2047": [
    {
      "answer": "Diesel engines",
      "score": 0.8965451717376709
    },
    {
      "answer": "gas turbines",
      "score": 0.8290414810180664
    }
  ],
  "2048": [
    {
      "answer": "steam turbines",
      "score": 0.5664461851119995
    },
    {
      "answer": "steam turbines",
      "score": 0.6368796825408936
    },
    {
      "answer": "steam turbines",
      "score": 0.6663824319839478
    },
    {
      "answer": "steam turbines",
      "score": 0.9498703479766846
    }
  ],
  "2049": [
    {
      "answer": "reduction",
      "score": 0.9841583967208862
    }
  ],
  "2050": [
    {
      "answer": "Rankine cycle",
      "score": 0.9635571241378784
    },
    {
      "answer": "Rankine cycle",
      "score": 0.9184035062789917
    }
  ],
  "2051": [
    {
      "answer": "removed in a condenser",
      "score": 0.9769343137741089
    }
  ],
  "2052": [
    {
      "answer": "1990s",
      "score": 0.9942827224731445
    }
  ],
  "2053": [
    {
      "answer": "biomass",
      "score": 0.9602475166320801
    },
    {
      "answer": "nuclear",
      "score": 0.7528330087661743
    }
  ],
  "2054": [
    {
      "answer": "Scottish",
      "score": 0.9943406581878662
    }
  ],
  "2055": [
    {
      "answer": "Rankine cycle",
      "score": 0.9428552389144897
    },
    {
      "answer": "Rankine cycle",
      "score": 0.9312885999679565
    }
  ],
  "2056": [
    {
      "answer": "removed in a condenser",
      "score": 0.9720437526702881
    }
  ],
  "2057": [
    {
      "answer": "1990s",
      "score": 0.9950479865074158
    }
  ],
  "2058": [
    {
      "answer": "Rankine cycle",
      "score": 0.867999792098999
    },
    {
      "answer": "Rankine cycle",
      "score": 0.8963699340820312
    }
  ],
  "2059": [
    {
      "answer": "Scottish",
      "score": 0.9927305579185486
    }
  ],
  "2060": [
    {
      "answer": "duty",
      "score": 0.8986369371414185
    },
    {
      "answer": "duty",
      "score": 0.6901733875274658
    },
    {
      "answer": "duty",
      "score": 0.549161970615387
    }
  ],
  "2061": [
    {
      "answer": "Watt",
      "score": 0.9918035268783569
    },
    {
      "answer": "Watt",
      "score": 0.815589964389801
    },
    {
      "answer": "Watt",
      "score": 0.7296065092086792
    }
  ],
  "2062": [
    {
      "answer": "94 pounds",
      "score": 0.9752227663993835
    }
  ],
  "2063": [
    {
      "answer": "7 million",
      "score": 0.9734383225440979
    }
  ],
  "2064": [
    {
      "answer": "17",
      "score": 0.9850233793258667
    }
  ],
  "2065": [
    {
      "answer": "duty",
      "score": 0.8692298531532288
    },
    {
      "answer": "duty",
      "score": 0.8225247263908386
    },
    {
      "answer": "duty",
      "score": 0.556898295879364
    }
  ],
  "2066": [
    {
      "answer": "Watt",
      "score": 0.9919204711914062
    },
    {
      "answer": "Watt",
      "score": 0.809795081615448
    },
    {
      "answer": "Watt",
      "score": 0.6965600848197937
    }
  ],
  "2067": [
    {
      "answer": "94 pounds",
      "score": 0.9858104586601257
    }
  ],
  "2068": [
    {
      "answer": "7 million",
      "score": 0.7762541770935059
    },
    {
      "answer": "25 million",
      "score": 0.645813524723053
    }
  ],
  "2069": [
    {
      "answer": "5 million",
      "score": 0.5566138029098511
    },
    {
      "answer": "17",
      "score": 0.7257449626922607
    }
  ],
  "2070": [
    {
      "answer": "steam turbines",
      "score": 0.932586133480072
    }
  ],
  "2071": [
    {
      "answer": "Reciprocating piston",
      "score": 0.9850974082946777
    }
  ],
  "2072": [
    {
      "answer": "turbine",
      "score": 0.9869526624679565
    }
  ],
  "2073": [
    {
      "answer": "internal combustion engines",
      "score": 0.6869065761566162
    },
    {
      "answer": "steam turbines",
      "score": 0.9596449136734009
    }
  ],
  "2074": [
    {
      "answer": "steam turbines",
      "score": 0.9714363217353821
    }
  ],
  "2075": [
    {
      "answer": "Reciprocating piston type",
      "score": 0.9464348554611206
    }
  ],
  "2076": [
    {
      "answer": "turbine",
      "score": 0.9829275012016296
    }
  ],
  "2077": [
    {
      "answer": "internal combustion engines",
      "score": 0.98576420545578
    }
  ],
  "2078": [
    {
      "answer": "steam age",
      "score": 0.9896863698959351
    }
  ],
  "2079": [
    {
      "answer": "Thomas Savery",
      "score": 0.9963927268981934
    }
  ],
  "2080": [
    {
      "answer": "water pump",
      "score": 0.9821549654006958
    }
  ],
  "2081": [
    {
      "answer": "1698",
      "score": 0.9871534705162048
    }
  ],
  "2082": [
    {
      "answer": "Bento de Moura Portugal",
      "score": 0.994994044303894
    }
  ],
  "2083": [
    {
      "answer": "John Smeaton",
      "score": 0.9870154857635498
    }
  ],
  "2084": [
    {
      "answer": "Thomas Savery",
      "score": 0.9965006709098816
    }
  ],
  "2085": [
    {
      "answer": "water pump",
      "score": 0.792005181312561
    }
  ],
  "2086": [
    {
      "answer": "1698",
      "score": 0.9793342351913452
    }
  ],
  "2087": [
    {
      "answer": "Bento de Moura Portugal",
      "score": 0.9957636594772339
    }
  ],
  "2088": [
    {
      "answer": "John Smeaton",
      "score": 0.9805376529693604
    }
  ],
  "2089": [
    {
      "answer": "Richard Trevithick",
      "score": 0.9898228049278259
    }
  ],
  "2090": [
    {
      "answer": "Richard Trevithick",
      "score": 0.958823561668396
    },
    {
      "answer": "Oliver Evans",
      "score": 0.9450491666793823
    }
  ],
  "2091": [
    {
      "answer": "1802",
      "score": 0.9862680435180664
    }
  ],
  "2092": [
    {
      "answer": "transport",
      "score": 0.99208003282547
    }
  ],
  "2093": [
    {
      "answer": "power",
      "score": 0.6261504888534546
    }
  ],
  "2094": [
    {
      "answer": "Richard Trevithick",
      "score": 0.9910761117935181
    }
  ],
  "2095": [
    {
      "answer": "Richard Trevithick",
      "score": 0.95738685131073
    },
    {
      "answer": "Oliver Evans",
      "score": 0.9495468139648438
    }
  ],
  "2096": [
    {
      "answer": "1801",
      "score": 0.9808226227760315
    }
  ],
  "2097": [
    {
      "answer": "transport",
      "score": 0.9926905035972595
    }
  ],
  "2098": [
    {
      "answer": "steam engine",
      "score": 0.7915600538253784
    }
  ],
  "2099": [
    {
      "answer": "Energiprojekt AB",
      "score": 0.9450879096984863
    }
  ],
  "2100": [
    {
      "answer": "Sweden",
      "score": 0.9582358002662659
    }
  ],
  "2101": [
    {
      "answer": "5-cylinder",
      "score": 0.9866859912872314
    }
  ],
  "2102": [
    {
      "answer": "4 kg",
      "score": 0.8159853219985962
    },
    {
      "answer": "8.8 lb",
      "score": 0.8688837289810181
    }
  ],
  "2103": [
    {
      "answer": "27-30%",
      "score": 0.9887794256210327
    }
  ],
  "2104": [
    {
      "answer": "Energiprojekt AB",
      "score": 0.9548018574714661
    }
  ],
  "2105": [
    {
      "answer": "Sweden",
      "score": 0.8950380682945251
    }
  ],
  "2106": [
    {
      "answer": "5-cylinder",
      "score": 0.9879220128059387
    }
  ],
  "2107": [
    {
      "answer": "4 kg",
      "score": 0.7872449159622192
    },
    {
      "answer": "8.8",
      "score": 0.93141770362854
    }
  ],
  "2108": [
    {
      "answer": "27-30%",
      "score": 0.9846804141998291
    }
  ],
  "2109": [
    {
      "answer": "surface condensers",
      "score": 0.9878922700881958
    }
  ],
  "2110": [
    {
      "answer": "automobile radiator",
      "score": 0.977684736251831
    }
  ],
  "2111": [
    {
      "answer": "locations where water is costly",
      "score": 0.9025867581367493
    }
  ],
  "2112": [
    {
      "answer": "wet",
      "score": 0.7835688591003418
    }
  ],
  "2113": [
    {
      "answer": "3600",
      "score": 0.9914488196372986
    }
  ],
  "2114": [
    {
      "answer": "surface condensers",
      "score": 0.9857524633407593
    }
  ],
  "2115": [
    {
      "answer": "automobile radiator",
      "score": 0.9568960070610046
    }
  ],
  "2116": [
    {
      "answer": "oceans",
      "score": 0.5887097716331482
    },
    {
      "answer": "lakes",
      "score": 0.5174180865287781
    }
  ],
  "2117": [
    {
      "answer": "dry type",
      "score": 0.944779634475708
    }
  ],
  "2118": [
    {
      "answer": "3600",
      "score": 0.9918670058250427
    }
  ],
  "2119": [
    {
      "answer": "centrifugal governor",
      "score": 0.9251304864883423
    }
  ],
  "2120": [
    {
      "answer": "Boulton",
      "score": 0.9573505520820618
    }
  ],
  "2121": [
    {
      "answer": "flour mill",
      "score": 0.9897650480270386
    }
  ],
  "2122": [
    {
      "answer": "cotton spinning",
      "score": 0.99192875623703
    }
  ],
  "2123": [
    {
      "answer": "hold a set speed",
      "score": 0.9758939146995544
    }
  ],
  "2124": [
    {
      "answer": "variable steam cut off",
      "score": 0.9638789892196655
    }
  ],
  "2125": [
    {
      "answer": "Boulton",
      "score": 0.9478772282600403
    }
  ],
  "2126": [
    {
      "answer": "flour mill",
      "score": 0.9870054721832275
    }
  ],
  "2127": [
    {
      "answer": "cotton spinning",
      "score": 0.9726468324661255
    }
  ],
  "2128": [
    {
      "answer": "hold a set speed",
      "score": 0.8913601636886597
    }
  ],
  "2129": [
    {
      "answer": "1880",
      "score": 0.9866928458213806
    }
  ],
  "2130": [
    {
      "answer": "railway locomotives",
      "score": 0.9897949695587158
    }
  ],
  "2131": [
    {
      "answer": "complicated",
      "score": 0.9861729741096497
    }
  ],
  "2132": [
    {
      "answer": "1930",
      "score": 0.9920322895050049
    }
  ],
  "2133": [
    {
      "answer": "industrial units",
      "score": 0.5681518316268921
    },
    {
      "answer": "road engines",
      "score": 0.9832919836044312
    }
  ],
  "2134": [
    {
      "answer": "1880",
      "score": 0.988009512424469
    }
  ],
  "2135": [
    {
      "answer": "railway locomotives",
      "score": 0.9906553626060486
    }
  ],
  "2136": [
    {
      "answer": "almost universal",
      "score": 0.9700803756713867
    }
  ],
  "2137": [
    {
      "answer": "1880",
      "score": 0.7389664053916931
    },
    {
      "answer": "1930",
      "score": 0.9539443850517273
    }
  ],
  "2138": [
    {
      "answer": "road engines",
      "score": 0.8741289377212524
    }
  ],
  "2139": [
    {
      "answer": "shortening the cutoff",
      "score": 0.8688766360282898
    }
  ],
  "2140": [
    {
      "answer": "kick back",
      "score": 0.9882514476776123
    }
  ],
  "2141": [
    {
      "answer": "evacuate the cylinder",
      "score": 0.9676286578178406
    }
  ],
  "2142": [
    {
      "answer": "fixed length",
      "score": 0.8702192306518555
    }
  ],
  "2143": [
    {
      "answer": "shortening the cutoff",
      "score": 0.6553880572319031
    },
    {
      "answer": "admission event",
      "score": 0.6883931159973145
    }
  ],
  "2144": [
    {
      "answer": "kick back",
      "score": 0.7121955156326294
    }
  ],
  "2145": [
    {
      "answer": "evacuate the cylinder",
      "score": 0.9667481184005737
    }
  ],
  "2146": [
    {
      "answer": "fixed length",
      "score": 0.7407137155532837
    }
  ],
  "2147": [
    {
      "answer": "events of fixed length",
      "score": 0.6036102175712585
    }
  ],
  "2148": [
    {
      "answer": "Jer\u00f3nimo de Ayanz y Beaumont",
      "score": 0.993939220905304
    }
  ],
  "2149": [
    {
      "answer": "Spanish",
      "score": 0.9874649047851562
    }
  ],
  "2150": [
    {
      "answer": "1606",
      "score": 0.9454153776168823
    }
  ],
  "2151": [
    {
      "answer": "1698",
      "score": 0.9793292284011841
    }
  ],
  "2152": [
    {
      "answer": "1712",
      "score": 0.9665881991386414
    }
  ],
  "2153": [
    {
      "answer": "Jer\u00f3nimo de Ayanz y Beaumont",
      "score": 0.9920218586921692
    }
  ],
  "2154": [
    {
      "answer": "Spanish",
      "score": 0.9140693545341492
    }
  ],
  "2155": [
    {
      "answer": "1712",
      "score": 0.9809077382087708
    }
  ],
  "2156": [
    {
      "answer": "1712",
      "score": 0.9821288585662842
    }
  ],
  "2157": [
    {
      "answer": "1698",
      "score": 0.9544373154640198
    }
  ],
  "2158": [
    {
      "answer": "rotating discs",
      "score": 0.6461093425750732
    }
  ],
  "2159": [
    {
      "answer": "drive shaft",
      "score": 0.9888561964035034
    }
  ],
  "2160": [
    {
      "answer": "static discs",
      "score": 0.8503662943840027
    }
  ],
  "2161": [
    {
      "answer": "turbine casing",
      "score": 0.9450534582138062
    }
  ],
  "2162": [
    {
      "answer": "3600 revolutions per minute",
      "score": 0.983635663986206
    }
  ],
  "2163": [],
  "2164": [
    {
      "answer": "drive shaft",
      "score": 0.9478362798690796
    }
  ],
  "2165": [],
  "2166": [
    {
      "answer": "drive shaft",
      "score": 0.6799213886260986
    }
  ],
  "2167": [
    {
      "answer": "3600 revolutions per minute",
      "score": 0.9370111227035522
    }
  ],
  "2168": [
    {
      "answer": "lower",
      "score": 0.9402487874031067
    }
  ],
  "2169": [
    {
      "answer": "internal combustion engines",
      "score": 0.7665030360221863
    },
    {
      "answer": "electric motors",
      "score": 0.9868570566177368
    }
  ],
  "2170": [
    {
      "answer": "steam turbine",
      "score": 0.9927489757537842
    }
  ],
  "2171": [
    {
      "answer": "Advanced Steam movement",
      "score": 0.9234968423843384
    }
  ],
  "2172": [
    {
      "answer": "pollution",
      "score": 0.9854787588119507
    }
  ],
  "2173": [
    {
      "answer": "lower than for internal combustion engines",
      "score": 0.8751740455627441
    }
  ],
  "2174": [
    {
      "answer": "electric motors",
      "score": 0.9432567358016968
    }
  ],
  "2175": [
    {
      "answer": "steam turbine",
      "score": 0.9842702150344849
    }
  ],
  "2176": [
    {
      "answer": "Advanced Steam movement",
      "score": 0.9280529022216797
    }
  ],
  "2177": [
    {
      "answer": "pollution",
      "score": 0.9862384796142578
    }
  ],
  "2178": [
    {
      "answer": "Wankel engine",
      "score": 0.9736714363098145
    }
  ],
  "2179": [
    {
      "answer": "cylinders",
      "score": 0.8530722856521606
    },
    {
      "answer": "valve gear",
      "score": 0.8808451890945435
    }
  ],
  "2180": [
    {
      "answer": "thermal expansion",
      "score": 0.988927960395813
    }
  ],
  "2181": [
    {
      "answer": "Wankel engine",
      "score": 0.956417441368103
    }
  ],
  "2182": [
    {
      "answer": "cylinders",
      "score": 0.8690533638000488
    },
    {
      "answer": "valve gear",
      "score": 0.8386377692222595
    }
  ],
  "2183": [
    {
      "answer": "thermal expansion",
      "score": 0.993532121181488
    }
  ],
  "2184": [],
  "2185": [
    {
      "answer": "Wankel engine",
      "score": 0.978232741355896
    }
  ],
  "2186": [
    {
      "answer": "1763",
      "score": 0.9430635571479797
    },
    {
      "answer": "1775",
      "score": 0.8596720099449158
    }
  ],
  "2187": [
    {
      "answer": "a separate condenser",
      "score": 0.9297357797622681
    }
  ],
  "2188": [
    {
      "answer": "half",
      "score": 0.9882729649543762
    }
  ],
  "2189": [
    {
      "answer": "John Smeaton",
      "score": 0.7180715799331665
    }
  ],
  "2190": [
    {
      "answer": "a piston",
      "score": 0.8684844374656677
    }
  ],
  "2191": [
    {
      "answer": "1763",
      "score": 0.8952405452728271
    },
    {
      "answer": "1775",
      "score": 0.8983374834060669
    }
  ],
  "2192": [
    {
      "answer": "a separate condenser",
      "score": 0.800778865814209
    }
  ],
  "2193": [
    {
      "answer": "half as much coal",
      "score": 0.8591486215591431
    }
  ],
  "2194": [
    {
      "answer": "John Smeaton",
      "score": 0.8490786552429199
    }
  ],
  "2195": [
    {
      "answer": "piston",
      "score": 0.8884923458099365
    }
  ],
  "2196": [
    {
      "answer": "two",
      "score": 0.9798436164855957
    }
  ],
  "2197": [
    {
      "answer": "plug valve",
      "score": 0.8608701229095459
    }
  ],
  "2198": [
    {
      "answer": "adjustable spring-loaded valve",
      "score": 0.9701401591300964
    }
  ],
  "2199": [
    {
      "answer": "seal",
      "score": 0.987539529800415
    }
  ],
  "2200": [
    {
      "answer": "greater steam pressure and more power",
      "score": 0.7809855341911316
    }
  ],
  "2201": [
    {
      "answer": "two",
      "score": 0.9799817800521851
    }
  ],
  "2202": [
    {
      "answer": "plug valve",
      "score": 0.8965579271316528
    }
  ],
  "2203": [
    {
      "answer": "adjustable spring-loaded valve",
      "score": 0.9707280993461609
    }
  ],
  "2204": [
    {
      "answer": "seal",
      "score": 0.9871206879615784
    }
  ],
  "2205": [
    {
      "answer": "more power",
      "score": 0.8270087242126465
    }
  ],
  "2206": [
    {
      "answer": "Corliss steam engine",
      "score": 0.9644349813461304
    }
  ],
  "2207": [
    {
      "answer": "1849",
      "score": 0.9800992608070374
    }
  ],
  "2208": [
    {
      "answer": "four-valve",
      "score": 0.9798811674118042
    }
  ],
  "2209": [
    {
      "answer": "Rumford medal",
      "score": 0.9606822729110718
    }
  ],
  "2210": [
    {
      "answer": "30%",
      "score": 0.9928017854690552
    }
  ],
  "2211": [
    {
      "answer": "Corliss steam engine",
      "score": 0.9620230197906494
    }
  ],
  "2212": [
    {
      "answer": "1849",
      "score": 0.9851387143135071
    }
  ],
  "2213": [
    {
      "answer": "four-valve",
      "score": 0.9786624312400818
    }
  ],
  "2214": [
    {
      "answer": "Rumford medal",
      "score": 0.9862729907035828
    }
  ],
  "2215": [
    {
      "answer": "30%",
      "score": 0.9922620058059692
    }
  ],
  "2216": [
    {
      "answer": "thermodynamic",
      "score": 0.9224362969398499
    }
  ],
  "2217": [
    {
      "answer": "Watt",
      "score": 0.9732986688613892
    },
    {
      "answer": "Watt",
      "score": 0.5717419981956482
    }
  ],
  "2218": [
    {
      "answer": "separate condenser",
      "score": 0.975084662437439
    }
  ],
  "2219": [
    {
      "answer": "Joseph Black",
      "score": 0.9930415153503418
    }
  ],
  "2220": [
    {
      "answer": "latent heat",
      "score": 0.879334568977356
    }
  ],
  "2221": [
    {
      "answer": "thermodynamic",
      "score": 0.902050256729126
    }
  ],
  "2222": [
    {
      "answer": "Watt",
      "score": 0.9763042330741882
    },
    {
      "answer": "Watt",
      "score": 0.5645996332168579
    }
  ],
  "2223": [
    {
      "answer": "the separate condenser",
      "score": 0.9399115443229675
    }
  ],
  "2224": [
    {
      "answer": "Joseph Black",
      "score": 0.9940807819366455
    }
  ],
  "2225": [
    {
      "answer": "latent heat",
      "score": 0.7713846564292908
    }
  ],
  "2226": [
    {
      "answer": "during the compression stage relatively little work is required to drive the pump",
      "score": 0.9150000810623169
    }
  ],
  "2227": [
    {
      "answer": "liquid",
      "score": 0.9928379654884338
    }
  ],
  "2228": [
    {
      "answer": "1% to 3%",
      "score": 0.9887591600418091
    }
  ],
  "2229": [
    {
      "answer": "1500 \u00b0C",
      "score": 0.9883131384849548
    }
  ],
  "2230": [
    {
      "answer": "during the compression stage relatively little work is required to drive the pump",
      "score": 0.7835832834243774
    }
  ],
  "2231": [
    {
      "answer": "liquid",
      "score": 0.9929078817367554
    }
  ],
  "2232": [
    {
      "answer": "1% to 3%",
      "score": 0.9586233496665955
    }
  ],
  "2233": [
    {
      "answer": "1500 \u00b0C",
      "score": 0.937874972820282
    }
  ],
  "2234": [
    {
      "answer": "condensing",
      "score": 0.9679527878761292
    }
  ],
  "2235": [
    {
      "answer": "injector",
      "score": 0.9719494581222534
    }
  ],
  "2236": [
    {
      "answer": "recover the latent heat of vaporisation",
      "score": 0.9749824404716492
    }
  ],
  "2237": [
    {
      "answer": "superheaters",
      "score": 0.9910248517990112
    }
  ],
  "2238": [
    {
      "answer": "bunker",
      "score": 0.9888273477554321
    }
  ],
  "2239": [
    {
      "answer": "chain or screw stoking mechanism",
      "score": 0.9447975158691406
    }
  ],
  "2240": [
    {
      "answer": "Mechanical stoker",
      "score": 0.6650457978248596
    }
  ],
  "2241": [],
  "2242": [
    {
      "answer": "superheaters",
      "score": 0.9917744994163513
    }
  ],
  "2243": [],
  "2244": [
    {
      "answer": "chain or screw stoking mechanism",
      "score": 0.9442610144615173
    }
  ],
  "2245": [
    {
      "answer": "water",
      "score": 0.9965813755989075
    }
  ],
  "2246": [
    {
      "answer": "British",
      "score": 0.9968922734260559
    }
  ],
  "2247": [
    {
      "answer": "dreadnought battleships",
      "score": 0.9425771832466125
    },
    {
      "answer": "ocean liners",
      "score": 0.6304817199707031
    }
  ],
  "2248": [
    {
      "answer": "dreadnought battleships",
      "score": 0.8747901320457458
    },
    {
      "answer": "ocean liners",
      "score": 0.9374869465827942
    }
  ],
  "2249": [
    {
      "answer": "1905",
      "score": 0.9920561909675598
    }
  ],
  "2250": [
    {
      "answer": "water",
      "score": 0.9608482718467712
    }
  ],
  "2251": [
    {
      "answer": "British",
      "score": 0.9948604702949524
    }
  ],
  "2252": [
    {
      "answer": "dreadnought battleships",
      "score": 0.8854093551635742
    },
    {
      "answer": "ocean liners",
      "score": 0.6171497106552124
    }
  ],
  "2253": [
    {
      "answer": "marine applications",
      "score": 0.7665185928344727
    }
  ],
  "2254": [],
  "2255": [
    {
      "answer": "water",
      "score": 0.9932657480239868
    }
  ],
  "2256": [
    {
      "answer": "turbine",
      "score": 0.9262896776199341
    }
  ],
  "2257": [
    {
      "answer": "electrical generator",
      "score": 0.987166702747345
    }
  ],
  "2258": [
    {
      "answer": "turbo-electric transmission",
      "score": 0.9909477829933167
    }
  ],
  "2259": [
    {
      "answer": "Sweden",
      "score": 0.9045360684394836
    },
    {
      "answer": "Britain",
      "score": 0.9653310179710388
    }
  ],
  "2260": [
    {
      "answer": "water",
      "score": 0.9930563569068909
    }
  ],
  "2261": [
    {
      "answer": "turbine",
      "score": 0.7964246869087219
    }
  ],
  "2262": [
    {
      "answer": "electrical generator",
      "score": 0.9817898869514465
    }
  ],
  "2263": [
    {
      "answer": "turbo-electric transmission",
      "score": 0.9901021718978882
    }
  ],
  "2264": [
    {
      "answer": "Sweden",
      "score": 0.895483672618866
    },
    {
      "answer": "Britain",
      "score": 0.9578734040260315
    }
  ],
  "2265": [
    {
      "answer": "practical Carnot cycle",
      "score": 0.9755911827087402
    }
  ],
  "2266": [
    {
      "answer": "condenser",
      "score": 0.9687304496765137
    },
    {
      "answer": "condenser",
      "score": 0.7609760165214539
    }
  ],
  "2267": [
    {
      "answer": "constant pressure",
      "score": 0.9913631081581116
    }
  ],
  "2268": [
    {
      "answer": "isothermal",
      "score": 0.9879611134529114
    }
  ],
  "2269": [
    {
      "answer": "liquid",
      "score": 0.9857980608940125
    },
    {
      "answer": "liquid",
      "score": 0.7910404205322266
    }
  ],
  "2270": [
    {
      "answer": "Carnot cycle",
      "score": 0.7662330865859985
    }
  ],
  "2271": [
    {
      "answer": "condenser",
      "score": 0.9687304496765137
    },
    {
      "answer": "condenser",
      "score": 0.7609760165214539
    }
  ],
  "2272": [],
  "2273": [
    {
      "answer": "isobaric",
      "score": 0.6167443990707397
    },
    {
      "answer": "isothermal",
      "score": 0.8834848999977112
    }
  ],
  "2274": [
    {
      "answer": "liquid",
      "score": 0.9836850166320801
    },
    {
      "answer": "liquid",
      "score": 0.8114179372787476
    }
  ],
  "2275": [
    {
      "answer": "8",
      "score": 0.9930851459503174
    }
  ],
  "2276": [
    {
      "answer": "hydrogen and helium",
      "score": 0.7598745226860046
    }
  ],
  "2277": [
    {
      "answer": "Diatomic oxygen",
      "score": 0.758549690246582
    }
  ],
  "2278": [
    {
      "answer": "two",
      "score": 0.99162757396698
    }
  ],
  "2279": [
    {
      "answer": "almost half",
      "score": 0.9582897424697876
    }
  ],
  "2280": [
    {
      "answer": "8",
      "score": 0.985775887966156
    }
  ],
  "2281": [
    {
      "answer": "chalcogen",
      "score": 0.9896939396858215
    }
  ],
  "2282": [
    {
      "answer": "oxides",
      "score": 0.9366604089736938
    }
  ],
  "2283": [
    {
      "answer": "third-most abundant element in the universe",
      "score": 0.9270609617233276
    }
  ],
  "2284": [
    {
      "answer": "dioxygen",
      "score": 0.9902731776237488
    }
  ],
  "2285": [
    {
      "answer": "Oxygen",
      "score": 0.603316605091095
    }
  ],
  "2286": [
    {
      "answer": "Oxygen",
      "score": 0.7227153778076172
    }
  ],
  "2287": [
    {
      "answer": "Oxygen",
      "score": 0.6487047672271729
    },
    {
      "answer": "oxygen",
      "score": 0.8333067893981934
    },
    {
      "answer": "oxygen",
      "score": 0.6506022810935974
    },
    {
      "answer": "oxygen",
      "score": 0.6506016850471497
    },
    {
      "answer": "Oxygen",
      "score": 0.6750676035881042
    }
  ],
  "2288": [
    {
      "answer": "Diatomic oxygen",
      "score": 0.8047947883605957
    }
  ],
  "2289": [
    {
      "answer": "photosynthesis",
      "score": 0.9891884922981262
    }
  ],
  "2290": [
    {
      "answer": "sunlight",
      "score": 0.9919756054878235
    }
  ],
  "2291": [],
  "2292": [
    {
      "answer": "oxygen",
      "score": 0.9649136662483215
    },
    {
      "answer": "oxygen",
      "score": 0.6778812408447266
    },
    {
      "answer": "Oxygen",
      "score": 0.6685487627983093
    },
    {
      "answer": "oxygen",
      "score": 0.699109673500061
    },
    {
      "answer": "oxygen",
      "score": 0.6923673748970032
    },
    {
      "answer": "oxygen",
      "score": 0.7465173006057739
    }
  ],
  "2293": [
    {
      "answer": "water",
      "score": 0.7338082790374756
    }
  ],
  "2294": [
    {
      "answer": "cellular respiration",
      "score": 0.8952184915542603
    },
    {
      "answer": "photosynthesis",
      "score": 0.954586923122406
    }
  ],
  "2295": [
    {
      "answer": "water",
      "score": 0.9293259382247925
    }
  ],
  "2296": [
    {
      "answer": "ozone",
      "score": 0.9381598830223083
    }
  ],
  "2297": [
    {
      "answer": "nucleic acids",
      "score": 0.7551134824752808
    },
    {
      "answer": "carbohydrates",
      "score": 0.7101460099220276
    },
    {
      "answer": "fats",
      "score": 0.7539530992507935
    }
  ],
  "2298": [
    {
      "answer": "oxygen",
      "score": 0.7565086483955383
    },
    {
      "answer": "oxygen",
      "score": 0.6853774785995483
    },
    {
      "answer": "Oxygen",
      "score": 0.9436724185943604
    },
    {
      "answer": "oxygen",
      "score": 0.7466347813606262
    },
    {
      "answer": "oxygen",
      "score": 0.6971426010131836
    },
    {
      "answer": "oxygen",
      "score": 0.7214470505714417
    }
  ],
  "2299": [
    {
      "answer": "ozone",
      "score": 0.9403825998306274
    }
  ],
  "2300": [
    {
      "answer": "smog",
      "score": 0.8971056342124939
    }
  ],
  "2301": [
    {
      "answer": "Robert Boyle",
      "score": 0.9965196847915649
    }
  ],
  "2302": [
    {
      "answer": "John Mayow",
      "score": 0.9970483779907227
    }
  ],
  "2303": [
    {
      "answer": "nitroaereus",
      "score": 0.9913943409919739
    }
  ],
  "2304": [
    {
      "answer": "1679",
      "score": 0.9939602613449097
    }
  ],
  "2305": [
    {
      "answer": "Robert Boyle",
      "score": 0.9942367076873779
    }
  ],
  "2306": [
    {
      "answer": "spiritus nitroaereus",
      "score": 0.9690529108047485
    }
  ],
  "2307": [
    {
      "answer": "17th",
      "score": 0.9944990277290344
    }
  ],
  "2308": [
    {
      "answer": "respiration",
      "score": 0.9698184728622437
    }
  ],
  "2309": [
    {
      "answer": "John Mayow",
      "score": 0.9970022439956665
    }
  ],
  "2310": [
    {
      "answer": "combustion",
      "score": 0.9459815621376038
    },
    {
      "answer": "combustion",
      "score": 0.6528477668762207
    }
  ],
  "2311": [
    {
      "answer": "1641",
      "score": 0.9634042978286743
    },
    {
      "answer": "1679",
      "score": 0.9440732002258301
    }
  ],
  "2312": [
    {
      "answer": "late 17th century",
      "score": 0.9464582204818726
    }
  ],
  "2313": [
    {
      "answer": "John Mayow",
      "score": 0.9911820888519287
    }
  ],
  "2314": [
    {
      "answer": "chemist",
      "score": 0.988140344619751
    }
  ],
  "2315": [
    {
      "answer": "Joseph Priestley",
      "score": 0.82600337266922
    }
  ],
  "2316": [
    {
      "answer": "clergyman",
      "score": 0.9957525730133057
    }
  ],
  "2317": [
    {
      "answer": "mercuric oxide",
      "score": 0.990277886390686
    }
  ],
  "2318": [
    {
      "answer": "HgO",
      "score": 0.9890978336334229
    }
  ],
  "2319": [
    {
      "answer": "mercuric oxide",
      "score": 0.8989677429199219
    }
  ],
  "2320": [
    {
      "answer": "dephlogisticated air",
      "score": 0.9879231452941895
    }
  ],
  "2321": [
    {
      "answer": "1775",
      "score": 0.9889885783195496
    }
  ],
  "2322": [
    {
      "answer": "he published his findings first",
      "score": 0.9810213446617126
    }
  ],
  "2323": [
    {
      "answer": "more active and lived longer",
      "score": 0.9681673049926758
    }
  ],
  "2324": [
    {
      "answer": "Joseph Priestley",
      "score": 0.9944993853569031
    }
  ],
  "2325": [
    {
      "answer": "mercuric oxide (HgO)",
      "score": 0.7891109585762024
    }
  ],
  "2326": [
    {
      "answer": "An Account of Further Discoveries in Air",
      "score": 0.8477728366851807
    }
  ],
  "2327": [
    {
      "answer": "dephlogisticated air",
      "score": 0.9915129542350769
    }
  ],
  "2328": [
    {
      "answer": "Leonardo da Vinci",
      "score": 0.996916651725769
    }
  ],
  "2329": [
    {
      "answer": "Philo of Byzantium",
      "score": 0.9826215505599976
    }
  ],
  "2330": [
    {
      "answer": "2nd century BCE",
      "score": 0.9782054424285889
    }
  ],
  "2331": [],
  "2332": [
    {
      "answer": "Philo of Byzantium",
      "score": 0.9890995025634766
    }
  ],
  "2333": [
    {
      "answer": "fire",
      "score": 0.986255943775177
    }
  ],
  "2334": [
    {
      "answer": "Pneumatica",
      "score": 0.9447906017303467
    }
  ],
  "2335": [
    {
      "answer": "Leonardo da Vinci",
      "score": 0.9952887892723083
    }
  ],
  "2336": [
    {
      "answer": "air",
      "score": 0.7357127070426941
    },
    {
      "answer": "air",
      "score": 0.6634790301322937
    },
    {
      "answer": "air",
      "score": 0.9596089720726013
    }
  ],
  "2337": [
    {
      "answer": "relationship between combustion and air",
      "score": 0.8530064821243286
    }
  ],
  "2338": [
    {
      "answer": "2nd",
      "score": 0.9904627203941345
    }
  ],
  "2339": [
    {
      "answer": "Leonardo da Vinci",
      "score": 0.9974698424339294
    }
  ],
  "2340": [
    {
      "answer": "Greek",
      "score": 0.9729722738265991
    }
  ],
  "2341": [
    {
      "answer": "an ignition event",
      "score": 0.7145864963531494
    },
    {
      "answer": "heat",
      "score": 0.9524771571159363
    }
  ],
  "2342": [
    {
      "answer": "oxidant",
      "score": 0.9374970197677612
    }
  ],
  "2343": [
    {
      "answer": "compounds of oxygen with a high oxidative potential",
      "score": 0.8131743669509888
    }
  ],
  "2344": [],
  "2345": [
    {
      "answer": "promote rapid combustion",
      "score": 0.6780315637588501
    }
  ],
  "2346": [
    {
      "answer": "ignition",
      "score": 0.9107150435447693
    }
  ],
  "2347": [
    {
      "answer": "oxidant",
      "score": 0.9903592467308044
    }
  ],
  "2348": [
    {
      "answer": "oxidant",
      "score": 0.6320258975028992
    }
  ],
  "2349": [
    {
      "answer": "peroxides",
      "score": 0.9469749331474304
    },
    {
      "answer": "chlorates",
      "score": 0.924890398979187
    },
    {
      "answer": "nitrates",
      "score": 0.9169660210609436
    },
    {
      "answer": "perchlorates",
      "score": 0.9016729593276978
    },
    {
      "answer": "dichromates",
      "score": 0.8786903619766235
    }
  ],
  "2350": [
    {
      "answer": "rapid combustion",
      "score": 0.9628683924674988
    }
  ],
  "2351": [
    {
      "answer": "Oxygen",
      "score": 0.8636240363121033
    },
    {
      "answer": "oxidant",
      "score": 0.795818567276001
    }
  ],
  "2352": [
    {
      "answer": "Oxygen is the oxidant",
      "score": 0.5557264089584351
    }
  ],
  "2353": [
    {
      "answer": "Fire and explosion",
      "score": 0.9326444864273071
    }
  ],
  "2354": [
    {
      "answer": "peroxides",
      "score": 0.6261886954307556
    },
    {
      "answer": "nitrates",
      "score": 0.6204607486724854
    },
    {
      "answer": "perchlorates",
      "score": 0.5928870439529419
    }
  ],
  "2355": [],
  "2356": [],
  "2357": [],
  "2358": [
    {
      "answer": "combustion",
      "score": 0.9873347282409668
    }
  ],
  "2359": [],
  "2360": [
    {
      "answer": "special training",
      "score": 0.8568819165229797
    },
    {
      "answer": "ignition sources are minimized",
      "score": 0.9099278450012207
    }
  ],
  "2361": [
    {
      "answer": "Apollo 1 crew",
      "score": 0.9834429025650024
    }
  ],
  "2362": [
    {
      "answer": "Concentrated O\n2",
      "score": 0.6170696020126343
    },
    {
      "answer": "act as a fuel",
      "score": 0.7068548798561096
    }
  ],
  "2363": [
    {
      "answer": "fire",
      "score": 0.8812589645385742
    }
  ],
  "2364": [
    {
      "answer": "proceed rapidly and energetically",
      "score": 0.9891824722290039
    }
  ],
  "2365": [],
  "2366": [
    {
      "answer": "silica SiO\n2",
      "score": 0.8686978220939636
    }
  ],
  "2367": [
    {
      "answer": "carbon dioxide",
      "score": 0.9908410310745239
    }
  ],
  "2368": [
    {
      "answer": "carbon dioxide",
      "score": 0.9734205007553101
    }
  ],
  "2369": [
    {
      "answer": "Earth's crustal rock",
      "score": 0.7781252861022949
    }
  ],
  "2370": [
    {
      "answer": "mantle",
      "score": 0.9698283672332764
    }
  ],
  "2371": [
    {
      "answer": "mantle",
      "score": 0.9897820949554443
    }
  ],
  "2372": [
    {
      "answer": "silicates",
      "score": 0.9319976568222046
    }
  ],
  "2373": [
    {
      "answer": "carbon dioxide",
      "score": 0.9306378960609436
    },
    {
      "answer": "CO\n2",
      "score": 0.6650035381317139
    }
  ],
  "2374": [
    {
      "answer": "silica SiO\n2",
      "score": 0.7262370586395264
    }
  ],
  "2375": [
    {
      "answer": "Al\n2O\n3",
      "score": 0.9167420864105225
    }
  ],
  "2376": [
    {
      "answer": "iron(III) oxide Fe\n2O\n3",
      "score": 0.8268461227416992
    }
  ],
  "2377": [
    {
      "answer": "monatomic",
      "score": 0.9910632371902466
    }
  ],
  "2378": [],
  "2379": [
    {
      "answer": "HO",
      "score": 0.9846217632293701
    }
  ],
  "2380": [
    {
      "answer": "hydrogen",
      "score": 0.6137319207191467
    },
    {
      "answer": "hydrogen",
      "score": 0.9701756238937378
    }
  ],
  "2381": [
    {
      "answer": "Amedeo Avogadro",
      "score": 0.8223791122436523
    }
  ],
  "2382": [
    {
      "answer": "original atomic hypothesis",
      "score": 0.7264551520347595
    },
    {
      "answer": "all elements were monatomic",
      "score": 0.5914686918258667
    }
  ],
  "2383": [
    {
      "answer": "all elements were monatomic",
      "score": 0.6556942462921143
    },
    {
      "answer": "water's formula was HO",
      "score": 0.5826855301856995
    }
  ],
  "2384": [
    {
      "answer": "water is formed of two volumes of hydrogen and one volume of oxygen",
      "score": 0.9817813634872437
    }
  ],
  "2385": [
    {
      "answer": "1805",
      "score": 0.9881799221038818
    }
  ],
  "2386": [
    {
      "answer": "Avogadro's law",
      "score": 0.7801547646522522
    }
  ],
  "2387": [
    {
      "answer": "phlogiston",
      "score": 0.9848623275756836
    },
    {
      "answer": "phlogiston",
      "score": 0.7300562858581543
    },
    {
      "answer": "phlogiston",
      "score": 0.6902241706848145
    },
    {
      "answer": "phlogiston",
      "score": 0.8814159035682678
    }
  ],
  "2388": [
    {
      "answer": "coal",
      "score": 0.709794819355011
    },
    {
      "answer": "iron",
      "score": 0.801507830619812
    }
  ],
  "2389": [
    {
      "answer": "buoyancy",
      "score": 0.8486741781234741
    }
  ],
  "2390": [
    {
      "answer": "metals",
      "score": 0.9688493013381958
    }
  ],
  "2391": [
    {
      "answer": "lighter",
      "score": 0.9816873669624329
    }
  ],
  "2392": [
    {
      "answer": "phlogiston",
      "score": 0.9244477152824402
    },
    {
      "answer": "phlogiston",
      "score": 0.7740306854248047
    },
    {
      "answer": "phlogiston",
      "score": 0.7223033308982849
    },
    {
      "answer": "phlogiston",
      "score": 0.8766094446182251
    }
  ],
  "2393": [
    {
      "answer": "iron",
      "score": 0.9869593977928162
    }
  ],
  "2394": [
    {
      "answer": "metals, too, gain weight in rusting",
      "score": 0.9721736907958984
    }
  ],
  "2395": [
    {
      "answer": "phlogiston",
      "score": 0.9720760583877563
    },
    {
      "answer": "phlogiston",
      "score": 0.7677971124649048
    },
    {
      "answer": "phlogiston",
      "score": 0.698725163936615
    },
    {
      "answer": "phlogiston",
      "score": 0.8671174049377441
    }
  ],
  "2396": [
    {
      "answer": "covalent double bond",
      "score": 0.9690769910812378
    }
  ],
  "2397": [
    {
      "answer": "two",
      "score": 0.7202745079994202
    },
    {
      "answer": "two",
      "score": 0.9748634099960327
    }
  ],
  "2398": [
    {
      "answer": "sequential",
      "score": 0.6704558730125427
    },
    {
      "answer": "Aufbau",
      "score": 0.943514883518219
    }
  ],
  "2399": [
    {
      "answer": "covalent double bond",
      "score": 0.721871018409729
    }
  ],
  "2400": [
    {
      "answer": "filling of molecular orbitals",
      "score": 0.9427790641784668
    }
  ],
  "2401": [
    {
      "answer": "a covalent double bond that results from the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms",
      "score": 0.8419584035873413
    }
  ],
  "2402": [
    {
      "answer": "filling of molecular orbitals",
      "score": 0.8886057138442993
    },
    {
      "answer": "sequential, low-to-high energy, or Aufbau, filling of orbitals",
      "score": 0.7665230631828308
    }
  ],
  "2403": [
    {
      "answer": "O-O molecular axis",
      "score": 0.7760145664215088
    },
    {
      "answer": "\u03c0",
      "score": 0.5056460499763489
    }
  ],
  "2404": [
    {
      "answer": "two",
      "score": 0.6744198203086853
    },
    {
      "answer": "two",
      "score": 0.9262985587120056
    }
  ],
  "2405": [
    {
      "answer": "1773",
      "score": 0.9907728433609009
    }
  ],
  "2406": [
    {
      "answer": "1774",
      "score": 0.9873950481414795
    }
  ],
  "2407": [
    {
      "answer": "his work was published first",
      "score": 0.9598720669746399
    }
  ],
  "2408": [
    {
      "answer": "Antoine Lavoisier",
      "score": 0.9750412702560425
    }
  ],
  "2409": [
    {
      "answer": "phlogiston theory of combustion and corrosion",
      "score": 0.9330239295959473
    }
  ],
  "2410": [
    {
      "answer": "1774",
      "score": 0.9870116710662842
    }
  ],
  "2411": [
    {
      "answer": "1773",
      "score": 0.9713157415390015
    },
    {
      "answer": "1774",
      "score": 0.7598670125007629
    }
  ],
  "2412": [
    {
      "answer": "Joseph Priestley",
      "score": 0.9360144734382629
    },
    {
      "answer": "Antoine Lavoisier",
      "score": 0.7002828121185303
    }
  ],
  "2413": [
    {
      "answer": "Antoine Lavoisier",
      "score": 0.9918373823165894
    }
  ],
  "2414": [
    {
      "answer": "spin triplet state",
      "score": 0.9043389558792114
    }
  ],
  "2415": [
    {
      "answer": "triplet oxygen",
      "score": 0.9900874495506287
    },
    {
      "answer": "triplet oxygen",
      "score": 0.8715200424194336
    }
  ],
  "2416": [
    {
      "answer": "unpaired electrons",
      "score": 0.9879757165908813
    }
  ],
  "2417": [
    {
      "answer": "spontaneous combustion",
      "score": 0.9828255772590637
    }
  ],
  "2418": [
    {
      "answer": "antibonding",
      "score": 0.9204027652740479
    }
  ],
  "2419": [
    {
      "answer": "triplet oxygen",
      "score": 0.9909265041351318
    },
    {
      "answer": "triplet oxygen",
      "score": 0.8513377904891968
    }
  ],
  "2420": [
    {
      "answer": "cancellations and \u03c3 and \u03c0 overlaps",
      "score": 0.9162148237228394
    }
  ],
  "2421": [
    {
      "answer": "organic molecules",
      "score": 0.9894771575927734
    }
  ],
  "2422": [
    {
      "answer": "spontaneous combustion",
      "score": 0.9939916729927063
    }
  ],
  "2423": [
    {
      "answer": "part of the trapped air",
      "score": 0.6397441029548645
    }
  ],
  "2424": [],
  "2425": [],
  "2426": [
    {
      "answer": "1777",
      "score": 0.9929049611091614
    }
  ],
  "2427": [
    {
      "answer": "azote",
      "score": 0.9821929931640625
    }
  ],
  "2428": [
    {
      "answer": "azote",
      "score": 0.7769938111305237
    },
    {
      "answer": "Azote",
      "score": 0.5546875
    }
  ],
  "2429": [
    {
      "answer": "Azote",
      "score": 0.6601070761680603
    },
    {
      "answer": "nitrogen",
      "score": 0.7244569659233093
    }
  ],
  "2430": [
    {
      "answer": "1777",
      "score": 0.9939370155334473
    }
  ],
  "2431": [
    {
      "answer": "ozone",
      "score": 0.9551213383674622
    },
    {
      "answer": "Ozone",
      "score": 0.7324253916740417
    },
    {
      "answer": "ozone",
      "score": 0.6777076125144958
    },
    {
      "answer": "ozone",
      "score": 0.7837399244308472
    }
  ],
  "2432": [],
  "2433": [
    {
      "answer": "damaging to lung tissue",
      "score": 0.7619044780731201
    }
  ],
  "2434": [
    {
      "answer": "protective radiation shield",
      "score": 0.9742691516876221
    }
  ],
  "2435": [
    {
      "answer": "UV",
      "score": 0.9628587365150452
    }
  ],
  "2436": [
    {
      "answer": "ozone",
      "score": 0.7576762437820435
    }
  ],
  "2437": [
    {
      "answer": "ozone layer",
      "score": 0.6056717038154602
    }
  ],
  "2438": [],
  "2439": [
    {
      "answer": "this phase, created by pressurizing O\n2 to 20 GPa, is in fact a rhombohedral O\n8 cluster",
      "score": 0.778451144695282
    }
  ],
  "2440": [
    {
      "answer": "dioxygen",
      "score": 0.9616928100585938
    }
  ],
  "2441": [
    {
      "answer": "dioxygen",
      "score": 0.8712179064750671
    }
  ],
  "2442": [
    {
      "answer": "dioxygen",
      "score": 0.8128762245178223
    }
  ],
  "2443": [
    {
      "answer": "bond length of 121 pm",
      "score": 0.88006991147995
    },
    {
      "answer": "bond energy of 498 kJ\u00b7mol\u22121",
      "score": 0.8153624534606934
    }
  ],
  "2444": [
    {
      "answer": "cellular respiration",
      "score": 0.9888832569122314
    }
  ],
  "2445": [
    {
      "answer": "dioxygen",
      "score": 0.9187675714492798
    }
  ],
  "2446": [],
  "2447": [
    {
      "answer": "O2",
      "score": 0.592104971408844
    }
  ],
  "2448": [
    {
      "answer": "energy content",
      "score": 0.9832704067230225
    }
  ],
  "2449": [
    {
      "answer": "James Dewar",
      "score": 0.9963752031326294
    }
  ],
  "2450": [
    {
      "answer": "1891",
      "score": 0.9811670184135437
    }
  ],
  "2451": [
    {
      "answer": "1895",
      "score": 0.9924535155296326
    }
  ],
  "2452": [
    {
      "answer": "oxyacetylene",
      "score": 0.9681150913238525
    }
  ],
  "2453": [
    {
      "answer": "James Dewar",
      "score": 0.9945884943008423
    }
  ],
  "2454": [],
  "2455": [
    {
      "answer": "The first commercially viable process for producing liquid oxygen",
      "score": 0.9003211259841919
    }
  ],
  "2456": [
    {
      "answer": "oxyacetylene welding",
      "score": 0.9847105741500854
    }
  ],
  "2457": [
    {
      "answer": "Oxygen",
      "score": 0.9521238207817078
    },
    {
      "answer": "oxygen",
      "score": 0.6833468079566956
    },
    {
      "answer": "oxygen",
      "score": 0.6549138426780701
    }
  ],
  "2458": [
    {
      "answer": "temperature-dependent",
      "score": 0.9793501496315002
    }
  ],
  "2459": [
    {
      "answer": "6.04",
      "score": 0.99249267578125
    }
  ],
  "2460": [
    {
      "answer": "freshwater",
      "score": 0.8652243614196777
    }
  ],
  "2461": [
    {
      "answer": "twice",
      "score": 0.8736984729766846
    },
    {
      "answer": "14.6",
      "score": 0.8842140436172485
    }
  ],
  "2462": [
    {
      "answer": "Oxygen",
      "score": 0.8604282736778259
    }
  ],
  "2463": [
    {
      "answer": "O\n2",
      "score": 0.9610270261764526
    }
  ],
  "2464": [
    {
      "answer": "temperature-dependent",
      "score": 0.9759220480918884
    }
  ],
  "2465": [
    {
      "answer": "atmosphere",
      "score": 0.875560998916626
    }
  ],
  "2466": [
    {
      "answer": "most",
      "score": 0.9678080677986145
    }
  ],
  "2467": [
    {
      "answer": "third most abundant chemical element",
      "score": 0.9133815169334412
    }
  ],
  "2468": [
    {
      "answer": "0.9%",
      "score": 0.9854594469070435
    }
  ],
  "2469": [],
  "2470": [
    {
      "answer": "ultraviolet radiation",
      "score": 0.9796118140220642
    }
  ],
  "2471": [
    {
      "answer": "Oxygen",
      "score": 0.9611032605171204
    },
    {
      "answer": "Oxygen",
      "score": 0.7245815396308899
    },
    {
      "answer": "oxygen",
      "score": 0.8386966586112976
    },
    {
      "answer": "Oxygen",
      "score": 0.7660827040672302
    },
    {
      "answer": "Oxygen",
      "score": 0.8039193153381348
    },
    {
      "answer": "oxygen",
      "score": 0.7802110910415649
    },
    {
      "answer": "oxygen-containing",
      "score": 0.6161417961120605
    }
  ],
  "2472": [
    {
      "answer": "hydrogen",
      "score": 0.9844366312026978
    }
  ],
  "2473": [
    {
      "answer": "oxygen",
      "score": 0.8778427243232727
    },
    {
      "answer": "Oxygen",
      "score": 0.5894910097122192
    }
  ],
  "2474": [
    {
      "answer": "Oxygen",
      "score": 0.5544828176498413
    },
    {
      "answer": "Oxygen",
      "score": 0.5799164175987244
    },
    {
      "answer": "oxygen",
      "score": 0.7655951976776123
    },
    {
      "answer": "Oxygen",
      "score": 0.8255331516265869
    },
    {
      "answer": "Oxygen",
      "score": 0.6387004256248474
    },
    {
      "answer": "oxygen",
      "score": 0.6249483823776245
    }
  ],
  "2475": [
    {
      "answer": "Oxygen gas",
      "score": 0.9833426475524902
    }
  ],
  "2476": [
    {
      "answer": "19th",
      "score": 0.9940762519836426
    }
  ],
  "2477": [
    {
      "answer": "compressing and cooling",
      "score": 0.973296046257019
    }
  ],
  "2478": [
    {
      "answer": "Raoul Pierre Pictet",
      "score": 0.9890278577804565
    }
  ],
  "2479": [
    {
      "answer": "a few drops",
      "score": 0.924275279045105
    }
  ],
  "2480": [
    {
      "answer": "March 29, 1883",
      "score": 0.9877026081085205
    }
  ],
  "2481": [
    {
      "answer": "chemist",
      "score": 0.9732258319854736
    },
    {
      "answer": "physicist",
      "score": 0.9543678164482117
    },
    {
      "answer": "physicist",
      "score": 0.7192738652229309
    }
  ],
  "2482": [
    {
      "answer": "telegram",
      "score": 0.8216788172721863
    }
  ],
  "2483": [
    {
      "answer": "oxygen",
      "score": 0.6203170418739319
    },
    {
      "answer": "oxygen",
      "score": 0.6029884815216064
    },
    {
      "answer": "Oxygen",
      "score": 0.931221067905426
    }
  ],
  "2484": [
    {
      "answer": "Zygmunt Wr\u00f3blewski",
      "score": 0.9642716646194458
    },
    {
      "answer": "Karol Olszewski",
      "score": 0.9518606662750244
    }
  ],
  "2485": [
    {
      "answer": "Jagiellonian University",
      "score": 0.9746114015579224
    }
  ],
  "2486": [
    {
      "answer": "Sun",
      "score": 0.9616106748580933
    },
    {
      "answer": "Sun",
      "score": 0.8195915222167969
    }
  ],
  "2487": [
    {
      "answer": "oxygen-16",
      "score": 0.8969365358352661
    }
  ],
  "2488": [
    {
      "answer": "Genesis",
      "score": 0.9936417937278748
    }
  ],
  "2489": [
    {
      "answer": "unknown process",
      "score": 0.980950117111206
    }
  ],
  "2490": [
    {
      "answer": "Earth",
      "score": 0.5605815649032593
    },
    {
      "answer": "Earth",
      "score": 0.9520794153213501
    }
  ],
  "2491": [
    {
      "answer": "Earth",
      "score": 0.8946506977081299
    },
    {
      "answer": "Moon",
      "score": 0.9070262908935547
    },
    {
      "answer": "Mars",
      "score": 0.9322353601455688
    },
    {
      "answer": "meteorites",
      "score": 0.645736038684845
    }
  ],
  "2492": [
    {
      "answer": "Sun",
      "score": 0.9809290766716003
    },
    {
      "answer": "the Sun",
      "score": 0.677453339099884
    }
  ],
  "2493": [
    {
      "answer": "silicon wafer",
      "score": 0.7268136739730835
    }
  ],
  "2494": [
    {
      "answer": "Sun",
      "score": 0.7041723728179932
    },
    {
      "answer": "Sun",
      "score": 0.9397805333137512
    }
  ],
  "2495": [
    {
      "answer": "Singlet oxygen",
      "score": 0.9616345167160034
    },
    {
      "answer": "singlet oxygen",
      "score": 0.8486982583999634
    },
    {
      "answer": "singlet oxygen",
      "score": 0.8087949156761169
    }
  ],
  "2496": [
    {
      "answer": "organic molecules",
      "score": 0.992547869682312
    }
  ],
  "2497": [
    {
      "answer": "photosynthesis",
      "score": 0.9837800860404968
    }
  ],
  "2498": [
    {
      "answer": "photolysis of ozone",
      "score": 0.9615208506584167
    }
  ],
  "2499": [
    {
      "answer": "Carotenoids",
      "score": 0.9856512546539307
    }
  ],
  "2500": [
    {
      "answer": "Singlet oxygen",
      "score": 0.561530351638794
    },
    {
      "answer": "singlet oxygen",
      "score": 0.9463329315185547
    },
    {
      "answer": "singlet oxygen",
      "score": 0.6528649926185608
    }
  ],
  "2501": [],
  "2502": [
    {
      "answer": "troposphere",
      "score": 0.9724707007408142
    }
  ],
  "2503": [
    {
      "answer": "Carotenoids",
      "score": 0.9865759611129761
    }
  ],
  "2504": [
    {
      "answer": "Paleoclimatologists",
      "score": 0.9866260290145874
    },
    {
      "answer": "Paleoclimatologists",
      "score": 0.9400774240493774
    }
  ],
  "2505": [
    {
      "answer": "snow",
      "score": 0.967180073261261
    },
    {
      "answer": "rain",
      "score": 0.9677618145942688
    }
  ],
  "2506": [
    {
      "answer": "12%",
      "score": 0.9888141751289368
    }
  ],
  "2507": [
    {
      "answer": "oxygen-18",
      "score": 0.8418662548065186
    }
  ],
  "2508": [
    {
      "answer": "lower global temperatures",
      "score": 0.9817086458206177
    }
  ],
  "2509": [
    {
      "answer": "Paleoclimatologists",
      "score": 0.9882228970527649
    },
    {
      "answer": "Paleoclimatologists",
      "score": 0.8733986616134644
    }
  ],
  "2510": [
    {
      "answer": "oxygen-18",
      "score": 0.5538554787635803
    }
  ],
  "2511": [
    {
      "answer": "12%",
      "score": 0.9244462847709656
    }
  ],
  "2512": [
    {
      "answer": "snow and rain",
      "score": 0.8937804102897644
    }
  ],
  "2513": [
    {
      "answer": "687 and 760 nm",
      "score": 0.9264117479324341
    }
  ],
  "2514": [
    {
      "answer": "carbon cycle",
      "score": 0.9841687083244324
    }
  ],
  "2515": [
    {
      "answer": "vegetation canopies",
      "score": 0.7421873211860657
    }
  ],
  "2516": [
    {
      "answer": "global scale",
      "score": 0.7876162528991699
    }
  ],
  "2517": [
    {
      "answer": "spectrophotometric absorption",
      "score": 0.7195124626159668
    },
    {
      "answer": "remote sensing",
      "score": 0.7210997939109802
    }
  ],
  "2518": [],
  "2519": [
    {
      "answer": "measurement of the radiance",
      "score": 0.8525140285491943
    }
  ],
  "2520": [
    {
      "answer": "low signal-to-noise ratio",
      "score": 0.8173781633377075
    }
  ],
  "2521": [
    {
      "answer": "paramagnetic",
      "score": 0.9955863952636719
    }
  ],
  "2522": [
    {
      "answer": "oxygen",
      "score": 0.7772068977355957
    },
    {
      "answer": "oxygen",
      "score": 0.8789478540420532
    }
  ],
  "2523": [
    {
      "answer": "magnetic moments",
      "score": 0.8998936414718628
    },
    {
      "answer": "unpaired electrons",
      "score": 0.7675122022628784
    }
  ],
  "2524": [
    {
      "answer": "magnetic",
      "score": 0.9797537922859192
    }
  ],
  "2525": [
    {
      "answer": "magnet",
      "score": 0.921109139919281
    },
    {
      "answer": "magnet",
      "score": 0.7298703193664551
    }
  ],
  "2526": [
    {
      "answer": "paramagnetic",
      "score": 0.985966145992279
    }
  ],
  "2527": [
    {
      "answer": "spin magnetic moments of the unpaired electrons in the molecule",
      "score": 0.9729098677635193
    },
    {
      "answer": "negative exchange energy between neighboring O\n2 molecules",
      "score": 0.8992117643356323
    }
  ],
  "2528": [
    {
      "answer": "oxygen",
      "score": 0.9695120453834534
    },
    {
      "answer": "liquid oxygen",
      "score": 0.6502372026443481
    }
  ],
  "2529": [],
  "2530": [
    {
      "answer": "to destroy invading microbes",
      "score": 0.9823755025863647
    }
  ],
  "2531": [
    {
      "answer": "pathogen",
      "score": 0.9876697659492493
    }
  ],
  "2532": [
    {
      "answer": "obligately anaerobic organisms",
      "score": 0.9871505498886108
    }
  ],
  "2533": [
    {
      "answer": "2.5 billion years ago",
      "score": 0.9857596755027771
    }
  ],
  "2534": [],
  "2535": [
    {
      "answer": "O\u2212\n2",
      "score": 0.7531113624572754
    }
  ],
  "2536": [],
  "2537": [
    {
      "answer": "O\n2",
      "score": 0.9835554957389832
    }
  ],
  "2538": [
    {
      "answer": "Great Oxygenation Event",
      "score": 0.991233229637146
    }
  ],
  "2539": [
    {
      "answer": "90.20 K",
      "score": 0.9742708206176758
    }
  ],
  "2540": [
    {
      "answer": "clear",
      "score": 0.9356150031089783
    }
  ],
  "2541": [
    {
      "answer": "air",
      "score": 0.9672161936759949
    }
  ],
  "2542": [
    {
      "answer": "nitrogen",
      "score": 0.9630958437919617
    }
  ],
  "2543": [
    {
      "answer": "combustible materials",
      "score": 0.9918590188026428
    }
  ],
  "2544": [
    {
      "answer": "Oxygen",
      "score": 0.9336237907409668
    }
  ],
  "2545": [
    {
      "answer": "Oxygen",
      "score": 0.9425137639045715
    },
    {
      "answer": "oxygen",
      "score": 0.5842149257659912
    }
  ],
  "2546": [],
  "2547": [
    {
      "answer": "absorption in the red",
      "score": 0.9512757658958435
    }
  ],
  "2548": [
    {
      "answer": "polar oceans",
      "score": 0.946118950843811
    }
  ],
  "2549": [
    {
      "answer": "lower temperatures",
      "score": 0.9086306095123291
    }
  ],
  "2550": [
    {
      "answer": "The increased solubility of O\n2 at lower temperatures",
      "score": 0.6638715863227844
    },
    {
      "answer": "higher oxygen content",
      "score": 0.8479093909263611
    }
  ],
  "2551": [
    {
      "answer": "biochemical oxygen demand",
      "score": 0.9560272097587585
    }
  ],
  "2552": [
    {
      "answer": "algae",
      "score": 0.991169810295105
    }
  ],
  "2553": [
    {
      "answer": "The increased solubility of O\n2 at lower temperatures",
      "score": 0.7044344544410706
    },
    {
      "answer": "Water polluted with plant nutrients such as nitrates or phosphates may stimulate growth of algae by a process called eutrophication and the decay of these organisms and other biomaterials may reduce amounts of O\n2 in eutrophic water bodies.",
      "score": 0.8433699011802673
    }
  ],
  "2554": [
    {
      "answer": "eutrophication",
      "score": 0.9828298687934875
    }
  ],
  "2555": [
    {
      "answer": "nitrates or phosphates",
      "score": 0.897455632686615
    }
  ],
  "2556": [
    {
      "answer": "stimulate growth of algae",
      "score": 0.7106659412384033
    }
  ],
  "2557": [
    {
      "answer": "3.5 billion years ago",
      "score": 0.987714409828186
    }
  ],
  "2558": [
    {
      "answer": "Paleoproterozoic",
      "score": 0.9963603615760803
    }
  ],
  "2559": [
    {
      "answer": "banded iron formations",
      "score": 0.9931661486625671
    }
  ],
  "2560": [
    {
      "answer": "1.7 billion years ago",
      "score": 0.9879500269889832
    }
  ],
  "2561": [
    {
      "answer": "3\u20132.7 billion years ago",
      "score": 0.9803684949874878
    }
  ],
  "2562": [
    {
      "answer": "photosynthetic archaea and bacteria",
      "score": 0.9870057106018066
    }
  ],
  "2563": [
    {
      "answer": "Paleoproterozoic",
      "score": 0.990903913974762
    }
  ],
  "2564": [
    {
      "answer": "free oxygen began to outgas from the oceans",
      "score": 0.9494845271110535
    }
  ],
  "2565": [
    {
      "answer": "10%",
      "score": 0.9717045426368713
    }
  ],
  "2566": [
    {
      "answer": "oxygen cycle",
      "score": 0.8258146047592163
    },
    {
      "answer": "oxygen cycle",
      "score": 0.6513880491256714
    },
    {
      "answer": "photosynthesis",
      "score": 0.5675747990608215
    }
  ],
  "2567": [
    {
      "answer": "biogeochemical",
      "score": 0.9822690486907959
    }
  ],
  "2568": [
    {
      "answer": "three",
      "score": 0.9619728326797485
    }
  ],
  "2569": [
    {
      "answer": "photosynthesis",
      "score": 0.9662816524505615
    }
  ],
  "2570": [
    {
      "answer": "oxygen",
      "score": 0.820713996887207
    },
    {
      "answer": "oxygen",
      "score": 0.7977200150489807
    },
    {
      "answer": "oxygen",
      "score": 0.8426535725593567
    },
    {
      "answer": "oxygen",
      "score": 0.772246241569519
    },
    {
      "answer": "oxygen",
      "score": 0.9736445546150208
    },
    {
      "answer": "oxygen",
      "score": 0.810324490070343
    }
  ],
  "2571": [
    {
      "answer": "oxygen",
      "score": 0.7697868347167969
    },
    {
      "answer": "oxygen",
      "score": 0.7457585334777832
    },
    {
      "answer": "oxygen",
      "score": 0.7998086810112
    },
    {
      "answer": "oxygen",
      "score": 0.7681992650032043
    },
    {
      "answer": "oxygen",
      "score": 0.8948647379875183
    },
    {
      "answer": "oxygen",
      "score": 0.8019392490386963
    }
  ],
  "2572": [
    {
      "answer": "the atmosphere",
      "score": 0.8665865659713745
    },
    {
      "answer": "the biosphere",
      "score": 0.8815122246742249
    }
  ],
  "2573": [
    {
      "answer": "production and consumption",
      "score": 0.9925183057785034
    }
  ],
  "2574": [
    {
      "answer": "photosynthesis",
      "score": 0.8980295658111572
    }
  ],
  "2575": [
    {
      "answer": "pressure swing adsorption",
      "score": 0.9017672538757324
    }
  ],
  "2576": [
    {
      "answer": "90%",
      "score": 0.9854486584663391
    },
    {
      "answer": "93%",
      "score": 0.9699157476425171
    }
  ],
  "2577": [
    {
      "answer": "nitrogen",
      "score": 0.9814687967300415
    },
    {
      "answer": "nitrogen",
      "score": 0.6389391422271729
    }
  ],
  "2578": [
    {
      "answer": "pressure swing adsorption",
      "score": 0.5816311836242676
    }
  ],
  "2579": [
    {
      "answer": "90% to 93%",
      "score": 0.8195398449897766
    }
  ],
  "2580": [
    {
      "answer": "zeolite",
      "score": 0.9339441657066345
    }
  ],
  "2581": [],
  "2582": [],
  "2583": [
    {
      "answer": "water",
      "score": 0.9854658842086792
    }
  ],
  "2584": [
    {
      "answer": "molecular oxygen and hydrogen",
      "score": 0.7161377668380737
    }
  ],
  "2585": [
    {
      "answer": "DC",
      "score": 0.9943380951881409
    },
    {
      "answer": "DC",
      "score": 0.7474767565727234
    }
  ],
  "2586": [
    {
      "answer": "oxides and oxoacids",
      "score": 0.873517632484436
    }
  ],
  "2587": [
    {
      "answer": "chemical oxygen generators",
      "score": 0.9324578046798706
    },
    {
      "answer": "oxygen candles",
      "score": 0.878993809223175
    }
  ],
  "2588": [],
  "2589": [
    {
      "answer": "if AC is used, the gases in each limb consist of hydrogen and oxygen in the explosive ratio 2:1",
      "score": 0.9757384061813354
    }
  ],
  "2590": [
    {
      "answer": "chemical oxygen generators",
      "score": 0.774364173412323
    }
  ],
  "2591": [
    {
      "answer": "O\n2",
      "score": 0.8637607097625732
    }
  ],
  "2592": [],
  "2593": [
    {
      "answer": "mild euphoric",
      "score": 0.96881103515625
    }
  ],
  "2594": [
    {
      "answer": "performance",
      "score": 0.9422823190689087
    },
    {
      "answer": "performance",
      "score": 0.7407211065292358
    }
  ],
  "2595": [
    {
      "answer": "aerobic exercise",
      "score": 0.9317126274108887
    }
  ],
  "2596": [
    {
      "answer": "placebo effect",
      "score": 0.9851856231689453
    }
  ],
  "2597": [
    {
      "answer": "Oxygen",
      "score": 0.9764714241027832
    },
    {
      "answer": "oxygen",
      "score": 0.6481300592422485
    },
    {
      "answer": "Oxygen",
      "score": 0.6763345003128052
    },
    {
      "answer": "oxygen",
      "score": 0.6469682455062866
    }
  ],
  "2598": [
    {
      "answer": "oxygen bars",
      "score": 0.9006339311599731
    },
    {
      "answer": "Oxygen bars",
      "score": 0.981310248374939
    }
  ],
  "2599": [
    {
      "answer": "Japan",
      "score": 0.9803088903427124
    },
    {
      "answer": "California",
      "score": 0.9749372601509094
    },
    {
      "answer": "Las Vegas, Nevada",
      "score": 0.974602460861206
    }
  ],
  "2600": [
    {
      "answer": "placebo effect",
      "score": 0.9882930517196655
    }
  ],
  "2601": [
    {
      "answer": "oxygen chambers",
      "score": 0.6463191509246826
    }
  ],
  "2602": [
    {
      "answer": "Carbon monoxide",
      "score": 0.5630993247032166
    },
    {
      "answer": "carbon monoxide",
      "score": 0.9667348861694336
    }
  ],
  "2603": [
    {
      "answer": "anaerobic bacteria",
      "score": 0.9809099435806274
    }
  ],
  "2604": [
    {
      "answer": "Decompression sickness",
      "score": 0.9363563060760498
    }
  ],
  "2605": [
    {
      "answer": "oxygen",
      "score": 0.8216199278831482
    }
  ],
  "2606": [
    {
      "answer": "Carbon monoxide poisoning",
      "score": 0.8462380766868591
    },
    {
      "answer": "gas gangrene",
      "score": 0.7739877700805664
    },
    {
      "answer": "decompression sickness",
      "score": 0.6588180661201477
    }
  ],
  "2607": [
    {
      "answer": "anaerobic bacteria",
      "score": 0.9471732378005981
    }
  ],
  "2608": [
    {
      "answer": "divers",
      "score": 0.9849017262458801
    }
  ],
  "2609": [
    {
      "answer": "respiration",
      "score": 0.954901933670044
    }
  ],
  "2610": [
    {
      "answer": "oxygen supplementation",
      "score": 0.9848579168319702
    }
  ],
  "2611": [
    {
      "answer": "heart",
      "score": 0.9931282997131348
    }
  ],
  "2612": [
    {
      "answer": "oxygen supplementation",
      "score": 0.8715310096740723
    },
    {
      "answer": "Oxygen therapy",
      "score": 0.6551003456115723
    }
  ],
  "2613": [],
  "2614": [
    {
      "answer": "Uptake of O\n2 from the air",
      "score": 0.8762242197990417
    }
  ],
  "2615": [
    {
      "answer": "medicine",
      "score": 0.8678441047668457
    }
  ],
  "2616": [],
  "2617": [
    {
      "answer": "increases oxygen levels in the patient's blood",
      "score": 0.933211624622345
    }
  ],
  "2618": [
    {
      "answer": "electronegativity",
      "score": 0.9929007291793823
    }
  ],
  "2619": [
    {
      "answer": "non-stoichiometric compounds",
      "score": 0.8743358850479126
    }
  ],
  "2620": [
    {
      "answer": "FeO",
      "score": 0.8947650194168091
    }
  ],
  "2621": [
    {
      "answer": "chemical bonds",
      "score": 0.9588620662689209
    }
  ],
  "2622": [
    {
      "answer": "corrosion",
      "score": 0.9446815848350525
    }
  ],
  "2623": [
    {
      "answer": "elements",
      "score": 0.768582820892334
    }
  ],
  "2624": [
    {
      "answer": "electronegativity",
      "score": 0.9961854815483093
    }
  ],
  "2625": [
    {
      "answer": "w\u00fcstite",
      "score": 0.8728201985359192
    }
  ],
  "2626": [
    {
      "answer": "0.05",
      "score": 0.952246367931366
    }
  ],
  "2627": [
    {
      "answer": "cabin depressurization",
      "score": 0.9895291924476624
    }
  ],
  "2628": [
    {
      "answer": "chemical oxygen generators",
      "score": 0.7632652521133423
    },
    {
      "answer": "exothermic reaction",
      "score": 0.8245973587036133
    }
  ],
  "2629": [
    {
      "answer": "exothermic",
      "score": 0.9897878170013428
    }
  ],
  "2630": [
    {
      "answer": "oxygen",
      "score": 0.9132962822914124
    }
  ],
  "2631": [
    {
      "answer": "People who climb mountains or fly in non-pressurized fixed-wing aircraft",
      "score": 0.9369685053825378
    }
  ],
  "2632": [
    {
      "answer": "Passengers",
      "score": 0.9555209279060364
    }
  ],
  "2633": [
    {
      "answer": "emergency supply of O\n2",
      "score": 0.8953482508659363
    }
  ],
  "2634": [
    {
      "answer": "exothermic",
      "score": 0.9929129481315613
    }
  ],
  "2635": [
    {
      "answer": "high pressure",
      "score": 0.6971548199653625
    }
  ],
  "2636": [
    {
      "answer": "liquid",
      "score": 0.9542930126190186
    },
    {
      "answer": "liquid",
      "score": 0.5490368604660034
    },
    {
      "answer": "Liquid",
      "score": 0.6102760434150696
    }
  ],
  "2637": [
    {
      "answer": "specially insulated tankers",
      "score": 0.8791815638542175
    }
  ],
  "2638": [
    {
      "answer": "compressed gas",
      "score": 0.9571568369865417
    }
  ],
  "2639": [
    {
      "answer": "hospitals",
      "score": 0.9907614588737488
    }
  ],
  "2640": [
    {
      "answer": "high pressure oxygen tanks",
      "score": 0.8279237747192383
    }
  ],
  "2641": [
    {
      "answer": "For reasons of economy",
      "score": 0.9015821218490601
    }
  ],
  "2642": [
    {
      "answer": "one liter of liquefied oxygen",
      "score": 0.6991797685623169
    }
  ],
  "2643": [],
  "2644": [
    {
      "answer": "organic solvents",
      "score": 0.758919358253479
    }
  ],
  "2645": [],
  "2646": [
    {
      "answer": "feeder materials",
      "score": 0.9597980976104736
    }
  ],
  "2647": [
    {
      "answer": "Epoxides",
      "score": 0.9870582222938538
    }
  ],
  "2648": [
    {
      "answer": "acetone, methanol, ethanol, isopropanol, furan, THF, diethyl ether, dioxane, ethyl acetate, DMF, DMSO, acetic acid, and formic acid",
      "score": 0.7110151052474976
    }
  ],
  "2649": [
    {
      "answer": "acetone",
      "score": 0.6847492456436157
    },
    {
      "answer": "isopropanol",
      "score": 0.6614197492599487
    },
    {
      "answer": "furan",
      "score": 0.6890695691108704
    },
    {
      "answer": "THF",
      "score": 0.7824919819831848
    },
    {
      "answer": "diethyl ether",
      "score": 0.7878803014755249
    },
    {
      "answer": "dioxane",
      "score": 0.7040784358978271
    },
    {
      "answer": "ethyl acetate",
      "score": 0.801735520362854
    },
    {
      "answer": "DMF",
      "score": 0.7458885312080383
    },
    {
      "answer": "DMSO",
      "score": 0.7492372393608093
    },
    {
      "answer": "acetic acid",
      "score": 0.7928475141525269
    },
    {
      "answer": "formic acid",
      "score": 0.8450074195861816
    }
  ],
  "2650": [
    {
      "answer": "carboxylic acids",
      "score": 0.6455655097961426
    },
    {
      "answer": "acid anhydrides",
      "score": 0.5844722390174866
    },
    {
      "answer": "furan",
      "score": 0.5348390340805054
    },
    {
      "answer": "THF",
      "score": 0.5766384601593018
    },
    {
      "answer": "diethyl ether",
      "score": 0.5996760129928589
    },
    {
      "answer": "dioxane",
      "score": 0.5504449605941772
    },
    {
      "answer": "ethyl acetate",
      "score": 0.6153331995010376
    },
    {
      "answer": "DMF",
      "score": 0.5642334818840027
    },
    {
      "answer": "DMSO",
      "score": 0.6003168225288391
    },
    {
      "answer": "acetic acid",
      "score": 0.6828510165214539
    },
    {
      "answer": "formic acid",
      "score": 0.7045643329620361
    },
    {
      "answer": "glutaraldehyde",
      "score": 0.5547043681144714
    },
    {
      "answer": "citric acid",
      "score": 0.5854692459106445
    },
    {
      "answer": "acetic anhydride",
      "score": 0.6628089547157288
    },
    {
      "answer": "acetamide",
      "score": 0.6294401288032532
    }
  ],
  "2651": [],
  "2652": [],
  "2653": [
    {
      "answer": "acid anhydrides",
      "score": 0.7320603132247925
    }
  ],
  "2654": [
    {
      "answer": "fats",
      "score": 0.5620673298835754
    },
    {
      "answer": "fatty acids",
      "score": 0.6448746919631958
    },
    {
      "answer": "amino acids",
      "score": 0.5954403877258301
    }
  ],
  "2655": [
    {
      "answer": "Only a few",
      "score": 0.8688005805015564
    }
  ],
  "2656": [
    {
      "answer": "carbohydrates",
      "score": 0.9904252886772156
    }
  ],
  "2657": [],
  "2658": [
    {
      "answer": "bones",
      "score": 0.9849590063095093
    }
  ],
  "2659": [
    {
      "answer": "oxygen",
      "score": 0.8600655198097229
    },
    {
      "answer": "oxygen",
      "score": 0.8153255581855774
    },
    {
      "answer": "oxygen",
      "score": 0.8452632427215576
    },
    {
      "answer": "Oxygen",
      "score": 0.7448268532752991
    }
  ],
  "2660": [
    {
      "answer": "oxygen",
      "score": 0.9729810953140259
    },
    {
      "answer": "oxygen",
      "score": 0.6977417469024658
    },
    {
      "answer": "oxygen",
      "score": 0.6625796556472778
    },
    {
      "answer": "Oxygen",
      "score": 0.6844915747642517
    }
  ],
  "2661": [],
  "2662": [
    {
      "answer": "oxygen",
      "score": 0.9863262176513672
    }
  ],
  "2663": [],
  "2664": [
    {
      "answer": "permanent pulmonary fibrosis",
      "score": 0.9714481830596924
    }
  ],
  "2665": [
    {
      "answer": "160 kPa",
      "score": 0.9871535301208496
    }
  ],
  "2666": [
    {
      "answer": "Acute oxygen toxicity",
      "score": 0.8612582683563232
    }
  ],
  "2667": [],
  "2668": [
    {
      "answer": "lead to permanent pulmonary fibrosis",
      "score": 0.8615447878837585
    }
  ],
  "2669": [],
  "2670": [],
  "2671": [],
  "2672": [
    {
      "answer": "low total pressures used",
      "score": 0.9640577435493469
    }
  ],
  "2673": [
    {
      "answer": "30 kPa",
      "score": 0.9796388149261475
    }
  ],
  "2674": [
    {
      "answer": "30 kPa",
      "score": 0.9164118766784668
    },
    {
      "answer": "1.4 times",
      "score": 0.896742582321167
    }
  ],
  "2675": [
    {
      "answer": "only marginally more than normal sea-level O\n2 partial pressure",
      "score": 0.8428676724433899
    }
  ],
  "2676": [
    {
      "answer": "no",
      "score": 0.9742586016654968
    }
  ],
  "2677": [
    {
      "answer": "no",
      "score": 0.9908671379089355
    }
  ],
  "2678": [
    {
      "answer": "low total pressures",
      "score": 0.9861873388290405
    }
  ],
  "2679": [
    {
      "answer": "O\n2",
      "score": 0.6267921328544617
    },
    {
      "answer": "O\n2",
      "score": 0.9555767774581909
    }
  ],
  "2680": [
    {
      "answer": "30 kPa",
      "score": 0.9816861152648926
    }
  ],
  "2681": [
    {
      "answer": "elevated partial pressures",
      "score": 0.7951133251190186
    }
  ],
  "2682": [
    {
      "answer": "more than 50 kilopascals",
      "score": 0.9610567688941956
    }
  ],
  "2683": [
    {
      "answer": "50% oxygen composition at standard pressure",
      "score": 0.9144113063812256
    }
  ],
  "2684": [
    {
      "answer": "oxygen masks",
      "score": 0.7545229196548462
    }
  ],
  "2685": [
    {
      "answer": "30%",
      "score": 0.9639972448348999
    },
    {
      "answer": "50%",
      "score": 0.7540786266326904
    }
  ],
  "2686": [
    {
      "answer": "elevated partial pressures",
      "score": 0.6227519512176514
    },
    {
      "answer": "more than 50 kilopascals (kPa)",
      "score": 0.7094519734382629
    }
  ],
  "2687": [],
  "2688": [
    {
      "answer": "kilopascals",
      "score": 0.8469040393829346
    }
  ],
  "2689": [],
  "2690": [
    {
      "answer": "October 1973",
      "score": 0.9914811849594116
    }
  ],
  "2691": [
    {
      "answer": "US$3 per barrel",
      "score": 0.8742063641548157
    },
    {
      "answer": "nearly $12",
      "score": 0.7513834834098816
    }
  ],
  "2692": [
    {
      "answer": "1979",
      "score": 0.9837436079978943
    }
  ],
  "2693": [
    {
      "answer": "shock",
      "score": 0.8068095445632935
    }
  ],
  "2694": [
    {
      "answer": "Organization of Arab Petroleum Exporting Countries",
      "score": 0.9756590723991394
    }
  ],
  "2695": [
    {
      "answer": "October 1973",
      "score": 0.9846464395523071
    }
  ],
  "2696": [
    {
      "answer": "1979 oil crisis",
      "score": 0.7918795943260193
    }
  ],
  "2697": [
    {
      "answer": "US$3",
      "score": 0.9472913146018982
    }
  ],
  "2698": [
    {
      "answer": "nearly $12",
      "score": 0.9618186950683594
    }
  ],
  "2699": [
    {
      "answer": "second oil shock",
      "score": 0.947246789932251
    }
  ],
  "2700": [
    {
      "answer": "October 1973",
      "score": 0.9726403951644897
    }
  ],
  "2701": [
    {
      "answer": "Egypt and Syria",
      "score": 0.9591156840324402
    }
  ],
  "2702": [
    {
      "answer": "first oil shock",
      "score": 0.8301123380661011
    }
  ],
  "2703": [
    {
      "answer": "1979 oil crisis",
      "score": 0.9742445945739746
    }
  ],
  "2704": [
    {
      "answer": "the members of the Organization of Arab Petroleum Exporting Countries (OAPEC, consisting of the Arab members of OPEC plus Egypt and Syria) proclaimed an oil embargo",
      "score": 0.7317414283752441
    }
  ],
  "2705": [
    {
      "answer": "to avoid being targeted by the boycott",
      "score": 0.9866763949394226
    }
  ],
  "2706": [
    {
      "answer": "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights",
      "score": 0.9364486932754517
    }
  ],
  "2707": [
    {
      "answer": "January 18, 1974",
      "score": 0.9887011051177979
    }
  ],
  "2708": [
    {
      "answer": "March 1974",
      "score": 0.9915632009506226
    }
  ],
  "2709": [
    {
      "answer": "had a major impact on international relations",
      "score": 0.7024827599525452
    },
    {
      "answer": "created a rift within NATO",
      "score": 0.8361181616783142
    }
  ],
  "2710": [
    {
      "answer": "Israel to pull back from the Sinai Peninsula and the Golan Heights",
      "score": 0.9422335028648376
    }
  ],
  "2711": [
    {
      "answer": "peace between the belligerents",
      "score": 0.9421036243438721
    }
  ],
  "2712": [
    {
      "answer": "Israel to pull back from the Sinai Peninsula and the Golan Heights",
      "score": 0.9291427135467529
    }
  ],
  "2713": [
    {
      "answer": "embargo",
      "score": 0.952242910861969
    }
  ],
  "2714": [
    {
      "answer": "NATO",
      "score": 0.9919784069061279
    }
  ],
  "2715": [
    {
      "answer": "Japan",
      "score": 0.9918006062507629
    }
  ],
  "2716": [
    {
      "answer": "Arab oil producers",
      "score": 0.9920677542686462
    },
    {
      "answer": "Arab oil producers",
      "score": 0.8980767726898193
    }
  ],
  "2717": [
    {
      "answer": "multilateral negotiations with the combatants",
      "score": 0.6963230967521667
    },
    {
      "answer": "Israel to pull back from the Sinai Peninsula and the Golan Heights",
      "score": 0.939039409160614
    }
  ],
  "2718": [
    {
      "answer": "Israel",
      "score": 0.9907283782958984
    },
    {
      "answer": "Israel",
      "score": 0.8887996077537537
    }
  ],
  "2719": [
    {
      "answer": "August 15, 1971",
      "score": 0.9882718324661255
    }
  ],
  "2720": [
    {
      "answer": "rise and fall according to market demand",
      "score": 0.9891146421432495
    }
  ],
  "2721": [
    {
      "answer": "Because oil was priced in dollars, oil producers' real income decreased",
      "score": 0.9528183937072754
    }
  ],
  "2722": [
    {
      "answer": "September 1971",
      "score": 0.986819326877594
    }
  ],
  "2723": [],
  "2724": [
    {
      "answer": "1971",
      "score": 0.9659279584884644
    },
    {
      "answer": "1971",
      "score": 0.9495548605918884
    }
  ],
  "2725": [
    {
      "answer": "depreciation of the dollar and other industrialized nations' currencies",
      "score": 0.8738130927085876
    }
  ],
  "2726": [
    {
      "answer": "floating the pound sterling",
      "score": 0.987598180770874
    }
  ],
  "2727": [
    {
      "answer": "Because oil was priced in dollars, oil producers' real income decreased",
      "score": 0.906970739364624
    }
  ],
  "2728": [
    {
      "answer": "August 15, 1971",
      "score": 0.9707238078117371
    }
  ],
  "2729": [
    {
      "answer": "Bretton Woods Accord",
      "score": 0.9892889261245728
    }
  ],
  "2730": [
    {
      "answer": "Gold Exchange Standard",
      "score": 0.9868013262748718
    }
  ],
  "2731": [
    {
      "answer": "depreciation",
      "score": 0.8384219408035278
    }
  ],
  "2732": [
    {
      "answer": "rise and fall according to market demand",
      "score": 0.9767590165138245
    }
  ],
  "2733": [
    {
      "answer": "September 1971",
      "score": 0.9909108281135559
    }
  ],
  "2734": [
    {
      "answer": "less than two percent",
      "score": 0.9757434725761414
    }
  ],
  "2735": [
    {
      "answer": "1971",
      "score": 0.9814311265945435
    }
  ],
  "2736": [
    {
      "answer": "1973",
      "score": 0.9475848078727722
    },
    {
      "answer": "1974",
      "score": 0.911108136177063
    }
  ],
  "2737": [
    {
      "answer": "the oil shock",
      "score": 0.865349292755127
    }
  ],
  "2738": [],
  "2739": [
    {
      "answer": "fairly stable",
      "score": 0.9806278944015503
    }
  ],
  "2740": [
    {
      "answer": "their real incomes lagged",
      "score": 0.6610045433044434
    }
  ],
  "2741": [
    {
      "answer": "1973",
      "score": 0.9309709668159485
    },
    {
      "answer": "1974",
      "score": 0.9230268001556396
    }
  ],
  "2742": [
    {
      "answer": "1971",
      "score": 0.9517010450363159
    }
  ],
  "2743": [
    {
      "answer": "OPEC",
      "score": 0.9741652607917786
    },
    {
      "answer": "OPEC",
      "score": 0.7915217876434326
    }
  ],
  "2744": [
    {
      "answer": "1947",
      "score": 0.9648719429969788
    },
    {
      "answer": "1967",
      "score": 0.9574559926986694
    }
  ],
  "2745": [
    {
      "answer": "substantial price increases",
      "score": 0.9344412684440613
    }
  ],
  "2746": [
    {
      "answer": "oil shock",
      "score": 0.9914753437042236
    }
  ],
  "2747": [
    {
      "answer": "October 6, 1973",
      "score": 0.9768332242965698
    }
  ],
  "2748": [
    {
      "answer": "Iran",
      "score": 0.9911115765571594
    },
    {
      "answer": "Iran",
      "score": 0.5508404970169067
    }
  ],
  "2749": [
    {
      "answer": "ten",
      "score": 0.9870742559432983
    }
  ],
  "2750": [
    {
      "answer": "Iran",
      "score": 0.9910077452659607
    },
    {
      "answer": "Iran",
      "score": 0.7506383657455444
    }
  ],
  "2751": [],
  "2752": [
    {
      "answer": "launched a surprise attack on Israel",
      "score": 0.8774793148040771
    }
  ],
  "2753": [
    {
      "answer": "Iran",
      "score": 0.9870845675468445
    },
    {
      "answer": "Iran",
      "score": 0.6005915403366089
    }
  ],
  "2754": [
    {
      "answer": "ten times more",
      "score": 0.973570704460144
    }
  ],
  "2755": [
    {
      "answer": "300 percent",
      "score": 0.9925327897071838
    }
  ],
  "2756": [
    {
      "answer": "a hundred times",
      "score": 0.98000568151474
    }
  ],
  "2757": [
    {
      "answer": "launched a surprise attack on Israel",
      "score": 0.9737266302108765
    }
  ],
  "2758": [
    {
      "answer": "Yom Kippur",
      "score": 0.9911152720451355
    }
  ],
  "2759": [
    {
      "answer": "second-largest",
      "score": 0.9872390627861023
    }
  ],
  "2760": [
    {
      "answer": "close US ally",
      "score": 0.9163886308670044
    }
  ],
  "2761": [
    {
      "answer": "ten times more",
      "score": 0.9250922203063965
    }
  ],
  "2762": [
    {
      "answer": "In response to American aid to Israel",
      "score": 0.9856102466583252
    }
  ],
  "2763": [
    {
      "answer": "October 16, 1973",
      "score": 0.9904080629348755
    }
  ],
  "2764": [
    {
      "answer": "In response to American aid to Israel",
      "score": 0.9669049978256226
    }
  ],
  "2765": [
    {
      "answer": "$2.2 billion",
      "score": 0.9701259732246399
    },
    {
      "answer": "$2.2 billion",
      "score": 0.8700804710388184
    }
  ],
  "2766": [
    {
      "answer": "In response to American aid to Israel",
      "score": 0.8184828162193298
    }
  ],
  "2767": [
    {
      "answer": "raised the posted price of oil by 70%",
      "score": 0.9813361763954163
    }
  ],
  "2768": [
    {
      "answer": "$2.2 billion in emergency aid to Israel",
      "score": 0.9613339304924011
    }
  ],
  "2769": [
    {
      "answer": "$2.2 billion",
      "score": 0.920737087726593
    }
  ],
  "2770": [
    {
      "answer": "embargo oil shipments to the United States",
      "score": 0.6129941344261169
    }
  ],
  "2771": [
    {
      "answer": "embargo",
      "score": 0.8679206967353821
    }
  ],
  "2772": [
    {
      "answer": "raised the posted price of oil by 70%",
      "score": 0.9873936772346497
    }
  ],
  "2773": [
    {
      "answer": "70%",
      "score": 0.9916425943374634
    }
  ],
  "2774": [
    {
      "answer": "$5.11",
      "score": 0.9948683977127075
    }
  ],
  "2775": [
    {
      "answer": "Libya",
      "score": 0.9894127249717712
    }
  ],
  "2776": [
    {
      "answer": "October 20, 1973",
      "score": 0.990398108959198
    }
  ],
  "2777": [
    {
      "answer": "over 100 billion dollars",
      "score": 0.9556077718734741
    }
  ],
  "2778": [
    {
      "answer": "underdeveloped nations",
      "score": 0.7570990324020386
    }
  ],
  "2779": [
    {
      "answer": "Middle East",
      "score": 0.9965368509292603
    }
  ],
  "2780": [
    {
      "answer": "higher oil prices and lower prices for their own export commodities",
      "score": 0.8345397114753723
    }
  ],
  "2781": [
    {
      "answer": "Wahhabism",
      "score": 0.9950172305107117
    }
  ],
  "2782": [
    {
      "answer": "over 100 billion dollars",
      "score": 0.9439504742622375
    }
  ],
  "2783": [
    {
      "answer": "Middle East",
      "score": 0.9947863817214966
    }
  ],
  "2784": [
    {
      "answer": "ensuing decades",
      "score": 0.8566368818283081
    }
  ],
  "2785": [
    {
      "answer": "Wahhabism",
      "score": 0.9956399202346802
    }
  ],
  "2786": [],
  "2787": [
    {
      "answer": "distribution and price disruptions",
      "score": 0.9866252541542053
    }
  ],
  "2788": [
    {
      "answer": "USSR",
      "score": 0.9967041611671448
    }
  ],
  "2789": [
    {
      "answer": "1973",
      "score": 0.9974516034126282
    }
  ],
  "2790": [
    {
      "answer": "Kissinger",
      "score": 0.9886767864227295
    }
  ],
  "2791": [
    {
      "answer": "production, distribution and price disruptions",
      "score": 0.8565086722373962
    }
  ],
  "2792": [
    {
      "answer": "the Middle East could become another superpower confrontation with the USSR",
      "score": 0.9216706156730652
    }
  ],
  "2793": [
    {
      "answer": "Kissinger's dominance",
      "score": 0.5834257006645203
    }
  ],
  "2794": [
    {
      "answer": "negotiated settlement based on equality",
      "score": 0.99187833070755
    }
  ],
  "2795": [
    {
      "answer": "Middle East",
      "score": 0.9889521598815918
    }
  ],
  "2796": [
    {
      "answer": "embargo",
      "score": 0.9858214259147644
    },
    {
      "answer": "The embargo",
      "score": 0.7324670553207397
    }
  ],
  "2797": [
    {
      "answer": "automobiles",
      "score": 0.9881671071052551
    }
  ],
  "2798": [
    {
      "answer": "Macroeconomic",
      "score": 0.9950573444366455
    }
  ],
  "2799": [
    {
      "answer": "Arctic",
      "score": 0.9966551065444946
    }
  ],
  "2800": [
    {
      "answer": "five to ten years",
      "score": 0.9974268078804016
    }
  ],
  "2801": [
    {
      "answer": "US economy",
      "score": 0.9638497829437256
    }
  ],
  "2802": [
    {
      "answer": "five to ten years",
      "score": 0.8901750445365906
    }
  ],
  "2803": [
    {
      "answer": "price increases",
      "score": 0.9771829843521118
    }
  ],
  "2804": [
    {
      "answer": "inflationary and deflationary impacts",
      "score": 0.7118634581565857
    }
  ],
  "2805": [
    {
      "answer": "new ways to increase oil supplies",
      "score": 0.9608874320983887
    }
  ],
  "2806": [
    {
      "answer": "Netherlands",
      "score": 0.989452600479126
    }
  ],
  "2807": [
    {
      "answer": "America",
      "score": 0.995349109172821
    }
  ],
  "2808": [
    {
      "answer": "UK",
      "score": 0.8942910432815552
    },
    {
      "answer": "UK",
      "score": 0.9888945817947388
    }
  ],
  "2809": [
    {
      "answer": "Israel",
      "score": 0.7014673352241516
    }
  ],
  "2810": [
    {
      "answer": "Ted Heath",
      "score": 0.9966039657592773
    }
  ],
  "2811": [],
  "2812": [
    {
      "answer": "airfields",
      "score": 0.9888917803764343
    }
  ],
  "2813": [
    {
      "answer": "Israelis",
      "score": 0.7834672331809998
    },
    {
      "answer": "Israelis",
      "score": 0.8925583362579346
    }
  ],
  "2814": [
    {
      "answer": "Israel",
      "score": 0.9645107984542847
    },
    {
      "answer": "Israel",
      "score": 0.6954792737960815
    }
  ],
  "2815": [
    {
      "answer": "withdraw to its pre-1967 borders",
      "score": 0.9888210296630859
    }
  ],
  "2816": [
    {
      "answer": "UK",
      "score": 0.9834083318710327
    },
    {
      "answer": "UK",
      "score": 0.8550029993057251
    }
  ],
  "2817": [
    {
      "answer": "a series of strikes by coal miners and railroad workers",
      "score": 0.9802194833755493
    }
  ],
  "2818": [
    {
      "answer": "1973\u201374",
      "score": 0.9877027869224548
    }
  ],
  "2819": [],
  "2820": [
    {
      "answer": "Sweden",
      "score": 0.9868981838226318
    }
  ],
  "2821": [
    {
      "answer": "flying",
      "score": 0.9688461422920227
    }
  ],
  "2822": [
    {
      "answer": "coal",
      "score": 0.9762659072875977
    }
  ],
  "2823": [],
  "2824": [
    {
      "answer": "UK",
      "score": 0.9791339635848999
    },
    {
      "answer": "UK",
      "score": 0.8575884103775024
    }
  ],
  "2825": [
    {
      "answer": "heat only one room in their houses",
      "score": 0.9582825303077698
    }
  ],
  "2826": [
    {
      "answer": "Price controls",
      "score": 0.9588148593902588
    }
  ],
  "2827": [
    {
      "answer": "encourage investment",
      "score": 0.9942620992660522
    }
  ],
  "2828": [
    {
      "answer": "limited the price of \"old oil\" (that which had already been discovered) while allowing newly discovered oil to be sold at a higher price to encourage investment",
      "score": 0.8258972764015198
    }
  ],
  "2829": [
    {
      "answer": "rationing",
      "score": 0.9902815818786621
    }
  ],
  "2830": [
    {
      "answer": "to encourage investment",
      "score": 0.9608952403068542
    }
  ],
  "2831": [
    {
      "answer": "old oil was withdrawn from the market, creating greater scarcity",
      "score": 0.8986896276473999
    }
  ],
  "2832": [
    {
      "answer": "oil exploration",
      "score": 0.9902424812316895
    }
  ],
  "2833": [
    {
      "answer": "rationing",
      "score": 0.9779332876205444
    }
  ],
  "2834": [
    {
      "answer": "old oil was withdrawn from the market",
      "score": 0.7533029913902283
    }
  ],
  "2835": [
    {
      "answer": "William E. Simon",
      "score": 0.9962925910949707
    }
  ],
  "2836": [
    {
      "answer": "1973",
      "score": 0.9840857982635498
    }
  ],
  "2837": [
    {
      "answer": "to coordinate the response to the embargo",
      "score": 0.991871178150177
    }
  ],
  "2838": [
    {
      "answer": "20%",
      "score": 0.9959759712219238
    }
  ],
  "2839": [
    {
      "answer": "20%",
      "score": 0.9860299229621887
    }
  ],
  "2840": [
    {
      "answer": "first Administrator of the Federal Energy Office",
      "score": 0.934045135974884
    }
  ],
  "2841": [
    {
      "answer": "reported that in the last week of February 1974, 20% of American gasoline stations had no fuel",
      "score": 0.9219902753829956
    }
  ],
  "2842": [
    {
      "answer": "the same amount of domestic oil",
      "score": 0.9554810523986816
    }
  ],
  "2843": [
    {
      "answer": "lines at gasoline stations",
      "score": 0.9893798828125
    }
  ],
  "2844": [
    {
      "answer": "55 mph",
      "score": 0.9815965294837952
    },
    {
      "answer": "55 mph",
      "score": 0.8881663084030151
    }
  ],
  "2845": [
    {
      "answer": "Emergency Highway Energy Conservation Act",
      "score": 0.9251000285148621
    }
  ],
  "2846": [
    {
      "answer": "Bill Clinton",
      "score": 0.9973421096801758
    }
  ],
  "2847": [
    {
      "answer": "November 28, 1995",
      "score": 0.9699491858482361
    }
  ],
  "2848": [
    {
      "answer": "1977",
      "score": 0.9897108674049377
    }
  ],
  "2849": [
    {
      "answer": "a national maximum speed limit of 55 mph",
      "score": 0.8926591277122498
    }
  ],
  "2850": [
    {
      "answer": "Bill Clinton",
      "score": 0.9462119936943054
    }
  ],
  "2851": [
    {
      "answer": "National Highway Designation Act",
      "score": 0.7700372934341431
    }
  ],
  "2852": [
    {
      "answer": "federal 55 mph (89 km/h) speed limit",
      "score": 0.9348692893981934
    }
  ],
  "2853": [
    {
      "answer": "55 mph",
      "score": 0.725693941116333
    },
    {
      "answer": "55 mph",
      "score": 0.9228230118751526
    }
  ],
  "2854": [
    {
      "answer": "energy crisis",
      "score": 0.9973348379135132
    }
  ],
  "2855": [
    {
      "answer": "market and technology",
      "score": 0.9893536567687988
    }
  ],
  "2856": [
    {
      "answer": "congresses and presidents",
      "score": 0.9820758104324341
    }
  ],
  "2857": [
    {
      "answer": "renewable energy",
      "score": 0.9779515266418457
    },
    {
      "answer": "nuclear power",
      "score": 0.959926187992096
    },
    {
      "answer": "domestic fossil fuels",
      "score": 0.9459893107414246
    }
  ],
  "2858": [
    {
      "answer": "American energy policies since the crisis have been dominated by crisis-mentality thinking, promoting expensive quick fixes and single-shot solutions that ignore market and technology realities",
      "score": 0.8418524861335754
    }
  ],
  "2859": [
    {
      "answer": "expensive quick fixes",
      "score": 0.963901937007904
    }
  ],
  "2860": [
    {
      "answer": "expensive quick fixes and single-shot solutions",
      "score": 0.8668349981307983
    }
  ],
  "2861": [
    {
      "answer": "quick fixes",
      "score": 0.9631282091140747
    }
  ],
  "2862": [
    {
      "answer": "U.S",
      "score": 0.8525253534317017
    }
  ],
  "2863": [
    {
      "answer": "British",
      "score": 0.7733315229415894
    },
    {
      "answer": "British",
      "score": 0.9557428956031799
    },
    {
      "answer": "British",
      "score": 0.8478084206581116
    }
  ],
  "2864": [
    {
      "answer": "10 years",
      "score": 0.9916661381721497
    }
  ],
  "2865": [
    {
      "answer": "Arabs",
      "score": 0.9850078821182251
    }
  ],
  "2866": [
    {
      "answer": "military action to forcibly seize Middle Eastern oilfields",
      "score": 0.9020646810531616
    }
  ],
  "2867": [
    {
      "answer": "declassified documents",
      "score": 0.6441152095794678
    }
  ],
  "2868": [
    {
      "answer": "it was no longer obvious to him that the U.S. could not use force",
      "score": 0.7965391874313354
    }
  ],
  "2869": [
    {
      "answer": "British intelligence estimate of U.S. intentions",
      "score": 0.9503142237663269
    }
  ],
  "2870": [
    {
      "answer": "not involve force",
      "score": 0.852074384689331
    }
  ],
  "2871": [
    {
      "answer": "Japan",
      "score": 0.9910570383071899
    },
    {
      "answer": "Japan",
      "score": 0.7197059392929077
    },
    {
      "answer": "Japan",
      "score": 0.7204046249389648
    },
    {
      "answer": "Japan",
      "score": 0.7658142447471619
    }
  ],
  "2872": [
    {
      "answer": "71%",
      "score": 0.9546076059341431
    }
  ],
  "2873": [
    {
      "answer": "declared Japan a \"nonfriendly\" country",
      "score": 0.9798322319984436
    }
  ],
  "2874": [
    {
      "answer": "November 22",
      "score": 0.9932912588119507
    }
  ],
  "2875": [
    {
      "answer": "December 25",
      "score": 0.9959663152694702
    }
  ],
  "2876": [
    {
      "answer": "Japan",
      "score": 0.9797044992446899
    },
    {
      "answer": "Japan",
      "score": 0.7962292432785034
    },
    {
      "answer": "Japan",
      "score": 0.789046049118042
    },
    {
      "answer": "Japan",
      "score": 0.7874699831008911
    }
  ],
  "2877": [
    {
      "answer": "the Saudi and Kuwaiti governments declared Japan a \"nonfriendly\" country",
      "score": 0.7300040125846863
    },
    {
      "answer": "a 5% production cut",
      "score": 0.8149123191833496
    }
  ],
  "2878": [
    {
      "answer": "a 5% production cut",
      "score": 0.9349058270454407
    }
  ],
  "2879": [
    {
      "answer": "November 7, 1973",
      "score": 0.9939326643943787
    }
  ],
  "2880": [
    {
      "answer": "panic",
      "score": 0.9767232537269592
    }
  ],
  "2881": [
    {
      "answer": "USSR",
      "score": 0.9863715767860413
    }
  ],
  "2882": [
    {
      "answer": "Saudi Arabia",
      "score": 0.9883918762207031
    },
    {
      "answer": "Iran",
      "score": 0.9635543823242188
    },
    {
      "answer": "Saudi Arabia",
      "score": 0.870159387588501
    },
    {
      "answer": "Saudi Arabia",
      "score": 0.8172568678855896
    },
    {
      "answer": "Saudi Arabia",
      "score": 0.8342926502227783
    }
  ],
  "2883": [
    {
      "answer": "Saudi Arabia",
      "score": 0.8312095999717712
    },
    {
      "answer": "Saudi",
      "score": 0.8745477795600891
    },
    {
      "answer": "Saudi Arabia",
      "score": 0.8205905556678772
    },
    {
      "answer": "Saudi Arabia",
      "score": 0.6707785129547119
    },
    {
      "answer": "Saudi Arabia",
      "score": 0.6971848011016846
    },
    {
      "answer": "Saudi",
      "score": 0.6270163059234619
    }
  ],
  "2884": [
    {
      "answer": "January 1979",
      "score": 0.8830097913742065
    }
  ],
  "2885": [
    {
      "answer": "November 1979",
      "score": 0.9785597324371338
    }
  ],
  "2886": [
    {
      "answer": "Iran",
      "score": 0.6215780377388
    },
    {
      "answer": "Iran",
      "score": 0.5363051891326904
    },
    {
      "answer": "Iran",
      "score": 0.5796427726745605
    }
  ],
  "2887": [
    {
      "answer": "increased American weapons sales, technology, and outright military presence",
      "score": 0.6702862977981567
    },
    {
      "answer": "seizure of the Grand Mosque in Mecca by Wahhabi extremists during November 1979",
      "score": 0.6941892504692078
    }
  ],
  "2888": [
    {
      "answer": "American security assurances",
      "score": 0.9016976356506348
    }
  ],
  "2889": [
    {
      "answer": "failure of the Shah during January 1979 to maintain control of Iran",
      "score": 0.9515961408615112
    }
  ],
  "2890": [],
  "2891": [
    {
      "answer": "large",
      "score": 0.8716931939125061
    }
  ],
  "2892": [
    {
      "answer": "Japanese",
      "score": 0.838044285774231
    },
    {
      "answer": "Japanese",
      "score": 0.898047685623169
    }
  ],
  "2893": [
    {
      "answer": "V8",
      "score": 0.9837897419929504
    },
    {
      "answer": "six cylinder",
      "score": 0.978554368019104
    }
  ],
  "2894": [
    {
      "answer": "Japanese",
      "score": 0.8337985873222351
    },
    {
      "answer": "Japanese",
      "score": 0.965259850025177
    }
  ],
  "2895": [
    {
      "answer": "unibody construction",
      "score": 0.9805842638015747
    },
    {
      "answer": "front-wheel drive",
      "score": 0.9802485704421997
    }
  ],
  "2896": [
    {
      "answer": "Toyota Corona",
      "score": 0.8031172156333923
    },
    {
      "answer": "Toyota Corolla",
      "score": 0.5186416506767273
    },
    {
      "answer": "Datsun B210",
      "score": 0.5198401212692261
    },
    {
      "answer": "Mitsubishi Galant",
      "score": 0.5758736729621887
    },
    {
      "answer": "Subaru DL",
      "score": 0.7083036303520203
    },
    {
      "answer": "Honda Accord",
      "score": 0.6779640913009644
    }
  ],
  "2897": [
    {
      "answer": "front-wheel drive",
      "score": 0.9820175170898438
    }
  ],
  "2898": [
    {
      "answer": "Japanese",
      "score": 0.8221112489700317
    },
    {
      "answer": "Japanese",
      "score": 0.9427329301834106
    }
  ],
  "2899": [
    {
      "answer": "crisis",
      "score": 0.9730510711669922
    }
  ],
  "2900": [
    {
      "answer": "1981",
      "score": 0.9853380918502808
    }
  ],
  "2901": [
    {
      "answer": "Toyota Corona Mark II",
      "score": 0.9292393326759338
    },
    {
      "answer": "Toyota Cressida",
      "score": 0.7150169610977173
    }
  ],
  "2902": [],
  "2903": [],
  "2904": [
    {
      "answer": "Mazda 616",
      "score": 0.8977965116500854
    }
  ],
  "2905": [],
  "2906": [
    {
      "answer": "mass-market brands",
      "score": 0.848686695098877
    }
  ],
  "2907": [
    {
      "answer": "small size",
      "score": 0.963281512260437
    }
  ],
  "2908": [
    {
      "answer": "air conditioning",
      "score": 0.836590051651001
    },
    {
      "answer": "power steering",
      "score": 0.8638201355934143
    },
    {
      "answer": "AM-FM radios",
      "score": 0.655115008354187
    },
    {
      "answer": "power windows",
      "score": 0.7204713821411133
    },
    {
      "answer": "central locking",
      "score": 0.5610131025314331
    }
  ],
  "2909": [
    {
      "answer": "Toyota Hilux",
      "score": 0.8893018960952759
    }
  ],
  "2910": [
    {
      "answer": "Dodge D-50",
      "score": 0.9933151006698608
    }
  ],
  "2911": [
    {
      "answer": "Ford",
      "score": 0.6734864115715027
    },
    {
      "answer": "Chrysler",
      "score": 0.8120613098144531
    },
    {
      "answer": "GM",
      "score": 0.7822826504707336
    }
  ],
  "2912": [
    {
      "answer": "captive import policy",
      "score": 0.9948815107345581
    }
  ],
  "2913": [
    {
      "answer": "Dodge D-50",
      "score": 0.9894765615463257
    }
  ],
  "2914": [],
  "2915": [],
  "2916": [
    {
      "answer": "captive import policy",
      "score": 0.9924106001853943
    }
  ],
  "2917": [
    {
      "answer": "Toyota Hilux",
      "score": 0.9221868515014648
    },
    {
      "answer": "Datsun Truck",
      "score": 0.6911631226539612
    }
  ],
  "2918": [
    {
      "answer": "An increase in imported cars into North America",
      "score": 0.983954668045044
    }
  ],
  "2919": [
    {
      "answer": "four",
      "score": 0.9854441285133362
    }
  ],
  "2920": [
    {
      "answer": "1970",
      "score": 0.658338189125061
    }
  ],
  "2921": [],
  "2922": [
    {
      "answer": "Chevrolet Bel Air",
      "score": 0.9783267974853516
    },
    {
      "answer": "Ford Galaxie 500",
      "score": 0.9672243595123291
    }
  ],
  "2923": [
    {
      "answer": "introduce smaller and fuel-efficient models for domestic sales",
      "score": 0.9597780108451843
    }
  ],
  "2924": [
    {
      "answer": "17.4",
      "score": 0.9819480180740356
    }
  ],
  "2925": [
    {
      "answer": "$12",
      "score": 0.9869657158851624
    }
  ],
  "2926": [
    {
      "answer": "Chevrolet Bel Air",
      "score": 0.9361473321914673
    },
    {
      "answer": "Ford Galaxie 500",
      "score": 0.9145388603210449
    }
  ],
  "2927": [
    {
      "answer": "13.5",
      "score": 0.6902343034744263
    }
  ],
  "2928": [
    {
      "answer": "1979",
      "score": 0.9816522002220154
    }
  ],
  "2929": [
    {
      "answer": "1981",
      "score": 0.9895986318588257
    }
  ],
  "2930": [
    {
      "answer": "Mustang I",
      "score": 0.9908331036567688
    }
  ],
  "2931": [],
  "2932": [
    {
      "answer": "1981",
      "score": 0.9709796905517578
    }
  ],
  "2933": [
    {
      "answer": "DOT \"downsize\" revision",
      "score": 0.9427192807197571
    }
  ],
  "2934": [
    {
      "answer": "full front-wheel drive",
      "score": 0.9148886203765869
    }
  ],
  "2935": [],
  "2936": [
    {
      "answer": "1981",
      "score": 0.9918596148490906
    }
  ],
  "2937": [
    {
      "answer": "1980s",
      "score": 0.9774848818778992
    }
  ],
  "2938": [
    {
      "answer": "to recover market share",
      "score": 0.9858769178390503
    }
  ],
  "2939": [
    {
      "answer": "nearly $40",
      "score": 0.9593875408172607
    }
  ],
  "2940": [
    {
      "answer": "1981",
      "score": 0.9880971908569336
    }
  ],
  "2941": [
    {
      "answer": "increased production",
      "score": 0.9757242202758789
    }
  ],
  "2942": [
    {
      "answer": "lost its preeminent position",
      "score": 0.6107308268547058
    },
    {
      "answer": "its production was surpassed by that of other countries",
      "score": 0.7324396967887878
    },
    {
      "answer": "its own member nations were divided",
      "score": 0.589160680770874
    },
    {
      "answer": "shrinking or eliminating profits for high-cost producers",
      "score": 0.6772903800010681
    }
  ],
  "2943": [
    {
      "answer": "nearly $40",
      "score": 0.9156985282897949
    }
  ],
  "2944": [
    {
      "answer": "less than $10",
      "score": 0.9622396230697632
    }
  ],
  "2945": [
    {
      "answer": "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states",
      "score": 0.8930600881576538
    }
  ],
  "2946": [
    {
      "answer": "the Treaties establishing the European Union",
      "score": 0.97276771068573
    }
  ],
  "2947": [
    {
      "answer": "regulations and directives which are based on the Treaties",
      "score": 0.9696255922317505
    }
  ],
  "2948": [
    {
      "answer": "European Parliament",
      "score": 0.9415730237960815
    },
    {
      "answer": "Council of the European Union",
      "score": 0.9370400309562683
    }
  ],
  "2949": [
    {
      "answer": "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states",
      "score": 0.8957455158233643
    }
  ],
  "2950": [
    {
      "answer": "direct effect or indirect effect",
      "score": 0.9370971918106079
    }
  ],
  "2951": [
    {
      "answer": "primary law",
      "score": 0.949781060218811
    },
    {
      "answer": "secondary law",
      "score": 0.9417243003845215
    }
  ],
  "2952": [
    {
      "answer": "European Parliament",
      "score": 0.9885421991348267
    },
    {
      "answer": "Council of the European Union",
      "score": 0.9614940881729126
    }
  ],
  "2953": [
    {
      "answer": "primary law, secondary law and supplementary law",
      "score": 0.6954202055931091
    },
    {
      "answer": "The main sources of primary law are the Treaties establishing the European Union",
      "score": 0.656666100025177
    }
  ],
  "2954": [
    {
      "answer": "the Treaties establishing the European Union",
      "score": 0.97276771068573
    }
  ],
  "2955": [
    {
      "answer": "European Parliament and the Council of the European Union",
      "score": 0.9420386552810669
    }
  ],
  "2956": [
    {
      "answer": "three",
      "score": 0.9873262047767639
    }
  ],
  "2957": [
    {
      "answer": "primary law",
      "score": 0.9458794593811035
    },
    {
      "answer": "secondary law",
      "score": 0.9362919330596924
    },
    {
      "answer": "supplementary law",
      "score": 0.9245344996452332
    }
  ],
  "2958": [
    {
      "answer": "treaties and legislation",
      "score": 0.9280872344970703
    }
  ],
  "2959": [],
  "2960": [
    {
      "answer": "supplementary law",
      "score": 0.7508244514465332
    }
  ],
  "2961": [
    {
      "answer": "European Parliament and the Council of the European Union",
      "score": 0.9719822406768799
    }
  ],
  "2962": [
    {
      "answer": "courts of member states",
      "score": 0.9815210700035095
    }
  ],
  "2963": [
    {
      "answer": "courts of member states",
      "score": 0.9842013120651245
    }
  ],
  "2964": [
    {
      "answer": "Court of Justice",
      "score": 0.8383333683013916
    },
    {
      "answer": "European Court of Justice",
      "score": 0.9552639126777649
    }
  ],
  "2965": [
    {
      "answer": "case law by the Court of Justice",
      "score": 0.9339661598205566
    },
    {
      "answer": "international law",
      "score": 0.9455982446670532
    },
    {
      "answer": "general principles of European Union law",
      "score": 0.9130178689956665
    }
  ],
  "2966": [
    {
      "answer": "courts of member states",
      "score": 0.9747880101203918
    },
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.9777010083198547
    },
    {
      "answer": "courts of member states",
      "score": 0.861992597579956
    }
  ],
  "2967": [
    {
      "answer": "Treaty on the Functioning of the European Union",
      "score": 0.9918820858001709
    }
  ],
  "2968": [
    {
      "answer": "Court of Justice",
      "score": 0.8172125816345215
    },
    {
      "answer": "European Court of Justice",
      "score": 0.9641709327697754
    }
  ],
  "2969": [
    {
      "answer": "case law by the Court of Justice",
      "score": 0.8931122422218323
    },
    {
      "answer": "international law",
      "score": 0.955268144607544
    },
    {
      "answer": "general principles of European Union law",
      "score": 0.8953436613082886
    }
  ],
  "2970": [
    {
      "answer": "courts of member states",
      "score": 0.9712933897972107
    },
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.9618145227432251
    },
    {
      "answer": "courts of member states",
      "score": 0.5426745414733887
    }
  ],
  "2971": [
    {
      "answer": "courts of member states",
      "score": 0.8945455551147461
    },
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.7896877527236938
    },
    {
      "answer": "courts of member states",
      "score": 0.9237391948699951
    },
    {
      "answer": "European Commission",
      "score": 0.6135467290878296
    }
  ],
  "2972": [
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.640180766582489
    },
    {
      "answer": "European Court of Justice",
      "score": 0.9727168083190918
    }
  ],
  "2973": [
    {
      "answer": "case law by the Court of Justice",
      "score": 0.9880449175834656
    },
    {
      "answer": "international law",
      "score": 0.9840397834777832
    },
    {
      "answer": "general principles of European Union law",
      "score": 0.9872423410415649
    }
  ],
  "2974": [
    {
      "answer": "courts of member states",
      "score": 0.9608575105667114
    },
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.9441706538200378
    }
  ],
  "2975": [
    {
      "answer": "courts of member states",
      "score": 0.6609535217285156
    },
    {
      "answer": "courts of member states",
      "score": 0.9770835041999817
    }
  ],
  "2976": [
    {
      "answer": "member state",
      "score": 0.9834608435630798
    }
  ],
  "2977": [
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.7523399591445923
    }
  ],
  "2978": [
    {
      "answer": "case law by the Court of Justice",
      "score": 0.986741304397583
    },
    {
      "answer": "international law",
      "score": 0.9834294319152832
    },
    {
      "answer": "general principles of European Union law",
      "score": 0.982733428478241
    }
  ],
  "2979": [
    {
      "answer": "Treaty on European Union (TEU)",
      "score": 0.9859501123428345
    },
    {
      "answer": "Treaty on the Functioning of the European Union (TFEU)",
      "score": 0.9827191233634949
    }
  ],
  "2980": [
    {
      "answer": "The European Commission",
      "score": 0.9480017423629761
    }
  ],
  "2981": [
    {
      "answer": "citizens",
      "score": 0.9843759536743164
    },
    {
      "answer": "citizens",
      "score": 0.7993568778038025
    }
  ],
  "2982": [
    {
      "answer": "European Court of Justice",
      "score": 0.99689781665802
    }
  ],
  "2983": [
    {
      "answer": "European Union",
      "score": 0.6221391558647156
    },
    {
      "answer": "European Council",
      "score": 0.9854394197463989
    }
  ],
  "2984": [
    {
      "answer": "European Union",
      "score": 0.9568027257919312
    },
    {
      "answer": "European Union",
      "score": 0.7672926187515259
    },
    {
      "answer": "European Union",
      "score": 0.8994580507278442
    }
  ],
  "2985": [
    {
      "answer": "Treaty on European Union (TEU)",
      "score": 0.9829709529876709
    },
    {
      "answer": "Treaty on the Functioning of the European Union (TFEU)",
      "score": 0.9766048192977905
    }
  ],
  "2986": [
    {
      "answer": "European Commission",
      "score": 0.9708515405654907
    }
  ],
  "2987": [
    {
      "answer": "citizens",
      "score": 0.9303426742553711
    },
    {
      "answer": "citizens",
      "score": 0.7313734292984009
    }
  ],
  "2988": [
    {
      "answer": "European Union",
      "score": 0.5687752962112427
    },
    {
      "answer": "European Council",
      "score": 0.9867777824401855
    }
  ],
  "2989": [
    {
      "answer": "TEU",
      "score": 0.6502187848091125
    },
    {
      "answer": "TEU",
      "score": 0.9702291488647461
    },
    {
      "answer": "TEU",
      "score": 0.6927281618118286
    },
    {
      "answer": "TEU",
      "score": 0.6873640418052673
    },
    {
      "answer": "TEU",
      "score": 0.772605836391449
    },
    {
      "answer": "TEU",
      "score": 0.7591655254364014
    },
    {
      "answer": "TEU",
      "score": 0.5558276772499084
    }
  ],
  "2990": [
    {
      "answer": "Faroe Islands",
      "score": 0.985944390296936
    }
  ],
  "2991": [
    {
      "answer": "can interpret the Treaties",
      "score": 0.9648021459579468
    }
  ],
  "2992": [
    {
      "answer": "the Treaty provisions have a direct effect",
      "score": 0.9698342084884644
    }
  ],
  "2993": [
    {
      "answer": "as soon as they enter into force",
      "score": 0.9898887872695923
    }
  ],
  "2994": [
    {
      "answer": "Treaty on European Union (TEU)",
      "score": 0.9731386303901672
    },
    {
      "answer": "Treaty on the Functioning of the European Union (TFEU)",
      "score": 0.9609469175338745
    }
  ],
  "2995": [
    {
      "answer": "Gibraltar",
      "score": 0.9807446599006653
    },
    {
      "answer": "\u00c5land islands",
      "score": 0.9803312420845032
    },
    {
      "answer": "Gibraltar",
      "score": 0.5535051226615906
    }
  ],
  "2996": [
    {
      "answer": "as soon as they enter into force",
      "score": 0.9867056608200073
    }
  ],
  "2997": [
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.9844600558280945
    },
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.7417158484458923
    }
  ],
  "2998": [],
  "2999": [
    {
      "answer": "Treaty on the Functioning of the European Union",
      "score": 0.640783429145813
    },
    {
      "answer": "Treaties",
      "score": 0.6638970971107483
    }
  ],
  "3000": [
    {
      "answer": "specifically excludes certain regions, for example the Faroe Islands, from the jurisdiction of European Union law",
      "score": 0.9082664847373962
    }
  ],
  "3001": [
    {
      "answer": "Faroe Islands",
      "score": 0.9892563819885254
    }
  ],
  "3002": [
    {
      "answer": "make specific provisions for regions",
      "score": 0.7493859529495239
    },
    {
      "answer": "The TEU specifically excludes certain regions, for example the Faroe Islands, from the jurisdiction of European Union law",
      "score": 0.8430392146110535
    }
  ],
  "3003": [
    {
      "answer": "common rules for coal and steel, and then atomic energy",
      "score": 0.9844746589660645
    }
  ],
  "3004": [
    {
      "answer": "Treaty of Rome 1957",
      "score": 0.9942022562026978
    },
    {
      "answer": "Maastricht Treaty 1992",
      "score": 0.9779257774353027
    }
  ],
  "3005": [
    {
      "answer": "1985",
      "score": 0.9596630930900574
    },
    {
      "answer": "1985",
      "score": 0.7503310441970825
    }
  ],
  "3006": [
    {
      "answer": "Norway did not",
      "score": 0.8264386653900146
    }
  ],
  "3007": [
    {
      "answer": "Greenland",
      "score": 0.9791714549064636
    }
  ],
  "3008": [
    {
      "answer": "common rules for coal and steel",
      "score": 0.9531272649765015
    },
    {
      "answer": "atomic energy",
      "score": 0.9608035087585449
    }
  ],
  "3009": [
    {
      "answer": "1992",
      "score": 0.6553813815116882
    }
  ],
  "3010": [
    {
      "answer": "1986",
      "score": 0.9830026030540466
    }
  ],
  "3011": [
    {
      "answer": "1972",
      "score": 0.9873207807540894
    }
  ],
  "3012": [
    {
      "answer": "1985",
      "score": 0.8275962471961975
    },
    {
      "answer": "1985",
      "score": 0.9707735776901245
    }
  ],
  "3013": [
    {
      "answer": "common rules for coal and steel, and then atomic energy",
      "score": 0.9814978837966919
    }
  ],
  "3014": [
    {
      "answer": "Treaty of Rome 1957",
      "score": 0.9942284822463989
    },
    {
      "answer": "Maastricht Treaty 1992",
      "score": 0.976658821105957
    }
  ],
  "3015": [
    {
      "answer": "Minor amendments",
      "score": 0.8815310001373291
    }
  ],
  "3016": [
    {
      "answer": "1985",
      "score": 0.9777502417564392
    },
    {
      "answer": "1985",
      "score": 0.8255224227905273
    }
  ],
  "3017": [
    {
      "answer": "1972",
      "score": 0.9847679734230042
    }
  ],
  "3018": [
    {
      "answer": "Nice Treaty",
      "score": 0.9255826473236084
    }
  ],
  "3019": [
    {
      "answer": "France",
      "score": 0.9608593583106995
    },
    {
      "answer": "Netherlands",
      "score": 0.8997412323951721
    }
  ],
  "3020": [
    {
      "answer": "very similar",
      "score": 0.9735488295555115
    }
  ],
  "3021": [
    {
      "answer": "amending treaty",
      "score": 0.989358127117157
    }
  ],
  "3022": [
    {
      "answer": "significantly altered the existing treaties \u2013 it did not completely replace them",
      "score": 0.6906023025512695
    }
  ],
  "3023": [
    {
      "answer": "reform the constitutional law of the European Union",
      "score": 0.8821951746940613
    }
  ],
  "3024": [
    {
      "answer": "more transparent",
      "score": 0.9145484566688538
    }
  ],
  "3025": [
    {
      "answer": "referendum in France",
      "score": 0.9922088384628296
    },
    {
      "answer": "referendum in the Netherlands",
      "score": 0.9822680950164795
    }
  ],
  "3026": [
    {
      "answer": "Lisbon Treaty",
      "score": 0.9925751686096191
    }
  ],
  "3027": [
    {
      "answer": "the 2004 Treaty establishing a Constitution for Europe never came into force",
      "score": 0.9563331604003906
    }
  ],
  "3028": [
    {
      "answer": "2004",
      "score": 0.9925933480262756
    }
  ],
  "3029": [
    {
      "answer": "Its substance was very similar to the proposed constitutional treaty",
      "score": 0.6360113024711609
    },
    {
      "answer": "formally an amending treaty",
      "score": 0.7888556122779846
    }
  ],
  "3030": [
    {
      "answer": "Lisbon Treaty",
      "score": 0.988203763961792
    }
  ],
  "3031": [
    {
      "answer": "referendum in France",
      "score": 0.9875008463859558
    },
    {
      "answer": "referendum in the Netherlands",
      "score": 0.9686756134033203
    }
  ],
  "3032": [
    {
      "answer": "European Commission",
      "score": 0.9894174337387085
    }
  ],
  "3033": [
    {
      "answer": "European Commission",
      "score": 0.8149980902671814
    }
  ],
  "3034": [
    {
      "answer": "President",
      "score": 0.9262341260910034
    },
    {
      "answer": "President",
      "score": 0.7449885606765747
    }
  ],
  "3035": [
    {
      "answer": "one",
      "score": 0.9696363210678101
    }
  ],
  "3036": [
    {
      "answer": "Federica Mogherini",
      "score": 0.9857872724533081
    }
  ],
  "3037": [
    {
      "answer": "Article 17(3",
      "score": 0.9763716459274292
    }
  ],
  "3038": [
    {
      "answer": "The Commission's President",
      "score": 0.9770614504814148
    }
  ],
  "3039": [
    {
      "answer": "Decisions are taken by a simple majority vote",
      "score": 0.9382883310317993
    }
  ],
  "3040": [
    {
      "answer": "Ireland",
      "score": 0.9916651844978333
    }
  ],
  "3041": [
    {
      "answer": "Commissioners",
      "score": 0.5641075968742371
    },
    {
      "answer": "Commissioners",
      "score": 0.9056165814399719
    }
  ],
  "3042": [
    {
      "answer": "European Commission",
      "score": 0.643876314163208
    }
  ],
  "3043": [
    {
      "answer": "Council",
      "score": 0.8380175828933716
    }
  ],
  "3044": [
    {
      "answer": "The Parliament",
      "score": 0.6415942907333374
    },
    {
      "answer": "Parliament",
      "score": 0.5278875827789307
    }
  ],
  "3045": [
    {
      "answer": "2007",
      "score": 0.9871649742126465
    }
  ],
  "3046": [
    {
      "answer": "The Commissioners",
      "score": 0.6897724270820618
    }
  ],
  "3047": [
    {
      "answer": "Santer",
      "score": 0.994629442691803
    }
  ],
  "3048": [
    {
      "answer": "not break any law",
      "score": 0.7897084951400757
    }
  ],
  "3049": [
    {
      "answer": "Committee of Independent Experts",
      "score": 0.9925308227539062
    }
  ],
  "3050": [
    {
      "answer": "European Council",
      "score": 0.9907367825508118
    }
  ],
  "3051": [
    {
      "answer": "The President of the Council and a Commissioner can sit in on ECB meetings, but do not have voting rights.",
      "score": 0.8402127623558044
    }
  ],
  "3052": [
    {
      "answer": "1999",
      "score": 0.9878061413764954
    }
  ],
  "3053": [
    {
      "answer": "Commission v Edith Cresson",
      "score": 0.9955288767814636
    }
  ],
  "3054": [
    {
      "answer": "Committee of Independent Experts",
      "score": 0.9912033677101135
    }
  ],
  "3055": [
    {
      "answer": "European Anti-fraud Office",
      "score": 0.9905499219894409
    }
  ],
  "3056": [
    {
      "answer": "2012",
      "score": 0.9847778081893921
    }
  ],
  "3057": [
    {
      "answer": "EU taxes",
      "score": 0.9477397203445435
    }
  ],
  "3058": [],
  "3059": [
    {
      "answer": "Santer",
      "score": 0.9921581745147705
    }
  ],
  "3060": [
    {
      "answer": "Santer",
      "score": 0.9752987623214722
    }
  ],
  "3061": [
    {
      "answer": "Commission v Edith Cresson",
      "score": 0.9824970364570618
    }
  ],
  "3062": [
    {
      "answer": "ministers",
      "score": 0.9746755957603455
    }
  ],
  "3063": [
    {
      "answer": "Donald Tusk",
      "score": 0.9922422170639038
    }
  ],
  "3064": [
    {
      "answer": "When voting takes place it is weighted inversely to member state size",
      "score": 0.9031263589859009
    }
  ],
  "3065": [
    {
      "answer": "352",
      "score": 0.9811277389526367
    },
    {
      "answer": "352",
      "score": 0.872201681137085
    }
  ],
  "3066": [
    {
      "answer": "260",
      "score": 0.8985968232154846
    }
  ],
  "3067": [
    {
      "answer": "Council",
      "score": 0.982418954372406
    },
    {
      "answer": "Council",
      "score": 0.5585235357284546
    },
    {
      "answer": "Council",
      "score": 0.9073710441589355
    },
    {
      "answer": "Council",
      "score": 0.8883860111236572
    }
  ],
  "3068": [
    {
      "answer": "each six months",
      "score": 0.9653002619743347
    }
  ],
  "3069": [
    {
      "answer": "352",
      "score": 0.9871764779090881
    },
    {
      "answer": "352",
      "score": 0.8792522549629211
    }
  ],
  "3070": [
    {
      "answer": "TEU article 16(4) and TFEU article 238(3) define this to mean at least 55 per cent of the Council members (not votes) representing 65 per cent of the population of the EU",
      "score": 0.9095005989074707
    }
  ],
  "3071": [
    {
      "answer": "different ministers of the member states",
      "score": 0.9268202185630798
    }
  ],
  "3072": [
    {
      "answer": "heads of government",
      "score": 0.935349702835083
    }
  ],
  "3073": [
    {
      "answer": "Donald Tusk",
      "score": 0.7571756839752197
    }
  ],
  "3074": [
    {
      "answer": "European Council",
      "score": 0.8444703817367554
    }
  ],
  "3075": [
    {
      "answer": "When voting takes place it is weighted inversely to member state size",
      "score": 0.883323073387146
    }
  ],
  "3076": [
    {
      "answer": "a majority of all MEPs",
      "score": 0.9666644334793091
    }
  ],
  "3077": [
    {
      "answer": "qualified majority",
      "score": 0.9637944102287292
    },
    {
      "answer": "qualified majority",
      "score": 0.739500880241394
    }
  ],
  "3078": [
    {
      "answer": "harder",
      "score": 0.9809448719024658
    }
  ],
  "3079": [
    {
      "answer": "TEU articles 4 and 5",
      "score": 0.9849991202354431
    }
  ],
  "3080": [
    {
      "answer": "Court of Justice",
      "score": 0.9961187839508057
    }
  ],
  "3081": [
    {
      "answer": "294",
      "score": 0.991835355758667
    }
  ],
  "3082": [
    {
      "answer": "a majority in Parliament, a minority in the Council, and a majority in the Commission",
      "score": 0.9249927401542664
    }
  ],
  "3083": [
    {
      "answer": "TEU articles 4 and 5",
      "score": 0.9797839522361755
    }
  ],
  "3084": [
    {
      "answer": "Conciliation Committee",
      "score": 0.9792081713676453
    }
  ],
  "3085": [
    {
      "answer": "ordinary legislative procedure",
      "score": 0.9266840815544128
    }
  ],
  "3086": [
    {
      "answer": "there are three readings, starting with a Commission proposal, where the Parliament must vote by a majority of all MEPs (not just those present) to block or suggest changes, and the Council must vote by qualified majority to approve changes, but by unanimity to block Commission amendment.",
      "score": 0.7229380011558533
    }
  ],
  "3087": [
    {
      "answer": "unanimity",
      "score": 0.6679137945175171
    }
  ],
  "3088": [
    {
      "answer": "TEU articles 4 and 5",
      "score": 0.9154177904129028
    }
  ],
  "3089": [
    {
      "answer": "Court of Justice",
      "score": 0.9839751124382019
    }
  ],
  "3090": [
    {
      "answer": "judicial",
      "score": 0.9899459481239319
    }
  ],
  "3091": [
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.975297749042511
    }
  ],
  "3092": [
    {
      "answer": "28",
      "score": 0.9938445091247559
    }
  ],
  "3093": [
    {
      "answer": "English Court of Appeal",
      "score": 0.9869427680969238
    }
  ],
  "3094": [
    {
      "answer": "ensure that in the interpretation and application of the Treaties the law is observed",
      "score": 0.9949154853820801
    }
  ],
  "3095": [
    {
      "answer": "assuming the task of interpreting the treaties",
      "score": 0.9671950340270996
    },
    {
      "answer": "accelerating economic and political integration",
      "score": 0.9627521634101868
    }
  ],
  "3096": [
    {
      "answer": "Court of Justice of the European Union",
      "score": 0.9754883646965027
    }
  ],
  "3097": [
    {
      "answer": "Civil Service Tribunal",
      "score": 0.9886924028396606
    }
  ],
  "3098": [
    {
      "answer": "three years",
      "score": 0.9815346002578735
    }
  ],
  "3099": [
    {
      "answer": "ensure that in the interpretation and application of the Treaties the law is observed",
      "score": 0.9949154853820801
    }
  ],
  "3100": [
    {
      "answer": "judicial",
      "score": 0.7463019490242004
    }
  ],
  "3101": [
    {
      "answer": "General Court",
      "score": 0.7744307518005371
    },
    {
      "answer": "General Court",
      "score": 0.7646045684814453
    }
  ],
  "3102": [
    {
      "answer": "28",
      "score": 0.9894200563430786
    }
  ],
  "3103": [
    {
      "answer": "English Court of Appeal",
      "score": 0.9475237727165222
    },
    {
      "answer": "German Bundesgerichtshof",
      "score": 0.924055814743042
    },
    {
      "answer": "Belgian Cour du travail",
      "score": 0.9362340569496155
    }
  ],
  "3104": [
    {
      "answer": "ensure that in the interpretation and application of the Treaties the law is observed",
      "score": 0.9554834961891174
    }
  ],
  "3105": [
    {
      "answer": "EU law has primacy",
      "score": 0.9399405121803284
    }
  ],
  "3106": [
    {
      "answer": "because the nationalisation law was from 1962, and the treaty was in force from 1958",
      "score": 0.9811336994171143
    }
  ],
  "3107": [
    {
      "answer": "1964",
      "score": 0.6779428720474243
    },
    {
      "answer": "1964",
      "score": 0.9267869591712952
    },
    {
      "answer": "1968",
      "score": 0.9387216567993164
    }
  ],
  "3108": [
    {
      "answer": "European Court of Justice",
      "score": 0.9881558418273926
    }
  ],
  "3109": [
    {
      "answer": "1964",
      "score": 0.9897514581680298
    },
    {
      "answer": "1964",
      "score": 0.9255958795547485
    }
  ],
  "3110": [
    {
      "answer": "Court of Justice",
      "score": 0.8513591289520264
    },
    {
      "answer": "Court of Justice",
      "score": 0.7378915548324585
    },
    {
      "answer": "Court of Justice",
      "score": 0.8362318873405457
    },
    {
      "answer": "Court of Justice",
      "score": 0.9599360227584839
    },
    {
      "answer": "Court of Justice",
      "score": 0.9211909174919128
    },
    {
      "answer": "Court of Justice",
      "score": 0.9293314218521118
    },
    {
      "answer": "Court of Justice",
      "score": 0.9460623264312744
    }
  ],
  "3111": [
    {
      "answer": "EU",
      "score": 0.9770224094390869
    },
    {
      "answer": "EU",
      "score": 0.7055253982543945
    }
  ],
  "3112": [
    {
      "answer": "European Court of Justice",
      "score": 0.8373860120773315
    }
  ],
  "3113": [
    {
      "answer": "Amministrazione delle Finanze v Simmenthal SpA",
      "score": 0.8317920565605164
    }
  ],
  "3114": [
    {
      "answer": "Court of Justice",
      "score": 0.7026976346969604
    },
    {
      "answer": "Court of Justice",
      "score": 0.684035062789917
    },
    {
      "answer": "Court of Justice",
      "score": 0.9531440734863281
    },
    {
      "answer": "Court of Justice",
      "score": 0.8316627740859985
    },
    {
      "answer": "Court of Justice",
      "score": 0.8137891292572021
    },
    {
      "answer": "Court of Justice",
      "score": 0.8385655283927917
    }
  ],
  "3115": [
    {
      "answer": "EU law",
      "score": 0.992081880569458
    },
    {
      "answer": "EU law",
      "score": 0.865700364112854
    }
  ],
  "3116": [
    {
      "answer": "foundational constitutional questions affecting democracy and human rights",
      "score": 0.968622088432312
    }
  ],
  "3117": [
    {
      "answer": "1972",
      "score": 0.978681743144989
    },
    {
      "answer": "1972",
      "score": 0.9177128672599792
    }
  ],
  "3118": [
    {
      "answer": "Solange I and Solange II decisions",
      "score": 0.8016964793205261
    }
  ],
  "3119": [
    {
      "answer": "the ultimate authority of member states, its factual commitment to human rights",
      "score": 0.9827859401702881
    }
  ],
  "3120": [],
  "3121": [
    {
      "answer": "Parliament, as the sovereign expression of democratic legitimacy, can decide whether it wishes to expressly legislate against EU law",
      "score": 0.8750835061073303
    }
  ],
  "3122": [
    {
      "answer": "1972",
      "score": 0.9623876810073853
    },
    {
      "answer": "1972",
      "score": 0.7298285961151123
    }
  ],
  "3123": [
    {
      "answer": "if the EU does not comply with its basic constitutional rights and principles (particularly democracy, the rule of law and the social state principles) then it cannot override German law",
      "score": 0.9450660943984985
    }
  ],
  "3124": [
    {
      "answer": "ultimate authority of member states",
      "score": 0.9658520817756653
    }
  ],
  "3125": [
    {
      "answer": "administrative law",
      "score": 0.9958561062812805
    }
  ],
  "3126": [
    {
      "answer": "1986",
      "score": 0.9703898429870605
    }
  ],
  "3127": [
    {
      "answer": "All",
      "score": 0.9552884697914124
    }
  ],
  "3128": [
    {
      "answer": "constitutional law",
      "score": 0.9933505058288574
    }
  ],
  "3129": [
    {
      "answer": "administrative law",
      "score": 0.8823851346969604
    }
  ],
  "3130": [
    {
      "answer": "1986",
      "score": 0.9548966884613037
    }
  ],
  "3131": [
    {
      "answer": "courts of member states",
      "score": 0.9858407974243164
    }
  ],
  "3132": [],
  "3133": [
    {
      "answer": "constitutional law",
      "score": 0.7744872570037842
    },
    {
      "answer": "administrative law",
      "score": 0.5963780879974365
    }
  ],
  "3134": [
    {
      "answer": "Van Gend en Loos v Nederlandse Administratie der Belastingen",
      "score": 0.9824341535568237
    }
  ],
  "3135": [
    {
      "answer": "article 30",
      "score": 0.7305706739425659
    },
    {
      "answer": "article 30",
      "score": 0.9008750915527344
    }
  ],
  "3136": [
    {
      "answer": "postal",
      "score": 0.9904988408088684
    }
  ],
  "3137": [
    {
      "answer": "Treaty provisions",
      "score": 0.9791651368141174
    }
  ],
  "3138": [
    {
      "answer": "not all EU laws give citizens standing to bring claims",
      "score": 0.902653157711029
    },
    {
      "answer": "not all EU laws have \"direct effect\"",
      "score": 0.6993539929389954
    }
  ],
  "3139": [
    {
      "answer": "Van Gend en Loos",
      "score": 0.9876354932785034
    }
  ],
  "3140": [
    {
      "answer": "no quantitative restrictions could be placed on trade",
      "score": 0.8672845959663391
    }
  ],
  "3141": [
    {
      "answer": "Directives",
      "score": 0.985325813293457
    },
    {
      "answer": "Directives",
      "score": 0.7408545613288879
    },
    {
      "answer": "Directives",
      "score": 0.8086264133453369
    },
    {
      "answer": "Directives",
      "score": 0.7726039290428162
    },
    {
      "answer": "Directives",
      "score": 0.8057619333267212
    },
    {
      "answer": "Directives",
      "score": 0.747151255607605
    }
  ],
  "3142": [
    {
      "answer": "4 weeks",
      "score": 0.97365802526474
    }
  ],
  "3143": [
    {
      "answer": "28",
      "score": 0.9902679324150085
    }
  ],
  "3144": [
    {
      "answer": "early 1990s",
      "score": 0.9902517199516296
    }
  ],
  "3145": [
    {
      "answer": "Directives",
      "score": 0.5946809649467468
    }
  ],
  "3146": [
    {
      "answer": "Directives are addressed to the member states and usually \"leave to the national authorities the choice of form and methods",
      "score": 0.8956683278083801
    }
  ],
  "3147": [
    {
      "answer": "4 weeks",
      "score": 0.9758971929550171
    }
  ],
  "3148": [
    {
      "answer": "Working Time Directive",
      "score": 0.9738239645957947
    }
  ],
  "3149": [
    {
      "answer": "the member state cannot enforce conflicting laws",
      "score": 0.9609640836715698
    }
  ],
  "3150": [
    {
      "answer": "the member state cannot enforce conflicting laws",
      "score": 0.7868277430534363
    },
    {
      "answer": "a citizen or company can invoke a Directive, not just in a dispute with a public authority, but in a dispute with another citizen or company",
      "score": 0.9015603065490723
    }
  ],
  "3151": [
    {
      "answer": "10 years",
      "score": 0.9585444927215576
    }
  ],
  "3152": [
    {
      "answer": "British Gas plc",
      "score": 0.9266635775566101
    },
    {
      "answer": "British Gas plc",
      "score": 0.9557275772094727
    }
  ],
  "3153": [
    {
      "answer": "60",
      "score": 0.9177864193916321
    },
    {
      "answer": "65",
      "score": 0.6400308609008789
    }
  ],
  "3154": [
    {
      "answer": "the member state cannot enforce conflicting laws, and a citizen may rely on the Directive in such an action (so called \"vertical\" direct effect)",
      "score": 0.7961218953132629
    }
  ],
  "3155": [
    {
      "answer": "Directive 73/173/EEC on packaging and labelling solvents",
      "score": 0.8926531672477722
    }
  ],
  "3156": [],
  "3157": [
    {
      "answer": "a citizen or company can invoke a Directive, not just in a dispute with a public authority, but in a dispute with another citizen or company.",
      "score": 0.7467746734619141
    }
  ],
  "3158": [
    {
      "answer": "Swedex GmbH & Co KG",
      "score": 0.6259138584136963
    },
    {
      "answer": "Swedex GmbH & Co KG",
      "score": 0.9122123122215271
    }
  ],
  "3159": [
    {
      "answer": "national courts",
      "score": 0.6680237650871277
    },
    {
      "answer": "Court of Justice",
      "score": 0.6394342184066772
    },
    {
      "answer": "Court of Justice",
      "score": 0.7365671992301941
    },
    {
      "answer": "Court of Justice",
      "score": 0.7072646617889404
    }
  ],
  "3160": [
    {
      "answer": "incorporations would only be nullified for a fixed list of reasons",
      "score": 0.9343484044075012
    }
  ],
  "3161": [
    {
      "answer": "set up an insurance fund for employees to claim unpaid wages",
      "score": 0.9861289858818054
    }
  ],
  "3162": [
    {
      "answer": "6 million Lira",
      "score": 0.9884052276611328
    }
  ],
  "3163": [
    {
      "answer": "Court of Justice",
      "score": 0.5818849802017212
    },
    {
      "answer": "Court of Justice",
      "score": 0.6038092374801636
    },
    {
      "answer": "Court of Justice",
      "score": 0.7927538752555847
    }
  ],
  "3164": [
    {
      "answer": "incorporations",
      "score": 0.9418968558311462
    }
  ],
  "3165": [
    {
      "answer": "the duty of interpretation cannot contradict plain words in a national statute",
      "score": 0.7024292945861816
    }
  ],
  "3166": [
    {
      "answer": "set up an insurance fund for employees to claim unpaid wages",
      "score": 0.9379777312278748
    }
  ],
  "3167": [
    {
      "answer": "6 million Lira",
      "score": 0.9782757759094238
    }
  ],
  "3168": [
    {
      "answer": "European Court of Justice",
      "score": 0.9968686103820801
    }
  ],
  "3169": [
    {
      "answer": "fundamental rights (see human rights)",
      "score": 0.8035351037979126
    },
    {
      "answer": "proportionality",
      "score": 0.8919991254806519
    },
    {
      "answer": "legal certainty",
      "score": 0.9416154623031616
    },
    {
      "answer": "equality before the law",
      "score": 0.9509677886962891
    },
    {
      "answer": "subsidiarity",
      "score": 0.8824177384376526
    }
  ],
  "3170": [
    {
      "answer": "European Court of Justice",
      "score": 0.9796420335769653
    }
  ],
  "3171": [
    {
      "answer": "public international law",
      "score": 0.9657398462295532
    },
    {
      "answer": "legal doctrines and principles present in the legal systems of European Union member states",
      "score": 0.9667027592658997
    }
  ],
  "3172": [
    {
      "answer": "proportionality",
      "score": 0.7223399877548218
    },
    {
      "answer": "legal certainty",
      "score": 0.8239266872406006
    },
    {
      "answer": "equality before the law",
      "score": 0.8315193057060242
    },
    {
      "answer": "subsidiarity",
      "score": 0.7416974902153015
    }
  ],
  "3173": [],
  "3174": [
    {
      "answer": "1950s",
      "score": 0.9907116293907166
    }
  ],
  "3175": [
    {
      "answer": "Article 5",
      "score": 0.9857581853866577
    }
  ],
  "3176": [
    {
      "answer": "least onerous",
      "score": 0.9964978098869324
    }
  ],
  "3177": [
    {
      "answer": "1950s",
      "score": 0.9829313158988953
    }
  ],
  "3178": [
    {
      "answer": "whether it was appropriate and necessary to achieve the objectives legitimately pursued",
      "score": 0.8442323207855225
    }
  ],
  "3179": [
    {
      "answer": "least onerous",
      "score": 0.9957859516143799
    }
  ],
  "3180": [
    {
      "answer": "Article 5",
      "score": 0.9343554973602295
    }
  ],
  "3181": [
    {
      "answer": "any action by the Community shall not go beyond what is necessary to achieve the objectives of this Treaty",
      "score": 0.9800018668174744
    }
  ],
  "3182": [
    {
      "answer": "1960s",
      "score": 0.9880687594413757
    }
  ],
  "3183": [
    {
      "answer": "legal certainty",
      "score": 0.7637763023376465
    },
    {
      "answer": "legal certainty",
      "score": 0.8110550045967102
    },
    {
      "answer": "legal certainty",
      "score": 0.7337400913238525
    },
    {
      "answer": "legal certainty",
      "score": 0.775943398475647
    }
  ],
  "3184": [
    {
      "answer": "proper legal basis",
      "score": 0.9871229529380798
    }
  ],
  "3185": [
    {
      "answer": "legal certainty",
      "score": 0.9718605875968933
    },
    {
      "answer": "good faith",
      "score": 0.9688295125961304
    },
    {
      "answer": "good faith",
      "score": 0.6014394164085388
    }
  ],
  "3186": [],
  "3187": [
    {
      "answer": "The concept of legal certainty",
      "score": 0.8421153426170349
    }
  ],
  "3188": [
    {
      "answer": "Ex post facto laws",
      "score": 0.6870341300964355
    }
  ],
  "3189": [
    {
      "answer": "proper legal basis",
      "score": 0.9860018491744995
    }
  ],
  "3190": [
    {
      "answer": "clearly understandable by those who are subject to the law",
      "score": 0.9549636840820312
    }
  ],
  "3191": [
    {
      "answer": "constitutional traditions",
      "score": 0.9952740669250488
    }
  ],
  "3192": [
    {
      "answer": "fundamental rights recognised and protected in the constitutions of member states",
      "score": 0.981986939907074
    }
  ],
  "3193": [
    {
      "answer": "late 60s",
      "score": 0.8294628858566284
    }
  ],
  "3194": [
    {
      "answer": "Fundamental rights",
      "score": 0.6619856357574463
    },
    {
      "answer": "fundamental rights",
      "score": 0.7554877996444702
    },
    {
      "answer": "fundamental rights",
      "score": 0.7903773188591003
    }
  ],
  "3195": [
    {
      "answer": "late 60s",
      "score": 0.7201611995697021
    }
  ],
  "3196": [
    {
      "answer": "international treaties for the protection of human rights on which the member states have collaborated or of which they are signatories, can supply guidelines which should be followed within the framework of Community law",
      "score": 0.8338698148727417
    }
  ],
  "3197": [],
  "3198": [
    {
      "answer": "member states",
      "score": 0.9381790161132812
    },
    {
      "answer": "European Convention on Human Rights",
      "score": 0.8170915842056274
    },
    {
      "answer": "European Court of Human Rights",
      "score": 0.6626890301704407
    },
    {
      "answer": "member states",
      "score": 0.6327645182609558
    }
  ],
  "3199": [
    {
      "answer": "1950",
      "score": 0.9935529232025146
    }
  ],
  "3200": [
    {
      "answer": "European Court of Human Rights",
      "score": 0.9788050651550293
    }
  ],
  "3201": [
    {
      "answer": "1999",
      "score": 0.9939437508583069
    }
  ],
  "3202": [],
  "3203": [
    {
      "answer": "European Union",
      "score": 0.7238863706588745
    },
    {
      "answer": "European Union",
      "score": 0.7290078401565552
    },
    {
      "answer": "European Union",
      "score": 0.761931300163269
    },
    {
      "answer": "European Union",
      "score": 0.7422874569892883
    },
    {
      "answer": "European Union",
      "score": 0.6780681610107422
    },
    {
      "answer": "European Union",
      "score": 0.7944552898406982
    },
    {
      "answer": "European Union",
      "score": 0.7659556269645691
    },
    {
      "answer": "European Union",
      "score": 0.7740774154663086
    },
    {
      "answer": "European Union",
      "score": 0.5705747008323669
    }
  ],
  "3204": [
    {
      "answer": "1950",
      "score": 0.995394766330719
    }
  ],
  "3205": [],
  "3206": [
    {
      "answer": "fundamental rights",
      "score": 0.6356534957885742
    },
    {
      "answer": "fundamental rights",
      "score": 0.7330604195594788
    },
    {
      "answer": "fundamental rights",
      "score": 0.6187663078308105
    }
  ],
  "3207": [
    {
      "answer": "2007",
      "score": 0.5599398612976074
    },
    {
      "answer": "7 December 2000",
      "score": 0.5673884153366089
    },
    {
      "answer": "2007",
      "score": 0.888811469078064
    }
  ],
  "3208": [
    {
      "answer": "Charter of Fundamental Rights of the European Union",
      "score": 0.943024754524231
    },
    {
      "answer": "Charter of Fundamental Rights of the European Union",
      "score": 0.9474185705184937
    }
  ],
  "3209": [
    {
      "answer": "European Union law",
      "score": 0.9934952259063721
    }
  ],
  "3210": [
    {
      "answer": "European Court of Justice",
      "score": 0.9933496713638306
    }
  ],
  "3211": [
    {
      "answer": "12 December 2007",
      "score": 0.9714174270629883
    }
  ],
  "3212": [
    {
      "answer": "Charter of Fundamental Rights of the European Union",
      "score": 0.8279685974121094
    },
    {
      "answer": "Charter of Fundamental Rights of the European Union",
      "score": 0.8002527952194214
    }
  ],
  "3213": [
    {
      "answer": "Charter of Fundamental Rights of the European Union",
      "score": 0.9265012741088867
    }
  ],
  "3214": [
    {
      "answer": "the Charter and the Convention",
      "score": 0.9017423987388611
    }
  ],
  "3215": [
    {
      "answer": "European Court of Justice",
      "score": 0.8818754553794861
    },
    {
      "answer": "European Court of Human Rights",
      "score": 0.9269375801086426
    }
  ],
  "3216": [
    {
      "answer": "1997 Treaty of Amsterdam",
      "score": 0.9765263795852661
    }
  ],
  "3217": [
    {
      "answer": "1997",
      "score": 0.9920418858528137
    }
  ],
  "3218": [
    {
      "answer": "1989",
      "score": 0.9860120415687561
    },
    {
      "answer": "1989",
      "score": 0.7497389316558838
    }
  ],
  "3219": [
    {
      "answer": "30",
      "score": 0.9926048517227173
    }
  ],
  "3220": [
    {
      "answer": "40",
      "score": 0.9882491827011108
    }
  ],
  "3221": [
    {
      "answer": "1997 Treaty of Amsterdam",
      "score": 0.9171097874641418
    }
  ],
  "3222": [
    {
      "answer": "1997",
      "score": 0.9862365126609802
    }
  ],
  "3223": [
    {
      "answer": "Social Chapter",
      "score": 0.9105721712112427
    }
  ],
  "3224": [
    {
      "answer": "30",
      "score": 0.9741033911705017
    }
  ],
  "3225": [
    {
      "answer": "40",
      "score": 0.9679574966430664
    }
  ],
  "3226": [
    {
      "answer": "11",
      "score": 0.9839679002761841
    }
  ],
  "3227": [
    {
      "answer": "UK",
      "score": 0.983866810798645
    },
    {
      "answer": "UK",
      "score": 0.8800423741340637
    },
    {
      "answer": "UK",
      "score": 0.8634006977081299
    }
  ],
  "3228": [
    {
      "answer": "Social Chapter",
      "score": 0.9377350807189941
    },
    {
      "answer": "Social Chapter",
      "score": 0.658484935760498
    }
  ],
  "3229": [
    {
      "answer": "1992",
      "score": 0.9638383388519287
    }
  ],
  "3230": [],
  "3231": [
    {
      "answer": "UK",
      "score": 0.9893741011619568
    },
    {
      "answer": "UK",
      "score": 0.8555871248245239
    },
    {
      "answer": "UK",
      "score": 0.8670087456703186
    }
  ],
  "3232": [
    {
      "answer": "UK",
      "score": 0.9781339764595032
    },
    {
      "answer": "UK",
      "score": 0.819845974445343
    },
    {
      "answer": "UK",
      "score": 0.8810455203056335
    }
  ],
  "3233": [
    {
      "answer": "UK",
      "score": 0.8764212131500244
    },
    {
      "answer": "UK",
      "score": 0.9300292134284973
    },
    {
      "answer": "UK",
      "score": 0.8189676403999329
    }
  ],
  "3234": [
    {
      "answer": "Social Chapter",
      "score": 0.8708954453468323
    },
    {
      "answer": "Social Chapter",
      "score": 0.5845493078231812
    }
  ],
  "3235": [
    {
      "answer": "election of the UK Labour Party to government in 1997",
      "score": 0.9666582345962524
    }
  ],
  "3236": [
    {
      "answer": "1997",
      "score": 0.9685801267623901
    },
    {
      "answer": "1997",
      "score": 0.8754686117172241
    },
    {
      "answer": "1997",
      "score": 0.9145951271057129
    }
  ],
  "3237": [
    {
      "answer": "Works Council Directive",
      "score": 0.98165363073349
    }
  ],
  "3238": [
    {
      "answer": "1996",
      "score": 0.9903573393821716
    }
  ],
  "3239": [
    {
      "answer": "workforce consultation in businesses",
      "score": 0.9922961592674255
    }
  ],
  "3240": [
    {
      "answer": "the UK formally subscribed to the Agreement on Social Policy",
      "score": 0.7777218222618103
    }
  ],
  "3241": [
    {
      "answer": "1997",
      "score": 0.8826346397399902
    },
    {
      "answer": "1997",
      "score": 0.7632333636283875
    },
    {
      "answer": "1997",
      "score": 0.8530157208442688
    }
  ],
  "3242": [
    {
      "answer": "1994 Works Council Directive",
      "score": 0.844970703125
    }
  ],
  "3243": [
    {
      "answer": "1996",
      "score": 0.99041348695755
    }
  ],
  "3244": [],
  "3245": [],
  "3246": [
    {
      "answer": "1951",
      "score": 0.9732843041419983
    }
  ],
  "3247": [
    {
      "answer": "cartels",
      "score": 0.9166982769966125
    }
  ],
  "3248": [
    {
      "answer": "article 66",
      "score": 0.8817256689071655
    }
  ],
  "3249": [
    {
      "answer": "1957",
      "score": 0.9720107316970825
    }
  ],
  "3250": [],
  "3251": [
    {
      "answer": "prevent Germany from re-establishing dominance in the production of coal and steel",
      "score": 0.8595871925354004
    }
  ],
  "3252": [],
  "3253": [
    {
      "answer": "mergers",
      "score": 0.864246129989624
    }
  ],
  "3254": [],
  "3255": [
    {
      "answer": "Article 101(1)",
      "score": 0.9608379602432251
    }
  ],
  "3256": [
    {
      "answer": "abuse of dominant position",
      "score": 0.9535320401191711
    }
  ],
  "3257": [
    {
      "answer": "Articles 106 and 107",
      "score": 0.8553113341331482
    }
  ],
  "3258": [
    {
      "answer": "Article 102",
      "score": 0.8752362728118896
    }
  ],
  "3259": [
    {
      "answer": "allows the European Council to regulations to govern mergers between firms",
      "score": 0.7219517230987549
    }
  ],
  "3260": [
    {
      "answer": "price discrimination and exclusive dealing",
      "score": 0.7717394828796387
    }
  ],
  "3261": [
    {
      "answer": "abuse of dominant position",
      "score": 0.8175575137138367
    }
  ],
  "3262": [
    {
      "answer": "Article 101(3)",
      "score": 0.7826260924339294
    },
    {
      "answer": "Articles 106 and 107",
      "score": 0.6630344986915588
    }
  ],
  "3263": [],
  "3264": [
    {
      "answer": "2007",
      "score": 0.9568661451339722
    }
  ],
  "3265": [
    {
      "answer": "Treaty of Rome 1957",
      "score": 0.8950557708740234
    }
  ],
  "3266": [
    {
      "answer": "consumer prices",
      "score": 0.9945942163467407
    }
  ],
  "3267": [
    {
      "answer": "free trade",
      "score": 0.9363687038421631
    }
  ],
  "3268": [
    {
      "answer": "Court of Justice",
      "score": 0.981830358505249
    }
  ],
  "3269": [
    {
      "answer": "social market economy",
      "score": 0.9589607119560242
    }
  ],
  "3270": [],
  "3271": [
    {
      "answer": "a free trade area had a tendency to give way to a customs union",
      "score": 0.8067811131477356
    }
  ],
  "3272": [
    {
      "answer": "free trade",
      "score": 0.6720823049545288
    }
  ],
  "3273": [
    {
      "answer": "Court of Justice",
      "score": 0.9902390837669373
    }
  ],
  "3274": [
    {
      "answer": "customs union",
      "score": 0.9472490549087524
    },
    {
      "answer": "the principle of non-discrimination",
      "score": 0.820091962814331
    }
  ],
  "3275": [
    {
      "answer": "parallel importers",
      "score": 0.9879297018051147
    }
  ],
  "3276": [
    {
      "answer": "private actors",
      "score": 0.9914860725402832
    }
  ],
  "3277": [
    {
      "answer": "Commission v France",
      "score": 0.9845346808433533
    }
  ],
  "3278": [
    {
      "answer": "protest that blocked heavy traffic passing over the A13, Brenner Autobahn, en route to Italy",
      "score": 0.8852742314338684
    }
  ],
  "3279": [
    {
      "answer": "fundamental human rights",
      "score": 0.6185793876647949
    }
  ],
  "3280": [
    {
      "answer": "Quantitative restrictions on imports",
      "score": 0.9831823110580444
    }
  ],
  "3281": [
    {
      "answer": "duties between member states are prohibited",
      "score": 0.7694019079208374
    }
  ],
  "3282": [
    {
      "answer": "Quantitative restrictions on imports and all measures having equivalent effect shall be prohibited between Member States",
      "score": 0.879807710647583
    }
  ],
  "3283": [
    {
      "answer": "Commission v France",
      "score": 0.9893128275871277
    }
  ],
  "3284": [
    {
      "answer": "25 per cent",
      "score": 0.9628645181655884
    },
    {
      "answer": "25 per cent",
      "score": 0.8687102198600769
    }
  ],
  "3285": [
    {
      "answer": "France",
      "score": 0.9961891770362854
    }
  ],
  "3286": [
    {
      "answer": "2003",
      "score": 0.984798014163971
    }
  ],
  "3287": [
    {
      "answer": "cocoa butter",
      "score": 0.9910142421722412
    }
  ],
  "3288": [
    {
      "answer": "motorcycles or mopeds pulling trailers",
      "score": 0.9394180178642273
    }
  ],
  "3289": [
    {
      "answer": "25 per cent",
      "score": 0.8097395300865173
    },
    {
      "answer": "25 per cent",
      "score": 0.8613731265068054
    }
  ],
  "3290": [
    {
      "answer": "France",
      "score": 0.9939716458320618
    }
  ],
  "3291": [
    {
      "answer": "the Court of Justice",
      "score": 0.684285581111908
    },
    {
      "answer": "Court of Justice",
      "score": 0.9768640398979187
    }
  ],
  "3292": [],
  "3293": [
    {
      "answer": "Keck and Mithouard",
      "score": 0.9772433638572693
    }
  ],
  "3294": [
    {
      "answer": "prevent cut throat competition",
      "score": 0.987341046333313
    }
  ],
  "3295": [
    {
      "answer": "Konsumentombudsmannen v De Agostini",
      "score": 0.9850475788116455
    }
  ],
  "3296": [
    {
      "answer": "Unfair Commercial Practices Directive",
      "score": 0.9891499280929565
    }
  ],
  "3297": [
    {
      "answer": "Keck and Mithouard",
      "score": 0.9741942286491394
    }
  ],
  "3298": [
    {
      "answer": "a total ban for advertising alcohol on the radio, TV and in magazines",
      "score": 0.8922036290168762
    }
  ],
  "3299": [
    {
      "answer": "to prevent cut throat competition",
      "score": 0.9335773587226868
    }
  ],
  "3300": [
    {
      "answer": "Konsumentombudsmannen v De Agostini",
      "score": 0.7726396322250366
    }
  ],
  "3301": [
    {
      "answer": "people to pursue their life goals in any country through free movement",
      "score": 0.9818124771118164
    }
  ],
  "3302": [
    {
      "answer": "European Community",
      "score": 0.9972630739212036
    }
  ],
  "3303": [
    {
      "answer": "citizenship",
      "score": 0.9852065443992615
    }
  ],
  "3304": [
    {
      "answer": "Steymann v Staatssecretaris van Justitie",
      "score": 0.7572857737541199
    },
    {
      "answer": "volunteered plumbing and household duties in the Bhagwan community",
      "score": 0.8596968054771423
    }
  ],
  "3305": [
    {
      "answer": "to stay",
      "score": 0.8521566390991211
    }
  ],
  "3306": [
    {
      "answer": "enable people to pursue their life goals in any country through free movement",
      "score": 0.9243841767311096
    }
  ],
  "3307": [
    {
      "answer": "free movement of workers",
      "score": 0.9610111117362976
    }
  ],
  "3308": [
    {
      "answer": "developing a more \"social\" Europe",
      "score": 0.9381759166717529
    }
  ],
  "3309": [
    {
      "answer": "people had rights to empower them to become economically and socially active",
      "score": 0.946388840675354
    }
  ],
  "3310": [
    {
      "answer": "stay, so long as there was at least an \"indirect quid pro quo\" for the work he did",
      "score": 0.742053210735321
    }
  ],
  "3311": [
    {
      "answer": "1 to 7",
      "score": 0.9212121963500977
    }
  ],
  "3312": [
    {
      "answer": "Jean-Marc Bosman",
      "score": 0.9886503219604492
    }
  ],
  "3313": [
    {
      "answer": "Gaelic",
      "score": 0.9874632358551025
    }
  ],
  "3314": [
    {
      "answer": "Hendrix v Employee Insurance Institute",
      "score": 0.7554170489311218
    }
  ],
  "3315": [
    {
      "answer": "3 and 14 hours a week",
      "score": 0.9121026992797852
    }
  ],
  "3316": [
    {
      "answer": "Free Movement of Workers Regulation articles 1 to 7",
      "score": 0.766453206539154
    }
  ],
  "3317": [],
  "3318": [
    {
      "answer": "Jean-Marc Bosman",
      "score": 0.9868857264518738
    }
  ],
  "3319": [
    {
      "answer": "residential qualifying periods",
      "score": 0.6753234267234802
    }
  ],
  "3320": [
    {
      "answer": "public policy, public security or public health",
      "score": 0.9833932518959045
    }
  ],
  "3321": [
    {
      "answer": "Citizenship of the EU",
      "score": 0.9841082096099854
    }
  ],
  "3322": [
    {
      "answer": "the number of social services",
      "score": 0.9386687278747559
    }
  ],
  "3323": [
    {
      "answer": "Commission v Austria",
      "score": 0.9974297285079956
    }
  ],
  "3324": [
    {
      "answer": "higher education",
      "score": 0.9889688491821289
    }
  ],
  "3325": [
    {
      "answer": "Citizenship of the EU",
      "score": 0.959607720375061
    }
  ],
  "3326": [
    {
      "answer": "the number of social services",
      "score": 0.8708332180976868
    }
  ],
  "3327": [
    {
      "answer": "Commission v Austria",
      "score": 0.9953448176383972
    }
  ],
  "3328": [
    {
      "answer": "higher education",
      "score": 0.9828351140022278
    }
  ],
  "3329": [
    {
      "answer": "Treaty on the Functioning of the European Union",
      "score": 0.992550253868103
    }
  ],
  "3330": [
    {
      "answer": "non-discriminatory",
      "score": 0.9902979731559753
    },
    {
      "answer": "justified by imperative requirements in the general interest",
      "score": 0.9779300689697266
    }
  ],
  "3331": [
    {
      "answer": "Reyners v Belgium",
      "score": 0.9890173673629761
    }
  ],
  "3332": [
    {
      "answer": "49",
      "score": 0.623867928981781
    },
    {
      "answer": "49",
      "score": 0.9612645506858826
    }
  ],
  "3333": [
    {
      "answer": "Commission v Italy",
      "score": 0.9857780337333679
    }
  ],
  "3334": [
    {
      "answer": "bargaining power",
      "score": 0.9888566732406616
    }
  ],
  "3335": [
    {
      "answer": "freedom of establishment",
      "score": 0.7988881468772888
    },
    {
      "answer": "freedom to provide services",
      "score": 0.8480195999145508
    }
  ],
  "3336": [
    {
      "answer": "All people or entities that engage in economic activity",
      "score": 0.930716335773468
    }
  ],
  "3337": [
    {
      "answer": "a member state government and a private party",
      "score": 0.9030526876449585
    }
  ],
  "3338": [
    {
      "answer": "not proven that this had any object or effect of limiting practitioners from entering the market",
      "score": 0.9223699569702148
    }
  ],
  "3339": [
    {
      "answer": "2006",
      "score": 0.9743091464042664
    }
  ],
  "3340": [
    {
      "answer": "toxic waste",
      "score": 0.9893210530281067
    }
  ],
  "3341": [
    {
      "answer": "October 2007",
      "score": 0.9908173084259033
    }
  ],
  "3342": [
    {
      "answer": "2005",
      "score": 0.9825050234794617
    }
  ],
  "3343": [
    {
      "answer": "2006",
      "score": 0.9478092789649963
    }
  ],
  "3344": [
    {
      "answer": "shipping toxic waste",
      "score": 0.9722287058830261
    }
  ],
  "3345": [
    {
      "answer": "draft intellectual property rights directive",
      "score": 0.8586351275444031
    }
  ],
  "3346": [
    {
      "answer": "October 2007",
      "score": 0.9919214844703674
    }
  ],
  "3347": [
    {
      "answer": "people who give services \"for remuneration\"",
      "score": 0.9600297212600708
    }
  ],
  "3348": [
    {
      "answer": "Dutch law said only people established in the Netherlands could give legal advice",
      "score": 0.9712411761283875
    }
  ],
  "3349": [
    {
      "answer": "narcotic drugs",
      "score": 0.9907914400100708
    }
  ],
  "3350": [
    {
      "answer": "treatment",
      "score": 0.9418385028839111
    }
  ],
  "3351": [
    {
      "answer": "secondary education",
      "score": 0.8216549158096313
    }
  ],
  "3352": [],
  "3353": [
    {
      "answer": "secondary education",
      "score": 0.9150736331939697
    }
  ],
  "3354": [
    {
      "answer": "treatment",
      "score": 0.9453351497650146
    }
  ],
  "3355": [
    {
      "answer": "hospital services",
      "score": 0.9881846308708191
    }
  ],
  "3356": [
    {
      "answer": "Daily Mail",
      "score": 0.9872119426727295
    }
  ],
  "3357": [
    {
      "answer": "UK law only required \u00a31",
      "score": 0.875124454498291
    }
  ],
  "3358": [
    {
      "answer": "UK law only required \u00a31 of capital to start a company",
      "score": 0.7228282690048218
    }
  ],
  "3359": [
    {
      "answer": "creditor protection",
      "score": 0.9658482074737549
    },
    {
      "answer": "labour rights to participate in work",
      "score": 0.9676844477653503
    },
    {
      "answer": "public interest in collecting taxes",
      "score": 0.9770779013633728
    }
  ],
  "3360": [
    {
      "answer": "\u00dcberseering BV v Nordic Construction GmbH",
      "score": 0.9851505160331726
    }
  ],
  "3361": [
    {
      "answer": "Court of Justice",
      "score": 0.9160477519035339
    }
  ],
  "3362": [
    {
      "answer": "the Daily Mail newspaper's parent company",
      "score": 0.8966905474662781
    }
  ],
  "3363": [
    {
      "answer": "rules on company seats were not yet harmonised",
      "score": 0.952190637588501
    }
  ],
  "3364": [
    {
      "answer": "\u00a31",
      "score": 0.9662292003631592
    }
  ],
  "3365": [
    {
      "answer": "\u00a31",
      "score": 0.954273521900177
    }
  ],
  "3366": [
    {
      "answer": "Amazonia",
      "score": 0.5566861033439636
    },
    {
      "answer": "Amazonia",
      "score": 0.851905882358551
    },
    {
      "answer": "Amazon Jungle",
      "score": 0.8924921751022339
    }
  ],
  "3367": [
    {
      "answer": "5,500,000",
      "score": 0.980758786201477
    }
  ],
  "3368": [
    {
      "answer": "nine",
      "score": 0.9917978048324585
    }
  ],
  "3369": [
    {
      "answer": "four",
      "score": 0.8867581486701965
    }
  ],
  "3370": [
    {
      "answer": "over half",
      "score": 0.9536278247833252
    }
  ],
  "3371": [
    {
      "answer": "Amazoneregenwoud",
      "score": 0.9328268766403198
    }
  ],
  "3372": [
    {
      "answer": "Amazon rainforest",
      "score": 0.9498180150985718
    }
  ],
  "3373": [
    {
      "answer": "Brazil",
      "score": 0.9830731153488159
    }
  ],
  "3374": [
    {
      "answer": "half",
      "score": 0.9836199283599854
    }
  ],
  "3375": [
    {
      "answer": "16,000",
      "score": 0.9902043342590332
    }
  ],
  "3376": [
    {
      "answer": "moist broadleaf",
      "score": 0.9924003481864929
    }
  ],
  "3377": [
    {
      "answer": "7,000,000",
      "score": 0.9711592793464661
    }
  ],
  "3378": [
    {
      "answer": "nine",
      "score": 0.9914692044258118
    }
  ],
  "3379": [
    {
      "answer": "Brazil",
      "score": 0.9947935938835144
    }
  ],
  "3380": [
    {
      "answer": "16,000",
      "score": 0.9378446340560913
    }
  ],
  "3381": [],
  "3382": [
    {
      "answer": "Amazon rainforest",
      "score": 0.9821684956550598
    }
  ],
  "3383": [
    {
      "answer": "Amazon basin of South America",
      "score": 0.7394504547119141
    }
  ],
  "3384": [
    {
      "answer": "territory",
      "score": 0.8475350737571716
    }
  ],
  "3385": [
    {
      "answer": "rainforests",
      "score": 0.9478569626808167
    }
  ],
  "3386": [
    {
      "answer": "wetter",
      "score": 0.9804341197013855
    }
  ],
  "3387": [
    {
      "answer": "Climate fluctuations",
      "score": 0.9918607473373413
    }
  ],
  "3388": [
    {
      "answer": "Oligocene",
      "score": 0.9870321750640869
    }
  ],
  "3389": [
    {
      "answer": "last glacial maximum",
      "score": 0.9819177985191345
    }
  ],
  "3390": [
    {
      "answer": "the rainforest still managed to thrive during these glacial periods",
      "score": 0.840969979763031
    }
  ],
  "3391": [
    {
      "answer": "extinction of the dinosaurs",
      "score": 0.9739781618118286
    },
    {
      "answer": "wetter climate",
      "score": 0.9277118444442749
    }
  ],
  "3392": [
    {
      "answer": "45\u00b0",
      "score": 0.954392671585083
    }
  ],
  "3393": [
    {
      "answer": "Climate fluctuations",
      "score": 0.9936903715133667
    }
  ],
  "3394": [
    {
      "answer": "Oligocene",
      "score": 0.992236316204071
    }
  ],
  "3395": [],
  "3396": [
    {
      "answer": "Cretaceous\u2013Paleogene extinction event",
      "score": 0.9373503923416138
    }
  ],
  "3397": [
    {
      "answer": "66",
      "score": 0.9140034914016724
    },
    {
      "answer": "34",
      "score": 0.8817429542541504
    }
  ],
  "3398": [
    {
      "answer": "Middle Miocene",
      "score": 0.84687340259552
    }
  ],
  "3399": [
    {
      "answer": "last glacial maximum",
      "score": 0.9906763434410095
    }
  ],
  "3400": [
    {
      "answer": "34",
      "score": 0.9924168586730957
    }
  ],
  "3401": [
    {
      "answer": "wetter",
      "score": 0.8987686038017273
    }
  ],
  "3402": [
    {
      "answer": "dinosaurs",
      "score": 0.9861353635787964
    }
  ],
  "3403": [
    {
      "answer": "rainforest",
      "score": 0.7798982262611389
    },
    {
      "answer": "rainforest",
      "score": 0.7900775671005249
    }
  ],
  "3404": [
    {
      "answer": "expand into the tropics",
      "score": 0.8114100098609924
    }
  ],
  "3405": [
    {
      "answer": "Oligocene",
      "score": 0.6605903506278992
    },
    {
      "answer": "last glacial maximum",
      "score": 0.8906185626983643
    }
  ],
  "3406": [
    {
      "answer": "the middle of the continent",
      "score": 0.8310253024101257
    }
  ],
  "3407": [
    {
      "answer": "the Atlantic",
      "score": 0.9779136180877686
    },
    {
      "answer": "the Atlantic",
      "score": 0.7518656849861145
    }
  ],
  "3408": [
    {
      "answer": "Solim\u00f5es Basin",
      "score": 0.9310266971588135
    }
  ],
  "3409": [
    {
      "answer": "5\u201310 million years",
      "score": 0.9785074591636658
    }
  ],
  "3410": [
    {
      "answer": "Atlantic",
      "score": 0.9614607095718384
    }
  ],
  "3411": [
    {
      "answer": "mid-Eocene",
      "score": 0.9852161407470703
    }
  ],
  "3412": [
    {
      "answer": "Atlantic",
      "score": 0.9912540316581726
    },
    {
      "answer": "Atlantic",
      "score": 0.9328950047492981
    }
  ],
  "3413": [
    {
      "answer": "Pacific",
      "score": 0.9939742684364319
    }
  ],
  "3414": [
    {
      "answer": "Amazonas Basin",
      "score": 0.9856860637664795
    }
  ],
  "3415": [
    {
      "answer": "Solim\u00f5es Basin",
      "score": 0.9736355543136597
    }
  ],
  "3416": [
    {
      "answer": "mid-Eocene",
      "score": 0.9913874268531799
    }
  ],
  "3417": [
    {
      "answer": "middle",
      "score": 0.9851222038269043
    }
  ],
  "3418": [
    {
      "answer": "Atlantic",
      "score": 0.9875122904777527
    },
    {
      "answer": "Atlantic",
      "score": 0.9213987588882446
    }
  ],
  "3419": [
    {
      "answer": "Pacific",
      "score": 0.9910101890563965
    }
  ],
  "3420": [
    {
      "answer": "Solim\u00f5es Basin",
      "score": 0.9537697434425354
    }
  ],
  "3421": [
    {
      "answer": "Purus Arch",
      "score": 0.995970606803894
    },
    {
      "answer": "Purus Arch",
      "score": 0.9645731449127197
    }
  ],
  "3422": [
    {
      "answer": "Atlantic",
      "score": 0.9902390241622925
    },
    {
      "answer": "Atlantic",
      "score": 0.9550716280937195
    }
  ],
  "3423": [
    {
      "answer": "Pacific",
      "score": 0.9972871541976929
    }
  ],
  "3424": [
    {
      "answer": "Solim\u00f5es Basin",
      "score": 0.9617403745651245
    }
  ],
  "3425": [
    {
      "answer": "Solim\u00f5es Basin",
      "score": 0.9471613168716431
    },
    {
      "answer": "Purus Arch",
      "score": 0.8013508319854736
    }
  ],
  "3426": [
    {
      "answer": "Last Glacial Maximum",
      "score": 0.9818028211593628
    }
  ],
  "3427": [
    {
      "answer": "rainfall in the basin during the LGM was lower than for the present",
      "score": 0.9775562882423401
    }
  ],
  "3428": [
    {
      "answer": "Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today",
      "score": 0.8906179666519165
    }
  ],
  "3429": [
    {
      "answer": "Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today.",
      "score": 0.7614986896514893
    }
  ],
  "3430": [
    {
      "answer": "both explanations are reasonably well supported by the available data",
      "score": 0.9200526475906372
    }
  ],
  "3431": [],
  "3432": [
    {
      "answer": "Last Glacial Maximum (LGM)",
      "score": 0.9414753913879395
    }
  ],
  "3433": [],
  "3434": [
    {
      "answer": "reduced moist tropical vegetation cover",
      "score": 0.9453703165054321
    }
  ],
  "3435": [],
  "3436": [],
  "3437": [],
  "3438": [
    {
      "answer": "open forest and grassland",
      "score": 0.9906361103057861
    }
  ],
  "3439": [
    {
      "answer": "the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin",
      "score": 0.9585913419723511
    }
  ],
  "3440": [],
  "3441": [
    {
      "answer": "rainfall",
      "score": 0.9802677631378174
    }
  ],
  "3442": [],
  "3443": [
    {
      "answer": "the rainforest",
      "score": 0.7091108560562134
    }
  ],
  "3444": [
    {
      "answer": "CALIPSO",
      "score": 0.9307769536972046
    }
  ],
  "3445": [
    {
      "answer": "182 million",
      "score": 0.9662795662879944
    }
  ],
  "3446": [
    {
      "answer": "1,600",
      "score": 0.9935789108276367
    }
  ],
  "3447": [
    {
      "answer": "Amazon",
      "score": 0.9618818163871765
    }
  ],
  "3448": [
    {
      "answer": "132",
      "score": 0.9923900961875916
    }
  ],
  "3449": [
    {
      "answer": "CALIPSO",
      "score": 0.9731334447860718
    }
  ],
  "3450": [
    {
      "answer": "182 million tons",
      "score": 0.9818441867828369
    }
  ],
  "3451": [
    {
      "answer": "27.7 million tons",
      "score": 0.9763213992118835
    }
  ],
  "3452": [
    {
      "answer": "132",
      "score": 0.9907920360565186
    }
  ],
  "3453": [
    {
      "answer": "43 million tons",
      "score": 0.9219362735748291
    }
  ],
  "3454": [
    {
      "answer": "CALIPSO",
      "score": 0.9916043877601624
    }
  ],
  "3455": [
    {
      "answer": "NASA",
      "score": 0.9854542016983032
    }
  ],
  "3456": [
    {
      "answer": "182 million tons",
      "score": 0.9814095497131348
    }
  ],
  "3457": [
    {
      "answer": "1,600",
      "score": 0.9924504160881042
    }
  ],
  "3458": [
    {
      "answer": "27.7",
      "score": 0.9921704530715942
    }
  ],
  "3459": [
    {
      "answer": "CALIPSO",
      "score": 0.9725143313407898
    }
  ],
  "3460": [
    {
      "answer": "182 million",
      "score": 0.9624082446098328
    }
  ],
  "3461": [
    {
      "answer": "1,600",
      "score": 0.9896559715270996
    }
  ],
  "3462": [
    {
      "answer": "182 million tons",
      "score": 0.9771007895469666
    }
  ],
  "3463": [
    {
      "answer": "Caribbean Sea",
      "score": 0.9835000038146973
    }
  ],
  "3464": [
    {
      "answer": "Amazonia: Man and Culture in a Counterfeit Paradise",
      "score": 0.8883683681488037
    }
  ],
  "3465": [
    {
      "answer": "0.2 inhabitants per square kilometre (0.52/sq mi)",
      "score": 0.824040412902832
    }
  ],
  "3466": [
    {
      "answer": "agriculture",
      "score": 0.6675528287887573
    },
    {
      "answer": "agriculture",
      "score": 0.9416165947914124
    }
  ],
  "3467": [
    {
      "answer": "anthropological",
      "score": 0.9836004376411438
    }
  ],
  "3468": [
    {
      "answer": "5 million",
      "score": 0.9896883964538574
    }
  ],
  "3469": [
    {
      "answer": "poor soil",
      "score": 0.9705829620361328
    }
  ],
  "3470": [
    {
      "answer": "Betty Meggers",
      "score": 0.9943362474441528
    }
  ],
  "3471": [
    {
      "answer": "0.2",
      "score": 0.987384021282196
    }
  ],
  "3472": [
    {
      "answer": "Amazonia: Man and Culture in a Counterfeit Paradise",
      "score": 0.9841558933258057
    }
  ],
  "3473": [
    {
      "answer": "Betty Meggers",
      "score": 0.9962325692176819
    }
  ],
  "3474": [
    {
      "answer": "Amazonia: Man and Culture in a Counterfeit Paradise",
      "score": 0.9900222420692444
    }
  ],
  "3475": [
    {
      "answer": "0.2",
      "score": 0.9813566207885742
    }
  ],
  "3476": [
    {
      "answer": "5 million",
      "score": 0.9882173538208008
    }
  ],
  "3477": [
    {
      "answer": "200,000",
      "score": 0.982041597366333
    }
  ],
  "3478": [
    {
      "answer": "Amazonia: Man and Culture in a Counterfeit Paradise",
      "score": 0.9464060664176941
    }
  ],
  "3479": [
    {
      "answer": "Amazon rainforest",
      "score": 0.9761354923248291
    }
  ],
  "3480": [
    {
      "answer": "Betty Meggers",
      "score": 0.9945610761642456
    }
  ],
  "3481": [
    {
      "answer": "Amazon rainforest",
      "score": 0.8304433226585388
    }
  ],
  "3482": [
    {
      "answer": "1980s",
      "score": 0.9959325194358826
    }
  ],
  "3483": [
    {
      "answer": "Francisco de Orellana",
      "score": 0.9944957494735718
    }
  ],
  "3484": [
    {
      "answer": "1540s",
      "score": 0.9909905195236206
    }
  ],
  "3485": [],
  "3486": [
    {
      "answer": "1970s",
      "score": 0.6521088480949402
    },
    {
      "answer": "1977",
      "score": 0.8978703618049622
    }
  ],
  "3487": [
    {
      "answer": "AD 0\u20131250",
      "score": 0.905029296875
    }
  ],
  "3488": [
    {
      "answer": "Francisco de Orellana",
      "score": 0.9944998621940613
    }
  ],
  "3489": [
    {
      "answer": "1542",
      "score": 0.9856875538825989
    }
  ],
  "3490": [
    {
      "answer": "AD 0\u20131250",
      "score": 0.9818761348724365
    }
  ],
  "3491": [
    {
      "answer": "Ondemar Dias",
      "score": 0.9945236444473267
    }
  ],
  "3492": [
    {
      "answer": "11,000",
      "score": 0.9805599451065063
    }
  ],
  "3493": [
    {
      "answer": "Francisco de Orellana",
      "score": 0.9684420824050903
    }
  ],
  "3494": [
    {
      "answer": "Francisco de Orellana",
      "score": 0.9601432681083679
    }
  ],
  "3495": [
    {
      "answer": "Amazon",
      "score": 0.7017881870269775
    },
    {
      "answer": "Amazon",
      "score": 0.779277503490448
    },
    {
      "answer": "Amazon",
      "score": 0.7082833647727966
    }
  ],
  "3496": [
    {
      "answer": "devastated",
      "score": 0.63765549659729
    }
  ],
  "3497": [
    {
      "answer": "11,000 years",
      "score": 0.9881055951118469
    }
  ],
  "3498": [
    {
      "answer": "black earth",
      "score": 0.9755337238311768
    }
  ],
  "3499": [
    {
      "answer": "large",
      "score": 0.967210590839386
    }
  ],
  "3500": [
    {
      "answer": "agriculture and silviculture",
      "score": 0.9899370074272156
    }
  ],
  "3501": [
    {
      "answer": "Xingu",
      "score": 0.9935674071311951
    }
  ],
  "3502": [
    {
      "answer": "Michael Heckenberger",
      "score": 0.9852577447891235
    },
    {
      "answer": "University of Florida",
      "score": 0.6417207717895508
    }
  ],
  "3503": [
    {
      "answer": "Terra preta",
      "score": 0.9822002649307251
    }
  ],
  "3504": [
    {
      "answer": "agriculture and silviculture",
      "score": 0.9900531768798828
    }
  ],
  "3505": [
    {
      "answer": "Xingu",
      "score": 0.9868371486663818
    }
  ],
  "3506": [
    {
      "answer": "Michael Heckenberger",
      "score": 0.9978553056716919
    }
  ],
  "3507": [
    {
      "answer": "roads",
      "score": 0.9786000847816467
    },
    {
      "answer": "bridges",
      "score": 0.9771199226379395
    },
    {
      "answer": "large plazas",
      "score": 0.9566551446914673
    }
  ],
  "3508": [
    {
      "answer": "Amazon forest",
      "score": 0.9786500930786133
    },
    {
      "answer": "Amazon forest",
      "score": 0.5468670129776001
    }
  ],
  "3509": [
    {
      "answer": "Terra preta",
      "score": 0.9577919244766235
    }
  ],
  "3510": [
    {
      "answer": "human management",
      "score": 0.9776706099510193
    }
  ],
  "3511": [
    {
      "answer": "Michael Heckenberger",
      "score": 0.997563898563385
    }
  ],
  "3512": [
    {
      "answer": "indigenous soil management",
      "score": 0.7112709879875183
    },
    {
      "answer": "human management",
      "score": 0.630824089050293
    }
  ],
  "3513": [
    {
      "answer": "2.5 million",
      "score": 0.9712912440299988
    }
  ],
  "3514": [
    {
      "answer": "One in five",
      "score": 0.9905309677124023
    },
    {
      "answer": "one in five",
      "score": 0.7020725011825562
    }
  ],
  "3515": [
    {
      "answer": "40,000",
      "score": 0.9858592748641968
    }
  ],
  "3516": [
    {
      "answer": "2,200",
      "score": 0.9655291438102722
    }
  ],
  "3517": [
    {
      "answer": "96,660",
      "score": 0.8848769068717957
    },
    {
      "answer": "128,843",
      "score": 0.7902334928512573
    }
  ],
  "3518": [
    {
      "answer": "2.5 million",
      "score": 0.991468071937561
    }
  ],
  "3519": [
    {
      "answer": "2,000",
      "score": 0.7997238039970398
    }
  ],
  "3520": [
    {
      "answer": "40,000",
      "score": 0.9835290312767029
    }
  ],
  "3521": [
    {
      "answer": "378",
      "score": 0.9855958223342896
    }
  ],
  "3522": [
    {
      "answer": "1,294",
      "score": 0.6440992951393127
    }
  ],
  "3523": [],
  "3524": [
    {
      "answer": "rainforests of the Amazon",
      "score": 0.9804424047470093
    }
  ],
  "3525": [
    {
      "answer": "Brazil",
      "score": 0.987305223941803
    }
  ],
  "3526": [
    {
      "answer": "378",
      "score": 0.9892578721046448
    }
  ],
  "3527": [
    {
      "answer": "a quarter square kilometer",
      "score": 0.6653023958206177
    },
    {
      "answer": "62",
      "score": 0.6216110587120056
    }
  ],
  "3528": [
    {
      "answer": "16,000",
      "score": 0.978813648223877
    }
  ],
  "3529": [
    {
      "answer": "90,790",
      "score": 0.9871360659599304
    }
  ],
  "3530": [
    {
      "answer": "356 \u00b1 47 tonnes per hectare",
      "score": 0.9718990325927734
    }
  ],
  "3531": [
    {
      "answer": "438,000",
      "score": 0.9888842105865479
    }
  ],
  "3532": [
    {
      "answer": "the highest on Earth",
      "score": 0.744573712348938
    }
  ],
  "3533": [
    {
      "answer": "1,100",
      "score": 0.9722763895988464
    }
  ],
  "3534": [
    {
      "answer": "90,790",
      "score": 0.9798001050949097
    }
  ],
  "3535": [
    {
      "answer": "356 \u00b1 47 tonnes",
      "score": 0.9747046232223511
    }
  ],
  "3536": [
    {
      "answer": "438,000",
      "score": 0.9215384721755981
    },
    {
      "answer": "16,000",
      "score": 0.5354186296463013
    }
  ],
  "3537": [
    {
      "answer": "plant species",
      "score": 0.9399968981742859
    }
  ],
  "3538": [],
  "3539": [
    {
      "answer": "1,100",
      "score": 0.8052367568016052
    }
  ],
  "3540": [
    {
      "answer": "plants",
      "score": 0.9062585234642029
    }
  ],
  "3541": [
    {
      "answer": "many more",
      "score": 0.6918951272964478
    }
  ],
  "3542": [
    {
      "answer": "electric eels",
      "score": 0.9949918985366821
    }
  ],
  "3543": [
    {
      "answer": "black caiman",
      "score": 0.9630696177482605
    }
  ],
  "3544": [
    {
      "answer": "piranha",
      "score": 0.9764730930328369
    }
  ],
  "3545": [
    {
      "answer": "lipophilic alkaloid toxins",
      "score": 0.9677871465682983
    }
  ],
  "3546": [
    {
      "answer": "Vampire",
      "score": 0.9889352917671204
    }
  ],
  "3547": [
    {
      "answer": "electric eels",
      "score": 0.994307279586792
    }
  ],
  "3548": [
    {
      "answer": "anaconda",
      "score": 0.6798346042633057
    }
  ],
  "3549": [
    {
      "answer": "bite and injure humans",
      "score": 0.9682666063308716
    }
  ],
  "3550": [
    {
      "answer": "alkaloid toxins",
      "score": 0.9839313626289368
    }
  ],
  "3551": [
    {
      "answer": "rabies virus",
      "score": 0.984124481678009
    }
  ],
  "3552": [
    {
      "answer": "slash and burn",
      "score": 0.869800329208374
    }
  ],
  "3553": [
    {
      "answer": "1960s",
      "score": 0.9929049611091614
    }
  ],
  "3554": [
    {
      "answer": "slash and burn",
      "score": 0.9942545890808105
    }
  ],
  "3555": [
    {
      "answer": "loss of soil fertility",
      "score": 0.9498404264450073
    },
    {
      "answer": "weed invasion",
      "score": 0.9532022476196289
    }
  ],
  "3556": [
    {
      "answer": "areas cleared of forest are visible to the naked eye from outer space",
      "score": 0.9115888476371765
    }
  ],
  "3557": [],
  "3558": [
    {
      "answer": "1960s",
      "score": 0.986753523349762
    },
    {
      "answer": "1960s",
      "score": 0.6458598971366882
    }
  ],
  "3559": [
    {
      "answer": "slash and burn",
      "score": 0.9458786845207214
    }
  ],
  "3560": [
    {
      "answer": "soils",
      "score": 0.9886261820793152
    }
  ],
  "3561": [
    {
      "answer": "outer space",
      "score": 0.9978933930397034
    }
  ],
  "3562": [
    {
      "answer": "415,000",
      "score": 0.9765510559082031
    }
  ],
  "3563": [
    {
      "answer": "415,000",
      "score": 0.9634191393852234
    },
    {
      "answer": "587,000",
      "score": 0.8117181658744812
    }
  ],
  "3564": [
    {
      "answer": "pasture for cattle",
      "score": 0.9881556034088135
    }
  ],
  "3565": [
    {
      "answer": "second-largest",
      "score": 0.9751306176185608
    }
  ],
  "3566": [
    {
      "answer": "Seventy percent",
      "score": 0.9272043704986572
    },
    {
      "answer": "91%",
      "score": 0.7561845779418945
    }
  ],
  "3567": [
    {
      "answer": "1991",
      "score": 0.993438184261322
    },
    {
      "answer": "2000",
      "score": 0.9403389096260071
    }
  ],
  "3568": [
    {
      "answer": "Brazil",
      "score": 0.9677990078926086
    },
    {
      "answer": "Brazil",
      "score": 0.7754422426223755
    }
  ],
  "3569": [
    {
      "answer": "land deforested since 1970",
      "score": 0.5622583627700806
    },
    {
      "answer": "livestock pasture",
      "score": 0.948139488697052
    }
  ],
  "3570": [
    {
      "answer": "Leydimere Oliveira",
      "score": 0.9724981784820557
    }
  ],
  "3571": [
    {
      "answer": "soy",
      "score": 0.9878439903259277
    }
  ],
  "3572": [
    {
      "answer": "increased settlement and deforestation",
      "score": 0.9825064539909363
    }
  ],
  "3573": [
    {
      "answer": "8,646",
      "score": 0.9886659383773804
    }
  ],
  "3574": [
    {
      "answer": "18%",
      "score": 0.985700249671936
    }
  ],
  "3575": [
    {
      "answer": "declined significantly",
      "score": 0.9244658946990967
    }
  ],
  "3576": [
    {
      "answer": "soy",
      "score": 0.982943058013916
    }
  ],
  "3577": [
    {
      "answer": "highways",
      "score": 0.942013144493103
    }
  ],
  "3578": [
    {
      "answer": "2000 to 2005",
      "score": 0.9564608931541443
    }
  ],
  "3579": [
    {
      "answer": "2000 to 2005",
      "score": 0.9586538076400757
    }
  ],
  "3580": [
    {
      "answer": "soy farmers",
      "score": 0.6240050792694092
    }
  ],
  "3581": [
    {
      "answer": "loss of biodiversity",
      "score": 0.9042166471481323
    }
  ],
  "3582": [
    {
      "answer": "destruction of the forest",
      "score": 0.9825524091720581
    }
  ],
  "3583": [
    {
      "answer": "loss of biodiversity",
      "score": 0.8093616962432861
    },
    {
      "answer": "release of the carbon",
      "score": 0.750350296497345
    }
  ],
  "3584": [
    {
      "answer": "1.1 \u00d7 1011",
      "score": 0.9940393567085266
    }
  ],
  "3585": [
    {
      "answer": "1.1 \u00d7 1011",
      "score": 0.9941089749336243
    }
  ],
  "3586": [
    {
      "answer": "global warming",
      "score": 0.5502324104309082
    }
  ],
  "3587": [
    {
      "answer": "global warming",
      "score": 0.9915958046913147
    }
  ],
  "3588": [
    {
      "answer": "10%",
      "score": 0.9120452404022217
    },
    {
      "answer": "10%",
      "score": 0.9362313747406006
    }
  ],
  "3589": [
    {
      "answer": "1.1 \u00d7 1011",
      "score": 0.9853751063346863
    }
  ],
  "3590": [
    {
      "answer": "reduced rainfall",
      "score": 0.9782864451408386
    },
    {
      "answer": "increased temperatures",
      "score": 0.9741566181182861
    }
  ],
  "3591": [
    {
      "answer": "greenhouse gas",
      "score": 0.994154155254364
    }
  ],
  "3592": [
    {
      "answer": "2100",
      "score": 0.9961775541305542
    }
  ],
  "3593": [
    {
      "answer": "2100",
      "score": 0.8827289938926697
    },
    {
      "answer": "21st century",
      "score": 0.667189359664917
    }
  ],
  "3594": [
    {
      "answer": "climate change",
      "score": 0.6764749884605408
    },
    {
      "answer": "climate change",
      "score": 0.6173433065414429
    },
    {
      "answer": "climate change",
      "score": 0.8726693987846375
    }
  ],
  "3595": [
    {
      "answer": "Amazon rainforest",
      "score": 0.9760441184043884
    }
  ],
  "3596": [
    {
      "answer": "rainforest",
      "score": 0.9652027487754822
    }
  ],
  "3597": [
    {
      "answer": "climate change",
      "score": 0.9019156694412231
    },
    {
      "answer": "deforestation",
      "score": 0.8019053339958191
    }
  ],
  "3598": [],
  "3599": [
    {
      "answer": "Amazon basin climate change",
      "score": 0.8871737718582153
    }
  ],
  "3600": [
    {
      "answer": "indigenous",
      "score": 0.963898241519928
    }
  ],
  "3601": [
    {
      "answer": "community-based",
      "score": 0.9795279502868652
    }
  ],
  "3602": [
    {
      "answer": "deforestation",
      "score": 0.9910731911659241
    },
    {
      "answer": "ecocide",
      "score": 0.9873431921005249
    }
  ],
  "3603": [
    {
      "answer": "Urarina",
      "score": 0.9736170768737793
    }
  ],
  "3604": [
    {
      "answer": "Peruvian",
      "score": 0.8425368070602417
    },
    {
      "answer": "Urarina",
      "score": 0.5691837072372437
    }
  ],
  "3605": [
    {
      "answer": "deforestation",
      "score": 0.9888251423835754
    },
    {
      "answer": "ecocide",
      "score": 0.8888289928436279
    }
  ],
  "3606": [],
  "3607": [
    {
      "answer": "Urarina",
      "score": 0.9794237613677979
    }
  ],
  "3608": [
    {
      "answer": "lowland South American",
      "score": 0.9841164350509644
    }
  ],
  "3609": [
    {
      "answer": "community-based",
      "score": 0.9844521284103394
    }
  ],
  "3610": [
    {
      "answer": "remote sensing",
      "score": 0.659293532371521
    },
    {
      "answer": "GPS",
      "score": 0.8297436833381653
    }
  ],
  "3611": [
    {
      "answer": "Trio",
      "score": 0.9892277717590332
    }
  ],
  "3612": [
    {
      "answer": "Suriname",
      "score": 0.991184651851654
    }
  ],
  "3613": [
    {
      "answer": "map out their ancestral lands",
      "score": 0.9474196434020996
    }
  ],
  "3614": [
    {
      "answer": "to protect their tribal lands from commercial interests",
      "score": 0.9712376594543457
    }
  ],
  "3615": [],
  "3616": [
    {
      "answer": "not have clearly defined boundaries",
      "score": 0.973576009273529
    }
  ],
  "3617": [
    {
      "answer": "tribes",
      "score": 0.8729681968688965
    }
  ],
  "3618": [],
  "3619": [
    {
      "answer": "Trio Tribe",
      "score": 0.9722402095794678
    }
  ],
  "3620": [
    {
      "answer": "tree growth",
      "score": 0.9859591722488403
    }
  ],
  "3621": [
    {
      "answer": "carbon",
      "score": 0.9839735627174377
    }
  ],
  "3622": [
    {
      "answer": "Tatiana Kuplich",
      "score": 0.9967687129974365
    }
  ],
  "3623": [
    {
      "answer": "2006",
      "score": 0.9835793375968933
    }
  ],
  "3624": [
    {
      "answer": "Synthetic aperture radar",
      "score": 0.9827522039413452
    }
  ],
  "3625": [
    {
      "answer": "To accurately map the Amazon's biomass and subsequent carbon related emissions",
      "score": 0.889005184173584
    }
  ],
  "3626": [
    {
      "answer": "Tatiana Kuplich",
      "score": 0.9967063665390015
    }
  ],
  "3627": [
    {
      "answer": "Synthetic aperture radar",
      "score": 0.9840500354766846
    }
  ],
  "3628": [],
  "3629": [
    {
      "answer": "mature forest",
      "score": 0.9073224067687988
    },
    {
      "answer": "regenerating forest",
      "score": 0.9282358884811401
    },
    {
      "answer": "regenerating forest",
      "score": 0.8911265134811401
    },
    {
      "answer": "regenerating forest",
      "score": 0.8450749516487122
    }
  ],
  "3630": [
    {
      "answer": "2005",
      "score": 0.9840716123580933
    }
  ],
  "3631": [
    {
      "answer": "Woods Hole Research Center",
      "score": 0.9888064861297607
    }
  ],
  "3632": [
    {
      "answer": "National Institute of Amazonian Research",
      "score": 0.9906581044197083
    }
  ],
  "3633": [
    {
      "answer": "deforestation",
      "score": 0.9763917326927185
    }
  ],
  "3634": [
    {
      "answer": "savanna",
      "score": 0.992074728012085
    }
  ],
  "3635": [
    {
      "answer": "2005",
      "score": 0.9863196015357971
    }
  ],
  "3636": [
    {
      "answer": "Woods Hole Research Center",
      "score": 0.9709850549697876
    }
  ],
  "3637": [
    {
      "answer": "tipping point",
      "score": 0.9390170574188232
    }
  ],
  "3638": [],
  "3639": [
    {
      "answer": "savanna",
      "score": 0.9364015460014343
    },
    {
      "answer": "desert",
      "score": 0.9615724682807922
    }
  ],
  "3640": [
    {
      "answer": "2010",
      "score": 0.973476767539978
    },
    {
      "answer": "2010",
      "score": 0.8779156804084778
    },
    {
      "answer": "2010",
      "score": 0.8927439451217651
    }
  ],
  "3641": [
    {
      "answer": "1,160,000",
      "score": 0.9872428178787231
    }
  ],
  "3642": [
    {
      "answer": "1,160,000 square miles",
      "score": 0.9552423357963562
    }
  ],
  "3643": [
    {
      "answer": "2010",
      "score": 0.8856370449066162
    },
    {
      "answer": "2005",
      "score": 0.5189886689186096
    },
    {
      "answer": "2010",
      "score": 0.9132705926895142
    },
    {
      "answer": "2010",
      "score": 0.8937661051750183
    }
  ],
  "3644": [
    {
      "answer": "1.5",
      "score": 0.990616500377655
    }
  ],
  "3645": [
    {
      "answer": "2010",
      "score": 0.7499992251396179
    }
  ],
  "3646": [
    {
      "answer": "8",
      "score": 0.9882239103317261
    }
  ],
  "3647": [
    {
      "answer": "vegetation died off",
      "score": 0.8494369387626648
    }
  ],
  "3648": [
    {
      "answer": "1.5 gigatons",
      "score": 0.9177064895629883
    }
  ],
  "3649": [],
  "3650": [],
  "3651": [
    {
      "answer": "cilia",
      "score": 0.6871983408927917
    }
  ],
  "3652": [
    {
      "answer": "water flow",
      "score": 0.9938827753067017
    }
  ],
  "3653": [
    {
      "answer": "1.5 m",
      "score": 0.9723306894302368
    }
  ],
  "3654": [
    {
      "answer": "combs",
      "score": 0.8843242526054382
    }
  ],
  "3655": [
    {
      "answer": "comb jellies",
      "score": 0.6707689762115479
    }
  ],
  "3656": [
    {
      "answer": "1.5 m",
      "score": 0.9705122113227844
    }
  ],
  "3657": [
    {
      "answer": "water flow through the body cavity",
      "score": 0.9851894378662109
    }
  ],
  "3658": [
    {
      "answer": "\u03ba\u03c4\u03b5\u03af\u03c2 kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'",
      "score": 0.6484008431434631
    }
  ],
  "3659": [
    {
      "answer": "marine waters",
      "score": 0.9705922603607178
    }
  ],
  "3660": [
    {
      "answer": "comb jellies",
      "score": 0.9579577445983887
    }
  ],
  "3661": [
    {
      "answer": "combs",
      "score": 0.8910690546035767
    }
  ],
  "3662": [
    {
      "answer": "swimming",
      "score": 0.9456883072853088
    }
  ],
  "3663": [
    {
      "answer": "separate phyla",
      "score": 0.9676614999771118
    }
  ],
  "3664": [],
  "3665": [
    {
      "answer": "100\u2013150",
      "score": 0.9848281741142273
    }
  ],
  "3666": [
    {
      "answer": "tentilla",
      "score": 0.9746478796005249
    }
  ],
  "3667": [
    {
      "answer": "ten times their own weight",
      "score": 0.9324691891670227
    }
  ],
  "3668": [
    {
      "answer": "tentacles",
      "score": 0.9575640559196472
    }
  ],
  "3669": [],
  "3670": [
    {
      "answer": "ten times their own weight",
      "score": 0.9472305178642273
    }
  ],
  "3671": [
    {
      "answer": "tentilla",
      "score": 0.9807079434394836
    }
  ],
  "3672": [
    {
      "answer": "huge mouths armed with groups of large, stiffened cilia",
      "score": 0.7311617732048035
    }
  ],
  "3673": [
    {
      "answer": "colloblasts",
      "score": 0.8926176428794861
    }
  ],
  "3674": [
    {
      "answer": "100\u2013150",
      "score": 0.9693667888641357
    }
  ],
  "3675": [
    {
      "answer": "predators",
      "score": 0.8774749636650085
    }
  ],
  "3676": [
    {
      "answer": "ten times their own weight",
      "score": 0.9052357077598572
    }
  ],
  "3677": [
    {
      "answer": "100\u2013150",
      "score": 0.9705389738082886
    }
  ],
  "3678": [
    {
      "answer": "25",
      "score": 0.9917312264442444
    }
  ],
  "3679": [
    {
      "answer": "live as parasites",
      "score": 0.9073116183280945
    }
  ],
  "3680": [
    {
      "answer": "a single animal can produce both eggs and sperm",
      "score": 0.9430416822433472
    }
  ],
  "3681": [
    {
      "answer": "produce both eggs and sperm at the same time",
      "score": 0.9876152873039246
    }
  ],
  "3682": [
    {
      "answer": "sequential",
      "score": 0.9826667904853821
    }
  ],
  "3683": [
    {
      "answer": "platyctenids",
      "score": 0.9791334271430969
    }
  ],
  "3684": [
    {
      "answer": "hermaphroditism and early reproduction",
      "score": 0.9705905914306641
    }
  ],
  "3685": [
    {
      "answer": "a single animal can produce both eggs and sperm",
      "score": 0.9545844197273254
    }
  ],
  "3686": [
    {
      "answer": "can produce both eggs and sperm at the same time",
      "score": 0.9617493748664856
    }
  ],
  "3687": [
    {
      "answer": "eggs and sperm mature at different times",
      "score": 0.9712395668029785
    }
  ],
  "3688": [
    {
      "answer": "platyctenids",
      "score": 0.9759751558303833
    }
  ],
  "3689": [
    {
      "answer": "beroids",
      "score": 0.9932918548583984
    }
  ],
  "3690": [
    {
      "answer": "Fertilization is generally external",
      "score": 0.9399421811103821
    }
  ],
  "3691": [
    {
      "answer": "Fertilization is generally external",
      "score": 0.9849909543991089
    }
  ],
  "3692": [
    {
      "answer": "metamorphose into the adult form",
      "score": 0.8442813158035278
    }
  ],
  "3693": [
    {
      "answer": "reproduction",
      "score": 0.9587193131446838
    }
  ],
  "3694": [
    {
      "answer": "explosive rate",
      "score": 0.9326017498970032
    }
  ],
  "3695": [
    {
      "answer": "other ctenophores",
      "score": 0.9635103940963745
    }
  ],
  "3696": [
    {
      "answer": "ctenophore",
      "score": 0.7274794578552246
    },
    {
      "answer": "Mnemiopsis",
      "score": 0.8426529169082642
    }
  ],
  "3697": [
    {
      "answer": "fish larvae",
      "score": 0.9538179039955139
    }
  ],
  "3698": [
    {
      "answer": "coastal locations",
      "score": 0.8886497020721436
    }
  ],
  "3699": [
    {
      "answer": "coastal locations",
      "score": 0.8465685248374939
    }
  ],
  "3700": [
    {
      "answer": "planktonic plants",
      "score": 0.9827672839164734
    }
  ],
  "3701": [
    {
      "answer": "Mnemiopsis",
      "score": 0.949400782585144
    }
  ],
  "3702": [
    {
      "answer": "causing fish stocks to collapse",
      "score": 0.9669429659843445
    }
  ],
  "3703": [
    {
      "answer": "The later accidental introduction of Beroe",
      "score": 0.9242862462997437
    }
  ],
  "3704": [
    {
      "answer": "summer",
      "score": 0.9847972989082336
    }
  ],
  "3705": [],
  "3706": [
    {
      "answer": "uncommon and difficult to find",
      "score": 0.7009283900260925
    }
  ],
  "3707": [
    {
      "answer": "Black Sea",
      "score": 0.986799955368042
    }
  ],
  "3708": [
    {
      "answer": "phytoplankton",
      "score": 0.5417371392250061
    }
  ],
  "3709": [
    {
      "answer": "66 million years ago",
      "score": 0.9878783226013184
    }
  ],
  "3710": [
    {
      "answer": "monophyletic",
      "score": 0.9853782653808594
    }
  ],
  "3711": [
    {
      "answer": "515 million years ago",
      "score": 0.9255669116973877
    }
  ],
  "3712": [],
  "3713": [
    {
      "answer": "515 million years ago",
      "score": 0.9064943790435791
    }
  ],
  "3714": [
    {
      "answer": "Cretaceous\u2013Paleogene extinction",
      "score": 0.9896769523620605
    }
  ],
  "3715": [
    {
      "answer": "not monophyletic",
      "score": 0.8827544450759888
    }
  ],
  "3716": [
    {
      "answer": "tentacles",
      "score": 0.7335397005081177
    },
    {
      "answer": "comb-rows",
      "score": 0.8460320830345154
    }
  ],
  "3717": [
    {
      "answer": "early Cambrian",
      "score": 0.8702114820480347
    },
    {
      "answer": "515 million years ago",
      "score": 0.7782278060913086
    }
  ],
  "3718": [
    {
      "answer": "cnidarians and bilaterians",
      "score": 0.8741726875305176
    }
  ],
  "3719": [
    {
      "answer": "cydippid-like",
      "score": 0.8937563896179199
    }
  ],
  "3720": [
    {
      "answer": "Cretaceous\u2013Paleogene extinction event 66 million years ago",
      "score": 0.9650185704231262
    }
  ],
  "3721": [
    {
      "answer": "ctenophores",
      "score": 0.7823479771614075
    }
  ],
  "3722": [
    {
      "answer": "cnidarians",
      "score": 0.9256842136383057
    }
  ],
  "3723": [
    {
      "answer": "colloblasts",
      "score": 0.9572997689247131
    }
  ],
  "3724": [
    {
      "answer": "bilaterians",
      "score": 0.9954541921615601
    }
  ],
  "3725": [
    {
      "answer": "Ctenophores",
      "score": 0.9527794122695923
    }
  ],
  "3726": [
    {
      "answer": "colloblasts",
      "score": 0.989861249923706
    }
  ],
  "3727": [],
  "3728": [
    {
      "answer": "colloblasts",
      "score": 0.9611061811447144
    }
  ],
  "3729": [
    {
      "answer": "colloblasts",
      "score": 0.9902605414390564
    }
  ],
  "3730": [
    {
      "answer": "ctenophores",
      "score": 0.9488825798034668
    },
    {
      "answer": "cnidarians",
      "score": 0.9259989857673645
    }
  ],
  "3731": [
    {
      "answer": "bilaterians",
      "score": 0.9951169490814209
    }
  ],
  "3732": [
    {
      "answer": "inter-cell connections",
      "score": 0.9809975624084473
    }
  ],
  "3733": [
    {
      "answer": "sensory",
      "score": 0.9870663285255432
    }
  ],
  "3734": [
    {
      "answer": "colloblasts",
      "score": 0.9763863682746887
    }
  ],
  "3735": [
    {
      "answer": "prey",
      "score": 0.9803669452667236
    }
  ],
  "3736": [
    {
      "answer": "colloblasts",
      "score": 0.9886857271194458
    }
  ],
  "3737": [
    {
      "answer": "mesoglea",
      "score": 0.9899789094924927
    }
  ],
  "3738": [
    {
      "answer": "diploblastic",
      "score": 0.985620379447937
    },
    {
      "answer": "diploblastic",
      "score": 0.8098064661026001
    }
  ],
  "3739": [
    {
      "answer": "cnidarians",
      "score": 0.6161124110221863
    },
    {
      "answer": "ctenophores",
      "score": 0.8287996053695679
    }
  ],
  "3740": [
    {
      "answer": "sponges",
      "score": 0.9231154918670654
    }
  ],
  "3741": [
    {
      "answer": "intermediate jelly-like layer",
      "score": 0.9125219583511353
    }
  ],
  "3742": [
    {
      "answer": "mesoglea",
      "score": 0.624816358089447
    },
    {
      "answer": "middle cell layer",
      "score": 0.8038051128387451
    }
  ],
  "3743": [
    {
      "answer": "diploblastic",
      "score": 0.9454465508460999
    },
    {
      "answer": "diploblastic",
      "score": 0.6535400152206421
    }
  ],
  "3744": [
    {
      "answer": "diploblastic",
      "score": 0.6091967225074768
    }
  ],
  "3745": [
    {
      "answer": "three",
      "score": 0.9722765684127808
    }
  ],
  "3746": [
    {
      "answer": "cilia",
      "score": 0.7039931416511536
    }
  ],
  "3747": [
    {
      "answer": "main method of locomotion",
      "score": 0.8252260684967041
    }
  ],
  "3748": [
    {
      "answer": "ctenes",
      "score": 0.9917507767677307
    }
  ],
  "3749": [
    {
      "answer": "comb-bearing",
      "score": 0.9839078187942505
    }
  ],
  "3750": [
    {
      "answer": "eight",
      "score": 0.973039984703064
    }
  ],
  "3751": [
    {
      "answer": "1 millimeter",
      "score": 0.87940514087677
    },
    {
      "answer": "1.5 meters",
      "score": 0.8805248737335205
    }
  ],
  "3752": [
    {
      "answer": "locomotion",
      "score": 0.9734289646148682
    }
  ],
  "3753": [],
  "3754": [
    {
      "answer": "non-colonial",
      "score": 0.9562623500823975
    }
  ],
  "3755": [
    {
      "answer": "cydippid",
      "score": 0.8783913254737854
    },
    {
      "answer": "Pleurobrachia",
      "score": 0.9337763786315918
    }
  ],
  "3756": [
    {
      "answer": "oceanic species",
      "score": 0.9735764861106873
    }
  ],
  "3757": [
    {
      "answer": "Coastal species need to be tough enough to withstand waves and swirling sediment particles",
      "score": 0.9021605253219604
    }
  ],
  "3758": [
    {
      "answer": "Pleurobrachia",
      "score": 0.8184292912483215
    },
    {
      "answer": "cydippid Pleurobrachia",
      "score": 0.6418372988700867
    }
  ],
  "3759": [
    {
      "answer": "Coastal species",
      "score": 0.8927255868911743
    },
    {
      "answer": "oceanic species",
      "score": 0.7290174961090088
    }
  ],
  "3760": [
    {
      "answer": "Coastal",
      "score": 0.9885127544403076
    },
    {
      "answer": "coastal",
      "score": 0.5959101319313049
    }
  ],
  "3761": [
    {
      "answer": "waves",
      "score": 0.949364423751831
    }
  ],
  "3762": [
    {
      "answer": "Coastal species",
      "score": 0.8920522928237915
    }
  ],
  "3763": [
    {
      "answer": "three",
      "score": 0.9692113995552063
    }
  ],
  "3764": [
    {
      "answer": "epithelium",
      "score": 0.9513731598854065
    }
  ],
  "3765": [
    {
      "answer": "bioluminescence",
      "score": 0.9890833497047424
    }
  ],
  "3766": [
    {
      "answer": "pharynx",
      "score": 0.9606373310089111
    }
  ],
  "3767": [
    {
      "answer": "a system of internal canals",
      "score": 0.828342080116272
    }
  ],
  "3768": [
    {
      "answer": "mouth and pharynx",
      "score": 0.9548662900924683
    }
  ],
  "3769": [
    {
      "answer": "epithelium",
      "score": 0.8781542778015137
    },
    {
      "answer": "gastrodermis",
      "score": 0.69553142786026
    }
  ],
  "3770": [
    {
      "answer": "muscles",
      "score": 0.9737663865089417
    },
    {
      "answer": "muscles",
      "score": 0.7873665690422058
    }
  ],
  "3771": [],
  "3772": [
    {
      "answer": "mouth",
      "score": 0.6544933319091797
    },
    {
      "answer": "mouth",
      "score": 0.6340831518173218
    }
  ],
  "3773": [
    {
      "answer": "sides nearest to and furthest from the organ that it supplies",
      "score": 0.9616355299949646
    }
  ],
  "3774": [
    {
      "answer": "swimming-plates",
      "score": 0.980385422706604
    }
  ],
  "3775": [
    {
      "answer": "ctenes",
      "score": 0.6681254506111145
    },
    {
      "answer": "comb plates",
      "score": 0.61809241771698
    }
  ],
  "3776": [
    {
      "answer": "supporting function",
      "score": 0.9684429168701172
    }
  ],
  "3777": [
    {
      "answer": "in the direction in which the mouth is pointing",
      "score": 0.8738428354263306
    }
  ],
  "3778": [
    {
      "answer": "2 millimeters",
      "score": 0.9804267287254333
    }
  ],
  "3779": [
    {
      "answer": "ctenes",
      "score": 0.904396653175354
    }
  ],
  "3780": [
    {
      "answer": "eight",
      "score": 0.9539710283279419
    }
  ],
  "3781": [
    {
      "answer": "2 millimeters",
      "score": 0.9703875780105591
    }
  ],
  "3782": [
    {
      "answer": "away from the mouth",
      "score": 0.7194302678108215
    }
  ],
  "3783": [
    {
      "answer": "escape",
      "score": 0.9729007482528687
    }
  ],
  "3784": [
    {
      "answer": "osmotic pressure",
      "score": 0.9557433128356934
    }
  ],
  "3785": [
    {
      "answer": "mesoglea",
      "score": 0.9884814023971558
    }
  ],
  "3786": [
    {
      "answer": "increase its bulk and decrease its density",
      "score": 0.9762137532234192
    }
  ],
  "3787": [],
  "3788": [
    {
      "answer": "If they enter less dense brackish water, the ciliary rosettes in the body cavity may pump this into the mesoglea to increase its bulk and decrease its density",
      "score": 0.8364456295967102
    }
  ],
  "3789": [
    {
      "answer": "osmotic pressure",
      "score": 0.8338085412979126
    }
  ],
  "3790": [
    {
      "answer": "seawater",
      "score": 0.9877088069915771
    },
    {
      "answer": "seawater",
      "score": 0.7387597560882568
    }
  ],
  "3791": [
    {
      "answer": "decrease its density",
      "score": 0.9261907935142517
    }
  ],
  "3792": [
    {
      "answer": "to avoid sinking",
      "score": 0.9326403141021729
    }
  ],
  "3793": [
    {
      "answer": "aboral organ",
      "score": 0.9922592043876648
    }
  ],
  "3794": [
    {
      "answer": "opposite end from the mouth",
      "score": 0.9465572237968445
    }
  ],
  "3795": [
    {
      "answer": "a transparent dome",
      "score": 0.9765512347221375
    }
  ],
  "3796": [
    {
      "answer": "statocyst",
      "score": 0.9680405855178833
    }
  ],
  "3797": [
    {
      "answer": "a balance sensor",
      "score": 0.9399294853210449
    }
  ],
  "3798": [
    {
      "answer": "aboral organ",
      "score": 0.9877430200576782
    }
  ],
  "3799": [
    {
      "answer": "transparent dome",
      "score": 0.983826756477356
    }
  ],
  "3800": [
    {
      "answer": "aboral organ",
      "score": 0.6776902675628662
    },
    {
      "answer": "statocyst",
      "score": 0.7807224988937378
    },
    {
      "answer": "statolith",
      "score": 0.5331657528877258
    }
  ],
  "3801": [
    {
      "answer": "balancers",
      "score": 0.9098004698753357
    }
  ],
  "3802": [
    {
      "answer": "its response is determined by the animal's \"mood\"",
      "score": 0.7984811663627625
    }
  ],
  "3803": [
    {
      "answer": "sea gooseberry",
      "score": 0.7752103805541992
    },
    {
      "answer": "Pleurobrachia",
      "score": 0.7618683576583862
    }
  ],
  "3804": [
    {
      "answer": "a pair of long, slender tentacles",
      "score": 0.8234070539474487
    }
  ],
  "3805": [
    {
      "answer": "rounded",
      "score": 0.9688816070556641
    },
    {
      "answer": "spherical",
      "score": 0.7692080736160278
    },
    {
      "answer": "cylindrical",
      "score": 0.7160829305648804
    },
    {
      "answer": "egg-shaped",
      "score": 0.8366600275039673
    }
  ],
  "3806": [
    {
      "answer": "sheath",
      "score": 0.9898073077201843
    }
  ],
  "3807": [
    {
      "answer": "narrow end",
      "score": 0.9889346361160278
    }
  ],
  "3808": [
    {
      "answer": "narrow end",
      "score": 0.831270694732666
    }
  ],
  "3809": [
    {
      "answer": "withdrawn",
      "score": 0.9043538570404053
    }
  ],
  "3810": [
    {
      "answer": "flattened",
      "score": 0.9374367594718933
    }
  ],
  "3811": [
    {
      "answer": "narrow end",
      "score": 0.7972215414047241
    }
  ],
  "3812": [
    {
      "answer": "sheath",
      "score": 0.8509228229522705
    }
  ],
  "3813": [
    {
      "answer": "tentilla",
      "score": 0.9534609913825989
    }
  ],
  "3814": [
    {
      "answer": "Colloblasts are specialized mushroom-shaped cells in the outer layer of the epidermis",
      "score": 0.9310688376426697
    }
  ],
  "3815": [
    {
      "answer": "they contain striated muscle, a cell type otherwise unknown in the phylum Ctenophora; and they are coiled when relaxed",
      "score": 0.8604312539100647
    }
  ],
  "3816": [
    {
      "answer": "flick out very quickly (in 40 to 60 milliseconds)",
      "score": 0.7437219023704529
    },
    {
      "answer": "they can wriggle",
      "score": 0.7048541307449341
    },
    {
      "answer": "they coil round prey",
      "score": 0.8350782990455627
    }
  ],
  "3817": [
    {
      "answer": "coil round prey",
      "score": 0.9353029131889343
    }
  ],
  "3818": [
    {
      "answer": "tentilla",
      "score": 0.8318270444869995
    },
    {
      "answer": "tentilla",
      "score": 0.5844942927360535
    },
    {
      "answer": "tentilla",
      "score": 0.5419280529022217
    },
    {
      "answer": "tentilla",
      "score": 0.5488857626914978
    },
    {
      "answer": "tentilla",
      "score": 0.6045780777931213
    }
  ],
  "3819": [
    {
      "answer": "fringed",
      "score": 0.9337703585624695
    }
  ],
  "3820": [
    {
      "answer": "three",
      "score": 0.7432096600532532
    }
  ],
  "3821": [],
  "3822": [],
  "3823": [
    {
      "answer": "eight",
      "score": 0.994030773639679
    }
  ],
  "3824": [
    {
      "answer": "near the mouth",
      "score": 0.9572523832321167
    }
  ],
  "3825": [
    {
      "answer": "evenly",
      "score": 0.9883434772491455
    }
  ],
  "3826": [
    {
      "answer": "ciliary groove",
      "score": 0.9881299138069153
    }
  ],
  "3827": [
    {
      "answer": "eight",
      "score": 0.9923531413078308
    }
  ],
  "3828": [
    {
      "answer": "metachronal",
      "score": 0.986438512802124
    }
  ],
  "3829": [
    {
      "answer": "evenly",
      "score": 0.9801446199417114
    }
  ],
  "3830": [
    {
      "answer": "metachronal rhythm",
      "score": 0.586418867111206
    }
  ],
  "3831": [
    {
      "answer": "ciliary groove",
      "score": 0.9305540323257446
    },
    {
      "answer": "comb rows",
      "score": 0.8213374018669128
    }
  ],
  "3832": [
    {
      "answer": "lobes",
      "score": 0.9332789778709412
    },
    {
      "answer": "lobes",
      "score": 0.6543958783149719
    },
    {
      "answer": "lobes",
      "score": 0.587389349937439
    }
  ],
  "3833": [
    {
      "answer": "gelatinous projections edged with cilia",
      "score": 0.955348789691925
    }
  ],
  "3834": [
    {
      "answer": "four",
      "score": 0.9948822259902954
    }
  ],
  "3835": [
    {
      "answer": "produce water currents that help direct microscopic prey toward the mouth",
      "score": 0.966444194316864
    }
  ],
  "3836": [
    {
      "answer": "suspended planktonic prey",
      "score": 0.9750387668609619
    }
  ],
  "3837": [
    {
      "answer": "pair",
      "score": 0.9591792821884155
    }
  ],
  "3838": [
    {
      "answer": "continuously",
      "score": 0.9805851578712463
    }
  ],
  "3839": [],
  "3840": [
    {
      "answer": "four",
      "score": 0.9955995082855225
    }
  ],
  "3841": [
    {
      "answer": "produce water currents",
      "score": 0.7639729380607605
    }
  ],
  "3842": [
    {
      "answer": "clapping their lobes",
      "score": 0.9772140383720398
    }
  ],
  "3843": [
    {
      "answer": "the jet of expelled water drives them backwards very quickly.",
      "score": 0.8372811675071716
    }
  ],
  "3844": [
    {
      "answer": "nerves",
      "score": 0.9925394654273987
    }
  ],
  "3845": [],
  "3846": [
    {
      "answer": "eight",
      "score": 0.7413018941879272
    }
  ],
  "3847": [
    {
      "answer": "quite passive",
      "score": 0.9741828441619873
    }
  ],
  "3848": [
    {
      "answer": "long and active",
      "score": 0.8935838937759399
    }
  ],
  "3849": [
    {
      "answer": "clapping their lobes",
      "score": 0.9565880298614502
    }
  ],
  "3850": [
    {
      "answer": "the jet of expelled water drives them backwards very quickly",
      "score": 0.8834277987480164
    }
  ],
  "3851": [
    {
      "answer": "Nuda",
      "score": 0.9940318465232849
    }
  ],
  "3852": [
    {
      "answer": "Beroida",
      "score": 0.9776840209960938
    }
  ],
  "3853": [
    {
      "answer": "zip\" the mouth shut",
      "score": 0.9749685525894165
    }
  ],
  "3854": [],
  "3855": [
    {
      "answer": "macrocilia",
      "score": 0.9831703305244446
    },
    {
      "answer": "macrocilia",
      "score": 0.792219340801239
    }
  ],
  "3856": [
    {
      "answer": "no feeding appendages",
      "score": 0.7030350565910339
    }
  ],
  "3857": [
    {
      "answer": "macrocilia",
      "score": 0.5250045657157898
    }
  ],
  "3858": [
    {
      "answer": "macrocilia",
      "score": 0.9636908769607544
    },
    {
      "answer": "macrocilia",
      "score": 0.6622492671012878
    }
  ],
  "3859": [
    {
      "answer": "bite\" off pieces of prey",
      "score": 0.8247708678245544
    }
  ],
  "3860": [],
  "3861": [
    {
      "answer": "Cestida",
      "score": 0.865153968334198
    },
    {
      "answer": "Cestum veneris",
      "score": 0.6012318134307861
    }
  ],
  "3862": [
    {
      "answer": "belt animals",
      "score": 0.947681188583374
    }
  ],
  "3863": [
    {
      "answer": "undulating their bodies",
      "score": 0.9743708372116089
    },
    {
      "answer": "beating of their comb-rows",
      "score": 0.954978346824646
    }
  ],
  "3864": [
    {
      "answer": "Cestum veneris",
      "score": 0.9841276407241821
    }
  ],
  "3865": [
    {
      "answer": "Velamen parallelum",
      "score": 0.9970312118530273
    }
  ],
  "3866": [
    {
      "answer": "1.5 meters",
      "score": 0.9647665619850159
    }
  ],
  "3867": [
    {
      "answer": "undulating their bodies",
      "score": 0.9427433013916016
    }
  ],
  "3868": [
    {
      "answer": "aboral",
      "score": 0.6778637766838074
    }
  ],
  "3869": [
    {
      "answer": "ribbon-shaped",
      "score": 0.9841262102127075
    }
  ],
  "3870": [
    {
      "answer": "in the middle",
      "score": 0.9242815971374512
    }
  ],
  "3871": [
    {
      "answer": "a pair of tentilla-bearing tentacles",
      "score": 0.8502501845359802
    }
  ],
  "3872": [
    {
      "answer": "a muscular \"foot\"",
      "score": 0.8218585848808289
    }
  ],
  "3873": [
    {
      "answer": "comb-rows",
      "score": 0.9531282782554626
    }
  ],
  "3874": [
    {
      "answer": "rocks",
      "score": 0.9790974259376526
    },
    {
      "answer": "algae",
      "score": 0.975196361541748
    },
    {
      "answer": "body surfaces of other invertebrates",
      "score": 0.960866391658783
    }
  ],
  "3875": [],
  "3876": [
    {
      "answer": "oval",
      "score": 0.9889612793922424
    }
  ],
  "3877": [
    {
      "answer": "pair",
      "score": 0.9799857139587402
    }
  ],
  "3878": [
    {
      "answer": "comb-rows",
      "score": 0.9716590046882629
    }
  ],
  "3879": [
    {
      "answer": "rocks",
      "score": 0.9724895358085632
    },
    {
      "answer": "algae",
      "score": 0.9734898805618286
    },
    {
      "answer": "body surfaces of other invertebrates",
      "score": 0.9506592154502869
    }
  ],
  "3880": [
    {
      "answer": "pores in the epidermis",
      "score": 0.9856913089752197
    }
  ],
  "3881": [
    {
      "answer": "internal fertilization",
      "score": 0.9708810448646545
    }
  ],
  "3882": [
    {
      "answer": "Mnemiopsis",
      "score": 0.9850912690162659
    }
  ],
  "3883": [],
  "3884": [
    {
      "answer": "external",
      "score": 0.9865028858184814
    }
  ],
  "3885": [
    {
      "answer": "hermaphrodites",
      "score": 0.9468744397163391
    }
  ],
  "3886": [
    {
      "answer": "brood chambers",
      "score": 0.9716850519180298
    }
  ],
  "3887": [
    {
      "answer": "eggs",
      "score": 0.9549248218536377
    },
    {
      "answer": "sperm",
      "score": 0.9649269580841064
    }
  ],
  "3888": [
    {
      "answer": "Self-fertilization",
      "score": 0.9922385811805725
    }
  ],
  "3889": [
    {
      "answer": "self-fertile",
      "score": 0.9379690289497375
    }
  ],
  "3890": [
    {
      "answer": "tentacles",
      "score": 0.9904728531837463
    },
    {
      "answer": "tentacle sheaths",
      "score": 0.9855026602745056
    }
  ],
  "3891": [
    {
      "answer": "among the plankton",
      "score": 0.9603922367095947
    }
  ],
  "3892": [],
  "3893": [
    {
      "answer": "true larvae",
      "score": 0.9783169031143188
    }
  ],
  "3894": [
    {
      "answer": "Beroe",
      "score": 0.9940534234046936
    }
  ],
  "3895": [
    {
      "answer": "Development of the fertilized eggs is direct",
      "score": 0.7963069081306458
    },
    {
      "answer": "gradually develop the body forms of their parents",
      "score": 0.727975606918335
    }
  ],
  "3896": [
    {
      "answer": "tentacles",
      "score": 0.9752825498580933
    },
    {
      "answer": "tentacle sheaths",
      "score": 0.9750207662582397
    }
  ],
  "3897": [],
  "3898": [
    {
      "answer": "plankton",
      "score": 0.9910401701927185
    }
  ],
  "3899": [
    {
      "answer": "a different ecological niche",
      "score": 0.8787795305252075
    }
  ],
  "3900": [],
  "3901": [
    {
      "answer": "disturbed",
      "score": 0.8702839016914368
    },
    {
      "answer": "Juveniles",
      "score": 0.5485213994979858
    }
  ],
  "3902": [
    {
      "answer": "ink",
      "score": 0.9871289730072021
    }
  ],
  "3903": [
    {
      "answer": "Juveniles will luminesce more brightly in relation to their body size than adults",
      "score": 0.8585442304611206
    }
  ],
  "3904": [
    {
      "answer": "secretions (ink)",
      "score": 0.8273018598556519
    }
  ],
  "3905": [],
  "3906": [],
  "3907": [
    {
      "answer": "produce secretions (ink) that luminesce at much the same wavelengths as their bodies",
      "score": 0.8130446672439575
    }
  ],
  "3908": [],
  "3909": [],
  "3910": [
    {
      "answer": "jellyfish",
      "score": 0.959273099899292
    }
  ],
  "3911": [
    {
      "answer": "Members of the genus Haeckelia prey on jellyfish and incorporate their prey's nematocysts (stinging cells) into their own tentacles instead of colloblasts.",
      "score": 0.8059629797935486
    }
  ],
  "3912": [
    {
      "answer": "rotifers and mollusc and crustacean larvae",
      "score": 0.9610647559165955
    }
  ],
  "3913": [
    {
      "answer": "Lampea",
      "score": 0.9248624444007874
    }
  ],
  "3914": [
    {
      "answer": "10 times their own weight",
      "score": 0.9336791038513184
    }
  ],
  "3915": [
    {
      "answer": "mollusc and fish larvae",
      "score": 0.7885240912437439
    },
    {
      "answer": "copepods, amphipods, and even krill",
      "score": 0.6504747271537781
    }
  ],
  "3916": [
    {
      "answer": "jellyfish",
      "score": 0.6169049143791199
    }
  ],
  "3917": [
    {
      "answer": "rotifers and mollusc and crustacean larvae",
      "score": 0.8508848547935486
    }
  ],
  "3918": [
    {
      "answer": "nematocysts",
      "score": 0.951693058013916
    }
  ],
  "3919": [
    {
      "answer": "low ratio of organic matter to salt and water",
      "score": 0.9898069500923157
    }
  ],
  "3920": [
    {
      "answer": "Oncorhynchus keta",
      "score": 0.8423420786857605
    }
  ],
  "3921": [],
  "3922": [
    {
      "answer": "Red Sea",
      "score": 0.9621840715408325
    }
  ],
  "3923": [
    {
      "answer": "Ctenophores",
      "score": 0.657666027545929
    },
    {
      "answer": "ctenophores",
      "score": 0.6171410083770752
    },
    {
      "answer": "ctenophores",
      "score": 0.6352630853652954
    },
    {
      "answer": "ctenophores",
      "score": 0.8265455961227417
    },
    {
      "answer": "ctenophores",
      "score": 0.6354353427886963
    },
    {
      "answer": "ctenophores",
      "score": 0.9828201532363892
    },
    {
      "answer": "ctenophores",
      "score": 0.5662070512771606
    }
  ],
  "3924": [
    {
      "answer": "dead ends",
      "score": 0.8651636838912964
    }
  ],
  "3925": [
    {
      "answer": "guts",
      "score": 0.9846445322036743
    }
  ],
  "3926": [
    {
      "answer": "20 times",
      "score": 0.9413959980010986
    }
  ],
  "3927": [
    {
      "answer": "ctenophores",
      "score": 0.7445282936096191
    }
  ],
  "3928": [
    {
      "answer": "ctenophore",
      "score": 0.8912054896354675
    }
  ],
  "3929": [
    {
      "answer": "Western Atlantic ctenophore Mnemiopsis leidyi",
      "score": 0.856701672077179
    }
  ],
  "3930": [
    {
      "answer": "the ballast tanks of ships",
      "score": 0.9645137190818787
    }
  ],
  "3931": [
    {
      "answer": "late 1980s",
      "score": 0.9490885734558105
    }
  ],
  "3932": [
    {
      "answer": "accidental introduction of the Mnemiopsis-eating North American ctenophore Beroe ovata",
      "score": 0.9618465304374695
    }
  ],
  "3933": [
    {
      "answer": "slowed the animal's metabolism",
      "score": 0.8849372267723083
    }
  ],
  "3934": [
    {
      "answer": "late 1980s",
      "score": 0.939791202545166
    }
  ],
  "3935": [
    {
      "answer": "Black Sea",
      "score": 0.9343485236167908
    },
    {
      "answer": "Sea of Azov",
      "score": 0.6652945876121521
    },
    {
      "answer": "Black Sea",
      "score": 0.8443838953971863
    }
  ],
  "3936": [
    {
      "answer": "ballast tanks of ships",
      "score": 0.9638346433639526
    }
  ],
  "3937": [
    {
      "answer": "fish catches",
      "score": 0.9710557460784912
    }
  ],
  "3938": [
    {
      "answer": "very rapidly",
      "score": 0.9619854688644409
    }
  ],
  "3939": [
    {
      "answer": "soft, gelatinous bodies",
      "score": 0.9915667772293091
    }
  ],
  "3940": [
    {
      "answer": "comb jelly",
      "score": 0.9920024871826172
    }
  ],
  "3941": [
    {
      "answer": "mid-Cambrian",
      "score": 0.9792430400848389
    }
  ],
  "3942": [
    {
      "answer": "Three",
      "score": 0.991972804069519
    },
    {
      "answer": "three",
      "score": 0.8386884331703186
    }
  ],
  "3943": [
    {
      "answer": "tentacles",
      "score": 0.9073335528373718
    }
  ],
  "3944": [
    {
      "answer": "mid-Cambrian period",
      "score": 0.7960286140441895
    }
  ],
  "3945": [
    {
      "answer": "24 and 80",
      "score": 0.7455045580863953
    }
  ],
  "3946": [
    {
      "answer": "505 million years",
      "score": 0.8424350619316101
    }
  ],
  "3947": [
    {
      "answer": "comb rows",
      "score": 0.9509463310241699
    }
  ],
  "3948": [
    {
      "answer": "1996",
      "score": 0.9748873114585876
    }
  ],
  "3949": [
    {
      "answer": "515 million years ago",
      "score": 0.9688428640365601
    }
  ],
  "3950": [
    {
      "answer": "Cambrian sessile frond-like fossil Stromatoveris",
      "score": 0.8222758173942566
    }
  ],
  "3951": [
    {
      "answer": "Stromatoveris",
      "score": 0.7959216833114624
    },
    {
      "answer": "Stromatoveris",
      "score": 0.8565700650215149
    }
  ],
  "3952": [
    {
      "answer": "Vendobionta",
      "score": 0.9947532415390015
    }
  ],
  "3953": [
    {
      "answer": "Ediacaran",
      "score": 0.9950456619262695
    }
  ],
  "3954": [
    {
      "answer": "Stromatoveris",
      "score": 0.6478734612464905
    },
    {
      "answer": "Stromatoveris",
      "score": 0.6819218397140503
    }
  ],
  "3955": [
    {
      "answer": "Cambrian",
      "score": 0.9448171257972717
    },
    {
      "answer": "Ediacaran",
      "score": 0.6990836262702942
    }
  ],
  "3956": [
    {
      "answer": "cilia",
      "score": 0.9863185882568359
    }
  ],
  "3957": [
    {
      "answer": "swimmers",
      "score": 0.99186110496521
    }
  ],
  "3958": [
    {
      "answer": "propulsion system",
      "score": 0.9906138181686401
    }
  ],
  "3959": [
    {
      "answer": "Bilateria",
      "score": 0.9590513110160828
    },
    {
      "answer": "Cnidaria",
      "score": 0.7072644829750061
    },
    {
      "answer": "Cnidaria",
      "score": 0.6975792050361633
    },
    {
      "answer": "Bilateria",
      "score": 0.7890923619270325
    }
  ],
  "3960": [
    {
      "answer": "Porifera",
      "score": 0.9919597506523132
    }
  ],
  "3961": [
    {
      "answer": "Ctenophores and sponges are also the only known animal phyla that lack any true hox genes.",
      "score": 0.7177503108978271
    }
  ],
  "3962": [],
  "3963": [
    {
      "answer": "Porifera",
      "score": 0.9474940299987793
    }
  ],
  "3964": [
    {
      "answer": "early evolution of animals and the origin of multicellularity",
      "score": 0.9074787497520447
    }
  ],
  "3965": [
    {
      "answer": "Ctenophores and sponges are also the only known animal phyla that lack any true hox genes.",
      "score": 0.9273346662521362
    }
  ],
  "3966": [
    {
      "answer": "beroids",
      "score": 0.9920210242271423
    }
  ],
  "3967": [
    {
      "answer": "not monophyletic",
      "score": 0.6165836453437805
    },
    {
      "answer": "not monophyletic",
      "score": 0.8040353059768677
    }
  ],
  "3968": [
    {
      "answer": "65.5 million years ago",
      "score": 0.9908407926559448
    }
  ],
  "3969": [
    {
      "answer": "Richard Harbison",
      "score": 0.9962694048881531
    }
  ],
  "3970": [
    {
      "answer": "the cydippids are not monophyletic",
      "score": 0.7227246165275574
    }
  ],
  "3971": [
    {
      "answer": "members of other ctenophore orders",
      "score": 0.7371661067008972
    }
  ],
  "3972": [
    {
      "answer": "65.5 million years ago",
      "score": 0.9446018934249878
    }
  ],
  "3973": [],
  "3974": [
    {
      "answer": "26",
      "score": 0.9425761103630066
    },
    {
      "answer": "4",
      "score": 0.7514215111732483
    }
  ],
  "3975": [
    {
      "answer": "Fresno",
      "score": 0.91353440284729
    },
    {
      "answer": "Fresno",
      "score": 0.7939565777778625
    },
    {
      "answer": "Fresno",
      "score": 0.8046493530273438
    },
    {
      "answer": "Fresno",
      "score": 0.8177090287208557
    }
  ],
  "3976": [
    {
      "answer": "220 miles",
      "score": 0.9867334961891174
    }
  ],
  "3977": [
    {
      "answer": "ash tree",
      "score": 0.9920557737350464
    }
  ],
  "3978": [
    {
      "answer": "ash leaf",
      "score": 0.9841932654380798
    }
  ],
  "3979": [
    {
      "answer": "\u02c8fr\u025bzno\u028a/ FREZ-noh",
      "score": 0.766533613204956
    }
  ],
  "3980": [
    {
      "answer": "520,159",
      "score": 0.8079296350479126
    }
  ],
  "3981": [
    {
      "answer": "ash tree",
      "score": 0.9760397672653198
    }
  ],
  "3982": [],
  "3983": [
    {
      "answer": "San Joaquin Valley",
      "score": 0.9693967700004578
    },
    {
      "answer": "San Joaquin Valley",
      "score": 0.8669671416282654
    }
  ],
  "3984": [
    {
      "answer": "Sacramento",
      "score": 0.7167749404907227
    }
  ],
  "3985": [
    {
      "answer": "1872",
      "score": 0.9943568110466003
    }
  ],
  "3986": [
    {
      "answer": "convenience of the railroad",
      "score": 0.9630435705184937
    },
    {
      "answer": "worried about flooding",
      "score": 0.8314499258995056
    }
  ],
  "3987": [
    {
      "answer": "1885",
      "score": 0.9907975196838379
    }
  ],
  "3988": [
    {
      "answer": "47",
      "score": 0.9923168420791626
    }
  ],
  "3989": [
    {
      "answer": "Central Pacific Railroad",
      "score": 0.9866077899932861
    }
  ],
  "3990": [
    {
      "answer": "1872",
      "score": 0.976702868938446
    }
  ],
  "3991": [
    {
      "answer": "1872",
      "score": 0.983326256275177
    }
  ],
  "3992": [
    {
      "answer": "49",
      "score": 0.9803184866905212
    }
  ],
  "3993": [
    {
      "answer": "1872",
      "score": 0.9700314402580261
    }
  ],
  "3994": [
    {
      "answer": "Millerton",
      "score": 0.8955461978912354
    }
  ],
  "3995": [
    {
      "answer": "2.7",
      "score": 0.989259660243988
    }
  ],
  "3996": [
    {
      "answer": "Chinatown",
      "score": 0.7863230109214783
    },
    {
      "answer": "Chinatown",
      "score": 0.960282027721405
    }
  ],
  "3997": [],
  "3998": [
    {
      "answer": "an interim facility for the relocation of Fresno area Japanese Americans to internment camps",
      "score": 0.9356977343559265
    }
  ],
  "3999": [
    {
      "answer": "assembly center",
      "score": 0.9742767810821533
    }
  ],
  "4000": [
    {
      "answer": "94.0%",
      "score": 0.9206849932670593
    }
  ],
  "4001": [
    {
      "answer": "3.3",
      "score": 0.9803190231323242
    }
  ],
  "4002": [
    {
      "answer": "1940",
      "score": 0.8145087957382202
    }
  ],
  "4003": [
    {
      "answer": "North Fresno",
      "score": 0.739264965057373
    }
  ],
  "4004": [
    {
      "answer": "North Fresno",
      "score": 0.9875001907348633
    }
  ],
  "4005": [
    {
      "answer": "BankAmericard",
      "score": 0.8978053331375122
    }
  ],
  "4006": [
    {
      "answer": "BankAmericard",
      "score": 0.9479078054428101
    },
    {
      "answer": "BankAmericard",
      "score": 0.7826595306396484
    },
    {
      "answer": "BankAmericard",
      "score": 0.6976045370101929
    }
  ],
  "4007": [
    {
      "answer": "revolve a balance",
      "score": 0.9752691984176636
    }
  ],
  "4008": [
    {
      "answer": "1976",
      "score": 0.9958474040031433
    }
  ],
  "4009": [
    {
      "answer": "Visa Inc",
      "score": 0.9886595606803894
    }
  ],
  "4010": [
    {
      "answer": "September 1958",
      "score": 0.991543173789978
    }
  ],
  "4011": [
    {
      "answer": "BankAmericard",
      "score": 0.8322615623474121
    },
    {
      "answer": "BankAmericard",
      "score": 0.8170675039291382
    },
    {
      "answer": "BankAmericard",
      "score": 0.8444740176200867
    }
  ],
  "4012": [
    {
      "answer": "revolve a balance",
      "score": 0.8584603071212769
    }
  ],
  "4013": [
    {
      "answer": "1958",
      "score": 0.989972710609436
    }
  ],
  "4014": [
    {
      "answer": "Fresno",
      "score": 0.9868481755256653
    }
  ],
  "4015": [
    {
      "answer": "Bill Aken",
      "score": 0.9964306950569153
    }
  ],
  "4016": [
    {
      "answer": "Bob Gallion",
      "score": 0.9973105788230896
    }
  ],
  "4017": [
    {
      "answer": "Madera",
      "score": 0.9582027196884155
    }
  ],
  "4018": [
    {
      "answer": "The Fresno Barn",
      "score": 0.967366635799408
    }
  ],
  "4019": [
    {
      "answer": "Lupe Mayorga",
      "score": 0.9964507818222046
    }
  ],
  "4020": [
    {
      "answer": "Walking Into Fresno",
      "score": 0.9810260534286499
    }
  ],
  "4021": [
    {
      "answer": "Mexican",
      "score": 0.9860969185829163
    }
  ],
  "4022": [
    {
      "answer": "Bob Gallion",
      "score": 0.9953866600990295
    }
  ],
  "4023": [
    {
      "answer": "WWVA Jamboree",
      "score": 0.824425220489502
    }
  ],
  "4024": [
    {
      "answer": "Bill Aken",
      "score": 0.9756540060043335
    }
  ],
  "4025": [
    {
      "answer": "three",
      "score": 0.9910674691200256
    }
  ],
  "4026": [
    {
      "answer": "Roeding Park",
      "score": 0.9951434135437012
    }
  ],
  "4027": [
    {
      "answer": "Kearney Park",
      "score": 0.9941489696502686
    }
  ],
  "4028": [],
  "4029": [
    {
      "answer": "Kearney Park",
      "score": 0.995087742805481
    }
  ],
  "4030": [
    {
      "answer": "Shinzen Japanese",
      "score": 0.9545155763626099
    }
  ],
  "4031": [
    {
      "answer": "Woodward Park",
      "score": 0.8552694320678711
    },
    {
      "answer": "Kearney Park",
      "score": 0.577642560005188
    }
  ],
  "4032": [
    {
      "answer": "Kearney Park",
      "score": 0.8845743536949158
    }
  ],
  "4033": [
    {
      "answer": "several miles",
      "score": 0.9383236169815063
    }
  ],
  "4034": [
    {
      "answer": "southwest",
      "score": 0.7387312054634094
    }
  ],
  "4035": [
    {
      "answer": "1880s",
      "score": 0.9771084785461426
    }
  ],
  "4036": [
    {
      "answer": "original Fresno County Courthouse",
      "score": 0.9369634389877319
    },
    {
      "answer": "Fresno Carnegie Public Library",
      "score": 0.8711191415786743
    },
    {
      "answer": "Bank of Italy Building",
      "score": 0.6970030069351196
    }
  ],
  "4037": [
    {
      "answer": "San Joaquin Light & Power Building",
      "score": 0.9865511655807495
    }
  ],
  "4038": [
    {
      "answer": "Hughes Hotel",
      "score": 0.9700964093208313
    }
  ],
  "4039": [
    {
      "answer": "1880s",
      "score": 0.9881501197814941
    }
  ],
  "4040": [
    {
      "answer": "Grand 1401",
      "score": 0.9913357496261597
    }
  ],
  "4041": [
    {
      "answer": "demolished",
      "score": 0.9431845545768738
    },
    {
      "answer": "demolished",
      "score": 0.9053059220314026
    }
  ],
  "4042": [
    {
      "answer": "San Joaquin Light & Power Building",
      "score": 0.8558921813964844
    }
  ],
  "4043": [
    {
      "answer": "San Joaquin Light & Power Building",
      "score": 0.9033194780349731
    }
  ],
  "4044": [
    {
      "answer": "1964",
      "score": 0.992468535900116
    }
  ],
  "4045": [
    {
      "answer": "Fulton Mall",
      "score": 0.9042519330978394
    },
    {
      "answer": "Fulton Mall",
      "score": 0.8325330018997192
    },
    {
      "answer": "Fulton Mall",
      "score": 0.8448096513748169
    }
  ],
  "4046": [
    {
      "answer": "Pierre-Auguste Renoir",
      "score": 0.9848290085792542
    }
  ],
  "4047": [
    {
      "answer": "near their current locations",
      "score": 0.9580967426300049
    }
  ],
  "4048": [
    {
      "answer": "wide sidewalks",
      "score": 0.9529812335968018
    }
  ],
  "4049": [
    {
      "answer": "1964",
      "score": 0.9653540253639221
    }
  ],
  "4050": [
    {
      "answer": "28'",
      "score": 0.6396421194076538
    }
  ],
  "4051": [
    {
      "answer": "Fulton Mall",
      "score": 0.8972387313842773
    },
    {
      "answer": "Fulton Mall",
      "score": 0.9277112483978271
    },
    {
      "answer": "Fulton Mall",
      "score": 0.9290101528167725
    }
  ],
  "4052": [
    {
      "answer": "sidewalks",
      "score": 0.9729650616645813
    }
  ],
  "4053": [
    {
      "answer": "east",
      "score": 0.9929453730583191
    }
  ],
  "4054": [
    {
      "answer": "far southeast side",
      "score": 0.8802883625030518
    }
  ],
  "4055": [
    {
      "answer": "Kings Canyon Avenue",
      "score": 0.9900586009025574
    },
    {
      "answer": "Clovis Avenue",
      "score": 0.9843082427978516
    }
  ],
  "4056": [
    {
      "answer": "1950s",
      "score": 0.9947575330734253
    },
    {
      "answer": "1970s",
      "score": 0.9790005087852478
    }
  ],
  "4057": [
    {
      "answer": "Sunnyside",
      "score": 0.8708614706993103
    },
    {
      "answer": "Sunnyside",
      "score": 0.8079214692115784
    },
    {
      "answer": "Sunnyside",
      "score": 0.9206892848014832
    }
  ],
  "4058": [
    {
      "answer": "William P. Bell",
      "score": 0.9968119263648987
    }
  ],
  "4059": [
    {
      "answer": "William P. Bell",
      "score": 0.9959553480148315
    }
  ],
  "4060": [
    {
      "answer": "1950s",
      "score": 0.9907659292221069
    }
  ],
  "4061": [
    {
      "answer": "Chestnut Avenue",
      "score": 0.9692267775535583
    }
  ],
  "4062": [
    {
      "answer": "Sunnyside",
      "score": 0.8028720021247864
    },
    {
      "answer": "Fresno",
      "score": 0.5633155107498169
    },
    {
      "answer": "Sunnyside",
      "score": 0.5266768336296082
    },
    {
      "answer": "Fresno",
      "score": 0.518153190612793
    },
    {
      "answer": "Sunnyside",
      "score": 0.5326728224754333
    }
  ],
  "4063": [
    {
      "answer": "Sunnyside",
      "score": 0.9226895570755005
    },
    {
      "answer": "Sunnyside",
      "score": 0.7753865122795105
    },
    {
      "answer": "Sunnyside",
      "score": 0.833299994468689
    }
  ],
  "4064": [
    {
      "answer": "Tower Theatre",
      "score": 0.9873781204223633
    }
  ],
  "4065": [
    {
      "answer": "1939",
      "score": 0.991295576095581
    }
  ],
  "4066": [
    {
      "answer": "water tower",
      "score": 0.9688941240310669
    }
  ],
  "4067": [
    {
      "answer": "Fresno Normal School",
      "score": 0.9924258589744568
    }
  ],
  "4068": [
    {
      "answer": "one-half mile",
      "score": 0.9890090227127075
    },
    {
      "answer": "one-half mile",
      "score": 0.9113612174987793
    }
  ],
  "4069": [
    {
      "answer": "1939",
      "score": 0.9922605156898499
    }
  ],
  "4070": [
    {
      "answer": "Olive and Wishon Avenues",
      "score": 0.9180818796157837
    }
  ],
  "4071": [],
  "4072": [
    {
      "answer": "1916",
      "score": 0.9725865721702576
    }
  ],
  "4073": [
    {
      "answer": "California State University at Fresno",
      "score": 0.9509761929512024
    }
  ],
  "4074": [
    {
      "answer": "late 1970s",
      "score": 0.9760712385177612
    }
  ],
  "4075": [
    {
      "answer": "second and third run movies",
      "score": 0.9938816428184509
    },
    {
      "answer": "classic films",
      "score": 0.9340304136276245
    }
  ],
  "4076": [
    {
      "answer": "1978",
      "score": 0.9896721839904785
    }
  ],
  "4077": [
    {
      "answer": "Fresno",
      "score": 0.9910598397254944
    }
  ],
  "4078": [
    {
      "answer": "Evita",
      "score": 0.9697801470756531
    },
    {
      "answer": "The Wiz",
      "score": 0.9732725620269775
    }
  ],
  "4079": [
    {
      "answer": "1970s",
      "score": 0.8167440891265869
    }
  ],
  "4080": [
    {
      "answer": "second and third run movies",
      "score": 0.7076980471611023
    },
    {
      "answer": "classic films",
      "score": 0.644926905632019
    }
  ],
  "4081": [
    {
      "answer": "1978",
      "score": 0.9882616400718689
    }
  ],
  "4082": [
    {
      "answer": "Tony",
      "score": 0.9941810965538025
    }
  ],
  "4083": [
    {
      "answer": "Audra McDonald",
      "score": 0.8953416347503662
    }
  ],
  "4084": [
    {
      "answer": "live",
      "score": 0.96820068359375
    }
  ],
  "4085": [
    {
      "answer": "a few hundred feet",
      "score": 0.9857167601585388
    }
  ],
  "4086": [
    {
      "answer": "Tower District",
      "score": 0.9857020378112793
    },
    {
      "answer": "Tower District",
      "score": 0.7128207683563232
    },
    {
      "answer": "Tower District",
      "score": 0.6331415176391602
    }
  ],
  "4087": [
    {
      "answer": "Tower District",
      "score": 0.8890085220336914
    },
    {
      "answer": "Tower District",
      "score": 0.9693953990936279
    },
    {
      "answer": "Tower District",
      "score": 0.8302379846572876
    }
  ],
  "4088": [
    {
      "answer": "Tower District",
      "score": 0.8564578294754028
    },
    {
      "answer": "Tower District",
      "score": 0.8632001876831055
    },
    {
      "answer": "Tower District",
      "score": 0.9714974164962769
    }
  ],
  "4089": [
    {
      "answer": "a few hundred feet",
      "score": 0.719164252281189
    }
  ],
  "4090": [
    {
      "answer": "live theater",
      "score": 0.8425441384315491
    }
  ],
  "4091": [],
  "4092": [
    {
      "answer": "LGBT and hipster Communities",
      "score": 0.7409635782241821
    },
    {
      "answer": "punk/goth/deathrock and heavy metal community",
      "score": 0.7749080657958984
    }
  ],
  "4093": [
    {
      "answer": "California Bungalow and American Craftsman style homes",
      "score": 0.9190956354141235
    },
    {
      "answer": "Spanish Colonial Revival Style architecture",
      "score": 0.8627420663833618
    },
    {
      "answer": "Mediterranean Revival Style architecture",
      "score": 0.8218968510627747
    },
    {
      "answer": "Mission Revival Style architecture",
      "score": 0.7688859105110168
    },
    {
      "answer": "Storybook houses",
      "score": 0.6552090644836426
    }
  ],
  "4094": [
    {
      "answer": "California Bungalow and American Craftsman style homes",
      "score": 0.7389523983001709
    },
    {
      "answer": "Spanish Colonial Revival Style architecture",
      "score": 0.6022389531135559
    },
    {
      "answer": "Mediterranean Revival Style architecture",
      "score": 0.6205921173095703
    },
    {
      "answer": "Mission Revival Style architecture",
      "score": 0.6658944487571716
    },
    {
      "answer": "Storybook",
      "score": 0.9653338193893433
    }
  ],
  "4095": [
    {
      "answer": "contrasts with the newer areas of tract homes urban sprawl in north and east areas of Fresno",
      "score": 0.9694469571113586
    }
  ],
  "4096": [
    {
      "answer": "recent decades",
      "score": 0.9771186113357544
    }
  ],
  "4097": [
    {
      "answer": "Hilliard, Taylor & Wheeler",
      "score": 0.9679210782051086
    }
  ],
  "4098": [],
  "4099": [
    {
      "answer": "early twentieth century",
      "score": 0.9939481616020203
    }
  ],
  "4100": [
    {
      "answer": "north and east",
      "score": 0.7075715065002441
    }
  ],
  "4101": [
    {
      "answer": "California",
      "score": 0.822914183139801
    }
  ],
  "4102": [
    {
      "answer": "Huntington Boulevard",
      "score": 0.9924538135528564
    },
    {
      "answer": "Huntington Boulevard",
      "score": 0.9807862043380737
    }
  ],
  "4103": [
    {
      "answer": "William Stranahan",
      "score": 0.9983674883842468
    }
  ],
  "4104": [
    {
      "answer": "1914",
      "score": 0.991510272026062
    }
  ],
  "4105": [
    {
      "answer": "267",
      "score": 0.98436039686203
    }
  ],
  "4106": [
    {
      "answer": "Fresno Traction Company",
      "score": 0.9954301118850708
    }
  ],
  "4107": [
    {
      "answer": "William Stranahan",
      "score": 0.9342959523200989
    }
  ],
  "4108": [
    {
      "answer": "the City",
      "score": 0.632826566696167
    }
  ],
  "4109": [
    {
      "answer": "267",
      "score": 0.9832994341850281
    }
  ],
  "4110": [
    {
      "answer": "Fresno Traction Company right-of-way",
      "score": 0.910759687423706
    }
  ],
  "4111": [
    {
      "answer": "1914",
      "score": 0.9662964344024658
    }
  ],
  "4112": [
    {
      "answer": "Southwest Fresno",
      "score": 0.9794424772262573
    }
  ],
  "4113": [
    {
      "answer": "southwest",
      "score": 0.992870032787323
    }
  ],
  "4114": [
    {
      "answer": "African-American",
      "score": 0.9946016073226929
    }
  ],
  "4115": [
    {
      "answer": "Hmong or Laotian",
      "score": 0.9145113825798035
    }
  ],
  "4116": [
    {
      "answer": "West Side",
      "score": 0.9107711911201477
    }
  ],
  "4117": [
    {
      "answer": "41 freeway",
      "score": 0.9834047555923462
    }
  ],
  "4118": [
    {
      "answer": "99 freeway",
      "score": 0.9952503442764282
    }
  ],
  "4119": [
    {
      "answer": "African-American",
      "score": 0.9885702729225159
    }
  ],
  "4120": [
    {
      "answer": "Hmong or Laotian",
      "score": 0.9283030033111572
    }
  ],
  "4121": [],
  "4122": [
    {
      "answer": "M. Theo Kearney",
      "score": 0.9851183295249939
    }
  ],
  "4123": [
    {
      "answer": "palm",
      "score": 0.9852498173713684
    }
  ],
  "4124": [
    {
      "answer": "Fresno Street",
      "score": 0.9556807279586792
    },
    {
      "answer": "Thorne Ave",
      "score": 0.962549090385437
    }
  ],
  "4125": [
    {
      "answer": "Brookhaven",
      "score": 0.9676800966262817
    }
  ],
  "4126": [
    {
      "answer": "southern edge of the West Side south of Jensen and west of Elm",
      "score": 0.7655152082443237
    }
  ],
  "4127": [
    {
      "answer": "M. Theo Kearney",
      "score": 0.9656766653060913
    }
  ],
  "4128": [
    {
      "answer": "20 mi",
      "score": 0.9666794538497925
    }
  ],
  "4129": [
    {
      "answer": "African-American families",
      "score": 0.9821891188621521
    }
  ],
  "4130": [
    {
      "answer": "M. Theo Kearney",
      "score": 0.9521447420120239
    }
  ],
  "4131": [
    {
      "answer": "Dogg Pound",
      "score": 0.9107736349105835
    }
  ],
  "4132": [
    {
      "answer": "1960s",
      "score": 0.9856382012367249
    },
    {
      "answer": "1990s",
      "score": 0.9114724397659302
    },
    {
      "answer": "1990s",
      "score": 0.8244718909263611
    }
  ],
  "4133": [
    {
      "answer": "Fresno and B streets",
      "score": 0.9899576306343079
    }
  ],
  "4134": [
    {
      "answer": "Cargill Meat Solutions",
      "score": 0.9804441332817078
    },
    {
      "answer": "Foster Farms",
      "score": 0.97347092628479
    }
  ],
  "4135": [
    {
      "answer": "West Side",
      "score": 0.9419870972633362
    }
  ],
  "4136": [
    {
      "answer": "very little",
      "score": 0.9874063730239868
    }
  ],
  "4137": [
    {
      "answer": "Fresno Housing Authority",
      "score": 0.6489881277084351
    },
    {
      "answer": "US Department of Housing and Urban Development",
      "score": 0.5891258120536804
    }
  ],
  "4138": [
    {
      "answer": "Fresno and B streets",
      "score": 0.9581320881843567
    }
  ],
  "4139": [
    {
      "answer": "western edge of the neighborhood",
      "score": 0.8927627801895142
    }
  ],
  "4140": [
    {
      "answer": "stench",
      "score": 0.9690253138542175
    }
  ],
  "4141": [
    {
      "answer": "1990s",
      "score": 0.9883933663368225
    }
  ],
  "4142": [
    {
      "answer": "Ralph Woodward",
      "score": 0.9843652248382568
    }
  ],
  "4143": [
    {
      "answer": "300",
      "score": 0.9840475916862488
    }
  ],
  "4144": [
    {
      "answer": "2,500",
      "score": 0.9797272682189941
    }
  ],
  "4145": [
    {
      "answer": "22",
      "score": 0.9742158055305481
    }
  ],
  "4146": [
    {
      "answer": "April through October",
      "score": 0.9733412265777588
    },
    {
      "answer": "November through March",
      "score": 0.9241336584091187
    }
  ],
  "4147": [
    {
      "answer": "1968",
      "score": 0.9712533950805664
    }
  ],
  "4148": [
    {
      "answer": "235 acres",
      "score": 0.6976770162582397
    },
    {
      "answer": "300 acres",
      "score": 0.7390066385269165
    }
  ],
  "4149": [],
  "4150": [
    {
      "answer": "2,500",
      "score": 0.8593204021453857
    }
  ],
  "4151": [
    {
      "answer": "April through October, 6am to 10pm and November through March, 6am to 7pm",
      "score": 0.883732259273529
    }
  ],
  "4152": [
    {
      "answer": "1946",
      "score": 0.979598879814148
    }
  ],
  "4153": [
    {
      "answer": "William Smilie",
      "score": 0.9973399639129639
    }
  ],
  "4154": [
    {
      "answer": "Sierra Sky Park",
      "score": 0.9033908843994141
    },
    {
      "answer": "Sierra Sky Park",
      "score": 0.7000064849853516
    }
  ],
  "4155": [
    {
      "answer": "automobiles",
      "score": 0.9914516806602478
    }
  ],
  "4156": [
    {
      "answer": "numerous such communities across the United States and around the world",
      "score": 0.790056586265564
    }
  ],
  "4157": [
    {
      "answer": "1946",
      "score": 0.9590647220611572
    }
  ],
  "4158": [
    {
      "answer": "William Smilie",
      "score": 0.997273325920105
    }
  ],
  "4159": [
    {
      "answer": "personal aircraft",
      "score": 0.9608076810836792
    }
  ],
  "4160": [
    {
      "answer": "personal aircraft and automobiles to share certain roads",
      "score": 0.7350046634674072
    }
  ],
  "4161": [
    {
      "answer": "Sierra Sky Park",
      "score": 0.9587666392326355
    }
  ],
  "4162": [
    {
      "answer": "hot and dry",
      "score": 0.7352434992790222
    }
  ],
  "4163": [
    {
      "answer": "July",
      "score": 0.9908310770988464
    },
    {
      "answer": "July",
      "score": 0.8420268893241882
    },
    {
      "answer": "July",
      "score": 0.8487996459007263
    }
  ],
  "4164": [
    {
      "answer": "11.5 inches",
      "score": 0.9734635353088379
    }
  ],
  "4165": [
    {
      "answer": "northwest",
      "score": 0.9951125979423523
    }
  ],
  "4166": [
    {
      "answer": "December",
      "score": 0.6241811513900757
    },
    {
      "answer": "December",
      "score": 0.9054213166236877
    },
    {
      "answer": "January",
      "score": 0.9549577832221985
    },
    {
      "answer": "February",
      "score": 0.969614565372467
    }
  ],
  "4167": [
    {
      "answer": "three or four",
      "score": 0.8701184988021851
    }
  ],
  "4168": [
    {
      "answer": "46",
      "score": 0.9505055546760559
    }
  ],
  "4169": [
    {
      "answer": "southeastern",
      "score": 0.9859511852264404
    }
  ],
  "4170": [
    {
      "answer": "83.0 \u00b0F (28.3 \u00b0C)",
      "score": 0.6725752353668213
    }
  ],
  "4171": [
    {
      "answer": "three or four",
      "score": 0.8931879997253418
    }
  ],
  "4172": [
    {
      "answer": "115 \u00b0F (46.1 \u00b0C)",
      "score": 0.8522503972053528
    }
  ],
  "4173": [
    {
      "answer": "January 6, 1913",
      "score": 0.9936099052429199
    }
  ],
  "4174": [
    {
      "answer": "1885",
      "score": 0.9543144106864929
    },
    {
      "answer": "1885",
      "score": 0.6915560960769653
    }
  ],
  "4175": [
    {
      "answer": "2.2 inches",
      "score": 0.9616867303848267
    }
  ],
  "4176": [
    {
      "answer": "3.55 inches (90.2 mm)",
      "score": 0.9664966464042664
    }
  ],
  "4177": [
    {
      "answer": "17 \u00b0F (\u22128 \u00b0C)",
      "score": 0.6635036468505859
    }
  ],
  "4178": [],
  "4179": [],
  "4180": [],
  "4181": [
    {
      "answer": "2.2 inches",
      "score": 0.924144983291626
    }
  ],
  "4182": [
    {
      "answer": "494,665",
      "score": 0.9784597754478455
    }
  ],
  "4183": [
    {
      "answer": "49.6%",
      "score": 0.9807627201080322
    }
  ],
  "4184": [
    {
      "answer": "8,525",
      "score": 0.9535279273986816
    }
  ],
  "4185": [
    {
      "answer": "30.0%",
      "score": 0.982168436050415
    }
  ],
  "4186": [
    {
      "answer": "4,404.5",
      "score": 0.9810594916343689
    }
  ],
  "4187": [
    {
      "answer": "494,665",
      "score": 0.882217288017273
    }
  ],
  "4188": [
    {
      "answer": "8,525",
      "score": 0.8904643058776855
    }
  ],
  "4189": [
    {
      "answer": "1.2%",
      "score": 0.9276629090309143
    }
  ],
  "4190": [
    {
      "answer": "Non-Hispanic Whites",
      "score": 0.9715991616249084
    }
  ],
  "4191": [
    {
      "answer": "4,404.5",
      "score": 0.9656844139099121
    }
  ],
  "4192": [
    {
      "answer": "68,511",
      "score": 0.9431049823760986
    }
  ],
  "4193": [
    {
      "answer": "19.3%",
      "score": 0.9940943121910095
    }
  ],
  "4194": [
    {
      "answer": "1,388",
      "score": 0.9632185697555542
    }
  ],
  "4195": [
    {
      "answer": "3.07",
      "score": 0.9079313278198242
    },
    {
      "answer": "3.62",
      "score": 0.7623493075370789
    }
  ],
  "4196": [
    {
      "answer": "3.07",
      "score": 0.9817147254943848
    }
  ],
  "4197": [
    {
      "answer": "43.3%",
      "score": 0.9953615665435791
    }
  ],
  "4198": [
    {
      "answer": "3.07",
      "score": 0.8691661357879639
    },
    {
      "answer": "3.62",
      "score": 0.738694429397583
    }
  ],
  "4199": [
    {
      "answer": "68,511",
      "score": 0.579079806804657
    },
    {
      "answer": "12,843",
      "score": 0.9720783233642578
    }
  ],
  "4200": [
    {
      "answer": "1,388",
      "score": 0.9824578762054443
    }
  ],
  "4201": [
    {
      "answer": "12,344",
      "score": 0.9802653789520264
    }
  ],
  "4202": [
    {
      "answer": "427,652",
      "score": 0.9801312685012817
    }
  ],
  "4203": [
    {
      "answer": "149,025",
      "score": 0.9891587495803833
    }
  ],
  "4204": [
    {
      "answer": "8.4%",
      "score": 0.9597206711769104
    }
  ],
  "4205": [
    {
      "answer": "a third",
      "score": 0.9854646921157837
    }
  ],
  "4206": [
    {
      "answer": "4,097.9",
      "score": 0.988817036151886
    }
  ],
  "4207": [
    {
      "answer": "Hmong",
      "score": 0.9934211373329163
    }
  ],
  "4208": [
    {
      "answer": "4,097.9",
      "score": 0.9696192145347595
    }
  ],
  "4209": [
    {
      "answer": "39.9%",
      "score": 0.968960165977478
    }
  ],
  "4210": [
    {
      "answer": "a third",
      "score": 0.9870154857635498
    }
  ],
  "4211": [
    {
      "answer": "a third",
      "score": 0.9594204425811768
    }
  ],
  "4212": [
    {
      "answer": "To avoid interference with existing VHF television stations in the San Francisco Bay Area and those planned for Chico, Sacramento, Salinas, and Stockton",
      "score": 0.9931140542030334
    }
  ],
  "4213": [
    {
      "answer": "KMJ-TV",
      "score": 0.9923560619354248
    }
  ],
  "4214": [
    {
      "answer": "June 1, 1953",
      "score": 0.9957988858222961
    }
  ],
  "4215": [
    {
      "answer": "KSEE",
      "score": 0.9892788529396057
    }
  ],
  "4216": [
    {
      "answer": "KGPE",
      "score": 0.9704271554946899
    }
  ],
  "4217": [
    {
      "answer": "UHF",
      "score": 0.9394962787628174
    }
  ],
  "4218": [
    {
      "answer": "KMJ-TV",
      "score": 0.9402429461479187
    }
  ],
  "4219": [
    {
      "answer": "June 1, 1953",
      "score": 0.9440773725509644
    }
  ],
  "4220": [
    {
      "answer": "KMJ-TV",
      "score": 0.7648391127586365
    }
  ],
  "4221": [
    {
      "answer": "KMPH",
      "score": 0.9585015177726746
    }
  ],
  "4222": [
    {
      "answer": "State Route 99",
      "score": 0.9466812610626221
    },
    {
      "answer": "State Route 41 (Yosemite Freeway/Eisenhower Freeway)",
      "score": 0.642051637172699
    }
  ],
  "4223": [
    {
      "answer": "Sierra Freeway",
      "score": 0.9869816303253174
    }
  ],
  "4224": [
    {
      "answer": "State Route 41",
      "score": 0.8698620200157166
    },
    {
      "answer": "Yosemite Freeway/Eisenhower Freeway",
      "score": 0.6401090025901794
    }
  ],
  "4225": [
    {
      "answer": "west",
      "score": 0.9905230402946472
    }
  ],
  "4226": [
    {
      "answer": "Kings Canyon Freeway",
      "score": 0.5415612459182739
    }
  ],
  "4227": [
    {
      "answer": "Sierra Freeway",
      "score": 0.9063359498977661
    }
  ],
  "4228": [
    {
      "answer": "Mendota",
      "score": 0.8743676543235779
    }
  ],
  "4229": [
    {
      "answer": "Kings Canyon National Park",
      "score": 0.9496495723724365
    }
  ],
  "4230": [
    {
      "answer": "Mendota",
      "score": 0.9874308109283447
    }
  ],
  "4231": [
    {
      "answer": "Fresno",
      "score": 0.9876853227615356
    }
  ],
  "4232": [
    {
      "answer": "1950s",
      "score": 0.9912047982215881
    }
  ],
  "4233": [
    {
      "answer": "State Route 99",
      "score": 0.8050095438957214
    }
  ],
  "4234": [
    {
      "answer": "rapidly raising population and traffic in cities along SR 99",
      "score": 0.9251766204833984
    },
    {
      "answer": "desirability of Federal funding",
      "score": 0.9365492463111877
    }
  ],
  "4235": [
    {
      "answer": "Fresno",
      "score": 0.5893580913543701
    }
  ],
  "4236": [
    {
      "answer": "1950s",
      "score": 0.9884995818138123
    }
  ],
  "4237": [
    {
      "answer": "traffic",
      "score": 0.9633215665817261
    }
  ],
  "4238": [
    {
      "answer": "State Route 99",
      "score": 0.5902078747749329
    },
    {
      "answer": "SR 99",
      "score": 0.782338559627533
    }
  ],
  "4239": [
    {
      "answer": "west",
      "score": 0.9387562870979309
    }
  ],
  "4240": [
    {
      "answer": "Amtrak San Joaquins",
      "score": 0.9864928722381592
    }
  ],
  "4241": [
    {
      "answer": "Downtown Fresno",
      "score": 0.9630922079086304
    }
  ],
  "4242": [
    {
      "answer": "Burlington Northern Santa Fe Railway",
      "score": 0.9704524278640747
    },
    {
      "answer": "Union Pacific Railroad",
      "score": 0.9679098129272461
    }
  ],
  "4243": [
    {
      "answer": "San Joaquin Valley Railroad",
      "score": 0.9652234315872192
    }
  ],
  "4244": [
    {
      "answer": "Fresno",
      "score": 0.8156211376190186
    },
    {
      "answer": "Fresno",
      "score": 0.7219631671905518
    },
    {
      "answer": "Fresno",
      "score": 0.9442899227142334
    }
  ],
  "4245": [
    {
      "answer": "Amtrak San Joaquins",
      "score": 0.9535974860191345
    }
  ],
  "4246": [
    {
      "answer": "Burlington Northern Santa Fe Railway",
      "score": 0.910226047039032
    },
    {
      "answer": "Union Pacific Railroad",
      "score": 0.9246561527252197
    }
  ],
  "4247": [],
  "4248": [
    {
      "answer": "San Joaquin Valley Railroad",
      "score": 0.9590824842453003
    }
  ],
  "4249": [
    {
      "answer": "Southern Pacific",
      "score": 0.6351026296615601
    }
  ],
  "4250": [],
  "4251": [],
  "4252": [],
  "4253": [],
  "4254": [],
  "4255": [
    {
      "answer": "to provide a fault-tolerant, efficient routing method for telecommunication messages",
      "score": 0.9835737943649292
    }
  ],
  "4256": [],
  "4257": [
    {
      "answer": "Distributed Adaptive Message Block Switching",
      "score": 0.9899868965148926
    }
  ],
  "4258": [
    {
      "answer": "provide a fault-tolerant, efficient routing method for telecommunication messages",
      "score": 0.9820785522460938
    }
  ],
  "4259": [
    {
      "answer": "funded by the US Department of Defense",
      "score": 0.8752629160881042
    }
  ],
  "4260": [],
  "4261": [
    {
      "answer": "the development of telecommunications",
      "score": 0.6899147033691406
    }
  ],
  "4262": [
    {
      "answer": "a fault-tolerant, efficient routing method for telecommunication messages",
      "score": 0.9307050704956055
    }
  ],
  "4263": [
    {
      "answer": "Donald Davies",
      "score": 0.9326308965682983
    }
  ],
  "4264": [
    {
      "answer": "Paul Baran",
      "score": 0.7367744445800781
    }
  ],
  "4265": [
    {
      "answer": "fault-tolerant, efficient routing method for telecommunication messages",
      "score": 0.968107283115387
    }
  ],
  "4266": [
    {
      "answer": "Paul Baran",
      "score": 0.9087985754013062
    }
  ],
  "4267": [
    {
      "answer": "provide a fault-tolerant, efficient routing method for telecommunication messages",
      "score": 0.82622891664505
    }
  ],
  "4268": [
    {
      "answer": "Donald Davies",
      "score": 0.9440909624099731
    }
  ],
  "4269": [
    {
      "answer": "US Department of Defense",
      "score": 0.7762513160705566
    }
  ],
  "4270": [
    {
      "answer": "US Department of Defense",
      "score": 0.8502296209335327
    }
  ],
  "4271": [
    {
      "answer": "contrasted and contradicted the theretofore established principles of pre-allocation of network bandwidth",
      "score": 0.9325310587882996
    }
  ],
  "4272": [],
  "4273": [
    {
      "answer": "provide a fault-tolerant, efficient routing method for telecommunication messages",
      "score": 0.9264920353889465
    }
  ],
  "4274": [
    {
      "answer": "RAND Corporation",
      "score": 0.6224073171615601
    },
    {
      "answer": "National Physical Laboratory (United Kingdom)",
      "score": 0.8774335384368896
    }
  ],
  "4275": [
    {
      "answer": "Paul Baran",
      "score": 0.7159088850021362
    },
    {
      "answer": "Donald Davies",
      "score": 0.5763319730758667
    }
  ],
  "4276": [
    {
      "answer": "development of telecommunications in the Bell System",
      "score": 0.985853910446167
    }
  ],
  "4277": [],
  "4278": [],
  "4279": [],
  "4280": [],
  "4281": [],
  "4282": [],
  "4283": [],
  "4284": [],
  "4285": [],
  "4286": [
    {
      "answer": "a fee per unit of information transmitted",
      "score": 0.7764612436294556
    }
  ],
  "4287": [
    {
      "answer": "a fee per unit of information transmitted",
      "score": 0.8193889260292053
    }
  ],
  "4288": [],
  "4289": [],
  "4290": [
    {
      "answer": "constant",
      "score": 0.981438934803009
    }
  ],
  "4291": [],
  "4292": [
    {
      "answer": "a fee per unit of information transmitted",
      "score": 0.8098759055137634
    }
  ],
  "4293": [],
  "4294": [],
  "4295": [],
  "4296": [],
  "4297": [],
  "4298": [
    {
      "answer": "characters, packets, or messages",
      "score": 0.8998448252677917
    }
  ],
  "4299": [],
  "4300": [],
  "4301": [],
  "4302": [],
  "4303": [],
  "4304": [],
  "4305": [],
  "4306": [
    {
      "answer": "Packet mode",
      "score": 0.9897451400756836
    }
  ],
  "4307": [
    {
      "answer": "multiple access scheme",
      "score": 0.9558648467063904
    }
  ],
  "4308": [
    {
      "answer": "shared physical",
      "score": 0.9771206378936768
    }
  ],
  "4309": [
    {
      "answer": "packet switches or routers",
      "score": 0.8100861310958862
    }
  ],
  "4310": [
    {
      "answer": "multiple access scheme",
      "score": 0.5685432553291321
    }
  ],
  "4311": [
    {
      "answer": "multiple access scheme",
      "score": 0.9584708213806152
    }
  ],
  "4312": [
    {
      "answer": "multiple access scheme",
      "score": 0.9818457365036011
    }
  ],
  "4313": [
    {
      "answer": "fair queuing, traffic shaping",
      "score": 0.8484622836112976
    },
    {
      "answer": "weighted fair queuing or leaky bucket",
      "score": 0.8602358102798462
    }
  ],
  "4314": [
    {
      "answer": "intermediate forwarding nodes",
      "score": 0.8020137548446655
    }
  ],
  "4315": [],
  "4316": [],
  "4317": [
    {
      "answer": "fair queuing, traffic shaping",
      "score": 0.7175406813621521
    },
    {
      "answer": "weighted fair queuing",
      "score": 0.7276801466941833
    }
  ],
  "4318": [],
  "4319": [
    {
      "answer": "weighted fair queuing",
      "score": 0.8668040633201599
    }
  ],
  "4320": [],
  "4321": [
    {
      "answer": "Packets are normally forwarded by intermediate network nodes asynchronously using first-in, first-out buffering",
      "score": 0.8355890512466431
    }
  ],
  "4322": [
    {
      "answer": "first-in, first-out buffering",
      "score": 0.9783154726028442
    }
  ],
  "4323": [],
  "4324": [
    {
      "answer": "first-in, first-out buffering",
      "score": 0.9654866456985474
    }
  ],
  "4325": [
    {
      "answer": "weighted fair queuing",
      "score": 0.92167729139328
    },
    {
      "answer": "leaky bucket",
      "score": 0.954266369342804
    }
  ],
  "4326": [],
  "4327": [],
  "4328": [
    {
      "answer": "use of a decentralized network with multiple paths between any two points",
      "score": 0.9652144312858582
    },
    {
      "answer": "dividing user messages into message blocks",
      "score": 0.9660449028015137
    },
    {
      "answer": "delivery of these messages by store and forward switching",
      "score": 0.9669188261032104
    }
  ],
  "4329": [],
  "4330": [],
  "4331": [],
  "4332": [],
  "4333": [],
  "4334": [
    {
      "answer": "distributed adaptive message block switching",
      "score": 0.9469038248062134
    }
  ],
  "4335": [
    {
      "answer": "use of a decentralized network with multiple paths between any two points",
      "score": 0.7021349668502808
    },
    {
      "answer": "delivery of these messages by store and forward switching",
      "score": 0.6658338308334351
    }
  ],
  "4336": [
    {
      "answer": "three",
      "score": 0.9748929738998413
    }
  ],
  "4337": [
    {
      "answer": "Baran",
      "score": 0.6634462475776672
    }
  ],
  "4338": [
    {
      "answer": "store and forward switching",
      "score": 0.9247920513153076
    }
  ],
  "4339": [
    {
      "answer": "Baran",
      "score": 0.9517588019371033
    }
  ],
  "4340": [],
  "4341": [
    {
      "answer": "distributed adaptive message block switching",
      "score": 0.8114629983901978
    }
  ],
  "4342": [
    {
      "answer": "store and forward switching",
      "score": 0.9956378936767578
    }
  ],
  "4343": [],
  "4344": [],
  "4345": [
    {
      "answer": "RAND report P-2626",
      "score": 0.834767758846283
    }
  ],
  "4346": [
    {
      "answer": "RAND report P-2626",
      "score": 0.5753973722457886
    }
  ],
  "4347": [],
  "4348": [],
  "4349": [
    {
      "answer": "distributed adaptive message block switching",
      "score": 0.9719831347465515
    }
  ],
  "4350": [
    {
      "answer": "store and forward switching",
      "score": 0.9968331456184387
    }
  ],
  "4351": [
    {
      "answer": "a general architecture for a large-scale, distributed, survivable communications network",
      "score": 0.9275020360946655
    }
  ],
  "4352": [
    {
      "answer": "distributed adaptive message block switching",
      "score": 0.9034902453422546
    }
  ],
  "4353": [
    {
      "answer": "decentralized network with multiple paths between any two points",
      "score": 0.8218782544136047
    }
  ],
  "4354": [],
  "4355": [
    {
      "answer": "packet switching",
      "score": 0.9658145904541016
    }
  ],
  "4356": [],
  "4357": [],
  "4358": [],
  "4359": [
    {
      "answer": "packet switching",
      "score": 0.9475516080856323
    }
  ],
  "4360": [],
  "4361": [
    {
      "answer": "Donald Davies",
      "score": 0.990766704082489
    }
  ],
  "4362": [
    {
      "answer": "UK",
      "score": 0.8307424783706665
    },
    {
      "answer": "UK",
      "score": 0.7160329818725586
    }
  ],
  "4363": [],
  "4364": [
    {
      "answer": "message routing methodology",
      "score": 0.7008115649223328
    },
    {
      "answer": "packet switching",
      "score": 0.7662861943244934
    }
  ],
  "4365": [
    {
      "answer": "the same message routing methodology as developed by Baran",
      "score": 0.7872018814086914
    }
  ],
  "4366": [],
  "4367": [],
  "4368": [
    {
      "answer": "packet switching",
      "score": 0.5601340532302856
    }
  ],
  "4369": [],
  "4370": [
    {
      "answer": "packet switching",
      "score": 0.9126068353652954
    }
  ],
  "4371": [
    {
      "answer": "ARPANET",
      "score": 0.9884146451950073
    }
  ],
  "4372": [
    {
      "answer": "nationwide network in the UK",
      "score": 0.9528195261955261
    }
  ],
  "4373": [
    {
      "answer": "a person from the Ministry of Defence",
      "score": 0.8733366131782532
    }
  ],
  "4374": [
    {
      "answer": "packet switching",
      "score": 0.9213166236877441
    }
  ],
  "4375": [],
  "4376": [],
  "4377": [],
  "4378": [],
  "4379": [
    {
      "answer": "The packets are routed individually",
      "score": 0.8274427652359009
    },
    {
      "answer": "different paths",
      "score": 0.7031888961791992
    }
  ],
  "4380": [
    {
      "answer": "At the destination, the original message/data is reassembled in the correct order, based on the packet sequence number.",
      "score": 0.8358686566352844
    }
  ],
  "4381": [
    {
      "answer": "The packets are routed individually",
      "score": 0.5912600755691528
    },
    {
      "answer": "Each packet is labeled with a destination address, source address, and port numbers.",
      "score": 0.746184229850769
    }
  ],
  "4382": [
    {
      "answer": "destination",
      "score": 0.9803920388221741
    }
  ],
  "4383": [
    {
      "answer": "virtual circuit or byte stream",
      "score": 0.8779909014701843
    }
  ],
  "4384": [],
  "4385": [
    {
      "answer": "At the destination, the original message/data is reassembled in the correct order, based on the packet sequence number",
      "score": 0.9040624499320984
    }
  ],
  "4386": [],
  "4387": [
    {
      "answer": "At the destination, the original message/data is reassembled in the correct order, based on the packet sequence number",
      "score": 0.8463007807731628
    }
  ],
  "4388": [
    {
      "answer": "destination address",
      "score": 0.9727805852890015
    },
    {
      "answer": "sequence number",
      "score": 0.8596885204315186
    }
  ],
  "4389": [
    {
      "answer": "The packets are routed individually",
      "score": 0.8435068130493164
    }
  ],
  "4390": [
    {
      "answer": "This precludes the need for a dedicated path to help the packet find its way to its destination",
      "score": 0.8711901903152466
    }
  ],
  "4391": [
    {
      "answer": "complete addressing information",
      "score": 0.9628586769104004
    }
  ],
  "4392": [],
  "4393": [
    {
      "answer": "The packets include a connection identifier",
      "score": 0.7454994916915894
    }
  ],
  "4394": [],
  "4395": [
    {
      "answer": "small",
      "score": 0.9553011059761047
    }
  ],
  "4396": [
    {
      "answer": "Connection-oriented transmission",
      "score": 0.8786122798919678
    }
  ],
  "4397": [
    {
      "answer": "The packets include a connection identifier rather than address information and are negotiated between endpoints",
      "score": 0.8018017411231995
    }
  ],
  "4398": [
    {
      "answer": "connection id",
      "score": 0.9407830834388733
    }
  ],
  "4399": [
    {
      "answer": "connection id",
      "score": 0.9652929902076721
    }
  ],
  "4400": [
    {
      "answer": "service parameters",
      "score": 0.9788839817047119
    }
  ],
  "4401": [],
  "4402": [
    {
      "answer": "Acceptable values for service parameters may be negotiated",
      "score": 0.9193253517150879
    }
  ],
  "4403": [],
  "4404": [
    {
      "answer": "Address information is only transferred to each node during the connection set-up phase",
      "score": 0.7698508501052856
    },
    {
      "answer": "Acceptable values for service parameters may be negotiated.",
      "score": 0.6721906661987305
    }
  ],
  "4405": [],
  "4406": [
    {
      "answer": "connection set-up phase",
      "score": 0.9554373025894165
    }
  ],
  "4407": [
    {
      "answer": "setup phase in each involved node before any packet is transferred",
      "score": 0.916346549987793
    }
  ],
  "4408": [
    {
      "answer": "sequence number",
      "score": 0.9035104513168335
    }
  ],
  "4409": [
    {
      "answer": "connection identifier",
      "score": 0.9512224793434143
    }
  ],
  "4410": [
    {
      "answer": "connection-oriented operations",
      "score": 0.7191015481948853
    }
  ],
  "4411": [],
  "4412": [],
  "4413": [],
  "4414": [
    {
      "answer": "connection-oriented operations",
      "score": 0.7623800039291382
    }
  ],
  "4415": [
    {
      "answer": "data link layer",
      "score": 0.9865902662277222
    },
    {
      "answer": "data link layer",
      "score": 0.6572595834732056
    }
  ],
  "4416": [
    {
      "answer": "X.25",
      "score": 0.6981850862503052
    },
    {
      "answer": "handshake",
      "score": 0.674304723739624
    }
  ],
  "4417": [
    {
      "answer": "X.25",
      "score": 0.9496582746505737
    }
  ],
  "4418": [
    {
      "answer": "UNI",
      "score": 0.7755351066589355
    },
    {
      "answer": "UNI",
      "score": 0.7499574422836304
    },
    {
      "answer": "UNI",
      "score": 0.9043489694595337
    },
    {
      "answer": "UNI",
      "score": 0.6874938607215881
    }
  ],
  "4419": [
    {
      "answer": "X.25",
      "score": 0.615005373954773
    },
    {
      "answer": "between the communicating parties",
      "score": 0.822576642036438
    }
  ],
  "4420": [
    {
      "answer": "conventional HDLC-type link management procedures",
      "score": 0.8373484015464783
    }
  ],
  "4421": [
    {
      "answer": "between nodes on a link",
      "score": 0.9312906265258789
    }
  ],
  "4422": [
    {
      "answer": "1980s",
      "score": 0.9858559370040894
    }
  ],
  "4423": [
    {
      "answer": "Frame Relay, by virtue of having no network layer procedures is connection-oriented at layer two, by using the HDLC/LAPD/LAPB Set Asynchronous Balanced Mode (SABM)",
      "score": 0.8789136409759521
    }
  ],
  "4424": [
    {
      "answer": "1969",
      "score": 0.9273174405097961
    }
  ],
  "4425": [],
  "4426": [
    {
      "answer": "sequenced delivery of data to the host",
      "score": 0.8260264992713928
    }
  ],
  "4427": [],
  "4428": [
    {
      "answer": "twenty",
      "score": 0.9941955208778381
    }
  ],
  "4429": [
    {
      "answer": "datagram system",
      "score": 0.5711969137191772
    },
    {
      "answer": "virtual call system",
      "score": 0.9442526698112488
    }
  ],
  "4430": [
    {
      "answer": "host interface",
      "score": 0.8408181667327881
    }
  ],
  "4431": [
    {
      "answer": "virtual call system",
      "score": 0.9765956401824951
    }
  ],
  "4432": [
    {
      "answer": "datagram system",
      "score": 0.7680805325508118
    },
    {
      "answer": "virtual call system",
      "score": 0.7028948068618774
    }
  ],
  "4433": [
    {
      "answer": "twenty",
      "score": 0.9886770248413086
    }
  ],
  "4434": [
    {
      "answer": "sequenced delivery of data",
      "score": 0.9834732413291931
    }
  ],
  "4435": [
    {
      "answer": "X.25",
      "score": 0.9901387691497803
    }
  ],
  "4436": [
    {
      "answer": "ensure orderly delivery of packets",
      "score": 0.9357110857963562
    }
  ],
  "4437": [],
  "4438": [],
  "4439": [],
  "4440": [],
  "4441": [
    {
      "answer": "AppleTalk",
      "score": 0.9400162100791931
    },
    {
      "answer": "AppleTalk",
      "score": 0.7471360564231873
    },
    {
      "answer": "AppleTalk",
      "score": 0.8233899474143982
    }
  ],
  "4442": [],
  "4443": [
    {
      "answer": "included features that allowed local area networks to be established ad hoc without the requirement for a centralized router or server",
      "score": 0.940068244934082
    },
    {
      "answer": "automatically assigned addresses, updated the distributed namespace, and configured any required inter-network routing",
      "score": 0.5649169683456421
    }
  ],
  "4444": [],
  "4445": [],
  "4446": [
    {
      "answer": "Apple Macintosh computers",
      "score": 0.9150971174240112
    }
  ],
  "4447": [
    {
      "answer": "ad hoc",
      "score": 0.9849138259887695
    }
  ],
  "4448": [
    {
      "answer": "plug-n-play",
      "score": 0.8568423390388489
    }
  ],
  "4449": [
    {
      "answer": "AppleTalk",
      "score": 0.9484057426452637
    },
    {
      "answer": "AppleTalk",
      "score": 0.84555983543396
    },
    {
      "answer": "AppleTalk",
      "score": 0.895391047000885
    }
  ],
  "4450": [],
  "4451": [],
  "4452": [],
  "4453": [],
  "4454": [
    {
      "answer": "CYCLADES",
      "score": 0.988714873790741
    }
  ],
  "4455": [
    {
      "answer": "CYCLADES",
      "score": 0.945541501045227
    }
  ],
  "4456": [
    {
      "answer": "CYCLADES",
      "score": 0.8118955492973328
    }
  ],
  "4457": [
    {
      "answer": "Louis Pouzin",
      "score": 0.9343927502632141
    }
  ],
  "4458": [
    {
      "answer": "ARPANET design",
      "score": 0.9692761898040771
    }
  ],
  "4459": [
    {
      "answer": "Louis Pouzin",
      "score": 0.9950218796730042
    }
  ],
  "4460": [
    {
      "answer": "to explore alternatives to the early ARPANET design",
      "score": 0.9893199801445007
    }
  ],
  "4461": [
    {
      "answer": "reliable delivery of data",
      "score": 0.9931039214134216
    }
  ],
  "4462": [
    {
      "answer": "make the hosts responsible for reliable delivery of data",
      "score": 0.6297191977500916
    },
    {
      "answer": "unreliable datagrams",
      "score": 0.941991925239563
    },
    {
      "answer": "end-to-end protocol mechanisms",
      "score": 0.8122138977050781
    }
  ],
  "4463": [],
  "4464": [],
  "4465": [],
  "4466": [],
  "4467": [
    {
      "answer": "Digital Equipment Corporation",
      "score": 0.781822919845581
    },
    {
      "answer": "Digital Equipment Corporation",
      "score": 0.585529625415802
    }
  ],
  "4468": [
    {
      "answer": "peer-to-peer network architectures",
      "score": 0.8080911040306091
    }
  ],
  "4469": [
    {
      "answer": "seven-layer OSI-compliant networking protocol",
      "score": 0.6430069804191589
    }
  ],
  "4470": [
    {
      "answer": "network protocols",
      "score": 0.5613799095153809
    }
  ],
  "4471": [
    {
      "answer": "Linux",
      "score": 0.9847203493118286
    }
  ],
  "4472": [
    {
      "answer": "to connect two PDP-11 minicomputers",
      "score": 0.9828260540962219
    }
  ],
  "4473": [
    {
      "answer": "three",
      "score": 0.9352824091911316
    }
  ],
  "4474": [
    {
      "answer": "peer-to-peer network architectures",
      "score": 0.9347902536392212
    }
  ],
  "4475": [
    {
      "answer": "Digital Equipment Corporation",
      "score": 0.9443048238754272
    },
    {
      "answer": "Digital Equipment Corporation",
      "score": 0.9764103889465332
    }
  ],
  "4476": [
    {
      "answer": "seven-layer OSI-compliant networking protocol",
      "score": 0.9295027256011963
    }
  ],
  "4477": [],
  "4478": [],
  "4479": [],
  "4480": [
    {
      "answer": "a time-sharing system",
      "score": 0.7958912253379822
    }
  ],
  "4481": [],
  "4482": [
    {
      "answer": "time-sharing system",
      "score": 0.9673811793327332
    }
  ],
  "4483": [
    {
      "answer": "computer time-sharing service",
      "score": 0.9752049446105957
    }
  ],
  "4484": [
    {
      "answer": "a data network",
      "score": 0.7183890342712402
    },
    {
      "answer": "computer time-sharing service",
      "score": 0.8254267573356628
    }
  ],
  "4485": [
    {
      "answer": "time-sharing system",
      "score": 0.8956488966941833
    }
  ],
  "4486": [
    {
      "answer": "computer service bureaus",
      "score": 0.9891526103019714
    }
  ],
  "4487": [
    {
      "answer": "Dartmouth",
      "score": 0.9960895776748657
    }
  ],
  "4488": [
    {
      "answer": "time-sharing system",
      "score": 0.60533607006073
    }
  ],
  "4489": [],
  "4490": [],
  "4491": [],
  "4492": [
    {
      "answer": "Merit Network, Inc.",
      "score": 0.5803279280662537
    },
    {
      "answer": "computer networking",
      "score": 0.6669741868972778
    }
  ],
  "4493": [
    {
      "answer": "University of Michigan in Ann Arbor",
      "score": 0.8559650182723999
    },
    {
      "answer": "Wayne State University in Detroit",
      "score": 0.6563202738761902
    }
  ],
  "4494": [
    {
      "answer": "Michigan Educational Research Information Triad",
      "score": 0.8926942944526672
    }
  ],
  "4495": [],
  "4496": [
    {
      "answer": "additional public universities",
      "score": 0.8089579939842224
    }
  ],
  "4497": [
    {
      "answer": "Michigan State University",
      "score": 0.9740599393844604
    }
  ],
  "4498": [
    {
      "answer": "1966",
      "score": 0.9065070748329163
    }
  ],
  "4499": [
    {
      "answer": "to explore computer networking between three of Michigan's public universities as a means to help the state's educational and economic development",
      "score": 0.9641346335411072
    }
  ],
  "4500": [
    {
      "answer": "NSFNET",
      "score": 0.9758743643760681
    }
  ],
  "4501": [
    {
      "answer": "terminal to host connections",
      "score": 0.8807044625282288
    },
    {
      "answer": "host to host batch connections",
      "score": 0.8485226035118103
    },
    {
      "answer": "interactive file transfer",
      "score": 0.7964843511581421
    },
    {
      "answer": "gateways to the Tymnet and Telenet public data networks",
      "score": 0.8385835289955139
    },
    {
      "answer": "X.25 host attachments",
      "score": 0.8489346504211426
    },
    {
      "answer": "gateways to X.25 data networks",
      "score": 0.8416567444801331
    },
    {
      "answer": "Ethernet attached hosts",
      "score": 0.8041303157806396
    },
    {
      "answer": "TCP/IP",
      "score": 0.6471422910690308
    }
  ],
  "4502": [],
  "4503": [],
  "4504": [],
  "4505": [],
  "4506": [],
  "4507": [
    {
      "answer": "Larry Roberts",
      "score": 0.9629836082458496
    }
  ],
  "4508": [
    {
      "answer": "a means of making ARPANET technology public",
      "score": 0.8619877099990845
    }
  ],
  "4509": [
    {
      "answer": "Telenet",
      "score": 0.861842155456543
    },
    {
      "answer": "Telenet",
      "score": 0.7952480316162109
    },
    {
      "answer": "Telenet",
      "score": 0.8580800890922546
    }
  ],
  "4510": [
    {
      "answer": "GTE",
      "score": 0.9275745153427124
    }
  ],
  "4511": [
    {
      "answer": "incompatible with their future",
      "score": 0.9928767681121826
    }
  ],
  "4512": [
    {
      "answer": "ARPANET",
      "score": 0.9108575582504272
    },
    {
      "answer": "ARPANET",
      "score": 0.967081606388092
    }
  ],
  "4513": [
    {
      "answer": "Larry Roberts",
      "score": 0.9927576780319214
    }
  ],
  "4514": [
    {
      "answer": "this was incompatible with their future",
      "score": 0.980139434337616
    }
  ],
  "4515": [
    {
      "answer": "Telenet",
      "score": 0.8075835108757019
    }
  ],
  "4516": [],
  "4517": [],
  "4518": [],
  "4519": [],
  "4520": [],
  "4521": [
    {
      "answer": "virtual call packet switched technology",
      "score": 0.6888569593429565
    },
    {
      "answer": "X.25",
      "score": 0.9262698888778687
    },
    {
      "answer": "SNA/SDLC",
      "score": 0.9209357500076294
    },
    {
      "answer": "BSC",
      "score": 0.873110830783844
    },
    {
      "answer": "ASCII",
      "score": 0.8888384103775024
    },
    {
      "answer": "X.25",
      "score": 0.7528166770935059
    }
  ],
  "4522": [
    {
      "answer": "to reach locations not on the private network",
      "score": 0.9915882349014282
    }
  ],
  "4523": [
    {
      "answer": "Another employee",
      "score": 0.967839241027832
    }
  ],
  "4524": [
    {
      "answer": "Users",
      "score": 0.9704299569129944
    }
  ],
  "4525": [
    {
      "answer": "San Jose, CA",
      "score": 0.8580045104026794
    }
  ],
  "4526": [
    {
      "answer": "Tymnet",
      "score": 0.8519241809844971
    }
  ],
  "4527": [
    {
      "answer": "build their own dedicated networks",
      "score": 0.9839330911636353
    }
  ],
  "4528": [
    {
      "answer": "X.25/X.75 gateways",
      "score": 0.9059247970581055
    }
  ],
  "4529": [
    {
      "answer": "connect host computers (servers)at thousands of large companies, educational institutions, and government agencies",
      "score": 0.9039261937141418
    }
  ],
  "4530": [
    {
      "answer": "government agencies and large companies",
      "score": 0.9593124389648438
    }
  ],
  "4531": [
    {
      "answer": "two",
      "score": 0.9920752048492432
    }
  ],
  "4532": [],
  "4533": [],
  "4534": [
    {
      "answer": "DATAPAC",
      "score": 0.9680159091949463
    },
    {
      "answer": "TRANSPAC",
      "score": 0.9270644187927246
    },
    {
      "answer": "DATAPAC",
      "score": 0.5650376677513123
    }
  ],
  "4535": [
    {
      "answer": "DATAPAC clones",
      "score": 0.9830706119537354
    }
  ],
  "4536": [
    {
      "answer": "call a host on a foreign network",
      "score": 0.9329508543014526
    }
  ],
  "4537": [
    {
      "answer": "DATAPAC clones",
      "score": 0.9833021759986877
    }
  ],
  "4538": [
    {
      "answer": "X.75 and X.121",
      "score": 0.9703503251075745
    }
  ],
  "4539": [],
  "4540": [
    {
      "answer": "Bell Canada",
      "score": 0.899925947189331
    },
    {
      "answer": "Northern Telecom",
      "score": 0.9562464356422424
    },
    {
      "answer": "Northern Telecom",
      "score": 0.9137416481971741
    }
  ],
  "4541": [
    {
      "answer": "Deutsche Bundespost",
      "score": 0.9871625304222107
    }
  ],
  "4542": [
    {
      "answer": "X.25 external interface",
      "score": 0.9426382184028625
    }
  ],
  "4543": [
    {
      "answer": "interconnection of national X.25 networks",
      "score": 0.9559751749038696
    }
  ],
  "4544": [],
  "4545": [],
  "4546": [],
  "4547": [
    {
      "answer": "AUSTPAC",
      "score": 0.9359970688819885
    },
    {
      "answer": "AUSTPAC",
      "score": 0.8580368161201477
    },
    {
      "answer": "AUSTPAC",
      "score": 0.7729280591011047
    },
    {
      "answer": "AUSTPAC",
      "score": 0.7410836815834045
    }
  ],
  "4548": [
    {
      "answer": "AUSTPAC",
      "score": 0.6203854084014893
    },
    {
      "answer": "AUSTPAC",
      "score": 0.8080360889434814
    },
    {
      "answer": "AUSTPAC",
      "score": 0.698742151260376
    },
    {
      "answer": "AUSTPAC",
      "score": 0.6217431426048279
    }
  ],
  "4549": [
    {
      "answer": "dial-up terminal to a PAD",
      "score": 0.8839836120605469
    },
    {
      "answer": "linking a permanent X.25 node to the network",
      "score": 0.7635818719863892
    }
  ],
  "4550": [
    {
      "answer": "academic institutions",
      "score": 0.9766476154327393
    }
  ],
  "4551": [
    {
      "answer": "on-line betting",
      "score": 0.9360123872756958
    },
    {
      "answer": "financial applications",
      "score": 0.9782382249832153
    }
  ],
  "4552": [
    {
      "answer": "AUSTPAC",
      "score": 0.9354780912399292
    },
    {
      "answer": "AUSTPAC",
      "score": 0.813197135925293
    },
    {
      "answer": "AUSTPAC",
      "score": 0.603289783000946
    },
    {
      "answer": "AUSTPAC",
      "score": 0.5595986247062683
    }
  ],
  "4553": [
    {
      "answer": "on-line betting",
      "score": 0.6523343324661255
    },
    {
      "answer": "financial applications",
      "score": 0.8979312181472778
    },
    {
      "answer": "remote terminal access to academic institutions",
      "score": 0.6202861666679382
    }
  ],
  "4554": [],
  "4555": [
    {
      "answer": "AUSTPAC",
      "score": 0.7473693490028381
    }
  ],
  "4556": [],
  "4557": [],
  "4558": [],
  "4559": [],
  "4560": [],
  "4561": [
    {
      "answer": "Telepad",
      "score": 0.973081111907959
    }
  ],
  "4562": [],
  "4563": [
    {
      "answer": "this use of the name",
      "score": 0.7122790813446045
    }
  ],
  "4564": [
    {
      "answer": "same people",
      "score": 0.9052703380584717
    }
  ],
  "4565": [
    {
      "answer": "DNIC 2049",
      "score": 0.9377912282943726
    }
  ],
  "4566": [
    {
      "answer": "Videotex",
      "score": 0.9220712780952454
    }
  ],
  "4567": [
    {
      "answer": "Datanet 1",
      "score": 0.8576167821884155
    },
    {
      "answer": "Datanet 1",
      "score": 0.7122607231140137
    },
    {
      "answer": "Datanet 1",
      "score": 0.6742349863052368
    }
  ],
  "4568": [
    {
      "answer": "same people within one department of KPN",
      "score": 0.9128289222717285
    }
  ],
  "4569": [],
  "4570": [
    {
      "answer": "to extend networking benefits, for computer science departments at academic and research institutions that could not be directly connected to ARPANET, due to funding or authorization limitations",
      "score": 0.9023444056510925
    }
  ],
  "4571": [],
  "4572": [
    {
      "answer": "the global Internet",
      "score": 0.9219875335693359
    }
  ],
  "4573": [
    {
      "answer": "Computer Science Network",
      "score": 0.7474827766418457
    }
  ],
  "4574": [
    {
      "answer": "computer science departments at academic and research institutions",
      "score": 0.9735443592071533
    }
  ],
  "4575": [
    {
      "answer": "U.S. National Science Foundation",
      "score": 0.9477759003639221
    }
  ],
  "4576": [
    {
      "answer": "ARPANET",
      "score": 0.9925561547279358
    }
  ],
  "4577": [],
  "4578": [
    {
      "answer": "to extend networking benefits",
      "score": 0.9763470888137817
    }
  ],
  "4579": [
    {
      "answer": "to extend networking benefits",
      "score": 0.8552814722061157
    }
  ],
  "4580": [
    {
      "answer": "spreading awareness of, and access to, national networking",
      "score": 0.9776329398155212
    }
  ],
  "4581": [
    {
      "answer": "development of the global Internet",
      "score": 0.838756263256073
    }
  ],
  "4582": [],
  "4583": [],
  "4584": [],
  "4585": [],
  "4586": [],
  "4587": [
    {
      "answer": "Qwest",
      "score": 0.9803763628005981
    }
  ],
  "4588": [
    {
      "answer": "a brand new nationwide network",
      "score": 0.9040687680244446
    }
  ],
  "4589": [
    {
      "answer": "Internet2 Network",
      "score": 0.9521857500076294
    }
  ],
  "4590": [
    {
      "answer": "Internet2 Network",
      "score": 0.5351435542106628
    },
    {
      "answer": "Internet2 Network",
      "score": 0.9216412305831909
    }
  ],
  "4591": [
    {
      "answer": "Internet2 Network",
      "score": 0.7084973454475403
    }
  ],
  "4592": [
    {
      "answer": "Abilene",
      "score": 0.9815791845321655
    },
    {
      "answer": "Abilene",
      "score": 0.743914008140564
    }
  ],
  "4593": [
    {
      "answer": "Level 3 Communications",
      "score": 0.9892131090164185
    }
  ],
  "4594": [
    {
      "answer": "members from the research and education communities, industry, and government",
      "score": 0.8893765211105347
    }
  ],
  "4595": [
    {
      "answer": "National LambdaRail",
      "score": 0.9904234409332275
    }
  ],
  "4596": [],
  "4597": [],
  "4598": [],
  "4599": [
    {
      "answer": "National Science Foundation",
      "score": 0.7704309225082397
    },
    {
      "answer": "National Science Foundation",
      "score": 0.9011325240135193
    }
  ],
  "4600": [],
  "4601": [
    {
      "answer": "promote advanced research and education networking",
      "score": 0.934658408164978
    }
  ],
  "4602": [
    {
      "answer": "a major part of the Internet backbone",
      "score": 0.9394644498825073
    }
  ],
  "4603": [
    {
      "answer": "National Science Foundation Network",
      "score": 0.9239445924758911
    }
  ],
  "4604": [
    {
      "answer": "advanced research and education networking",
      "score": 0.9957683682441711
    }
  ],
  "4605": [
    {
      "answer": "a major part of the Internet backbone",
      "score": 0.9560264348983765
    }
  ],
  "4606": [
    {
      "answer": "National Science Foundation Network",
      "score": 0.6623074412345886
    }
  ],
  "4607": [
    {
      "answer": "to link researchers to the nation's NSF-funded supercomputing centers",
      "score": 0.9811186790466309
    }
  ],
  "4608": [],
  "4609": [],
  "4610": [],
  "4611": [],
  "4612": [],
  "4613": [],
  "4614": [
    {
      "answer": "The network was engineered and operated by MCI Telecommunications under a cooperative agreement with the NSF",
      "score": 0.8287056088447571
    }
  ],
  "4615": [
    {
      "answer": "MCI Telecommunications",
      "score": 0.95335853099823
    }
  ],
  "4616": [],
  "4617": [
    {
      "answer": "February 1999",
      "score": 0.9834984540939331
    }
  ],
  "4618": [
    {
      "answer": "to provide high-speed interconnection between NSF-sponsored supercomputing centers and select access points in the United States",
      "score": 0.9823318123817444
    }
  ],
  "4619": [
    {
      "answer": "MCI Telecommunications",
      "score": 0.9970274567604065
    }
  ],
  "4620": [
    {
      "answer": "100",
      "score": 0.9909663200378418
    }
  ],
  "4621": [],
  "4622": [
    {
      "answer": "12",
      "score": 0.9880113005638123
    }
  ],
  "4623": [
    {
      "answer": "Central Asia",
      "score": 0.9938704967498779
    }
  ],
  "4624": [
    {
      "answer": "travelled along the Silk Road",
      "score": 0.634924054145813
    },
    {
      "answer": "carried by Oriental rat fleas",
      "score": 0.9097712635993958
    }
  ],
  "4625": [
    {
      "answer": "30\u201360%",
      "score": 0.990152895450592
    }
  ],
  "4626": [
    {
      "answer": "17th century",
      "score": 0.9739227890968323
    }
  ],
  "4627": [
    {
      "answer": "until the 19th century",
      "score": 0.9296034574508667
    }
  ],
  "4628": [
    {
      "answer": "1343",
      "score": 0.9852250218391418
    }
  ],
  "4629": [],
  "4630": [
    {
      "answer": "30\u201360%",
      "score": 0.9074910879135132
    }
  ],
  "4631": [
    {
      "answer": "30\u201360%",
      "score": 0.946361243724823
    }
  ],
  "4632": [
    {
      "answer": "1343",
      "score": 0.9934501647949219
    }
  ],
  "4633": [
    {
      "answer": "commonly present) in populations of fleas carried by ground rodents",
      "score": 0.8675307035446167
    }
  ],
  "4634": [
    {
      "answer": "1338\u201339",
      "score": 0.9799939393997192
    }
  ],
  "4635": [
    {
      "answer": "China",
      "score": 0.7149081826210022
    },
    {
      "answer": "China",
      "score": 0.9901788234710693
    },
    {
      "answer": "China",
      "score": 0.7339092493057251
    }
  ],
  "4636": [
    {
      "answer": "1331",
      "score": 0.987360417842865
    }
  ],
  "4637": [
    {
      "answer": "25 million",
      "score": 0.9797453880310059
    }
  ],
  "4638": [
    {
      "answer": "1338",
      "score": 0.9737610816955566
    }
  ],
  "4639": [
    {
      "answer": "13th",
      "score": 0.9908269047737122
    }
  ],
  "4640": [
    {
      "answer": "25 million",
      "score": 0.9184379577636719
    }
  ],
  "4641": [
    {
      "answer": "China",
      "score": 0.6012707352638245
    }
  ],
  "4642": [
    {
      "answer": "enzootic",
      "score": 0.9750350713729858
    }
  ],
  "4643": [
    {
      "answer": "Genoese traders",
      "score": 0.992795467376709
    },
    {
      "answer": "Genoese traders",
      "score": 0.6406426429748535
    }
  ],
  "4644": [
    {
      "answer": "Mongol",
      "score": 0.9727500081062317
    }
  ],
  "4645": [
    {
      "answer": "infected corpses",
      "score": 0.9611347913742065
    }
  ],
  "4646": [
    {
      "answer": "Sicily",
      "score": 0.9865283966064453
    }
  ],
  "4647": [
    {
      "answer": "war",
      "score": 0.9677013158798218
    },
    {
      "answer": "famine",
      "score": 0.9745914936065674
    },
    {
      "answer": "weather",
      "score": 0.9846478700637817
    }
  ],
  "4648": [
    {
      "answer": "1347",
      "score": 0.9939160943031311
    }
  ],
  "4649": [
    {
      "answer": "1347",
      "score": 0.9923781156539917
    }
  ],
  "4650": [
    {
      "answer": "Genoese",
      "score": 0.8729652166366577
    },
    {
      "answer": "Genoese",
      "score": 0.7005813717842102
    }
  ],
  "4651": [
    {
      "answer": "Sicily",
      "score": 0.9478545784950256
    }
  ],
  "4652": [
    {
      "answer": "Genoese",
      "score": 0.7975987195968628
    },
    {
      "answer": "Genoese",
      "score": 0.5920132994651794
    }
  ],
  "4653": [
    {
      "answer": "northwest",
      "score": 0.9868460893630981
    }
  ],
  "4654": [
    {
      "answer": "Russia",
      "score": 0.807632327079773
    }
  ],
  "4655": [
    {
      "answer": "Basque Country",
      "score": 0.8448264598846436
    },
    {
      "answer": "isolated parts of Belgium and the Netherlands",
      "score": 0.763898491859436
    },
    {
      "answer": "isolated alpine villages",
      "score": 0.9324595928192139
    }
  ],
  "4656": [
    {
      "answer": "Germany",
      "score": 0.9313374161720276
    },
    {
      "answer": "Scandinavia",
      "score": 0.9373840689659119
    }
  ],
  "4657": [
    {
      "answer": "1349",
      "score": 0.9835320711135864
    }
  ],
  "4658": [
    {
      "answer": "1348",
      "score": 0.9605149030685425
    }
  ],
  "4659": [
    {
      "answer": "Norway",
      "score": 0.9938881993293762
    }
  ],
  "4660": [
    {
      "answer": "1349",
      "score": 0.9874492883682251
    }
  ],
  "4661": [
    {
      "answer": "Basque Country",
      "score": 0.9350472688674927
    },
    {
      "answer": "isolated parts of Belgium and the Netherlands",
      "score": 0.7035741209983826
    }
  ],
  "4662": [
    {
      "answer": "Belgium",
      "score": 0.8861666917800903
    },
    {
      "answer": "Netherlands",
      "score": 0.8795676231384277
    }
  ],
  "4663": [
    {
      "answer": "serious depopulation",
      "score": 0.9736372232437134
    },
    {
      "answer": "permanent change in both economic and social structures",
      "score": 0.9705511927604675
    }
  ],
  "4664": [
    {
      "answer": "1347",
      "score": 0.9852014183998108
    },
    {
      "answer": "1347",
      "score": 0.6847777366638184
    }
  ],
  "4665": [
    {
      "answer": "through the port's trade with Constantinople, and ports on the Black Sea",
      "score": 0.9632270336151123
    }
  ],
  "4666": [
    {
      "answer": "north",
      "score": 0.5346434712409973
    },
    {
      "answer": "north",
      "score": 0.991072952747345
    }
  ],
  "4667": [
    {
      "answer": "1347",
      "score": 0.9128212332725525
    },
    {
      "answer": "1347",
      "score": 0.8649646639823914
    }
  ],
  "4668": [
    {
      "answer": "north",
      "score": 0.5489515662193298
    },
    {
      "answer": "north",
      "score": 0.9889262914657593
    }
  ],
  "4669": [
    {
      "answer": "1348",
      "score": 0.9273643493652344
    }
  ],
  "4670": [
    {
      "answer": "Alexandria",
      "score": 0.9754990339279175
    }
  ],
  "4671": [
    {
      "answer": "Syria",
      "score": 0.9179901480674744
    }
  ],
  "4672": [
    {
      "answer": "Gasquet",
      "score": 0.9871209263801575
    }
  ],
  "4673": [
    {
      "answer": "atra mors",
      "score": 0.9541248083114624
    }
  ],
  "4674": [
    {
      "answer": "Gasquet",
      "score": 0.6138581037521362
    },
    {
      "answer": "J.I. Pontanus",
      "score": 0.9335765242576599
    }
  ],
  "4675": [
    {
      "answer": "1823",
      "score": 0.9928715825080872
    }
  ],
  "4676": [
    {
      "answer": "Scandinavia",
      "score": 0.7120276689529419
    },
    {
      "answer": "Germany",
      "score": 0.8651354908943176
    }
  ],
  "4677": [
    {
      "answer": "1631",
      "score": 0.9758313298225403
    }
  ],
  "4678": [
    {
      "answer": "1823",
      "score": 0.993748664855957
    }
  ],
  "4679": [
    {
      "answer": "1631",
      "score": 0.9951308965682983
    }
  ],
  "4680": [
    {
      "answer": "1631",
      "score": 0.9706399440765381
    }
  ],
  "4681": [
    {
      "answer": "atra mors",
      "score": 0.791008710861206
    }
  ],
  "4682": [
    {
      "answer": "heavens",
      "score": 0.9326895475387573
    }
  ],
  "4683": [
    {
      "answer": "king of France",
      "score": 0.9925126433372498
    }
  ],
  "4684": [
    {
      "answer": "Miasma",
      "score": 0.9601602554321289
    }
  ],
  "4685": [
    {
      "answer": "Miasma",
      "score": 0.9918826222419739
    }
  ],
  "4686": [
    {
      "answer": "Paris",
      "score": 0.9912410378456116
    }
  ],
  "4687": [
    {
      "answer": "bad air",
      "score": 0.988616406917572
    }
  ],
  "4688": [
    {
      "answer": "1345",
      "score": 0.9925428628921509
    }
  ],
  "4689": [
    {
      "answer": "1345",
      "score": 0.9879145622253418
    }
  ],
  "4690": [
    {
      "answer": "Yersinia pestis",
      "score": 0.9868193864822388
    },
    {
      "answer": "Yersinia pestis",
      "score": 0.8243056535720825
    }
  ],
  "4691": [
    {
      "answer": "Hong Kong",
      "score": 0.8842608332633972
    },
    {
      "answer": "1894",
      "score": 0.928509533405304
    }
  ],
  "4692": [
    {
      "answer": "Alexandre Yersin",
      "score": 0.9958142042160034
    }
  ],
  "4693": [
    {
      "answer": "The mechanism by which Y. pestis was usually transmitted",
      "score": 0.9529687762260437
    }
  ],
  "4694": [
    {
      "answer": "two populations of rodents",
      "score": 0.9348373413085938
    }
  ],
  "4695": [
    {
      "answer": "1865",
      "score": 0.9934020638465881
    }
  ],
  "4696": [
    {
      "answer": "1894",
      "score": 0.9936739206314087
    }
  ],
  "4697": [
    {
      "answer": "French-Swiss",
      "score": 0.9582699537277222
    }
  ],
  "4698": [
    {
      "answer": "Alexandre Yersin",
      "score": 0.5719115734100342
    }
  ],
  "4699": [
    {
      "answer": "Alexandre Yersin",
      "score": 0.9962903261184692
    }
  ],
  "4700": [
    {
      "answer": "Francis Aidan Gasquet",
      "score": 0.9948734045028687
    }
  ],
  "4701": [
    {
      "answer": "ordinary Eastern or bubonic plague",
      "score": 0.9299770593643188
    }
  ],
  "4702": [
    {
      "answer": "1908",
      "score": 0.9925171136856079
    }
  ],
  "4703": [
    {
      "answer": "rats",
      "score": 0.9817026853561401
    },
    {
      "answer": "fleas",
      "score": 0.9719669222831726
    }
  ],
  "4704": [
    {
      "answer": "Justinian plague",
      "score": 0.9842281341552734
    }
  ],
  "4705": [
    {
      "answer": "1893",
      "score": 0.984662652015686
    }
  ],
  "4706": [
    {
      "answer": "1893",
      "score": 0.8343597650527954
    }
  ],
  "4707": [
    {
      "answer": "Justinian plague",
      "score": 0.6180698275566101
    }
  ],
  "4708": [
    {
      "answer": "1893",
      "score": 0.9035854339599609
    }
  ],
  "4709": [
    {
      "answer": "30\u201375%",
      "score": 0.9927921295166016
    }
  ],
  "4710": [
    {
      "answer": "38\u201341 \u00b0C",
      "score": 0.6923626065254211
    },
    {
      "answer": "high",
      "score": 0.7818068861961365
    }
  ],
  "4711": [
    {
      "answer": "80",
      "score": 0.9957083463668823
    }
  ],
  "4712": [
    {
      "answer": "90 to 95 percent",
      "score": 0.9934674501419067
    }
  ],
  "4713": [],
  "4714": [
    {
      "answer": "red",
      "score": 0.9402351975440979
    }
  ],
  "4715": [
    {
      "answer": "38\u201341 \u00b0C",
      "score": 0.9644840359687805
    },
    {
      "answer": "100\u2013106 \u00b0F",
      "score": 0.6703109741210938
    }
  ],
  "4716": [
    {
      "answer": "high fevers",
      "score": 0.7848427295684814
    }
  ],
  "4717": [
    {
      "answer": "near 100%",
      "score": 0.8778997659683228
    }
  ],
  "4718": [
    {
      "answer": "90 to 95 percent",
      "score": 0.9876056909561157
    }
  ],
  "4719": [
    {
      "answer": "October 2010",
      "score": 0.9830988645553589
    }
  ],
  "4720": [],
  "4721": [
    {
      "answer": "Polymerase Chain Reaction (PCR)",
      "score": 0.9581127166748047
    }
  ],
  "4722": [
    {
      "answer": "tooth sockets in human skeletons from mass graves in northern, central and southern Europe",
      "score": 0.8732675313949585
    }
  ],
  "4723": [],
  "4724": [
    {
      "answer": "2010",
      "score": 0.946885347366333
    }
  ],
  "4725": [
    {
      "answer": "France",
      "score": 0.7611376047134399
    },
    {
      "answer": "Germany",
      "score": 0.5421790480613708
    }
  ],
  "4726": [
    {
      "answer": "1998",
      "score": 0.9913554787635803
    }
  ],
  "4727": [
    {
      "answer": "PLoS Pathogens",
      "score": 0.9750863313674927
    }
  ],
  "4728": [
    {
      "answer": "October",
      "score": 0.5925063490867615
    }
  ],
  "4729": [
    {
      "answer": "genetic branches) of the Y. pestis genome",
      "score": 0.7001221179962158
    }
  ],
  "4730": [
    {
      "answer": "Y. p. orientalis",
      "score": 0.9174265265464783
    },
    {
      "answer": "Y. p. medievalis",
      "score": 0.8497952818870544
    }
  ],
  "4731": [
    {
      "answer": "the plague may have entered Europe in two waves",
      "score": 0.9270740151405334
    }
  ],
  "4732": [
    {
      "answer": "November 1347",
      "score": 0.972196102142334
    }
  ],
  "4733": [
    {
      "answer": "1349",
      "score": 0.9732634425163269
    },
    {
      "answer": "1349",
      "score": 0.7166255116462708
    }
  ],
  "4734": [
    {
      "answer": "1347",
      "score": 0.992668628692627
    }
  ],
  "4735": [
    {
      "answer": "1349",
      "score": 0.7576626539230347
    },
    {
      "answer": "1349",
      "score": 0.9176318049430847
    }
  ],
  "4736": [],
  "4737": [
    {
      "answer": "spring",
      "score": 0.9663851857185364
    }
  ],
  "4738": [
    {
      "answer": "England",
      "score": 0.7062541246414185
    },
    {
      "answer": "England",
      "score": 0.5417050123214722
    }
  ],
  "4739": [
    {
      "answer": "confirmed and amended",
      "score": 0.9535051584243774
    }
  ],
  "4740": [
    {
      "answer": "East Smithfield",
      "score": 0.7779819369316101
    },
    {
      "answer": "England",
      "score": 0.9656826257705688
    }
  ],
  "4741": [
    {
      "answer": "no longer exist",
      "score": 0.9771401286125183
    }
  ],
  "4742": [
    {
      "answer": "October 2011",
      "score": 0.9772621989250183
    }
  ],
  "4743": [
    {
      "answer": "2011",
      "score": 0.9815836548805237
    },
    {
      "answer": "2011",
      "score": 0.9170220494270325
    }
  ],
  "4744": [
    {
      "answer": "Schuenemann",
      "score": 0.936970591545105
    }
  ],
  "4745": [],
  "4746": [
    {
      "answer": "2011",
      "score": 0.9822462797164917
    },
    {
      "answer": "2011",
      "score": 0.9336061477661133
    }
  ],
  "4747": [
    {
      "answer": "J. F. D. Shrewsbury",
      "score": 0.9924076795578003
    }
  ],
  "4748": [
    {
      "answer": "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague",
      "score": 0.9509791135787964
    }
  ],
  "4749": [
    {
      "answer": "contemporary accounts were exaggerations",
      "score": 0.9760131239891052
    }
  ],
  "4750": [
    {
      "answer": "the first major work to challenge the bubonic plague theory directly",
      "score": 0.9541991949081421
    }
  ],
  "4751": [
    {
      "answer": "Samuel K. Cohn, Jr.",
      "score": 0.9777441620826721
    }
  ],
  "4752": [
    {
      "answer": "J. F. D. Shrewsbury",
      "score": 0.9815942645072937
    }
  ],
  "4753": [],
  "4754": [
    {
      "answer": "zoologist",
      "score": 0.983256459236145
    }
  ],
  "4755": [
    {
      "answer": "J. F. D. Shrewsbury",
      "score": 0.755287766456604
    }
  ],
  "4756": [
    {
      "answer": "2002",
      "score": 0.9899711012840271
    }
  ],
  "4757": [
    {
      "answer": "an epidemiological account",
      "score": 0.9755191802978516
    }
  ],
  "4758": [
    {
      "answer": "lack of reliable statistics",
      "score": 0.9698222279548645
    }
  ],
  "4759": [
    {
      "answer": "over 100%",
      "score": 0.964812159538269
    }
  ],
  "4760": [
    {
      "answer": "figures from the clergy",
      "score": 0.8513803482055664
    }
  ],
  "4761": [
    {
      "answer": "between the time of publication of the Domesday Book and the year 1377",
      "score": 0.903849720954895
    }
  ],
  "4762": [
    {
      "answer": "1377",
      "score": 0.9821037650108337
    }
  ],
  "4763": [
    {
      "answer": "1377",
      "score": 0.9895738959312439
    }
  ],
  "4764": [
    {
      "answer": "plague",
      "score": 0.8126688599586487
    },
    {
      "answer": "plague",
      "score": 0.7702214121818542
    }
  ],
  "4765": [
    {
      "answer": "1377",
      "score": 0.9933795928955078
    }
  ],
  "4766": [
    {
      "answer": "transference via fleas in goods was likely to be of marginal significance",
      "score": 0.7081705927848816
    },
    {
      "answer": "lack of accounts of the death of rats before outbreaks of plague between the 14th and 17th centuries",
      "score": 0.8210929036140442
    },
    {
      "answer": "temperatures that are too cold in northern Europe for the survival of fleas",
      "score": 0.9111087322235107
    }
  ],
  "4767": [
    {
      "answer": "marginal significance",
      "score": 0.9665489792823792
    }
  ],
  "4768": [
    {
      "answer": "too cold in northern Europe for the survival of fleas",
      "score": 0.9020437598228455
    }
  ],
  "4769": [
    {
      "answer": "much faster",
      "score": 0.8790498971939087
    }
  ],
  "4770": [
    {
      "answer": "5 to 15",
      "score": 0.9884940981864929
    }
  ],
  "4771": [],
  "4772": [
    {
      "answer": "too cold in northern Europe for the survival of fleas",
      "score": 0.7121416926383972
    }
  ],
  "4773": [],
  "4774": [
    {
      "answer": "5 to 15",
      "score": 0.9609405398368835
    }
  ],
  "4775": [
    {
      "answer": "5 to 15 years",
      "score": 0.6163547039031982
    }
  ],
  "4776": [
    {
      "answer": "transmission must have been person to person",
      "score": 0.8062616586685181
    }
  ],
  "4777": [
    {
      "answer": "a combination of anthrax and other pandemics",
      "score": 0.9665270447731018
    }
  ],
  "4778": [
    {
      "answer": "bubonic plague",
      "score": 0.6055921316146851
    },
    {
      "answer": "typhus",
      "score": 0.9062400460243225
    },
    {
      "answer": "smallpox",
      "score": 0.9026328921318054
    },
    {
      "answer": "respiratory infections",
      "score": 0.9263005256652832
    }
  ],
  "4779": [
    {
      "answer": "a type of \"blood poisoning",
      "score": 0.8837558627128601
    }
  ],
  "4780": [
    {
      "answer": "25",
      "score": 0.9906309247016907
    }
  ],
  "4781": [],
  "4782": [],
  "4783": [],
  "4784": [
    {
      "answer": "2001",
      "score": 0.9605025053024292
    }
  ],
  "4785": [],
  "4786": [
    {
      "answer": "a third",
      "score": 0.8532779812812805
    },
    {
      "answer": "a third",
      "score": 0.6945052146911621
    }
  ],
  "4787": [
    {
      "answer": "Half",
      "score": 0.9841354489326477
    }
  ],
  "4788": [
    {
      "answer": "at least some pre-planning and Christian burials",
      "score": 0.9453193545341492
    }
  ],
  "4789": [
    {
      "answer": "50%",
      "score": 0.8841243386268616
    }
  ],
  "4790": [
    {
      "answer": "most isolated areas",
      "score": 0.8948332667350769
    }
  ],
  "4791": [],
  "4792": [],
  "4793": [
    {
      "answer": "Middle East",
      "score": 0.9869229197502136
    }
  ],
  "4794": [],
  "4795": [
    {
      "answer": "a third",
      "score": 0.5209456086158752
    },
    {
      "answer": "a third",
      "score": 0.9321720600128174
    }
  ],
  "4796": [
    {
      "answer": "1346",
      "score": 0.9620795249938965
    },
    {
      "answer": "1671",
      "score": 0.8366345167160034
    }
  ],
  "4797": [
    {
      "answer": "the plague was present somewhere in Europe in every year between 1346 and 1671",
      "score": 0.9724885821342468
    }
  ],
  "4798": [
    {
      "answer": "a million",
      "score": 0.9806760549545288
    }
  ],
  "4799": [
    {
      "answer": "Biraben",
      "score": 0.573456346988678
    }
  ],
  "4800": [
    {
      "answer": "1671",
      "score": 0.9743800163269043
    }
  ],
  "4801": [
    {
      "answer": "France",
      "score": 0.992830216884613
    }
  ],
  "4802": [
    {
      "answer": "Europe",
      "score": 0.8497082591056824
    },
    {
      "answer": "Mediterranean",
      "score": 0.6582947373390198
    },
    {
      "answer": "Europe",
      "score": 0.7469316720962524
    },
    {
      "answer": "Europe",
      "score": 0.6035712957382202
    }
  ],
  "4803": [
    {
      "answer": "almost a million",
      "score": 0.8751896619796753
    }
  ],
  "4804": [
    {
      "answer": "propose a range of preincident population figures from as high as 7 million to as low as 4 million in 1300",
      "score": 0.9806590676307678
    }
  ],
  "4805": [
    {
      "answer": "1350",
      "score": 0.9912343621253967
    }
  ],
  "4806": [
    {
      "answer": "10\u201315%",
      "score": 0.9607816934585571
    }
  ],
  "4807": [
    {
      "answer": "1665",
      "score": 0.992770254611969
    }
  ],
  "4808": [],
  "4809": [
    {
      "answer": "20%",
      "score": 0.8825079202651978
    }
  ],
  "4810": [],
  "4811": [],
  "4812": [],
  "4813": [
    {
      "answer": "40,000",
      "score": 0.9912490844726562
    }
  ],
  "4814": [
    {
      "answer": "Russia",
      "score": 0.9972118735313416
    }
  ],
  "4815": [
    {
      "answer": "22",
      "score": 0.9914690256118774
    }
  ],
  "4816": [
    {
      "answer": "Italian Plague of 1629\u20131631",
      "score": 0.9922463297843933
    }
  ],
  "4817": [
    {
      "answer": "1654",
      "score": 0.9841019511222839
    }
  ],
  "4818": [
    {
      "answer": "30 per cent",
      "score": 0.6934852600097656
    }
  ],
  "4819": [],
  "4820": [],
  "4821": [
    {
      "answer": "Italian",
      "score": 0.7719677686691284
    }
  ],
  "4822": [
    {
      "answer": "50",
      "score": 0.9567802548408508
    }
  ],
  "4823": [
    {
      "answer": "1.7 million",
      "score": 0.9901601672172546
    }
  ],
  "4824": [
    {
      "answer": "half",
      "score": 0.9389781355857849
    }
  ],
  "4825": [
    {
      "answer": "half",
      "score": 0.6336606740951538
    },
    {
      "answer": "half",
      "score": 0.9596627354621887
    }
  ],
  "4826": [
    {
      "answer": "Sweden",
      "score": 0.9235970377922058
    },
    {
      "answer": "Russia",
      "score": 0.6231170892715454
    }
  ],
  "4827": [
    {
      "answer": "1720",
      "score": 0.9908342957496643
    }
  ],
  "4828": [
    {
      "answer": "Spain",
      "score": 0.9873362183570862
    }
  ],
  "4829": [
    {
      "answer": "Sweden",
      "score": 0.8828572630882263
    },
    {
      "answer": "Sweden",
      "score": 0.5175185203552246
    }
  ],
  "4830": [
    {
      "answer": "14%",
      "score": 0.9535906314849854
    }
  ],
  "4831": [
    {
      "answer": "a third",
      "score": 0.9281470775604248
    }
  ],
  "4832": [
    {
      "answer": "Europe",
      "score": 0.6027509570121765
    }
  ],
  "4833": [
    {
      "answer": "1500",
      "score": 0.9519283771514893
    },
    {
      "answer": "1850",
      "score": 0.9442877769470215
    }
  ],
  "4834": [
    {
      "answer": "30 to 50 thousand",
      "score": 0.9772915840148926
    }
  ],
  "4835": [
    {
      "answer": "1500 and 1850",
      "score": 0.9044671058654785
    }
  ],
  "4836": [
    {
      "answer": "two-thirds",
      "score": 0.9478206634521484
    }
  ],
  "4837": [],
  "4838": [
    {
      "answer": "thirty-seven",
      "score": 0.9822821617126465
    }
  ],
  "4839": [
    {
      "answer": "thirty-seven",
      "score": 0.9776607751846313
    },
    {
      "answer": "thirty-one",
      "score": 0.6920159459114075
    }
  ],
  "4840": [
    {
      "answer": "thirty-seven",
      "score": 0.554192066192627
    },
    {
      "answer": "thirty-one",
      "score": 0.6288296580314636
    }
  ],
  "4841": [
    {
      "answer": "thirty-seven",
      "score": 0.9770092368125916
    },
    {
      "answer": "thirty-one",
      "score": 0.5419219136238098
    }
  ],
  "4842": [
    {
      "answer": "melt",
      "score": 0.8457369208335876
    },
    {
      "answer": "magma",
      "score": 0.7378968596458435
    }
  ],
  "4843": [
    {
      "answer": "metamorphic rock",
      "score": 0.7543534636497498
    },
    {
      "answer": "metamorphic rock",
      "score": 0.7925324440002441
    }
  ],
  "4844": [
    {
      "answer": "a new magma",
      "score": 0.9357855319976807
    }
  ],
  "4845": [
    {
      "answer": "igneous, sedimentary, and metamorphic",
      "score": 0.98594731092453
    }
  ],
  "4846": [
    {
      "answer": "heat and pressure",
      "score": 0.9967808127403259
    }
  ],
  "4847": [],
  "4848": [
    {
      "answer": "rock cycle",
      "score": 0.9914692640304565
    }
  ],
  "4849": [
    {
      "answer": "igneous rock",
      "score": 0.9365667700767517
    }
  ],
  "4850": [
    {
      "answer": "heat and pressure",
      "score": 0.9900555610656738
    },
    {
      "answer": "heat and pressure",
      "score": 0.6210373044013977
    }
  ],
  "4851": [
    {
      "answer": "a new magma is formed",
      "score": 0.9309448599815369
    }
  ],
  "4852": [
    {
      "answer": "rock cycle",
      "score": 0.9936268329620361
    }
  ],
  "4853": [
    {
      "answer": "metamorphic rock",
      "score": 0.6680416464805603
    },
    {
      "answer": "igneous rock",
      "score": 0.538329541683197
    }
  ],
  "4854": [
    {
      "answer": "weathered and eroded",
      "score": 0.8306905031204224
    },
    {
      "answer": "heat and pressure",
      "score": 0.8271090984344482
    }
  ],
  "4855": [
    {
      "answer": "mineral content of the rock",
      "score": 0.7802228331565857
    }
  ],
  "4856": [
    {
      "answer": "mineral content",
      "score": 0.9782149195671082
    }
  ],
  "4857": [
    {
      "answer": "seafloor spreading",
      "score": 0.9962539672851562
    }
  ],
  "4858": [
    {
      "answer": "crust",
      "score": 0.9773918390274048
    },
    {
      "answer": "rigid uppermost portion of the upper mantle",
      "score": 0.9469830989837646
    }
  ],
  "4859": [
    {
      "answer": "asthenosphere",
      "score": 0.9876151084899902
    }
  ],
  "4860": [
    {
      "answer": "convection of the mantle",
      "score": 0.8645153045654297
    }
  ],
  "4861": [
    {
      "answer": "1960s",
      "score": 0.9930635094642639
    }
  ],
  "4862": [
    {
      "answer": "1960s",
      "score": 0.9912235736846924
    }
  ],
  "4863": [
    {
      "answer": "plate tectonics",
      "score": 0.8859719634056091
    }
  ],
  "4864": [
    {
      "answer": "the same direction",
      "score": 0.8129134178161621
    }
  ],
  "4865": [
    {
      "answer": "oceanic plate motions and mantle convection currents always move in the same direction",
      "score": 0.7281765341758728
    },
    {
      "answer": "plate tectonics",
      "score": 0.7645015716552734
    }
  ],
  "4866": [
    {
      "answer": "mantle convection",
      "score": 0.9529920816421509
    }
  ],
  "4867": [
    {
      "answer": "asthenosphere",
      "score": 0.839277446269989
    }
  ],
  "4868": [
    {
      "answer": "the oceanic lithosphere is the rigid upper thermal boundary layer of the convecting mantle",
      "score": 0.9597243070602417
    }
  ],
  "4869": [
    {
      "answer": "oceanic lithosphere",
      "score": 0.9658563137054443
    }
  ],
  "4870": [
    {
      "answer": "1960s",
      "score": 0.9894647598266602
    }
  ],
  "4871": [],
  "4872": [
    {
      "answer": "divergent boundaries",
      "score": 0.9698322415351868
    }
  ],
  "4873": [
    {
      "answer": "convergent boundaries",
      "score": 0.9672273397445679
    }
  ],
  "4874": [
    {
      "answer": "Transform boundaries",
      "score": 0.9524334669113159
    },
    {
      "answer": "San Andreas fault system",
      "score": 0.622197151184082
    }
  ],
  "4875": [
    {
      "answer": "Alfred Wegener",
      "score": 0.9959230422973633
    }
  ],
  "4876": [
    {
      "answer": "convecting mantle",
      "score": 0.9840638041496277
    }
  ],
  "4877": [
    {
      "answer": "Transform boundaries",
      "score": 0.5979644060134888
    },
    {
      "answer": "widespread powerful earthquakes",
      "score": 0.834335446357727
    }
  ],
  "4878": [
    {
      "answer": "divergent boundaries",
      "score": 0.985726535320282
    }
  ],
  "4879": [
    {
      "answer": "widespread powerful earthquakes",
      "score": 0.9092159271240234
    }
  ],
  "4880": [
    {
      "answer": "The power of the theory of plate tectonics lies in its ability to combine all of these observations into a single theory of how the lithosphere moves over the convecting mantle",
      "score": 0.8494614958763123
    }
  ],
  "4881": [
    {
      "answer": "Alfred Wegener",
      "score": 0.8148983716964722
    }
  ],
  "4882": [
    {
      "answer": "The power of the theory of plate tectonics lies in its ability to combine all of these observations into a single theory of how the lithosphere moves over the convecting mantle.",
      "score": 0.8614309430122375
    }
  ],
  "4883": [
    {
      "answer": "Mid-ocean ridges",
      "score": 0.8441070914268494
    }
  ],
  "4884": [
    {
      "answer": "divergent boundaries",
      "score": 0.7137433290481567
    },
    {
      "answer": "convergent boundaries",
      "score": 0.6201751232147217
    }
  ],
  "4885": [],
  "4886": [
    {
      "answer": "seismic waves",
      "score": 0.761310338973999
    }
  ],
  "4887": [
    {
      "answer": "crust",
      "score": 0.9466018080711365
    },
    {
      "answer": "lithosphere",
      "score": 0.9377383589744568
    }
  ],
  "4888": [
    {
      "answer": "outer core",
      "score": 0.6061761379241943
    },
    {
      "answer": "inner core",
      "score": 0.6214427947998047
    },
    {
      "answer": "outer core",
      "score": 0.843524158000946
    },
    {
      "answer": "inner core",
      "score": 0.8528320789337158
    }
  ],
  "4889": [
    {
      "answer": "mantle",
      "score": 0.9795646667480469
    }
  ],
  "4890": [
    {
      "answer": "wave speeds",
      "score": 0.971953272819519
    }
  ],
  "4891": [
    {
      "answer": "arrival times of seismic waves",
      "score": 0.9330973029136658
    }
  ],
  "4892": [
    {
      "answer": "shear waves",
      "score": 0.9787556529045105
    }
  ],
  "4893": [
    {
      "answer": "410",
      "score": 0.9837226271629333
    },
    {
      "answer": "660",
      "score": 0.8118550181388855
    }
  ],
  "4894": [
    {
      "answer": "much more detailed view of the interior of the Earth",
      "score": 0.9349836707115173
    }
  ],
  "4895": [
    {
      "answer": "seismic discontinuities",
      "score": 0.9920307993888855
    }
  ],
  "4896": [
    {
      "answer": "liquid",
      "score": 0.9763332009315491
    }
  ],
  "4897": [
    {
      "answer": "410 and 660 kilometers",
      "score": 0.9250978827476501
    }
  ],
  "4898": [],
  "4899": [
    {
      "answer": "the second scale shows the most recent eon with an expanded scale",
      "score": 0.8644687533378601
    }
  ],
  "4900": [
    {
      "answer": "Quaternary",
      "score": 0.9667444825172424
    },
    {
      "answer": "Quaternary",
      "score": 0.7066391706466675
    }
  ],
  "4901": [
    {
      "answer": "Holocene",
      "score": 0.9869658946990967
    }
  ],
  "4902": [
    {
      "answer": "Quaternary",
      "score": 0.9235682487487793
    }
  ],
  "4903": [
    {
      "answer": "most recent eon",
      "score": 0.737034797668457
    },
    {
      "answer": "most recent era",
      "score": 0.9052192568778992
    }
  ],
  "4904": [
    {
      "answer": "The first shows the entire time from the formation of the Earth to the present",
      "score": 0.7823768854141235
    }
  ],
  "4905": [
    {
      "answer": "The first shows the entire time from the formation of the Earth to the present, but this compresses the most recent eon",
      "score": 0.7752306461334229
    }
  ],
  "4906": [
    {
      "answer": "fourth scale",
      "score": 0.9807744026184082
    },
    {
      "answer": "fourth scale",
      "score": 0.8882308006286621
    }
  ],
  "4907": [
    {
      "answer": "too small to be shown clearly on the third timeline on the right",
      "score": 0.9354943633079529
    }
  ],
  "4908": [
    {
      "answer": "Pleistocene (P) epoch",
      "score": 0.7291675806045532
    }
  ],
  "4909": [
    {
      "answer": "The first",
      "score": 0.6611360311508179
    }
  ],
  "4910": [
    {
      "answer": "four",
      "score": 0.8528363108634949
    },
    {
      "answer": "fourth",
      "score": 0.5439581274986267
    },
    {
      "answer": "fourth",
      "score": 0.655698299407959
    }
  ],
  "4911": [
    {
      "answer": "most recent eon",
      "score": 0.9871175289154053
    }
  ],
  "4912": [
    {
      "answer": "Pleistocene",
      "score": 0.9481184482574463
    }
  ],
  "4913": [
    {
      "answer": "cross-cutting relationships",
      "score": 0.9949003458023071
    }
  ],
  "4914": [
    {
      "answer": "younger than the fault",
      "score": 0.6421430110931396
    }
  ],
  "4915": [
    {
      "answer": "key bed",
      "score": 0.9955403804779053
    }
  ],
  "4916": [
    {
      "answer": "the formations that were cut are older than the fault",
      "score": 0.6272789835929871
    }
  ],
  "4917": [
    {
      "answer": "cross-cutting relationships",
      "score": 0.9945277571678162
    }
  ],
  "4918": [
    {
      "answer": "rocks",
      "score": 0.6585103869438171
    },
    {
      "answer": "fault",
      "score": 0.6493074297904968
    },
    {
      "answer": "fault",
      "score": 0.8387575745582581
    }
  ],
  "4919": [
    {
      "answer": "key bed",
      "score": 0.87422776222229
    }
  ],
  "4920": [
    {
      "answer": "younger",
      "score": 0.9627130627632141
    }
  ],
  "4921": [
    {
      "answer": "determine whether the fault is a normal fault or a thrust fault",
      "score": 0.9593597650527954
    }
  ],
  "4922": [
    {
      "answer": "key bed",
      "score": 0.9061791896820068
    }
  ],
  "4923": [
    {
      "answer": "cross-cutting relationships",
      "score": 0.9935911297798157
    }
  ],
  "4924": [],
  "4925": [
    {
      "answer": "key bed",
      "score": 0.7227336764335632
    }
  ],
  "4926": [
    {
      "answer": "the formations that were cut are older than the fault",
      "score": 0.9519945383071899
    }
  ],
  "4927": [
    {
      "answer": "xenoliths",
      "score": 0.9899438619613647
    },
    {
      "answer": "xenoliths",
      "score": 0.8992995023727417
    }
  ],
  "4928": [
    {
      "answer": "magma or lava flows",
      "score": 0.9802154898643494
    }
  ],
  "4929": [
    {
      "answer": "clasts",
      "score": 0.6436145305633545
    }
  ],
  "4930": [
    {
      "answer": "inclusions and components",
      "score": 0.9837158918380737
    }
  ],
  "4931": [
    {
      "answer": "gravel",
      "score": 0.9534831047058105
    }
  ],
  "4932": [
    {
      "answer": "These foreign bodies are picked up as magma or lava flows, and are incorporated, later to cool in the matrix.",
      "score": 0.7431621551513672
    },
    {
      "answer": "xenoliths are older than the rock which contains them",
      "score": 0.688216507434845
    }
  ],
  "4933": [
    {
      "answer": "older formation",
      "score": 0.9743503332138062
    }
  ],
  "4934": [
    {
      "answer": "ripped up and included in a newer layer",
      "score": 0.9325387477874756
    },
    {
      "answer": "These foreign bodies are picked up as magma or lava flows, and are incorporated, later to cool in the matrix",
      "score": 0.7827041745185852
    }
  ],
  "4935": [
    {
      "answer": "xenoliths",
      "score": 0.7543426752090454
    },
    {
      "answer": "xenoliths",
      "score": 0.7142235040664673
    }
  ],
  "4936": [
    {
      "answer": "older than the rock which contains them",
      "score": 0.836333155632019
    }
  ],
  "4937": [
    {
      "answer": "These foreign bodies are picked up as magma or lava flows, and are incorporated, later to cool in the matrix.",
      "score": 0.8055562973022461
    },
    {
      "answer": "As a result, xenoliths are older than the rock which contains them.",
      "score": 0.7832411527633667
    }
  ],
  "4938": [
    {
      "answer": "igneous rocks",
      "score": 0.9134291410446167
    }
  ],
  "4939": [
    {
      "answer": "principle of inclusions and components",
      "score": 0.9717669486999512
    }
  ],
  "4940": [],
  "4941": [],
  "4942": [
    {
      "answer": "faunal succession",
      "score": 0.9894827604293823
    }
  ],
  "4943": [
    {
      "answer": "William Smith",
      "score": 0.9982632398605347
    }
  ],
  "4944": [
    {
      "answer": "complex",
      "score": 0.9823784232139587
    }
  ],
  "4945": [
    {
      "answer": "fossils",
      "score": 0.9709761738777161
    },
    {
      "answer": "fossils",
      "score": 0.5553121566772461
    }
  ],
  "4946": [
    {
      "answer": "William Smith",
      "score": 0.9466207027435303
    },
    {
      "answer": "Charles Darwin",
      "score": 0.9302893280982971
    }
  ],
  "4947": [
    {
      "answer": "globally",
      "score": 0.971112847328186
    }
  ],
  "4948": [
    {
      "answer": "appearance of fossils in sedimentary rocks",
      "score": 0.8975849151611328
    }
  ],
  "4949": [
    {
      "answer": "relative age",
      "score": 0.832870364189148
    }
  ],
  "4950": [
    {
      "answer": "almost a hundred years",
      "score": 0.961835503578186
    }
  ],
  "4951": [
    {
      "answer": "fossilization",
      "score": 0.9821451902389526
    }
  ],
  "4952": [
    {
      "answer": "a hundred years",
      "score": 0.8254232406616211
    }
  ],
  "4953": [
    {
      "answer": "William Smith",
      "score": 0.9982055425643921
    }
  ],
  "4954": [
    {
      "answer": "uncertainties of fossilization",
      "score": 0.956803023815155
    },
    {
      "answer": "localization of fossil types due to lateral changes in habitat (facies change in sedimentary strata)",
      "score": 0.8679468631744385
    }
  ],
  "4955": [
    {
      "answer": "As organisms exist at the same time period throughout the world, their presence or (sometimes) absence may be used to provide a relative age of the formations in which they are found.",
      "score": 0.808109700679779
    }
  ],
  "4956": [
    {
      "answer": "evolutionary thought",
      "score": 0.942199170589447
    }
  ],
  "4957": [
    {
      "answer": "beginning of the 20th century",
      "score": 0.9127111434936523
    }
  ],
  "4958": [
    {
      "answer": "stratigraphic",
      "score": 0.9809555411338806
    }
  ],
  "4959": [
    {
      "answer": "absolute ages",
      "score": 0.960066556930542
    }
  ],
  "4960": [
    {
      "answer": "one another",
      "score": 0.989284873008728
    }
  ],
  "4961": [
    {
      "answer": "fossil sequences",
      "score": 0.9845743179321289
    }
  ],
  "4962": [],
  "4963": [
    {
      "answer": "understanding of geologic time",
      "score": 0.7721518278121948
    }
  ],
  "4964": [
    {
      "answer": "20th century",
      "score": 0.9782267808914185
    }
  ],
  "4965": [
    {
      "answer": "assign absolute ages to rock units",
      "score": 0.9697360396385193
    }
  ],
  "4966": [
    {
      "answer": "fossil",
      "score": 0.910729169845581
    }
  ],
  "4967": [
    {
      "answer": "beginning of the 20th century",
      "score": 0.9224550127983093
    }
  ],
  "4968": [
    {
      "answer": "20th century",
      "score": 0.971464991569519
    }
  ],
  "4969": [
    {
      "answer": "absolute dates",
      "score": 0.60024094581604
    },
    {
      "answer": "isotopic dates",
      "score": 0.5775949954986572
    },
    {
      "answer": "absolute ages to rock units",
      "score": 0.586372435092926
    }
  ],
  "4970": [
    {
      "answer": "absolute ages",
      "score": 0.9681824445724487
    }
  ],
  "4971": [
    {
      "answer": "datable material",
      "score": 0.81276535987854
    }
  ],
  "4972": [
    {
      "answer": "Thermochemical",
      "score": 0.9882434010505676
    }
  ],
  "4973": [
    {
      "answer": "closure temperature",
      "score": 0.9952899217605591
    }
  ],
  "4974": [
    {
      "answer": "isotope",
      "score": 0.9731174111366272
    }
  ],
  "4975": [
    {
      "answer": "Dating of lava and volcanic ash layers",
      "score": 0.9638024568557739
    }
  ],
  "4976": [
    {
      "answer": "minerals",
      "score": 0.9507843852043152
    }
  ],
  "4977": [
    {
      "answer": "isotope ratios of radioactive elements",
      "score": 0.6321646571159363
    }
  ],
  "4978": [
    {
      "answer": "absolute age data for sedimentary rock units",
      "score": 0.7234728932380676
    },
    {
      "answer": "ages of pluton emplacement",
      "score": 0.8247922658920288
    }
  ],
  "4979": [
    {
      "answer": "ages",
      "score": 0.9047967791557312
    }
  ],
  "4980": [
    {
      "answer": "geochronologic and thermochronologic studies",
      "score": 0.6863839626312256
    }
  ],
  "4981": [
    {
      "answer": "minerals",
      "score": 0.9740762114524841
    }
  ],
  "4982": [
    {
      "answer": "Thermochemical techniques",
      "score": 0.8851931691169739
    }
  ],
  "4983": [
    {
      "answer": "closure temperature",
      "score": 0.9939219951629639
    }
  ],
  "4984": [
    {
      "answer": "Thermochemical techniques",
      "score": 0.6363382339477539
    }
  ],
  "4985": [
    {
      "answer": "Thermochemical techniques",
      "score": 0.9896048903465271
    }
  ],
  "4986": [],
  "4987": [
    {
      "answer": "shallow crust",
      "score": 0.9890134334564209
    }
  ],
  "4988": [
    {
      "answer": "antiforms",
      "score": 0.969639778137207
    },
    {
      "answer": "synforms",
      "score": 0.7894495725631714
    },
    {
      "answer": "antiforms",
      "score": 0.5899085402488708
    },
    {
      "answer": "synforms",
      "score": 0.6433426141738892
    }
  ],
  "4989": [
    {
      "answer": "antiforms",
      "score": 0.6313521265983582
    },
    {
      "answer": "synforms",
      "score": 0.981120765209198
    },
    {
      "answer": "synforms",
      "score": 0.6524527072906494
    }
  ],
  "4990": [
    {
      "answer": "anticlines",
      "score": 0.9763042330741882
    },
    {
      "answer": "synclines",
      "score": 0.9519846439361572
    }
  ],
  "4991": [
    {
      "answer": "shorten and become thicker",
      "score": 0.98749840259552
    }
  ],
  "4992": [
    {
      "answer": "faulting",
      "score": 0.988192617893219
    },
    {
      "answer": "folding",
      "score": 0.9787468314170837
    }
  ],
  "4993": [
    {
      "answer": "older rocks moving on top of younger ones",
      "score": 0.8639334440231323
    }
  ],
  "4994": [
    {
      "answer": "rocks behave plastically, and fold instead of faulting",
      "score": 0.9503805637359619
    }
  ],
  "4995": [
    {
      "answer": "thrust faults",
      "score": 0.9823360443115234
    }
  ],
  "4996": [],
  "4997": [
    {
      "answer": "principle of superposition",
      "score": 0.9634195566177368
    }
  ],
  "4998": [
    {
      "answer": "plastically",
      "score": 0.9930487871170044
    }
  ],
  "4999": [
    {
      "answer": "shorten and become thicker",
      "score": 0.9335179924964905
    }
  ],
  "5000": [
    {
      "answer": "synforms",
      "score": 0.9704858660697937
    },
    {
      "answer": "synforms",
      "score": 0.5934593081474304
    }
  ],
  "5001": [],
  "5002": [
    {
      "answer": "boudins",
      "score": 0.9854838252067566
    }
  ],
  "5003": [
    {
      "answer": "Maria Fold and Thrust Belt",
      "score": 0.9855304956436157
    }
  ],
  "5004": [
    {
      "answer": "metamorphosed",
      "score": 0.9949191212654114
    }
  ],
  "5005": [
    {
      "answer": "normal faulting",
      "score": 0.986650288105011
    },
    {
      "answer": "ductile stretching",
      "score": 0.9785798788070679
    }
  ],
  "5006": [
    {
      "answer": "boudins",
      "score": 0.8052409291267395
    },
    {
      "answer": "sausage",
      "score": 0.6457123756408691
    }
  ],
  "5007": [
    {
      "answer": "Maria Fold and Thrust Belt",
      "score": 0.9872400164604187
    }
  ],
  "5008": [
    {
      "answer": "metamorphosed",
      "score": 0.6786333322525024
    }
  ],
  "5009": [
    {
      "answer": "causes the rock units as a whole to become longer and thinner",
      "score": 0.803144633769989
    }
  ],
  "5010": [
    {
      "answer": "normal faulting",
      "score": 0.9617782831192017
    },
    {
      "answer": "ductile stretching and thinning",
      "score": 0.9138649702072144
    }
  ],
  "5011": [
    {
      "answer": "Normal faults",
      "score": 0.800339937210083
    }
  ],
  "5012": [
    {
      "answer": "a meter",
      "score": 0.9379792213439941
    }
  ],
  "5013": [
    {
      "answer": "less than a meter",
      "score": 0.8772352933883667
    }
  ],
  "5014": [
    {
      "answer": "Maria Fold and Thrust Belt",
      "score": 0.981265664100647
    }
  ],
  "5015": [
    {
      "answer": "sedimentary",
      "score": 0.8358159065246582
    },
    {
      "answer": "boudins",
      "score": 0.5737618207931519
    }
  ],
  "5016": [
    {
      "answer": "Dikes",
      "score": 0.9896743893623352
    }
  ],
  "5017": [
    {
      "answer": "areas that are being actively deformed",
      "score": 0.7845079898834229
    },
    {
      "answer": "Canadian shield",
      "score": 0.8933357000350952
    },
    {
      "answer": "rings of dikes around the lava tube of a volcano",
      "score": 0.7012602090835571
    }
  ],
  "5018": [
    {
      "answer": "topographic",
      "score": 0.9898924827575684
    }
  ],
  "5019": [
    {
      "answer": "Continual motion",
      "score": 0.9882146120071411
    }
  ],
  "5020": [
    {
      "answer": "Deformational events",
      "score": 0.9395147562026978
    }
  ],
  "5021": [
    {
      "answer": "depositionally",
      "score": 0.9470238089561462
    },
    {
      "answer": "intrusively",
      "score": 0.9351546168327332
    }
  ],
  "5022": [
    {
      "answer": "deformation",
      "score": 0.7728926539421082
    },
    {
      "answer": "deformational",
      "score": 0.5261339545249939
    }
  ],
  "5023": [
    {
      "answer": "volcanism",
      "score": 0.7788214683532715
    },
    {
      "answer": "igneous activity",
      "score": 0.739587664604187
    }
  ],
  "5024": [
    {
      "answer": "topographic gradient",
      "score": 0.982008695602417
    }
  ],
  "5025": [
    {
      "answer": "accommodation space",
      "score": 0.9836228489875793
    }
  ],
  "5026": [
    {
      "answer": "Faulting",
      "score": 0.9713470935821533
    }
  ],
  "5027": [
    {
      "answer": "eroded by hillslopes and channels",
      "score": 0.8103057742118835
    }
  ],
  "5028": [
    {
      "answer": "Faulting",
      "score": 0.9514967203140259
    }
  ],
  "5029": [
    {
      "answer": "Faulting",
      "score": 0.8045616745948792
    }
  ],
  "5030": [
    {
      "answer": "emplacement",
      "score": 0.7366194725036621
    }
  ],
  "5031": [
    {
      "answer": "basaltic lava flows",
      "score": 0.9567732214927673
    }
  ],
  "5032": [
    {
      "answer": "Acasta gneiss",
      "score": 0.9726129174232483
    }
  ],
  "5033": [
    {
      "answer": "sedimentary",
      "score": 0.9528796076774597
    }
  ],
  "5034": [
    {
      "answer": "Cambrian",
      "score": 0.9942339062690735
    }
  ],
  "5035": [
    {
      "answer": "northwestern Canada",
      "score": 0.934069037437439
    }
  ],
  "5036": [
    {
      "answer": "sedimentary rocks",
      "score": 0.8445566892623901
    }
  ],
  "5037": [
    {
      "answer": "metamorphosed, faulted, foliated, and folded",
      "score": 0.9617553353309631
    }
  ],
  "5038": [
    {
      "answer": "metamorphosed to the point where their origin is undiscernable without laboratory analysis",
      "score": 0.8507218360900879
    }
  ],
  "5039": [
    {
      "answer": "undiscernable without laboratory analysis",
      "score": 0.8544475436210632
    }
  ],
  "5040": [
    {
      "answer": "Slave craton",
      "score": 0.7783448696136475
    }
  ],
  "5041": [
    {
      "answer": "Acasta gneiss",
      "score": 0.8057494163513184
    }
  ],
  "5042": [
    {
      "answer": "Cambrian",
      "score": 0.9794930815696716
    }
  ],
  "5043": [],
  "5044": [
    {
      "answer": "basaltic lava flows",
      "score": 0.8190797567367554
    }
  ],
  "5045": [],
  "5046": [
    {
      "answer": "the study of rocks",
      "score": 0.9870142936706543
    }
  ],
  "5047": [
    {
      "answer": "the study of sedimentary layers",
      "score": 0.9771747589111328
    }
  ],
  "5048": [
    {
      "answer": "the study of positions of rock units and their deformation",
      "score": 0.9944868087768555
    }
  ],
  "5049": [
    {
      "answer": "soils",
      "score": 0.8922262787818909
    },
    {
      "answer": "rivers",
      "score": 0.9443320035934448
    },
    {
      "answer": "landscapes",
      "score": 0.9357798099517822
    },
    {
      "answer": "glaciers",
      "score": 0.96436607837677
    }
  ],
  "5050": [
    {
      "answer": "field, laboratory, and numerical modeling methods",
      "score": 0.909086287021637
    }
  ],
  "5051": [
    {
      "answer": "biogeochemical pathways",
      "score": 0.9585257172584534
    }
  ],
  "5052": [
    {
      "answer": "geophysical methods",
      "score": 0.9760268926620483
    }
  ],
  "5053": [
    {
      "answer": "stratigraphy",
      "score": 0.8762151598930359
    }
  ],
  "5054": [
    {
      "answer": "past and current life",
      "score": 0.7907649278640747
    }
  ],
  "5055": [
    {
      "answer": "geophysical methods",
      "score": 0.9553421139717102
    }
  ],
  "5056": [
    {
      "answer": "geophysical methods",
      "score": 0.9399977922439575
    }
  ],
  "5057": [
    {
      "answer": "past and current life",
      "score": 0.8843355178833008
    }
  ],
  "5058": [
    {
      "answer": "geophysical methods",
      "score": 0.9889442920684814
    }
  ],
  "5059": [
    {
      "answer": "Earth history",
      "score": 0.8785831332206726
    }
  ],
  "5060": [
    {
      "answer": "individual locations are analyzed for their exact chemical compositions and variation in composition within individual crystals",
      "score": 0.7978293895721436
    }
  ],
  "5061": [
    {
      "answer": "interference",
      "score": 0.9562182426452637
    }
  ],
  "5062": [
    {
      "answer": "geochemical evolution of rock units",
      "score": 0.9889265298843384
    }
  ],
  "5063": [
    {
      "answer": "laboratory",
      "score": 0.9901387691497803
    }
  ],
  "5064": [
    {
      "answer": "petrographic microscope",
      "score": 0.9559085369110107
    }
  ],
  "5065": [
    {
      "answer": "laboratory",
      "score": 0.9190829396247864
    },
    {
      "answer": "laboratory",
      "score": 0.8530455827713013
    }
  ],
  "5066": [
    {
      "answer": "optical microscopy",
      "score": 0.9839513301849365
    }
  ],
  "5067": [
    {
      "answer": "electron microprobe",
      "score": 0.6556925177574158
    },
    {
      "answer": "electron microprobe",
      "score": 0.6581933498382568
    }
  ],
  "5068": [
    {
      "answer": "birefringence, pleochroism, twinning, and interference properties with a conoscopic lens",
      "score": 0.7754724025726318
    },
    {
      "answer": "variation in composition",
      "score": 0.5485671758651733
    }
  ],
  "5069": [
    {
      "answer": "optical microscopy",
      "score": 0.5422472357749939
    },
    {
      "answer": "plane-polarized and cross-polarized light",
      "score": 0.6098297834396362
    }
  ],
  "5070": [
    {
      "answer": "provide insight into the geochemical evolution of rock units",
      "score": 0.9396119713783264
    }
  ],
  "5071": [
    {
      "answer": "chemical compositions",
      "score": 0.9243704080581665
    },
    {
      "answer": "variation in composition",
      "score": 0.8496865034103394
    }
  ],
  "5072": [],
  "5073": [
    {
      "answer": "optical microscopy",
      "score": 0.6966813802719116
    }
  ],
  "5074": [
    {
      "answer": "conoscopic",
      "score": 0.9923250675201416
    }
  ],
  "5075": [
    {
      "answer": "fluid inclusion data",
      "score": 0.9250221252441406
    },
    {
      "answer": "high temperature and pressure physical experiments",
      "score": 0.9043743014335632
    }
  ],
  "5076": [
    {
      "answer": "fluid inclusion data",
      "score": 0.930320143699646
    },
    {
      "answer": "high temperature and pressure physical experiments",
      "score": 0.9184832572937012
    }
  ],
  "5077": [
    {
      "answer": "metamorphic processes",
      "score": 0.9432446956634521
    }
  ],
  "5078": [
    {
      "answer": "fluid inclusion data",
      "score": 0.9649871587753296
    },
    {
      "answer": "high temperature and pressure physical experiments",
      "score": 0.832094669342041
    }
  ],
  "5079": [
    {
      "answer": "fluid inclusion data",
      "score": 0.9178658723831177
    },
    {
      "answer": "high temperature and pressure physical experiments",
      "score": 0.9308834075927734
    }
  ],
  "5080": [
    {
      "answer": "temperatures and pressures",
      "score": 0.6664584875106812
    }
  ],
  "5081": [
    {
      "answer": "metamorphic processes",
      "score": 0.579032301902771
    }
  ],
  "5082": [
    {
      "answer": "subduction",
      "score": 0.9067228436470032
    },
    {
      "answer": "magma chamber evolution",
      "score": 0.8797504305839539
    }
  ],
  "5083": [
    {
      "answer": "subduction",
      "score": 0.9401580095291138
    }
  ],
  "5084": [
    {
      "answer": "subduction",
      "score": 0.9751155376434326
    },
    {
      "answer": "magma chamber evolution",
      "score": 0.9708633422851562
    }
  ],
  "5085": [
    {
      "answer": "high temperature and pressure",
      "score": 0.9591429829597473
    }
  ],
  "5086": [
    {
      "answer": "subduction and magma chamber evolution",
      "score": 0.8535556793212891
    }
  ],
  "5087": [
    {
      "answer": "Structural geologists",
      "score": 0.9734447598457336
    }
  ],
  "5088": [
    {
      "answer": "microscopic analysis of oriented thin sections",
      "score": 0.9636631011962891
    }
  ],
  "5089": [
    {
      "answer": "plot and combine measurements",
      "score": 0.7986772656440735
    }
  ],
  "5090": [
    {
      "answer": "analog and numerical experiments",
      "score": 0.9782286882400513
    }
  ],
  "5091": [
    {
      "answer": "analog and numerical experiments",
      "score": 0.9657317399978638
    }
  ],
  "5092": [
    {
      "answer": "analog and numerical experiments",
      "score": 0.9787204265594482
    }
  ],
  "5093": [
    {
      "answer": "to better understand the orientations of faults and folds in order to reconstruct the history of rock deformation in the area",
      "score": 0.8504315614700317
    }
  ],
  "5094": [
    {
      "answer": "strain",
      "score": 0.9829640984535217
    }
  ],
  "5095": [],
  "5096": [
    {
      "answer": "strain within the crystalline structure of the rocks",
      "score": 0.9334678649902344
    }
  ],
  "5097": [
    {
      "answer": "microscopic analysis",
      "score": 0.8343809843063354
    },
    {
      "answer": "analog and numerical experiments",
      "score": 0.7086611986160278
    }
  ],
  "5098": [
    {
      "answer": "strain",
      "score": 0.9773284792900085
    }
  ],
  "5099": [
    {
      "answer": "analog and numerical experiments",
      "score": 0.9596814513206482
    }
  ],
  "5100": [
    {
      "answer": "analog",
      "score": 0.7713269591331482
    }
  ],
  "5101": [
    {
      "answer": "orogenic wedges",
      "score": 0.9938045740127563
    },
    {
      "answer": "orogenic wedge",
      "score": 0.7651568651199341
    }
  ],
  "5102": [
    {
      "answer": "orogenic wedges",
      "score": 0.9645305275917053
    }
  ],
  "5103": [
    {
      "answer": "sand",
      "score": 0.9956642985343933
    }
  ],
  "5104": [
    {
      "answer": "all angles remain the same",
      "score": 0.9738485217094421
    }
  ],
  "5105": [
    {
      "answer": "Numerical models",
      "score": 0.7924355864524841
    }
  ],
  "5106": [
    {
      "answer": "Numerical models",
      "score": 0.993928074836731
    }
  ],
  "5107": [
    {
      "answer": "Numerical models",
      "score": 0.9472751617431641
    }
  ],
  "5108": [
    {
      "answer": "patterns of erosion and uplift",
      "score": 0.9724699258804321
    }
  ],
  "5109": [
    {
      "answer": "Numerical models",
      "score": 0.8749990463256836
    }
  ],
  "5110": [
    {
      "answer": "orogenic wedges",
      "score": 0.950941264629364
    }
  ],
  "5111": [
    {
      "answer": "sand",
      "score": 0.9670547246932983
    }
  ],
  "5112": [],
  "5113": [
    {
      "answer": "horizontal layers of sand",
      "score": 0.8377394676208496
    }
  ],
  "5114": [
    {
      "answer": "pathways for metamorphism through pressure, temperature, space, and time",
      "score": 0.7782721519470215
    }
  ],
  "5115": [
    {
      "answer": "patterns of erosion and uplift in the mountain belt",
      "score": 0.8719377517700195
    }
  ],
  "5116": [
    {
      "answer": "stratigraphers",
      "score": 0.8340609669685364
    },
    {
      "answer": "Stratigraphers",
      "score": 0.6225568652153015
    },
    {
      "answer": "stratigraphers",
      "score": 0.6910907626152039
    },
    {
      "answer": "Stratigraphers",
      "score": 0.6259673833847046
    }
  ],
  "5117": [
    {
      "answer": "geophysical",
      "score": 0.9843903183937073
    }
  ],
  "5118": [
    {
      "answer": "well logs",
      "score": 0.9793881177902222
    }
  ],
  "5119": [
    {
      "answer": "computer programs",
      "score": 0.9510790109634399
    }
  ],
  "5120": [
    {
      "answer": "water",
      "score": 0.9560794830322266
    },
    {
      "answer": "coal",
      "score": 0.9264847636222839
    },
    {
      "answer": "hydrocarbon",
      "score": 0.9728708267211914
    }
  ],
  "5121": [
    {
      "answer": "samples of stratigraphic sections",
      "score": 0.8306227922439575
    }
  ],
  "5122": [
    {
      "answer": "drill cores",
      "score": 0.7097679376602173
    }
  ],
  "5123": [],
  "5124": [
    {
      "answer": "reconstruct ancient processes occurring on the surface of the Earth",
      "score": 0.8856950998306274
    },
    {
      "answer": "interpret past environments",
      "score": 0.7209742069244385
    },
    {
      "answer": "locate areas for water, coal, and hydrocarbon extraction",
      "score": 0.618410587310791
    }
  ],
  "5125": [
    {
      "answer": "ancient processes occurring on the surface of the Earth",
      "score": 0.9439720511436462
    }
  ],
  "5126": [
    {
      "answer": "samples of stratigraphic sections",
      "score": 0.8491010665893555
    },
    {
      "answer": "drill cores",
      "score": 0.8568769693374634
    }
  ],
  "5127": [
    {
      "answer": "stratigraphic sections",
      "score": 0.6343799829483032
    }
  ],
  "5128": [
    {
      "answer": "computer programs",
      "score": 0.9707211852073669
    }
  ],
  "5129": [],
  "5130": [
    {
      "answer": "reconstruct",
      "score": 0.9076589941978455
    }
  ],
  "5131": [
    {
      "answer": "biostratigraphers",
      "score": 0.9737528562545776
    }
  ],
  "5132": [
    {
      "answer": "Geochronologists",
      "score": 0.9891858100891113
    }
  ],
  "5133": [
    {
      "answer": "to provide better absolute bounds on the timing and rates of deposition",
      "score": 0.9641687870025635
    }
  ],
  "5134": [
    {
      "answer": "Magnetic stratigraphers",
      "score": 0.9424370527267456
    }
  ],
  "5135": [
    {
      "answer": "to date the core",
      "score": 0.8317561149597168
    }
  ],
  "5136": [
    {
      "answer": "core",
      "score": 0.7538661360740662
    }
  ],
  "5137": [
    {
      "answer": "stable isotope studies",
      "score": 0.9282152652740479
    }
  ],
  "5138": [],
  "5139": [
    {
      "answer": "fossils",
      "score": 0.6434149146080017
    }
  ],
  "5140": [
    {
      "answer": "fossils",
      "score": 0.8939566016197205
    }
  ],
  "5141": [
    {
      "answer": "fossils",
      "score": 0.5960763096809387
    },
    {
      "answer": "fossils",
      "score": 0.6646339297294617
    }
  ],
  "5142": [
    {
      "answer": "past climate",
      "score": 0.8932260870933533
    }
  ],
  "5143": [
    {
      "answer": "stratigraphic section",
      "score": 0.8117830753326416
    }
  ],
  "5144": [
    {
      "answer": "date rocks within the stratigraphic section",
      "score": 0.6092793345451355
    },
    {
      "answer": "stable isotope studies",
      "score": 0.7713372111320496
    }
  ],
  "5145": [
    {
      "answer": "Persia",
      "score": 0.9954980611801147
    }
  ],
  "5146": [
    {
      "answer": "Abu al-Rayhan al-Biruni",
      "score": 0.9605147242546082
    }
  ],
  "5147": [
    {
      "answer": "Shen Kuo",
      "score": 0.9747629165649414
    }
  ],
  "5148": [
    {
      "answer": "Ibn Sina",
      "score": 0.9810711145401001
    }
  ],
  "5149": [
    {
      "answer": "fossil animal shells",
      "score": 0.9887892603874207
    }
  ],
  "5150": [
    {
      "answer": "Persia",
      "score": 0.9580408930778503
    }
  ],
  "5151": [
    {
      "answer": "the Indian subcontinent was once a sea",
      "score": 0.9790129661560059
    }
  ],
  "5152": [
    {
      "answer": "Greek and Indian scientific",
      "score": 0.9862642288208008
    }
  ],
  "5153": [
    {
      "answer": "fossil animal shells in a geological stratum in a mountain hundreds of miles from the ocean",
      "score": 0.8037936687469482
    }
  ],
  "5154": [
    {
      "answer": "erosion of the mountains and by deposition of silt",
      "score": 0.9787355065345764
    }
  ],
  "5155": [
    {
      "answer": "Persia",
      "score": 0.9232050776481628
    }
  ],
  "5156": [
    {
      "answer": "Muslim",
      "score": 0.9292431473731995
    },
    {
      "answer": "Muslim",
      "score": 0.9089716076850891
    }
  ],
  "5157": [
    {
      "answer": "Muslim conquests",
      "score": 0.6799860000610352
    },
    {
      "answer": "Muslim conquests",
      "score": 0.9385584592819214
    }
  ],
  "5158": [
    {
      "answer": "Greek and Indian scientific literature",
      "score": 0.9837369918823242
    }
  ],
  "5159": [
    {
      "answer": "973",
      "score": 0.5914556384086609
    }
  ],
  "5160": [
    {
      "answer": "James Hutton",
      "score": 0.9967755675315857
    }
  ],
  "5161": [
    {
      "answer": "Theory of the Earth",
      "score": 0.9932938814163208
    }
  ],
  "5162": [
    {
      "answer": "1795",
      "score": 0.9936246871948242
    }
  ],
  "5163": [
    {
      "answer": "the Earth must be much older than had previously been supposed",
      "score": 0.9587236046791077
    }
  ],
  "5164": [
    {
      "answer": "1785",
      "score": 0.9834612607955933
    }
  ],
  "5165": [
    {
      "answer": "1785",
      "score": 0.993359386920929
    }
  ],
  "5166": [
    {
      "answer": "Theory of the Earth",
      "score": 0.9872345924377441
    }
  ],
  "5167": [
    {
      "answer": "Theory of the Earth",
      "score": 0.9788966178894043
    }
  ],
  "5168": [
    {
      "answer": "to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea",
      "score": 0.9771638512611389
    }
  ],
  "5169": [
    {
      "answer": "1785",
      "score": 0.9834612607955933
    }
  ],
  "5170": [
    {
      "answer": "1785",
      "score": 0.9933377504348755
    }
  ],
  "5171": [
    {
      "answer": "to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea",
      "score": 0.9778308868408203
    }
  ],
  "5172": [
    {
      "answer": "James Hutton",
      "score": 0.9931449890136719
    }
  ],
  "5173": [
    {
      "answer": "1785",
      "score": 0.6679632067680359
    },
    {
      "answer": "1795",
      "score": 0.9523857235908508
    }
  ],
  "5174": [
    {
      "answer": "William Maclure",
      "score": 0.9951943755149841
    }
  ],
  "5175": [
    {
      "answer": "1809",
      "score": 0.9847666025161743
    }
  ],
  "5176": [
    {
      "answer": "1809",
      "score": 0.825303852558136
    },
    {
      "answer": "1807",
      "score": 0.8367807865142822
    }
  ],
  "5177": [
    {
      "answer": "American Philosophical Society",
      "score": 0.9951009750366211
    }
  ],
  "5178": [
    {
      "answer": "Observations on the Geology of the United States explanatory of a Geological Map",
      "score": 0.9753032326698303
    }
  ],
  "5179": [
    {
      "answer": "1809",
      "score": 0.8038218021392822
    }
  ],
  "5180": [],
  "5181": [
    {
      "answer": "Allegheny Mountains",
      "score": 0.9801946878433228
    }
  ],
  "5182": [
    {
      "answer": "Observations on the Geology of the United States explanatory of a Geological Map",
      "score": 0.9650852680206299
    }
  ],
  "5183": [
    {
      "answer": "geological map of England",
      "score": 0.9277948141098022
    }
  ],
  "5184": [
    {
      "answer": "1809",
      "score": 0.9912275671958923
    }
  ],
  "5185": [
    {
      "answer": "50",
      "score": 0.9918516278266907
    }
  ],
  "5186": [
    {
      "answer": "American Philosophical Society",
      "score": 0.9859878420829773
    }
  ],
  "5187": [
    {
      "answer": "1807",
      "score": 0.9872232675552368
    }
  ],
  "5188": [
    {
      "answer": "six years",
      "score": 0.6936237215995789
    }
  ],
  "5189": [
    {
      "answer": "Principles of Geology",
      "score": 0.9964954853057861
    }
  ],
  "5190": [
    {
      "answer": "uniformitarianism",
      "score": 0.9357773661613464
    }
  ],
  "5191": [
    {
      "answer": "uniformitarianism",
      "score": 0.9943418502807617
    },
    {
      "answer": "uniformitarianism",
      "score": 0.8774702548980713
    }
  ],
  "5192": [
    {
      "answer": "catastrophism",
      "score": 0.9952384233474731
    }
  ],
  "5193": [
    {
      "answer": "Charles Darwin",
      "score": 0.9924378395080566
    }
  ],
  "5194": [
    {
      "answer": "Principles of Geology",
      "score": 0.9371728301048279
    }
  ],
  "5195": [
    {
      "answer": "uniformitarianism",
      "score": 0.9795235991477966
    },
    {
      "answer": "uniformitarianism",
      "score": 0.7294753789901733
    }
  ],
  "5196": [
    {
      "answer": "slow geological processes",
      "score": 0.9733279943466187
    }
  ],
  "5197": [
    {
      "answer": "not widely accepted",
      "score": 0.9618192911148071
    }
  ],
  "5198": [
    {
      "answer": "Earth's features",
      "score": 0.9320049285888672
    }
  ],
  "5199": [
    {
      "answer": "Principles of Geology",
      "score": 0.9836933612823486
    }
  ],
  "5200": [
    {
      "answer": "uniformitarianism",
      "score": 0.9155707955360413
    },
    {
      "answer": "uniformitarianism",
      "score": 0.8334402441978455
    }
  ],
  "5201": [
    {
      "answer": "1830",
      "score": 0.9762319922447205
    }
  ],
  "5202": [
    {
      "answer": "Charles Darwin",
      "score": 0.9962854981422424
    }
  ],
  "5203": [
    {
      "answer": "uniformitarianism",
      "score": 0.7583370804786682
    },
    {
      "answer": "catastrophism",
      "score": 0.9094176292419434
    },
    {
      "answer": "uniformitarianism",
      "score": 0.8072444796562195
    }
  ],
  "5204": [
    {
      "answer": "pharma",
      "score": 0.962653636932373
    },
    {
      "answer": "pharma",
      "score": 0.8439553380012512
    },
    {
      "answer": "pharma",
      "score": 0.7646960020065308
    },
    {
      "answer": "pharma",
      "score": 0.7949191927909851
    }
  ],
  "5205": [
    {
      "answer": "ingredients for medicines",
      "score": 0.9478881359100342
    },
    {
      "answer": "tobacco",
      "score": 0.977449357509613
    },
    {
      "answer": "patent medicines",
      "score": 0.9832059741020203
    }
  ],
  "5206": [
    {
      "answer": "poison",
      "score": 0.9784375429153442
    }
  ],
  "5207": [
    {
      "answer": "outdated or only approproriate if herbal remedies were on offer to a large extent",
      "score": 0.9425485730171204
    }
  ],
  "5208": [
    {
      "answer": "many other herbs",
      "score": 0.9016491770744324
    }
  ],
  "5209": [
    {
      "answer": "patent medicines",
      "score": 0.7240246534347534
    }
  ],
  "5210": [
    {
      "answer": "sorcery or even poison",
      "score": 0.9585983157157898
    }
  ],
  "5211": [
    {
      "answer": "sorcery",
      "score": 0.7440877556800842
    },
    {
      "answer": "poison",
      "score": 0.9035391211509705
    }
  ],
  "5212": [
    {
      "answer": "15th\u201317th",
      "score": 0.9642398357391357
    }
  ],
  "5213": [
    {
      "answer": "healthcare professionals",
      "score": 0.8610976934432983
    }
  ],
  "5214": [
    {
      "answer": "optimal",
      "score": 0.9496666789054871
    }
  ],
  "5215": [
    {
      "answer": "optimisation of a drug treatment",
      "score": 0.893439769744873
    }
  ],
  "5216": [
    {
      "answer": "small-business proprietors",
      "score": 0.9369074702262878
    }
  ],
  "5217": [
    {
      "answer": "specialised education and training",
      "score": 0.9277551770210266
    }
  ],
  "5218": [],
  "5219": [
    {
      "answer": "optimal",
      "score": 0.8915828466415405
    }
  ],
  "5220": [],
  "5221": [],
  "5222": [],
  "5223": [
    {
      "answer": "other senior pharmacy technicians",
      "score": 0.9445222616195679
    }
  ],
  "5224": [
    {
      "answer": "General Pharmaceutical Council",
      "score": 0.9906042814254761
    }
  ],
  "5225": [
    {
      "answer": "regulates the practice of pharmacists and pharmacy technicians",
      "score": 0.7308074831962585
    }
  ],
  "5226": [
    {
      "answer": "health care professional",
      "score": 0.9866282939910889
    }
  ],
  "5227": [
    {
      "answer": "manage the pharmacy department and specialised areas in pharmacy practice",
      "score": 0.9594585299491882
    }
  ],
  "5228": [
    {
      "answer": "pharmacist",
      "score": 0.9392014145851135
    }
  ],
  "5229": [
    {
      "answer": "General Pharmaceutical Council",
      "score": 0.9403716921806335
    }
  ],
  "5230": [
    {
      "answer": "regulates the practice of pharmacists and pharmacy technicians",
      "score": 0.7462707757949829
    }
  ],
  "5231": [
    {
      "answer": "manage the pharmacy department and specialised areas in pharmacy practice",
      "score": 0.8756639361381531
    }
  ],
  "5232": [
    {
      "answer": "Diocles of Carystus",
      "score": 0.991614043712616
    }
  ],
  "5233": [
    {
      "answer": "writing a five volume book in his native Greek \u03a0\u03b5\u03c1\u03af \u03cd\u03bb\u03b7\u03c2 \u03b9\u03b1\u03c4\u03c1\u03b9\u03ba\u03ae\u03c2 in the 1st century AD",
      "score": 0.7627333998680115
    }
  ],
  "5234": [
    {
      "answer": "De Materia Medica",
      "score": 0.9648868441581726
    }
  ],
  "5235": [
    {
      "answer": "materia medica",
      "score": 0.9589167833328247
    }
  ],
  "5236": [
    {
      "answer": "middle eastern scientists",
      "score": 0.9406449794769287
    }
  ],
  "5237": [
    {
      "answer": "Diocles of Carystus",
      "score": 0.8582295775413513
    }
  ],
  "5238": [
    {
      "answer": "writing a five volume book in his native Greek \u03a0\u03b5\u03c1\u03af \u03cd\u03bb\u03b7\u03c2 \u03b9\u03b1\u03c4\u03c1\u03b9\u03ba\u03ae\u03c2",
      "score": 0.6953524351119995
    }
  ],
  "5239": [
    {
      "answer": "De Materia Medica",
      "score": 0.8998257517814636
    }
  ],
  "5240": [
    {
      "answer": "Diocles of Carystus",
      "score": 0.8731426000595093
    }
  ],
  "5241": [
    {
      "answer": "Diocles of Carystus",
      "score": 0.9849960803985596
    }
  ],
  "5242": [
    {
      "answer": "highly respected",
      "score": 0.9876964092254639
    }
  ],
  "5243": [
    {
      "answer": "Taih\u014d Code",
      "score": 0.9905398488044739
    },
    {
      "answer": "Y\u014dr\u014d Code",
      "score": 0.9746462106704712
    }
  ],
  "5244": [
    {
      "answer": "Taih\u014d Code",
      "score": 0.9743216633796692
    }
  ],
  "5245": [
    {
      "answer": "superior to all others in health-related fields such as physicians and acupuncturists",
      "score": 0.876558244228363
    }
  ],
  "5246": [],
  "5247": [
    {
      "answer": "Meiji Restoration",
      "score": 0.9904706478118896
    }
  ],
  "5248": [
    {
      "answer": "Taih\u014d Code",
      "score": 0.98455810546875
    },
    {
      "answer": "Y\u014dr\u014d Code",
      "score": 0.9742403030395508
    }
  ],
  "5249": [],
  "5250": [],
  "5251": [
    {
      "answer": "botany and chemistry",
      "score": 0.5952033996582031
    },
    {
      "answer": "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes)",
      "score": 0.6801831722259521
    },
    {
      "answer": "Al-Biruni",
      "score": 0.5275099873542786
    }
  ],
  "5252": [
    {
      "answer": "Muhammad ibn Zakar\u012bya R\u0101zi",
      "score": 0.986185610294342
    }
  ],
  "5253": [
    {
      "answer": "Abu al-Qasim al-Zahrawi",
      "score": 0.9638656377792358
    }
  ],
  "5254": [
    {
      "answer": "sodium carbonate",
      "score": 0.9858458042144775
    },
    {
      "answer": "potassium carbonate",
      "score": 0.9884837865829468
    }
  ],
  "5255": [
    {
      "answer": "Al-Muwaffaq",
      "score": 0.9727423191070557
    }
  ],
  "5256": [
    {
      "answer": "Muhammad ibn Zakar\u012bya R\u0101zi",
      "score": 0.9468678832054138
    }
  ],
  "5257": [],
  "5258": [
    {
      "answer": "Al-Muwaffaq",
      "score": 0.9734773635864258
    }
  ],
  "5259": [
    {
      "answer": "arsenious oxide",
      "score": 0.551285445690155
    },
    {
      "answer": "lead compounds",
      "score": 0.6046364903450012
    }
  ],
  "5260": [],
  "5261": [
    {
      "answer": "1317",
      "score": 0.9882261157035828
    }
  ],
  "5262": [
    {
      "answer": "Florence, Italy",
      "score": 0.946916937828064
    }
  ],
  "5263": [
    {
      "answer": "museum",
      "score": 0.9139915704727173
    }
  ],
  "5264": [
    {
      "answer": "albarellos from the 16th and 17th centuries",
      "score": 0.7806471586227417
    },
    {
      "answer": "old prescription books",
      "score": 0.8586534261703491
    },
    {
      "answer": "antique drugs",
      "score": 0.872753918170929
    }
  ],
  "5265": [
    {
      "answer": "1221",
      "score": 0.9708743691444397
    }
  ],
  "5266": [
    {
      "answer": "Dubrovnik, Croatia",
      "score": 0.6511366367340088
    }
  ],
  "5267": [
    {
      "answer": "1221",
      "score": 0.9704831838607788
    }
  ],
  "5268": [],
  "5269": [
    {
      "answer": "antique drugs",
      "score": 0.6962983012199402
    }
  ],
  "5270": [
    {
      "answer": "pharmacy legislation",
      "score": 0.9956238269805908
    }
  ],
  "5271": [],
  "5272": [
    {
      "answer": "automation",
      "score": 0.9736687541007996
    }
  ],
  "5273": [
    {
      "answer": "patient safety issues",
      "score": 0.8419171571731567
    }
  ],
  "5274": [
    {
      "answer": "storage conditions",
      "score": 0.9690479040145874
    },
    {
      "answer": "compulsory texts",
      "score": 0.9718581438064575
    }
  ],
  "5275": [
    {
      "answer": "pharmacy legislation",
      "score": 0.9943571090698242
    }
  ],
  "5276": [
    {
      "answer": "automation",
      "score": 0.9541946649551392
    }
  ],
  "5277": [
    {
      "answer": "storage conditions",
      "score": 0.8883216381072998
    },
    {
      "answer": "compulsory texts",
      "score": 0.9232598543167114
    }
  ],
  "5278": [
    {
      "answer": "patient safety issues",
      "score": 0.7840010523796082
    }
  ],
  "5279": [
    {
      "answer": "automation",
      "score": 0.6213001608848572
    },
    {
      "answer": "patient safety issues",
      "score": 0.6993179321289062
    }
  ],
  "5280": [
    {
      "answer": "pharmacy practice residency",
      "score": 0.978545069694519
    }
  ],
  "5281": [],
  "5282": [
    {
      "answer": "safety of medications",
      "score": 0.8882975578308105
    },
    {
      "answer": "patient compliance issues",
      "score": 0.818037211894989
    }
  ],
  "5283": [
    {
      "answer": "clinical pharmacists",
      "score": 0.6187497973442078
    }
  ],
  "5284": [],
  "5285": [],
  "5286": [
    {
      "answer": "safety of medications",
      "score": 0.9047989845275879
    },
    {
      "answer": "patient compliance issues",
      "score": 0.844292402267456
    }
  ],
  "5287": [],
  "5288": [],
  "5289": [
    {
      "answer": "unit-dose, or a single dose of medicine",
      "score": 0.9179032444953918
    }
  ],
  "5290": [
    {
      "answer": "high risk preparations and some other compounding functions",
      "score": 0.7673189640045166
    }
  ],
  "5291": [
    {
      "answer": "high cost of medications and drug-related technology",
      "score": 0.9583380818367004
    }
  ],
  "5292": [],
  "5293": [],
  "5294": [],
  "5295": [],
  "5296": [
    {
      "answer": "high cost of medications and drug-related technology",
      "score": 0.9646176099777222
    }
  ],
  "5297": [],
  "5298": [
    {
      "answer": "optimizes the use of medication",
      "score": 0.8845376968383789
    }
  ],
  "5299": [
    {
      "answer": "inside hospitals and clinics",
      "score": 0.9639931321144104
    }
  ],
  "5300": [
    {
      "answer": "physicians",
      "score": 0.965874433517456
    }
  ],
  "5301": [
    {
      "answer": "patient care rounds drug product selection",
      "score": 0.9626264572143555
    }
  ],
  "5302": [
    {
      "answer": "hospitals and clinics",
      "score": 0.73771733045578
    }
  ],
  "5303": [
    {
      "answer": "inside hospitals and clinics",
      "score": 0.9578613042831421
    }
  ],
  "5304": [
    {
      "answer": "physicians and other healthcare professionals",
      "score": 0.7217385172843933
    }
  ],
  "5305": [
    {
      "answer": "patient care rounds drug product selection",
      "score": 0.702646017074585
    }
  ],
  "5306": [
    {
      "answer": "hospitals and clinics",
      "score": 0.9356570243835449
    }
  ],
  "5307": [
    {
      "answer": "creating a comprehensive drug therapy plan for patient-specific problems",
      "score": 0.8409518599510193
    },
    {
      "answer": "identifying goals of therapy",
      "score": 0.6996110677719116
    },
    {
      "answer": "reviewing all prescribed medications prior to dispensing and administration to the patient",
      "score": 0.8242485523223877
    }
  ],
  "5308": [
    {
      "answer": "evaluation of the appropriateness of the drug therapy",
      "score": 0.9461022615432739
    }
  ],
  "5309": [],
  "5310": [
    {
      "answer": "potential drug interactions",
      "score": 0.9040794372558594
    },
    {
      "answer": "adverse drug reactions",
      "score": 0.884718120098114
    }
  ],
  "5311": [
    {
      "answer": "creating a comprehensive drug therapy plan for patient-specific problems",
      "score": 0.7503159642219543
    },
    {
      "answer": "identifying goals of therapy",
      "score": 0.6542801856994629
    },
    {
      "answer": "reviewing all prescribed medications prior to dispensing and administration to the patient",
      "score": 0.7982456088066101
    },
    {
      "answer": "monitor for potential drug interactions, adverse drug reactions",
      "score": 0.714438259601593
    }
  ],
  "5312": [
    {
      "answer": "evaluation of the appropriateness of the drug therapy",
      "score": 0.9114086031913757
    }
  ],
  "5313": [],
  "5314": [
    {
      "answer": "drug interactions",
      "score": 0.9184894561767578
    },
    {
      "answer": "adverse drug reactions",
      "score": 0.8619303703308105
    }
  ],
  "5315": [
    {
      "answer": "full independent prescribing authority",
      "score": 0.9764567017555237
    }
  ],
  "5316": [
    {
      "answer": "North Carolina",
      "score": 0.7805144786834717
    },
    {
      "answer": "New Mexico",
      "score": 0.784856379032135
    }
  ],
  "5317": [
    {
      "answer": "2011",
      "score": 0.9901240468025208
    }
  ],
  "5318": [
    {
      "answer": "Board Certified Ambulatory Care Pharmacist",
      "score": 0.9901828765869141
    }
  ],
  "5319": [
    {
      "answer": "VA",
      "score": 0.9310516715049744
    }
  ],
  "5320": [
    {
      "answer": "full independent prescribing authority",
      "score": 0.9469689130783081
    }
  ],
  "5321": [
    {
      "answer": "North Carolina",
      "score": 0.8561129570007324
    },
    {
      "answer": "New Mexico",
      "score": 0.8658055067062378
    }
  ],
  "5322": [
    {
      "answer": "2011",
      "score": 0.992319643497467
    }
  ],
  "5323": [
    {
      "answer": "VA",
      "score": 0.878537654876709
    }
  ],
  "5324": [
    {
      "answer": "Board Certified Ambulatory Care Pharmacist",
      "score": 0.8637046217918396
    }
  ],
  "5325": [
    {
      "answer": "medication regimen review",
      "score": 0.98521488904953
    }
  ],
  "5326": [
    {
      "answer": "nursing homes",
      "score": 0.9900943040847778
    }
  ],
  "5327": [
    {
      "answer": "Omnicare",
      "score": 0.9533410668373108
    },
    {
      "answer": "Kindred Healthcare",
      "score": 0.9489303827285767
    },
    {
      "answer": "PharMerica",
      "score": 0.9294463396072388
    }
  ],
  "5328": [
    {
      "answer": "many elderly people are now taking numerous medications but continue to live outside of institutional settings",
      "score": 0.9433916807174683
    }
  ],
  "5329": [
    {
      "answer": "provide consulting services",
      "score": 0.9612945914268494
    }
  ],
  "5330": [
    {
      "answer": "medication regimen review",
      "score": 0.5567018985748291
    },
    {
      "answer": "actual dispensing of drugs",
      "score": 0.9005735516548157
    }
  ],
  "5331": [
    {
      "answer": "nursing homes",
      "score": 0.9358595609664917
    },
    {
      "answer": "non-institutional settings",
      "score": 0.8792182207107544
    }
  ],
  "5332": [
    {
      "answer": "Omnicare",
      "score": 0.8377395868301392
    },
    {
      "answer": "Kindred Healthcare",
      "score": 0.8401918411254883
    },
    {
      "answer": "PharMerica",
      "score": 0.7994325757026672
    }
  ],
  "5333": [
    {
      "answer": "many elderly people are now taking numerous medications but continue to live outside of institutional settings",
      "score": 0.9133024215698242
    }
  ],
  "5334": [
    {
      "answer": "provide consulting services",
      "score": 0.9051837921142578
    }
  ],
  "5335": [
    {
      "answer": "2000",
      "score": 0.9855021238327026
    }
  ],
  "5336": [
    {
      "answer": "brick-and-mortar community pharmacies",
      "score": 0.971190333366394
    }
  ],
  "5337": [
    {
      "answer": "online pharmacies",
      "score": 0.9779589176177979
    }
  ],
  "5338": [
    {
      "answer": "more convenient and private method",
      "score": 0.9250892996788025
    }
  ],
  "5339": [
    {
      "answer": "the method by which the medications are requested and received",
      "score": 0.9838577508926392
    }
  ],
  "5340": [
    {
      "answer": "2000",
      "score": 0.9800026416778564
    }
  ],
  "5341": [
    {
      "answer": "brick-and-mortar community pharmacies",
      "score": 0.9173857569694519
    }
  ],
  "5342": [
    {
      "answer": "online pharmacies",
      "score": 0.8707289695739746
    }
  ],
  "5343": [
    {
      "answer": "more convenient and private method",
      "score": 0.9029040336608887
    }
  ],
  "5344": [
    {
      "answer": "the method by which the medications are requested and received",
      "score": 0.965772807598114
    }
  ],
  "5345": [
    {
      "answer": "to avoid the \"inconvenience\" of visiting a doctor",
      "score": 0.981397807598114
    },
    {
      "answer": "to obtain medications which their doctors were unwilling to prescribe",
      "score": 0.955830991268158
    }
  ],
  "5346": [],
  "5347": [
    {
      "answer": "potentially dangerous",
      "score": 0.9652285575866699
    }
  ],
  "5348": [
    {
      "answer": "sell prescription drugs without requiring a prescription",
      "score": 0.9808357954025269
    }
  ],
  "5349": [
    {
      "answer": "sell prescription drugs and require a valid prescription",
      "score": 0.9652395248413086
    },
    {
      "answer": "sell prescription drugs without requiring a prescription",
      "score": 0.824690580368042
    }
  ],
  "5350": [
    {
      "answer": "to avoid the \"inconvenience\" of visiting a doctor",
      "score": 0.7703343629837036
    },
    {
      "answer": "potentially dangerous",
      "score": 0.7302343249320984
    }
  ],
  "5351": [
    {
      "answer": "sell prescription drugs without requiring a prescription",
      "score": 0.846155047416687
    }
  ],
  "5352": [
    {
      "answer": "valid prescription",
      "score": 0.7575399875640869
    }
  ],
  "5353": [],
  "5354": [
    {
      "answer": "issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
      "score": 0.9813826084136963
    }
  ],
  "5355": [
    {
      "answer": "the ease with which people, youth in particular, can obtain controlled substances (e.g., Vicodin, generically known as hydrocodone) via the Internet without a prescription issued by a doctor/practitioner who has an established doctor-patient relationship",
      "score": 0.8456516265869141
    }
  ],
  "5356": [
    {
      "answer": "issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
      "score": 0.9650169014930725
    }
  ],
  "5357": [
    {
      "answer": "The filling pharmacy has a corresponding responsibility to ensure that the prescription is valid",
      "score": 0.9037607312202454
    }
  ],
  "5358": [
    {
      "answer": "individual state laws",
      "score": 0.9557043313980103
    }
  ],
  "5359": [
    {
      "answer": "Vicodin",
      "score": 0.9757183790206909
    }
  ],
  "5360": [],
  "5361": [
    {
      "answer": "individual state laws",
      "score": 0.7871931791305542
    }
  ],
  "5362": [
    {
      "answer": "Vicodin",
      "score": 0.8702442646026611
    }
  ],
  "5363": [
    {
      "answer": "issued for a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship",
      "score": 0.9431793689727783
    }
  ],
  "5364": [
    {
      "answer": "The filling pharmacy has a corresponding responsibility to ensure that the prescription is valid",
      "score": 0.7720534801483154
    }
  ],
  "5365": [
    {
      "answer": "reduce consumer costs",
      "score": 0.9941930770874023
    }
  ],
  "5366": [
    {
      "answer": "Canada",
      "score": 0.9812768697738647
    }
  ],
  "5367": [
    {
      "answer": "international drug suppliers",
      "score": 0.9875589609146118
    }
  ],
  "5368": [
    {
      "answer": "There is no known case of any U.S. citizens buying Canadian drugs for personal use with a prescription, who has ever been charged by authorities.",
      "score": 0.823110818862915
    }
  ],
  "5369": [
    {
      "answer": "legalize importation of medications from Canada and other countries",
      "score": 0.9267889857292175
    }
  ],
  "5370": [
    {
      "answer": "to reduce consumer costs",
      "score": 0.9783196449279785
    }
  ],
  "5371": [
    {
      "answer": "U.S",
      "score": 0.8254267573356628
    }
  ],
  "5372": [
    {
      "answer": "international drug suppliers",
      "score": 0.9454330205917358
    },
    {
      "answer": "consumers",
      "score": 0.8496630787849426
    }
  ],
  "5373": [
    {
      "answer": "While in most cases importation of prescription medications violates Food and Drug Administration (FDA) regulations and federal laws, enforcement is generally targeted at international drug suppliers, rather than consumers.",
      "score": 0.8116685748100281
    },
    {
      "answer": "There is no known case of any U.S. citizens buying Canadian drugs for personal use with a prescription, who has ever been charged by authorities.",
      "score": 0.794065535068512
    }
  ],
  "5374": [
    {
      "answer": "pharmacy practice science",
      "score": 0.8937930464744568
    },
    {
      "answer": "applied information science",
      "score": 0.9461991190910339
    }
  ],
  "5375": [
    {
      "answer": "information technology departments",
      "score": 0.9049504995346069
    },
    {
      "answer": "healthcare information technology",
      "score": 0.7246172428131104
    }
  ],
  "5376": [
    {
      "answer": "national and international patient information projects",
      "score": 0.9796974062919617
    }
  ],
  "5377": [
    {
      "answer": "medication management system development, deployment and optimization",
      "score": 0.8317939043045044
    }
  ],
  "5378": [
    {
      "answer": "quickly",
      "score": 0.93711256980896
    }
  ],
  "5379": [
    {
      "answer": "applied information science",
      "score": 0.7094453573226929
    }
  ],
  "5380": [
    {
      "answer": "information technology",
      "score": 0.94264155626297
    },
    {
      "answer": "healthcare information technology",
      "score": 0.6767005920410156
    }
  ],
  "5381": [
    {
      "answer": "patient information projects",
      "score": 0.9366787672042847
    },
    {
      "answer": "health system interoperability goals",
      "score": 0.8520512580871582
    }
  ],
  "5382": [
    {
      "answer": "medication management system development, deployment and optimization",
      "score": 0.7547619342803955
    }
  ],
  "5383": [
    {
      "answer": "Specialty pharmacies",
      "score": 0.6402120590209961
    },
    {
      "answer": "specialty pharmacies",
      "score": 0.5833355784416199
    },
    {
      "answer": "specialty pharmacies",
      "score": 0.6459888815879822
    }
  ],
  "5384": [
    {
      "answer": "19",
      "score": 0.9796333312988281
    }
  ],
  "5385": [],
  "5386": [
    {
      "answer": "high cost injectable, oral, infused, or inhaled medications",
      "score": 0.7574882507324219
    }
  ],
  "5387": [
    {
      "answer": "lab monitoring, adherence counseling",
      "score": 0.9343913197517395
    },
    {
      "answer": "assist patients with cost-containment strategies",
      "score": 0.8622998595237732
    }
  ],
  "5388": [],
  "5389": [
    {
      "answer": "19",
      "score": 0.9771388173103333
    }
  ],
  "5390": [],
  "5391": [],
  "5392": [
    {
      "answer": "regulated separately from physicians",
      "score": 0.9805808067321777
    }
  ],
  "5393": [
    {
      "answer": "pharmacists",
      "score": 0.8274993896484375
    },
    {
      "answer": "pharmacists",
      "score": 0.9775720238685608
    },
    {
      "answer": "pharmacists",
      "score": 0.5621623992919922
    }
  ],
  "5394": [
    {
      "answer": "American Medical Association",
      "score": 0.9812731146812439
    }
  ],
  "5395": [
    {
      "answer": "7 to 10 percent",
      "score": 0.99139404296875
    }
  ],
  "5396": [
    {
      "answer": "form business partnerships with physicians",
      "score": 0.9747671484947205
    }
  ],
  "5397": [
    {
      "answer": "pharmacists",
      "score": 0.7494128346443176
    },
    {
      "answer": "pharmacists",
      "score": 0.9434474110603333
    }
  ],
  "5398": [
    {
      "answer": "American Medical Association",
      "score": 0.9528653025627136
    }
  ],
  "5399": [
    {
      "answer": "pharmacists are regulated separately from physicians",
      "score": 0.8872968554496765
    }
  ],
  "5400": [
    {
      "answer": "rural areas in the United Kingdom",
      "score": 0.8937348127365112
    }
  ],
  "5401": [
    {
      "answer": "United Kingdom",
      "score": 0.6687861680984497
    },
    {
      "answer": "Austria",
      "score": 0.8500957489013672
    }
  ],
  "5402": [
    {
      "answer": "1.6 kilometres",
      "score": 0.993319034576416
    }
  ],
  "5403": [
    {
      "answer": "1.6 kilometres",
      "score": 0.9919164180755615
    }
  ],
  "5404": [
    {
      "answer": "rural areas in the United Kingdom",
      "score": 0.8707994818687439
    }
  ],
  "5405": [
    {
      "answer": "Austria",
      "score": 0.9894885420799255
    }
  ],
  "5406": [
    {
      "answer": "1.6 kilometres",
      "score": 0.9904122352600098
    }
  ],
  "5407": [
    {
      "answer": "1.6 kilometres",
      "score": 0.9821417331695557
    }
  ],
  "5408": [
    {
      "answer": "high risk of a conflict of interest",
      "score": 0.9550349712371826
    }
  ],
  "5409": [
    {
      "answer": "financial self-interest",
      "score": 0.8380247354507446
    }
  ],
  "5410": [
    {
      "answer": "checks and balances system",
      "score": 0.9868186116218567
    }
  ],
  "5411": [
    {
      "answer": "obtaining cost-effective medication and avoiding the unnecessary use of medication that may have side-effects",
      "score": 0.8865185379981995
    }
  ],
  "5412": [
    {
      "answer": "financial self-interest in \"diagnosing\" as many conditions as possible, and in exaggerating their seriousness",
      "score": 0.7649460434913635
    },
    {
      "answer": "sell more medications to the patient",
      "score": 0.7394241690635681
    }
  ],
  "5413": [
    {
      "answer": "high risk of a conflict of interest",
      "score": 0.9490967392921448
    }
  ],
  "5414": [
    {
      "answer": "high risk of a conflict of interest",
      "score": 0.8995689153671265
    },
    {
      "answer": "avoidance of absolute powers",
      "score": 0.7695528268814087
    }
  ],
  "5415": [
    {
      "answer": "checks and balances system",
      "score": 0.9801638126373291
    }
  ],
  "5416": [
    {
      "answer": "obtaining cost-effective medication",
      "score": 0.9370376467704773
    }
  ],
  "5417": [],
  "5418": [
    {
      "answer": "more integral within the health care system",
      "score": 0.7681580185890198
    }
  ],
  "5419": [
    {
      "answer": "patient care skills",
      "score": 0.8312351107597351
    }
  ],
  "5420": [
    {
      "answer": "clinical services",
      "score": 0.9746885299682617
    }
  ],
  "5421": [
    {
      "answer": "thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual",
      "score": 0.8659647107124329
    }
  ],
  "5422": [
    {
      "answer": "increased patient health outcomes",
      "score": 0.9614846110343933
    },
    {
      "answer": "decreased costs to the health care system",
      "score": 0.9231286644935608
    }
  ],
  "5423": [
    {
      "answer": "more integral within the health care system",
      "score": 0.7520312666893005
    }
  ],
  "5424": [
    {
      "answer": "patient care skills",
      "score": 0.7842459678649902
    }
  ],
  "5425": [
    {
      "answer": "clinical services",
      "score": 0.9778426885604858
    }
  ],
  "5426": [
    {
      "answer": "thorough analysis of all medication (prescription, non-prescription, and herbals) currently being taken by an individual",
      "score": 0.7981342673301697
    }
  ],
  "5427": [
    {
      "answer": "increased patient health outcomes",
      "score": 0.8411969542503357
    },
    {
      "answer": "decreased costs to the health care system",
      "score": 0.8644379377365112
    }
  ],
  "5428": [
    {
      "answer": "Alberta",
      "score": 0.9838895797729492
    },
    {
      "answer": "British Columbia",
      "score": 0.9837104082107544
    }
  ],
  "5429": [
    {
      "answer": "Australian Government",
      "score": 0.9845854043960571
    }
  ],
  "5430": [
    {
      "answer": "medicine use reviews",
      "score": 0.9873363971710205
    }
  ],
  "5431": [
    {
      "answer": "pharmaceutical care",
      "score": 0.9699701070785522
    },
    {
      "answer": "clinical pharmacy",
      "score": 0.9528341293334961
    }
  ],
  "5432": [
    {
      "answer": "Doctor of Pharmacy (Pharm. D.)",
      "score": 0.9347755908966064
    }
  ],
  "5433": [
    {
      "answer": "Alberta",
      "score": 0.9847126007080078
    },
    {
      "answer": "British Columbia",
      "score": 0.9846656322479248
    }
  ],
  "5434": [
    {
      "answer": "Australian Government",
      "score": 0.9658350944519043
    }
  ],
  "5435": [
    {
      "answer": "medicine use reviews",
      "score": 0.9894968271255493
    }
  ],
  "5436": [
    {
      "answer": "pharmaceutical care",
      "score": 0.9326246976852417
    },
    {
      "answer": "clinical pharmacy",
      "score": 0.9050233364105225
    }
  ],
  "5437": [
    {
      "answer": "Doctor of Pharmacy (Pharm. D.)",
      "score": 0.8607943654060364
    }
  ],
  "5438": [
    {
      "answer": "mortar and pestle",
      "score": 0.9858372211456299
    },
    {
      "answer": "\u211e (recipere) character",
      "score": 0.9205670356750488
    }
  ],
  "5439": [
    {
      "answer": "show globe",
      "score": 0.9885327816009521
    }
  ],
  "5440": [
    {
      "answer": "Netherlands",
      "score": 0.9920127987861633
    },
    {
      "answer": "Netherlands",
      "score": 0.9244697690010071
    }
  ],
  "5441": [
    {
      "answer": "Germany",
      "score": 0.9832164645195007
    },
    {
      "answer": "Austria",
      "score": 0.9696044921875
    }
  ],
  "5442": [
    {
      "answer": "France",
      "score": 0.9296656250953674
    },
    {
      "answer": "Argentina",
      "score": 0.9250448942184448
    },
    {
      "answer": "United Kingdom",
      "score": 0.8768339157104492
    },
    {
      "answer": "Belgium",
      "score": 0.9097379446029663
    },
    {
      "answer": "Ireland",
      "score": 0.9302451014518738
    },
    {
      "answer": "Italy",
      "score": 0.9310052990913391
    },
    {
      "answer": "Spain",
      "score": 0.9410744905471802
    },
    {
      "answer": "India",
      "score": 0.9137938022613525
    }
  ],
  "5443": [
    {
      "answer": "mortar and pestle",
      "score": 0.9833495020866394
    },
    {
      "answer": "\u211e (recipere) character",
      "score": 0.9168588519096375
    }
  ],
  "5444": [
    {
      "answer": "show globe",
      "score": 0.9894201755523682
    }
  ],
  "5445": [
    {
      "answer": "Netherlands",
      "score": 0.951961874961853
    },
    {
      "answer": "Netherlands",
      "score": 0.8329952359199524
    }
  ],
  "5446": [
    {
      "answer": "Germany",
      "score": 0.9745582938194275
    },
    {
      "answer": "Austria",
      "score": 0.9609147310256958
    }
  ],
  "5447": [
    {
      "answer": "France",
      "score": 0.6387768387794495
    },
    {
      "answer": "Ireland",
      "score": 0.6540848612785339
    },
    {
      "answer": "Spain",
      "score": 0.6919652819633484
    },
    {
      "answer": "India",
      "score": 0.7107536792755127
    },
    {
      "answer": "Germany",
      "score": 0.8259647488594055
    },
    {
      "answer": "Austria",
      "score": 0.8146433234214783
    }
  ],
  "5448": [
    {
      "answer": "Civil disobedience",
      "score": 0.9930977821350098
    }
  ],
  "5449": [],
  "5450": [
    {
      "answer": "Singing Revolution",
      "score": 0.9815955758094788
    }
  ],
  "5451": [
    {
      "answer": "Ukraine",
      "score": 0.9937251210212708
    }
  ],
  "5452": [
    {
      "answer": "Georgia",
      "score": 0.9894160628318787
    }
  ],
  "5453": [
    {
      "answer": "Egyptians",
      "score": 0.9914516806602478
    }
  ],
  "5454": [
    {
      "answer": "British occupation",
      "score": 0.9842821359634399
    }
  ],
  "5455": [],
  "5456": [
    {
      "answer": "British occupation",
      "score": 0.5565646886825562
    },
    {
      "answer": "unfair laws",
      "score": 0.9260619878768921
    }
  ],
  "5457": [
    {
      "answer": "American Civil Rights Movement",
      "score": 0.6957002282142639
    }
  ],
  "5458": [],
  "5459": [
    {
      "answer": "independence from the British Empire",
      "score": 0.6649438738822937
    },
    {
      "answer": "oust their communist governments",
      "score": 0.7178329229354858
    }
  ],
  "5460": [
    {
      "answer": "British",
      "score": 0.9895700216293335
    },
    {
      "answer": "British",
      "score": 0.8629225492477417
    }
  ],
  "5461": [
    {
      "answer": "Baltic countries",
      "score": 0.950533390045166
    }
  ],
  "5462": [
    {
      "answer": "Czechoslovakia",
      "score": 0.6695446968078613
    },
    {
      "answer": "Ukraine",
      "score": 0.8537347316741943
    }
  ],
  "5463": [
    {
      "answer": "Antigone",
      "score": 0.9702704548835754
    },
    {
      "answer": "Antigone",
      "score": 0.6481711864471436
    }
  ],
  "5464": [
    {
      "answer": "Oedipus",
      "score": 0.9929282069206238
    }
  ],
  "5465": [
    {
      "answer": "Creon",
      "score": 0.9938638210296631
    }
  ],
  "5466": [
    {
      "answer": "Antigone",
      "score": 0.8153222799301147
    },
    {
      "answer": "Antigone",
      "score": 0.7909814119338989
    }
  ],
  "5467": [
    {
      "answer": "giving her brother Polynices a proper burial",
      "score": 0.9886743426322937
    }
  ],
  "5468": [
    {
      "answer": "Antigone",
      "score": 0.9404836297035217
    },
    {
      "answer": "Antigone",
      "score": 0.5168527364730835
    }
  ],
  "5469": [
    {
      "answer": "Sophocles",
      "score": 0.9927085041999817
    }
  ],
  "5470": [
    {
      "answer": "Creon",
      "score": 0.9758641123771667
    }
  ],
  "5471": [],
  "5472": [],
  "5473": [
    {
      "answer": "Antigone",
      "score": 0.9557852745056152
    },
    {
      "answer": "Antigone",
      "score": 0.6623014807701111
    }
  ],
  "5474": [
    {
      "answer": "Oedipus",
      "score": 0.9930927753448486
    }
  ],
  "5475": [
    {
      "answer": "Creon",
      "score": 0.9968825578689575
    }
  ],
  "5476": [
    {
      "answer": "she must obey her conscience rather than human law",
      "score": 0.9463421702384949
    }
  ],
  "5477": [
    {
      "answer": "obey her conscience",
      "score": 0.9880966544151306
    }
  ],
  "5478": [
    {
      "answer": "Percy Shelley",
      "score": 0.9951745271682739
    }
  ],
  "5479": [
    {
      "answer": "nonviolent",
      "score": 0.9858142733573914
    }
  ],
  "5480": [],
  "5481": [
    {
      "answer": "Satyagraha",
      "score": 0.9744748473167419
    },
    {
      "answer": "Satyagraha",
      "score": 0.8311976790428162
    }
  ],
  "5482": [
    {
      "answer": "a free India",
      "score": 0.9594696760177612
    }
  ],
  "5483": [
    {
      "answer": "Percy Shelley",
      "score": 0.9962527751922607
    }
  ],
  "5484": [
    {
      "answer": "Peterloo massacre",
      "score": 0.7262006998062134
    },
    {
      "answer": "unjust forms of authority",
      "score": 0.6547781229019165
    }
  ],
  "5485": [
    {
      "answer": "nonviolent protest",
      "score": 0.983203649520874
    }
  ],
  "5486": [
    {
      "answer": "Gandhi",
      "score": 0.5972949862480164
    },
    {
      "answer": "Gandhi",
      "score": 0.56110018491745
    },
    {
      "answer": "Gandhi",
      "score": 0.5542380809783936
    }
  ],
  "5487": [
    {
      "answer": "Satyagraha",
      "score": 0.953400194644928
    },
    {
      "answer": "Satyagraha",
      "score": 0.8285349607467651
    }
  ],
  "5488": [
    {
      "answer": "1819",
      "score": 0.9911910891532898
    }
  ],
  "5489": [],
  "5490": [],
  "5491": [
    {
      "answer": "unjust forms of authority",
      "score": 0.9511934518814087
    }
  ],
  "5492": [
    {
      "answer": "Masque of Anarchy",
      "score": 0.9733459949493408
    }
  ],
  "5493": [
    {
      "answer": "muggers",
      "score": 0.9802007675170898
    },
    {
      "answer": "arsonists",
      "score": 0.976561427116394
    },
    {
      "answer": "draft evaders",
      "score": 0.9793739318847656
    },
    {
      "answer": "campaign hecklers",
      "score": 0.9772722721099854
    },
    {
      "answer": "campus militants",
      "score": 0.9801576137542725
    },
    {
      "answer": "anti-war demonstrators",
      "score": 0.9776820540428162
    },
    {
      "answer": "juvenile delinquents",
      "score": 0.9745796322822571
    },
    {
      "answer": "political assassins",
      "score": 0.9757281541824341
    }
  ],
  "5494": [
    {
      "answer": "ambiguity",
      "score": 0.9836074709892273
    }
  ],
  "5495": [
    {
      "answer": "debased",
      "score": 0.8681696057319641
    }
  ],
  "5496": [
    {
      "answer": "Marshall Cohen",
      "score": 0.9913251996040344
    }
  ],
  "5497": [
    {
      "answer": "utterly debased",
      "score": 0.9463770389556885
    }
  ],
  "5498": [
    {
      "answer": "Marshall Cohen",
      "score": 0.9941576719284058
    }
  ],
  "5499": [
    {
      "answer": "utterly debased",
      "score": 0.9792253971099854
    }
  ],
  "5500": [
    {
      "answer": "Agnew",
      "score": 0.9814671874046326
    }
  ],
  "5501": [
    {
      "answer": "ambiguity",
      "score": 0.9211384654045105
    }
  ],
  "5502": [
    {
      "answer": "ambiguity",
      "score": 0.9729156494140625
    }
  ],
  "5503": [
    {
      "answer": "it has become a code-word describing the activities of muggers, arsonists, draft evaders, campaign hecklers, campus militants, anti-war demonstrators, juvenile delinquents and political assassins",
      "score": 0.9209721088409424
    }
  ],
  "5504": [],
  "5505": [
    {
      "answer": "muggers",
      "score": 0.9596707820892334
    },
    {
      "answer": "arsonists",
      "score": 0.9517105221748352
    },
    {
      "answer": "draft evaders",
      "score": 0.9488149285316467
    },
    {
      "answer": "campaign hecklers",
      "score": 0.9306394457817078
    },
    {
      "answer": "campus militants",
      "score": 0.9293054938316345
    },
    {
      "answer": "anti-war demonstrators",
      "score": 0.92535400390625
    },
    {
      "answer": "juvenile delinquents",
      "score": 0.9035952091217041
    },
    {
      "answer": "political assassins",
      "score": 0.8884234428405762
    }
  ],
  "5506": [
    {
      "answer": "muggers",
      "score": 0.8416284918785095
    },
    {
      "answer": "arsonists",
      "score": 0.8215236663818359
    },
    {
      "answer": "draft evaders",
      "score": 0.7282527685165405
    },
    {
      "answer": "campus militants",
      "score": 0.581074595451355
    },
    {
      "answer": "anti-war demonstrators",
      "score": 0.5745882987976074
    },
    {
      "answer": "juvenile delinquents",
      "score": 0.6395095586776733
    },
    {
      "answer": "political assassins",
      "score": 0.5723366737365723
    }
  ],
  "5507": [
    {
      "answer": "LeGrande",
      "score": 0.9906015396118164
    }
  ],
  "5508": [
    {
      "answer": "semantical problems and grammatical niceties",
      "score": 0.5989189743995667
    }
  ],
  "5509": [],
  "5510": [
    {
      "answer": "semantical",
      "score": 0.9407917261123657
    }
  ],
  "5511": [],
  "5512": [
    {
      "answer": "LeGrande",
      "score": 0.9877163767814636
    }
  ],
  "5513": [
    {
      "answer": "voluminous",
      "score": 0.9192795753479004
    }
  ],
  "5514": [
    {
      "answer": "semantical problems",
      "score": 0.9844641089439392
    }
  ],
  "5515": [
    {
      "answer": "nonviolent",
      "score": 0.9865427017211914
    }
  ],
  "5516": [
    {
      "answer": "violent",
      "score": 0.98328697681427
    }
  ],
  "5517": [
    {
      "answer": "LeGrande",
      "score": 0.9910929799079895
    }
  ],
  "5518": [
    {
      "answer": "semantical problems",
      "score": 0.8894997835159302
    }
  ],
  "5519": [
    {
      "answer": "semantical problems",
      "score": 0.9908957481384277
    }
  ],
  "5520": [
    {
      "answer": "voluminous",
      "score": 0.9128202199935913
    }
  ],
  "5521": [
    {
      "answer": "Alice in Wonderland",
      "score": 0.9928716421127319
    }
  ],
  "5522": [
    {
      "answer": "not",
      "score": 0.9730439782142639
    }
  ],
  "5523": [],
  "5524": [
    {
      "answer": "pertaining to a citizen's relation to the state and its laws",
      "score": 0.903160572052002
    }
  ],
  "5525": [],
  "5526": [
    {
      "answer": "two public agencies, especially two equally sovereign branches of government, conflict",
      "score": 0.6787874698638916
    }
  ],
  "5527": [
    {
      "answer": "a citizen's relation to the state and its laws",
      "score": 0.9279687404632568
    }
  ],
  "5528": [
    {
      "answer": "the head of government of a country were to refuse to enforce a decision of that country's highest court",
      "score": 0.8799701929092407
    }
  ],
  "5529": [
    {
      "answer": "head of government",
      "score": 0.993501603603363
    },
    {
      "answer": "head of government",
      "score": 0.8041097521781921
    }
  ],
  "5530": [
    {
      "answer": "citizen",
      "score": 0.9250141382217407
    }
  ],
  "5531": [
    {
      "answer": "head of government",
      "score": 0.7091492414474487
    }
  ],
  "5532": [
    {
      "answer": "two equally sovereign branches of government",
      "score": 0.7036954760551453
    }
  ],
  "5533": [],
  "5534": [
    {
      "answer": "two",
      "score": 0.9105164408683777
    },
    {
      "answer": "two",
      "score": 0.8044449687004089
    }
  ],
  "5535": [],
  "5536": [],
  "5537": [
    {
      "answer": "Thoreau",
      "score": 0.9781549572944641
    },
    {
      "answer": "Thoreau",
      "score": 0.7251055240631104
    },
    {
      "answer": "Thoreau",
      "score": 0.7174871563911438
    },
    {
      "answer": "Thoreau",
      "score": 0.7581290006637573
    },
    {
      "answer": "Thoreau",
      "score": 0.7587592005729675
    }
  ],
  "5538": [
    {
      "answer": "imprisonment",
      "score": 0.9820026159286499
    }
  ],
  "5539": [],
  "5540": [
    {
      "answer": "Resign",
      "score": 0.9885440468788147
    }
  ],
  "5541": [
    {
      "answer": "individual",
      "score": 0.6688165068626404
    },
    {
      "answer": "individual",
      "score": 0.6406536102294922
    },
    {
      "answer": "individual",
      "score": 0.7369072437286377
    }
  ],
  "5542": [
    {
      "answer": "The individual",
      "score": 0.9618411064147949
    }
  ],
  "5543": [
    {
      "answer": "individual",
      "score": 0.9309646487236023
    },
    {
      "answer": "individual",
      "score": 0.6206371784210205
    }
  ],
  "5544": [
    {
      "answer": "Thoreau",
      "score": 0.5915733575820923
    },
    {
      "answer": "Thoreau",
      "score": 0.8661300539970398
    },
    {
      "answer": "Thoreau",
      "score": 0.6744434833526611
    },
    {
      "answer": "Thoreau",
      "score": 0.6347171068191528
    }
  ],
  "5545": [
    {
      "answer": "Resign",
      "score": 0.9895225167274475
    }
  ],
  "5546": [
    {
      "answer": "The majority may be powerful but it is not necessarily right",
      "score": 0.8805645704269409
    }
  ],
  "5547": [
    {
      "answer": "Resign",
      "score": 0.8527142405509949
    }
  ],
  "5548": [
    {
      "answer": "right and wrong",
      "score": 0.966552734375
    }
  ],
  "5549": [
    {
      "answer": "Thoreau",
      "score": 0.6493100523948669
    },
    {
      "answer": "Thoreau",
      "score": 0.5645474195480347
    }
  ],
  "5550": [
    {
      "answer": "Resign",
      "score": 0.9701217412948608
    }
  ],
  "5551": [
    {
      "answer": "elite politicians",
      "score": 0.7883418798446655
    }
  ],
  "5552": [
    {
      "answer": "governmental entities",
      "score": 0.933824360370636
    }
  ],
  "5553": [
    {
      "answer": "trade unions",
      "score": 0.9760583639144897
    },
    {
      "answer": "banks",
      "score": 0.967104434967041
    },
    {
      "answer": "private universities",
      "score": 0.9800702333450317
    }
  ],
  "5554": [
    {
      "answer": "non-governmental agencies",
      "score": 0.7294310927391052
    }
  ],
  "5555": [
    {
      "answer": "trade unions, banks, and private universities",
      "score": 0.6638908386230469
    },
    {
      "answer": "international organizations",
      "score": 0.9313096404075623
    },
    {
      "answer": "foreign governments",
      "score": 0.9483261108398438
    }
  ],
  "5556": [
    {
      "answer": "civil disobedience is only justified against governmental entities",
      "score": 0.9734143018722534
    }
  ],
  "5557": [
    {
      "answer": "Brownlee",
      "score": 0.9921437501907349
    }
  ],
  "5558": [
    {
      "answer": "a larger challenge to the legal system",
      "score": 0.9746626615524292
    }
  ],
  "5559": [
    {
      "answer": "private universities",
      "score": 0.9882049560546875
    }
  ],
  "5560": [
    {
      "answer": "Brownlee",
      "score": 0.9799179434776306
    }
  ],
  "5561": [
    {
      "answer": "international organizations",
      "score": 0.9461731314659119
    },
    {
      "answer": "foreign governments",
      "score": 0.951767086982727
    }
  ],
  "5562": [
    {
      "answer": "a larger challenge to the legal system that permits those decisions to be taken\"",
      "score": 0.8925098776817322
    }
  ],
  "5563": [
    {
      "answer": "protest",
      "score": 0.8826176524162292
    }
  ],
  "5564": [
    {
      "answer": "a larger challenge to the legal system that permits those decisions to be taken\"",
      "score": 0.9151836037635803
    }
  ],
  "5565": [
    {
      "answer": "civil disobedience",
      "score": 0.9787278175354004
    },
    {
      "answer": "civil disobedience",
      "score": 0.9022226333618164
    },
    {
      "answer": "civil disobedience",
      "score": 0.8614417314529419
    }
  ],
  "5566": [
    {
      "answer": "covert lawbreaking",
      "score": 0.9508905410766602
    }
  ],
  "5567": [],
  "5568": [
    {
      "answer": "Book of Exodus",
      "score": 0.9686329364776611
    }
  ],
  "5569": [
    {
      "answer": "Shiphrah",
      "score": 0.9898147583007812
    },
    {
      "answer": "Puah",
      "score": 0.9760573506355286
    }
  ],
  "5570": [
    {
      "answer": "publicly announced",
      "score": 0.9892445802688599
    }
  ],
  "5571": [
    {
      "answer": "rules that conflict with morality",
      "score": 0.9876247644424438
    }
  ],
  "5572": [
    {
      "answer": "assisting in fabricating evidence or committing perjury",
      "score": 0.9797533750534058
    }
  ],
  "5573": [
    {
      "answer": "the dilemma faced by German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house",
      "score": 0.9063698053359985
    }
  ],
  "5574": [
    {
      "answer": "Exodus",
      "score": 0.9819966554641724
    }
  ],
  "5575": [
    {
      "answer": "lawbreaking",
      "score": 0.9674547910690308
    }
  ],
  "5576": [
    {
      "answer": "A Primer for Prospective Jurors",
      "score": 0.8163350224494934
    }
  ],
  "5577": [
    {
      "answer": "Book of Exodus",
      "score": 0.9212288856506348
    }
  ],
  "5578": [
    {
      "answer": "Shiphrah",
      "score": 0.991393506526947
    }
  ],
  "5579": [
    {
      "answer": "the dilemma faced by German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house",
      "score": 0.9171654582023621
    }
  ],
  "5580": [],
  "5581": [
    {
      "answer": "Black's Law Dictionary",
      "score": 0.9846157431602478
    }
  ],
  "5582": [
    {
      "answer": "rebellion",
      "score": 0.888026773929596
    },
    {
      "answer": "rebellion",
      "score": 0.9714175462722778
    },
    {
      "answer": "rebellion",
      "score": 0.8387576341629028
    },
    {
      "answer": "rebellion",
      "score": 0.8344883322715759
    }
  ],
  "5583": [],
  "5584": [
    {
      "answer": "non-violent",
      "score": 0.827657163143158
    },
    {
      "answer": "non-violent",
      "score": 0.6874104738235474
    }
  ],
  "5585": [
    {
      "answer": "non-violent",
      "score": 0.870026171207428
    },
    {
      "answer": "non-violent",
      "score": 0.6779312491416931
    }
  ],
  "5586": [],
  "5587": [],
  "5588": [
    {
      "answer": "to help preserve society's tolerance of civil disobedience",
      "score": 0.9657241106033325
    }
  ],
  "5589": [
    {
      "answer": "refraining from violence",
      "score": 0.9909056425094604
    }
  ],
  "5590": [
    {
      "answer": "non-violent",
      "score": 0.6085841655731201
    },
    {
      "answer": "non-violence",
      "score": 0.9679853916168213
    },
    {
      "answer": "non-violent",
      "score": 0.7860666513442993
    }
  ],
  "5591": [
    {
      "answer": "carefully chosen and legitimate means",
      "score": 0.8252485394477844
    }
  ],
  "5592": [
    {
      "answer": "non-violent",
      "score": 0.7292650938034058
    }
  ],
  "5593": [],
  "5594": [
    {
      "answer": "Revolutionary civil disobedience",
      "score": 0.9640890955924988
    },
    {
      "answer": "revolutionary civil disobedience",
      "score": 0.8242700099945068
    },
    {
      "answer": "revolutionary civil disobedience",
      "score": 0.8443202972412109
    }
  ],
  "5595": [
    {
      "answer": "Hungarians",
      "score": 0.9913917779922485
    }
  ],
  "5596": [
    {
      "answer": "Ferenc De\u00e1k",
      "score": 0.9969577193260193
    }
  ],
  "5597": [
    {
      "answer": "Gandhi",
      "score": 0.9723359942436218
    }
  ],
  "5598": [
    {
      "answer": "peaceable revolution",
      "score": 0.6947176456451416
    }
  ],
  "5599": [
    {
      "answer": "Non-revolutionary",
      "score": 0.9856164455413818
    }
  ],
  "5600": [
    {
      "answer": "to render certain laws ineffective",
      "score": 0.8834646344184875
    },
    {
      "answer": "to cause their repeal",
      "score": 0.8196132183074951
    },
    {
      "answer": "to exert pressure to get one's political wishes on some other issue",
      "score": 0.8129822611808777
    }
  ],
  "5601": [
    {
      "answer": "to render certain laws ineffective",
      "score": 0.8456327319145203
    },
    {
      "answer": "to cause their repeal",
      "score": 0.8069783449172974
    }
  ],
  "5602": [
    {
      "answer": "Revolutionary",
      "score": 0.9702032208442688
    },
    {
      "answer": "revolutionary",
      "score": 0.9002155065536499
    },
    {
      "answer": "revolutionary",
      "score": 0.9408342242240906
    }
  ],
  "5603": [
    {
      "answer": "Gandhi",
      "score": 0.9497494697570801
    }
  ],
  "5604": [
    {
      "answer": "government",
      "score": 0.9239403605461121
    },
    {
      "answer": "government",
      "score": 0.8364715576171875
    },
    {
      "answer": "government",
      "score": 0.7895881533622742
    }
  ],
  "5605": [
    {
      "answer": "Non-revolutionary civil disobedience",
      "score": 0.5696357488632202
    },
    {
      "answer": "wrong",
      "score": 0.6776695251464844
    }
  ],
  "5606": [
    {
      "answer": "alter or abolish\" an unjust government",
      "score": 0.804808497428894
    }
  ],
  "5607": [
    {
      "answer": "peaceable revolution",
      "score": 0.8915813565254211
    }
  ],
  "5608": [
    {
      "answer": "revolutionary civil disobedience",
      "score": 0.9188896417617798
    }
  ],
  "5609": [
    {
      "answer": "Roman Empire",
      "score": 0.9788399934768677
    }
  ],
  "5610": [
    {
      "answer": "Unarmed Jews gathered in the streets",
      "score": 0.9667119383811951
    }
  ],
  "5611": [
    {
      "answer": "not covered in any newspapers in the days, weeks and months after it happened",
      "score": 0.9639168381690979
    }
  ],
  "5612": [
    {
      "answer": "higher political office",
      "score": 0.9918656349182129
    }
  ],
  "5613": [
    {
      "answer": "after the end of the Mexican War",
      "score": 0.9898011684417725
    }
  ],
  "5614": [
    {
      "answer": "Roman Empire",
      "score": 0.971918523311615
    }
  ],
  "5615": [
    {
      "answer": "prevent the installation of pagan images in the Temple in Jerusalem",
      "score": 0.9832412004470825
    }
  ],
  "5616": [],
  "5617": [
    {
      "answer": "jail solidarity",
      "score": 0.9633796215057373
    }
  ],
  "5618": [
    {
      "answer": "days, weeks and months",
      "score": 0.7895687222480774
    }
  ],
  "5619": [
    {
      "answer": "Unarmed Jews gathered in the streets to prevent the installation of pagan images in the Temple in Jerusalem",
      "score": 0.6109040379524231
    }
  ],
  "5620": [
    {
      "answer": "pagan images",
      "score": 0.9920474886894226
    }
  ],
  "5621": [
    {
      "answer": "bail",
      "score": 0.9739612936973572
    },
    {
      "answer": "bail",
      "score": 0.7252916097640991
    }
  ],
  "5622": [
    {
      "answer": "not covered in any newspapers",
      "score": 0.9509458541870117
    }
  ],
  "5623": [
    {
      "answer": "after the end of the Mexican War",
      "score": 0.9814165830612183
    }
  ],
  "5624": [
    {
      "answer": "illegal acts",
      "score": 0.9798304438591003
    }
  ],
  "5625": [
    {
      "answer": "propaganda",
      "score": 0.9929268956184387
    }
  ],
  "5626": [
    {
      "answer": "Voice in the Wilderness",
      "score": 0.9884511232376099
    }
  ],
  "5627": [
    {
      "answer": "738",
      "score": 0.9961679577827454
    }
  ],
  "5628": [
    {
      "answer": "preventing it from being cut down",
      "score": 0.9706646203994751
    }
  ],
  "5629": [
    {
      "answer": "trespassing at a nuclear-missile installation",
      "score": 0.6595532894134521
    },
    {
      "answer": "harassment",
      "score": 0.7330792546272278
    }
  ],
  "5630": [
    {
      "answer": "trespassing at a nuclear-missile installation",
      "score": 0.9931103587150574
    }
  ],
  "5631": [
    {
      "answer": "harassment",
      "score": 0.9633766412734985
    }
  ],
  "5632": [
    {
      "answer": "provision of medication to the sick",
      "score": 0.9686722755432129
    }
  ],
  "5633": [
    {
      "answer": "Julia Butterfly Hill",
      "score": 0.9971164464950562
    }
  ],
  "5634": [
    {
      "answer": "738",
      "score": 0.9937998652458191
    }
  ],
  "5635": [
    {
      "answer": "Luna",
      "score": 0.9616101384162903
    }
  ],
  "5636": [
    {
      "answer": "propaganda purpose",
      "score": 0.8827986717224121
    }
  ],
  "5637": [
    {
      "answer": "Voice in the Wilderness",
      "score": 0.9952555894851685
    }
  ],
  "5638": [
    {
      "answer": "trespassing at a nuclear-missile installation",
      "score": 0.9923713803291321
    }
  ],
  "5639": [
    {
      "answer": "sending an email to the Lebanon, New Hampshire city councilors stating, \"Wise up or die",
      "score": 0.9413712620735168
    }
  ],
  "5640": [
    {
      "answer": "Wise up or die",
      "score": 0.9972590208053589
    }
  ],
  "5641": [
    {
      "answer": "engaging in the forbidden speech",
      "score": 0.9298751950263977
    }
  ],
  "5642": [
    {
      "answer": "1978 Supreme Court case of FCC v. Pacifica Foundation",
      "score": 0.9900369644165039
    }
  ],
  "5643": [
    {
      "answer": "1978",
      "score": 0.996866762638092
    }
  ],
  "5644": [
    {
      "answer": "speech",
      "score": 0.9130411744117737
    },
    {
      "answer": "speech",
      "score": 0.7229780554771423
    }
  ],
  "5645": [
    {
      "answer": "civil disobedience",
      "score": 0.5419930815696716
    },
    {
      "answer": "engaging in the forbidden speech",
      "score": 0.8797885179519653
    }
  ],
  "5646": [
    {
      "answer": "engaging in the forbidden speech",
      "score": 0.9595133066177368
    }
  ],
  "5647": [
    {
      "answer": "broadcasting the track \"Filthy Words\" from a George Carlin comedy album",
      "score": 0.7675008177757263
    }
  ],
  "5648": [
    {
      "answer": "Filthy Words",
      "score": 0.9351301193237305
    },
    {
      "answer": "Wise up or die",
      "score": 0.7373968362808228
    }
  ],
  "5649": [
    {
      "answer": "Wise up or die",
      "score": 0.9910857677459717
    }
  ],
  "5650": [
    {
      "answer": "arrested",
      "score": 0.9216038584709167
    }
  ],
  "5651": [
    {
      "answer": "FCC v. Pacifica Foundation",
      "score": 0.9962913393974304
    }
  ],
  "5652": [
    {
      "answer": "civil disobedience",
      "score": 0.6765366196632385
    },
    {
      "answer": "engaging in the forbidden speech",
      "score": 0.8947134017944336
    },
    {
      "answer": "Threatening government officials",
      "score": 0.8486589193344116
    }
  ],
  "5653": [
    {
      "answer": "system to function",
      "score": 0.9900233149528503
    }
  ],
  "5654": [
    {
      "answer": "padlocking the gates",
      "score": 0.982489287853241
    },
    {
      "answer": "using sickles to deflate one of the large domes covering two satellite dishes",
      "score": 0.914252758026123
    }
  ],
  "5655": [
    {
      "answer": "padlocking the gates",
      "score": 0.9455224871635437
    },
    {
      "answer": "using sickles to deflate one of the large domes covering two satellite dishes",
      "score": 0.8171980977058411
    }
  ],
  "5656": [
    {
      "answer": "civil disobedience",
      "score": 0.7552986145019531
    }
  ],
  "5657": [
    {
      "answer": "coercive",
      "score": 0.9752979874610901
    }
  ],
  "5658": [
    {
      "answer": "illegal boycotts",
      "score": 0.9345734119415283
    },
    {
      "answer": "refusals to pay taxes",
      "score": 0.9154497385025024
    },
    {
      "answer": "draft dodging",
      "score": 0.8658221960067749
    },
    {
      "answer": "distributed denial-of-service attacks",
      "score": 0.8979873061180115
    },
    {
      "answer": "sit-ins",
      "score": 0.6573135852813721
    }
  ],
  "5659": [
    {
      "answer": "coercive",
      "score": 0.9291936755180359
    },
    {
      "answer": "coercion",
      "score": 0.5357232689857483
    }
  ],
  "5660": [
    {
      "answer": "make it more difficult for a system to function",
      "score": 0.8444865942001343
    }
  ],
  "5661": [
    {
      "answer": "illegal boycotts",
      "score": 0.7477868795394897
    },
    {
      "answer": "refusals to pay taxes",
      "score": 0.7364625930786133
    },
    {
      "answer": "distributed denial-of-service attacks",
      "score": 0.7361745238304138
    }
  ],
  "5662": [],
  "5663": [
    {
      "answer": "coercive",
      "score": 0.8740020394325256
    },
    {
      "answer": "coercion",
      "score": 0.6093753576278687
    }
  ],
  "5664": [
    {
      "answer": "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes",
      "score": 0.906165361404419
    }
  ],
  "5665": [
    {
      "answer": "coercion",
      "score": 0.6464744806289673
    },
    {
      "answer": "coercion",
      "score": 0.8639406561851501
    }
  ],
  "5666": [
    {
      "answer": "make it more difficult for a system to function",
      "score": 0.6333854794502258
    }
  ],
  "5667": [
    {
      "answer": "criminal",
      "score": 0.9052415490150452
    }
  ],
  "5668": [
    {
      "answer": "arrest",
      "score": 0.9626147150993347
    }
  ],
  "5669": [
    {
      "answer": "talking to criminal investigators can serve no useful purpose",
      "score": 0.9254065752029419
    }
  ],
  "5670": [
    {
      "answer": "lack of understanding of the legal ramifications",
      "score": 0.9822543263435364
    },
    {
      "answer": "fear of seeming rude",
      "score": 0.9706726670265198
    }
  ],
  "5671": [
    {
      "answer": "due to a lack of understanding of the legal ramifications",
      "score": 0.7793208956718445
    },
    {
      "answer": "Also, some civil disobedients seek to use the arrest as an opportunity to make an impression on the officers",
      "score": 0.8182759284973145
    }
  ],
  "5672": [
    {
      "answer": "consent",
      "score": 0.8991793990135193
    }
  ],
  "5673": [
    {
      "answer": "lack of understanding of the legal ramifications",
      "score": 0.9590897560119629
    },
    {
      "answer": "fear of seeming rude",
      "score": 0.9327394962310791
    }
  ],
  "5674": [
    {
      "answer": "officers",
      "score": 0.9728220701217651
    }
  ],
  "5675": [
    {
      "answer": "whether or not to grant a consent search of his property",
      "score": 0.9756782054901123
    },
    {
      "answer": "whether or not to talk to police officers",
      "score": 0.7153662443161011
    }
  ],
  "5676": [
    {
      "answer": "a suspect's talking to criminal investigators can serve no useful purpose, and may be harmful",
      "score": 0.9023681282997131
    }
  ],
  "5677": [],
  "5678": [
    {
      "answer": "belief in the validity of the social contract",
      "score": 0.9695301055908203
    }
  ],
  "5679": [
    {
      "answer": "legitimacy of any government",
      "score": 0.8243374824523926
    }
  ],
  "5680": [
    {
      "answer": "anarchists",
      "score": 0.9887847900390625
    }
  ],
  "5681": [
    {
      "answer": "legitimacy of any government",
      "score": 0.9237377047538757
    }
  ],
  "5682": [
    {
      "answer": "don't believe in the legitimacy of any government",
      "score": 0.8447624444961548
    }
  ],
  "5683": [
    {
      "answer": "don't believe in the legitimacy of any government",
      "score": 0.8924714922904968
    }
  ],
  "5684": [
    {
      "answer": "don't believe in the legitimacy of any government",
      "score": 0.651477575302124
    }
  ],
  "5685": [
    {
      "answer": "punishment",
      "score": 0.9723854660987854
    }
  ],
  "5686": [
    {
      "answer": "don't believe in the legitimacy of any government",
      "score": 0.8220553398132324
    }
  ],
  "5687": [
    {
      "answer": "whether or not to plead guilty",
      "score": 0.9676133990287781
    }
  ],
  "5688": [
    {
      "answer": "submit to the punishment prescribed by law",
      "score": 0.9925506114959717
    }
  ],
  "5689": [
    {
      "answer": "it is a civil disobedient's duty to submit to the punishment prescribed by law",
      "score": 0.7879869341850281
    },
    {
      "answer": "defending oneself in court will increase the possibility of changing the unjust law",
      "score": 0.8701227903366089
    }
  ],
  "5690": [
    {
      "answer": "beauty that surrounds us",
      "score": 0.8482054471969604
    }
  ],
  "5691": [
    {
      "answer": "I plead for the beauty that surrounds us",
      "score": 0.7298756837844849
    },
    {
      "answer": "not guilty",
      "score": 0.7358367443084717
    }
  ],
  "5692": [
    {
      "answer": "civil disobedients",
      "score": 0.8777767419815063
    }
  ],
  "5693": [
    {
      "answer": "not guilty",
      "score": 0.6403424143791199
    },
    {
      "answer": "not guilty",
      "score": 0.9180703163146973
    }
  ],
  "5694": [
    {
      "answer": "submit to the punishment prescribed by law",
      "score": 0.9825329780578613
    }
  ],
  "5695": [
    {
      "answer": "defending oneself in court will increase the possibility of changing the unjust law",
      "score": 0.9367927312850952
    }
  ],
  "5696": [
    {
      "answer": "not guilty",
      "score": 0.7592567205429077
    },
    {
      "answer": "not guilty",
      "score": 0.8037511706352234
    },
    {
      "answer": "not guilty",
      "score": 0.880691647529602
    }
  ],
  "5697": [
    {
      "answer": "Camp Mercury nuclear test site",
      "score": 0.8318918347358704
    }
  ],
  "5698": [
    {
      "answer": "attempted to enter the test site",
      "score": 0.9433236122131348
    }
  ],
  "5699": [
    {
      "answer": "The arrested persons were found \"guilty,\" nevertheless, and given suspended sentences, conditional on their not reentering the test site grounds",
      "score": 0.8505435585975647
    }
  ],
  "5700": [
    {
      "answer": "nolo contendere",
      "score": 0.9959206581115723
    }
  ],
  "5701": [
    {
      "answer": "suspended sentences",
      "score": 0.9330165386199951
    }
  ],
  "5702": [],
  "5703": [
    {
      "answer": "Camp Mercury nuclear test site near Las Vegas, Nevada",
      "score": 0.6604754328727722
    },
    {
      "answer": "Nye County seat of Tonopah, Nevada",
      "score": 0.7863531708717346
    }
  ],
  "5704": [
    {
      "answer": "13",
      "score": 0.9791472554206848
    }
  ],
  "5705": [
    {
      "answer": "Tonopah, Nevada",
      "score": 0.9628952741622925
    }
  ],
  "5706": [
    {
      "answer": "suspended sentences",
      "score": 0.9710961580276489
    }
  ],
  "5707": [
    {
      "answer": "as a way of reminding their countrymen of injustice",
      "score": 0.9496281743049622
    }
  ],
  "5708": [
    {
      "answer": "reminding their countrymen of injustice",
      "score": 0.943589985370636
    }
  ],
  "5709": [
    {
      "answer": "spirit of protest",
      "score": 0.9886035919189453
    }
  ],
  "5710": [
    {
      "answer": "the spirit of protest should be maintained all the way",
      "score": 0.8624776005744934
    },
    {
      "answer": "To accept jail penitently as an accession to 'the rules' is to switch suddenly to a spirit of subservience, to demean the seriousness of the protest",
      "score": 0.792378306388855
    }
  ],
  "5711": [
    {
      "answer": "neo-conservative insistence on a guilty plea",
      "score": 0.7374610304832458
    }
  ],
  "5712": [
    {
      "answer": "the spirit of protest should be maintained all the way",
      "score": 0.946248471736908
    }
  ],
  "5713": [
    {
      "answer": "neo-conservative insistence on a guilty plea",
      "score": 0.9892155528068542
    }
  ],
  "5714": [
    {
      "answer": "the spirit of protest",
      "score": 0.7108192443847656
    },
    {
      "answer": "spirit of subservience",
      "score": 0.6081835627555847
    }
  ],
  "5715": [],
  "5716": [
    {
      "answer": "plea bargain",
      "score": 0.9265543222427368
    },
    {
      "answer": "plea bargain",
      "score": 0.8119287490844727
    }
  ],
  "5717": [],
  "5718": [
    {
      "answer": "solidarity",
      "score": 0.9872625470161438
    }
  ],
  "5719": [
    {
      "answer": "blind plea",
      "score": 0.9808552861213684
    }
  ],
  "5720": [
    {
      "answer": "Mohandas Gandhi",
      "score": 0.996350884437561
    }
  ],
  "5721": [
    {
      "answer": "an opportunity to plead guilty to one misdemeanor count and receive no jail time",
      "score": 0.9191359281539917
    }
  ],
  "5722": [
    {
      "answer": "activists",
      "score": 0.5590358972549438
    },
    {
      "answer": "activists",
      "score": 0.9551626443862915
    }
  ],
  "5723": [
    {
      "answer": "solidarity tactics",
      "score": 0.9939191937446594
    }
  ],
  "5724": [
    {
      "answer": "solidarity tactics",
      "score": 0.8520263433456421
    }
  ],
  "5725": [
    {
      "answer": "solidarity tactics",
      "score": 0.8411237001419067
    }
  ],
  "5726": [
    {
      "answer": "defiant speech",
      "score": 0.9650647640228271
    }
  ],
  "5727": [],
  "5728": [
    {
      "answer": "her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions",
      "score": 0.9110231995582581
    }
  ],
  "5729": [],
  "5730": [
    {
      "answer": "mistreatment",
      "score": 0.9930408000946045
    }
  ],
  "5731": [
    {
      "answer": "mistreatment",
      "score": 0.947197675704956
    }
  ],
  "5732": [],
  "5733": [
    {
      "answer": "60",
      "score": 0.9640917778015137
    }
  ],
  "5734": [
    {
      "answer": "mistreatment from government officials",
      "score": 0.9612408876419067
    }
  ],
  "5735": [
    {
      "answer": "her statement suggested a lack of remorse, an attempt to avoid responsibility for her actions",
      "score": 0.9535729885101318
    }
  ],
  "5736": [
    {
      "answer": "to win an acquittal and avoid imprisonment or a fine",
      "score": 0.9596956372261047
    }
  ],
  "5737": [
    {
      "answer": "use the proceedings as a forum to inform the jury and the public of the political circumstances surrounding the case and their reasons for breaking the law via civil disobedience",
      "score": 0.90108722448349
    }
  ],
  "5738": [
    {
      "answer": "jury nullification",
      "score": 0.8946095108985901
    },
    {
      "answer": "jury nullification",
      "score": 0.7031923532485962
    }
  ],
  "5739": [
    {
      "answer": "Vietnam",
      "score": 0.9959381818771362
    }
  ],
  "5740": [
    {
      "answer": "jury nullification",
      "score": 0.7648559212684631
    },
    {
      "answer": "jury nullification",
      "score": 0.5941068530082703
    }
  ],
  "5741": [
    {
      "answer": "technical defense",
      "score": 0.7759040594100952
    },
    {
      "answer": "technical defense",
      "score": 0.6386946439743042
    }
  ],
  "5742": [
    {
      "answer": "reduced",
      "score": 0.9127577543258667
    }
  ],
  "5743": [
    {
      "answer": "to win an acquittal and avoid imprisonment or a fine",
      "score": 0.9433043599128723
    },
    {
      "answer": "to use the proceedings as a forum to inform the jury and the public of the political circumstances surrounding the case and their reasons for breaking the law via civil disobedience",
      "score": 0.7944974899291992
    }
  ],
  "5744": [
    {
      "answer": "not guilty",
      "score": 0.9932315945625305
    }
  ],
  "5745": [
    {
      "answer": "nullification prerogative",
      "score": 0.9860222339630127
    }
  ],
  "5746": [
    {
      "answer": "undermine the law",
      "score": 0.9632749557495117
    }
  ],
  "5747": [],
  "5748": [
    {
      "answer": ", while disobedience may be helpful, any great amount of it would undermine the law by encouraging general disobedience which is neither conscientious nor of social benefit",
      "score": 0.878423273563385
    }
  ],
  "5749": [],
  "5750": [],
  "5751": [
    {
      "answer": "law",
      "score": 0.9756373763084412
    }
  ],
  "5752": [
    {
      "answer": "undermine the law",
      "score": 0.7158163785934448
    },
    {
      "answer": "not civil disobedience",
      "score": 0.6208940148353577
    }
  ],
  "5753": [
    {
      "answer": ", while disobedience may be helpful, any great amount of it would undermine the law by encouraging general disobedience which is neither conscientious nor of social benefit",
      "score": 0.8796390295028687
    }
  ],
  "5754": [],
  "5755": [],
  "5756": [
    {
      "answer": "Indirect civil disobedience",
      "score": 0.9749211072921753
    }
  ],
  "5757": [
    {
      "answer": "direct civil disobedience",
      "score": 0.9325556755065918
    }
  ],
  "5758": [
    {
      "answer": "Vietnam War",
      "score": 0.9204608201980591
    },
    {
      "answer": "Vietnam War",
      "score": 0.9151480197906494
    }
  ],
  "5759": [
    {
      "answer": "necessity defense",
      "score": 0.9899649024009705
    },
    {
      "answer": "necessity defense",
      "score": 0.8675997853279114
    }
  ],
  "5760": [],
  "5761": [
    {
      "answer": "violating a law",
      "score": 0.8989090919494629
    }
  ],
  "5762": [
    {
      "answer": "protesting the existence of a particular law by breaking that law",
      "score": 0.9107385277748108
    }
  ],
  "5763": [
    {
      "answer": "Fully Informed Jury Association",
      "score": 0.9910396933555603
    }
  ],
  "5764": [
    {
      "answer": "leaflets",
      "score": 0.9799149632453918
    }
  ],
  "5765": [],
  "5766": [
    {
      "answer": "crime control via incapacitation and deterrence",
      "score": 0.9264450073242188
    }
  ],
  "5767": [],
  "5768": [
    {
      "answer": "the state",
      "score": 0.932908296585083
    }
  ],
  "5769": [
    {
      "answer": "utilitarian grounds",
      "score": 0.6025234460830688
    }
  ],
  "5770": [
    {
      "answer": "achieving crime control via incapacitation and deterrence",
      "score": 0.7230686545372009
    }
  ],
  "5771": [
    {
      "answer": "crime control",
      "score": 0.8494478464126587
    }
  ],
  "5772": [
    {
      "answer": "the state",
      "score": 0.9350992441177368
    }
  ],
  "5773": [
    {
      "answer": "whether it would do more harm than good",
      "score": 0.9931972622871399
    }
  ],
  "5774": [
    {
      "answer": "utilitarian",
      "score": 0.975189208984375
    }
  ],
  "5775": [
    {
      "answer": "Construction",
      "score": 0.60489821434021
    },
    {
      "answer": "construction",
      "score": 0.5796600580215454
    },
    {
      "answer": "Construction",
      "score": 0.6522412896156311
    }
  ],
  "5776": [
    {
      "answer": "manufacturing",
      "score": 0.8120533227920532
    },
    {
      "answer": "manufacturing",
      "score": 0.979607105255127
    }
  ],
  "5777": [
    {
      "answer": "six to nine percent",
      "score": 0.9929046630859375
    }
  ],
  "5778": [
    {
      "answer": "planning",
      "score": 0.946183443069458
    },
    {
      "answer": "design",
      "score": 0.889824628829956
    },
    {
      "answer": "financing",
      "score": 0.9789142608642578
    }
  ],
  "5779": [
    {
      "answer": "client",
      "score": 0.9844277501106262
    }
  ],
  "5780": [
    {
      "answer": "manufacturing",
      "score": 0.6905453205108643
    },
    {
      "answer": "manufacturing",
      "score": 0.9252805113792419
    }
  ],
  "5781": [
    {
      "answer": "Construction",
      "score": 0.5876083970069885
    },
    {
      "answer": "construction",
      "score": 0.9309204816818237
    }
  ],
  "5782": [
    {
      "answer": "gross domestic product",
      "score": 0.98769611120224
    }
  ],
  "5783": [
    {
      "answer": "planning",
      "score": 0.9746729135513306
    },
    {
      "answer": "design",
      "score": 0.9434643983840942
    },
    {
      "answer": "financing",
      "score": 0.9767218828201294
    }
  ],
  "5784": [
    {
      "answer": "on location",
      "score": 0.9382402896881104
    }
  ],
  "5785": [
    {
      "answer": "six to nine percent",
      "score": 0.9881954193115234
    }
  ],
  "5786": [
    {
      "answer": "manufacturing",
      "score": 0.6831719875335693
    },
    {
      "answer": "manufacturing",
      "score": 0.984978199005127
    }
  ],
  "5787": [
    {
      "answer": "until the project is built and ready for use",
      "score": 0.9836909174919128
    }
  ],
  "5788": [
    {
      "answer": "planning",
      "score": 0.673729658126831
    },
    {
      "answer": "financing",
      "score": 0.8887642025947571
    }
  ],
  "5789": [
    {
      "answer": "architect",
      "score": 0.9878765344619751
    }
  ],
  "5790": [
    {
      "answer": "construction manager",
      "score": 0.9488071203231812
    },
    {
      "answer": "design engineer",
      "score": 0.9066632390022278
    },
    {
      "answer": "construction engineer",
      "score": 0.8921262621879578
    },
    {
      "answer": "project manager",
      "score": 0.8783778548240662
    }
  ],
  "5791": [
    {
      "answer": "effective planning",
      "score": 0.9882193803787231
    }
  ],
  "5792": [
    {
      "answer": "megaprojects",
      "score": 0.9918628931045532
    }
  ],
  "5793": [
    {
      "answer": "Those involved with the design and execution of the infrastructure in question",
      "score": 0.9330775737762451
    }
  ],
  "5794": [],
  "5795": [
    {
      "answer": "construction-site safety",
      "score": 0.6548537015914917
    },
    {
      "answer": "availability and transportation of building materials",
      "score": 0.6840107440948486
    },
    {
      "answer": "inconvenience to the public caused by construction delays and bidding",
      "score": 0.7060351371765137
    }
  ],
  "5796": [
    {
      "answer": "megaprojects",
      "score": 0.9895119071006775
    }
  ],
  "5797": [
    {
      "answer": "zoning requirements",
      "score": 0.9303203821182251
    },
    {
      "answer": "environmental impact of the job",
      "score": 0.8064752817153931
    },
    {
      "answer": "successful scheduling",
      "score": 0.8042080402374268
    },
    {
      "answer": "budgeting",
      "score": 0.9115635752677917
    },
    {
      "answer": "construction-site safety",
      "score": 0.951346755027771
    },
    {
      "answer": "availability and transportation of building materials",
      "score": 0.9530982971191406
    },
    {
      "answer": "logistics",
      "score": 0.8987857103347778
    },
    {
      "answer": "inconvenience to the public caused by construction delays and bidding",
      "score": 0.9515970349311829
    }
  ],
  "5798": [
    {
      "answer": "Large-scale construction",
      "score": 0.9615302085876465
    }
  ],
  "5799": [
    {
      "answer": "architect",
      "score": 0.9868584871292114
    }
  ],
  "5800": [
    {
      "answer": "construction manager",
      "score": 0.9048289060592651
    },
    {
      "answer": "design engineer",
      "score": 0.821106493473053
    },
    {
      "answer": "construction engineer",
      "score": 0.7992914915084839
    },
    {
      "answer": "project manager",
      "score": 0.7983007431030273
    }
  ],
  "5801": [
    {
      "answer": "megaprojects",
      "score": 0.990358293056488
    }
  ],
  "5802": [
    {
      "answer": "effective planning",
      "score": 0.9357784390449524
    }
  ],
  "5803": [
    {
      "answer": "buildings, infrastructure",
      "score": 0.8728803396224976
    }
  ],
  "5804": [
    {
      "answer": "residential and non-residential (commercial/institutional)",
      "score": 0.956479549407959
    }
  ],
  "5805": [
    {
      "answer": "heavy/highway",
      "score": 0.9829036593437195
    },
    {
      "answer": "heavy civil or heavy engineering",
      "score": 0.9628281593322754
    }
  ],
  "5806": [
    {
      "answer": "infrastructure",
      "score": 0.7889955639839172
    },
    {
      "answer": "Infrastructure",
      "score": 0.9797612428665161
    }
  ],
  "5807": [
    {
      "answer": "industrial",
      "score": 0.7959539294242859
    },
    {
      "answer": "Industrial",
      "score": 0.9806845784187317
    }
  ],
  "5808": [],
  "5809": [],
  "5810": [
    {
      "answer": "infrastructure",
      "score": 0.7798815369606018
    },
    {
      "answer": "Infrastructure",
      "score": 0.9877684712409973
    }
  ],
  "5811": [
    {
      "answer": "industrial",
      "score": 0.6752688884735107
    },
    {
      "answer": "Industrial",
      "score": 0.9803887605667114
    }
  ],
  "5812": [
    {
      "answer": "infrastructure",
      "score": 0.9354162216186523
    },
    {
      "answer": "industrial",
      "score": 0.9236716628074646
    },
    {
      "answer": "Infrastructure",
      "score": 0.7073851227760315
    },
    {
      "answer": "Industrial",
      "score": 0.67522794008255
    }
  ],
  "5813": [
    {
      "answer": "residential and non-residential (commercial/institutional)",
      "score": 0.7557000517845154
    }
  ],
  "5814": [
    {
      "answer": "industrial",
      "score": 0.5116578936576843
    },
    {
      "answer": "Industrial",
      "score": 0.9430961012840271
    }
  ],
  "5815": [
    {
      "answer": "There are other ways to break the industry into sectors or markets.",
      "score": 0.7278653383255005
    }
  ],
  "5816": [
    {
      "answer": "other ways",
      "score": 0.9022484421730042
    }
  ],
  "5817": [
    {
      "answer": "a trade magazine for the construction industry",
      "score": 0.9163888096809387
    }
  ],
  "5818": [],
  "5819": [
    {
      "answer": "2014",
      "score": 0.9285072684288025
    }
  ],
  "5820": [
    {
      "answer": "hazardous waste",
      "score": 0.9939522743225098
    }
  ],
  "5821": [],
  "5822": [
    {
      "answer": "Engineering News-Record",
      "score": 0.8620515465736389
    }
  ],
  "5823": [],
  "5824": [
    {
      "answer": "by amount of work they are doing outside their home country",
      "score": 0.9840497374534607
    }
  ],
  "5825": [],
  "5826": [
    {
      "answer": "Engineering News-Record",
      "score": 0.8518267273902893
    }
  ],
  "5827": [],
  "5828": [
    {
      "answer": "list of the largest companies in the United States",
      "score": 0.8590124249458313
    },
    {
      "answer": "list the largest global firms",
      "score": 0.6257430911064148
    }
  ],
  "5829": [
    {
      "answer": "largest global firms",
      "score": 0.9664349555969238
    }
  ],
  "5830": [
    {
      "answer": "2014",
      "score": 0.9759604930877686
    }
  ],
  "5831": [
    {
      "answer": "building construction",
      "score": 0.9874139428138733
    },
    {
      "answer": "heavy and civil engineering construction",
      "score": 0.9871639609336853
    },
    {
      "answer": "specialty trade contractors",
      "score": 0.9792671203613281
    }
  ],
  "5832": [
    {
      "answer": "construction service firms",
      "score": 0.9794363975524902
    },
    {
      "answer": "construction managers",
      "score": 0.9436290264129639
    }
  ],
  "5833": [
    {
      "answer": "Standard Industrial Classification",
      "score": 0.9821564555168152
    },
    {
      "answer": "North American Industry Classification System",
      "score": 0.915949821472168
    }
  ],
  "5834": [
    {
      "answer": "firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project",
      "score": 0.9852762818336487
    }
  ],
  "5835": [
    {
      "answer": "building construction",
      "score": 0.981518030166626
    },
    {
      "answer": "heavy and civil engineering construction",
      "score": 0.9837334752082825
    },
    {
      "answer": "specialty trade contractors",
      "score": 0.9673342108726501
    }
  ],
  "5836": [
    {
      "answer": "Standard Industrial Classification",
      "score": 0.9695919752120972
    }
  ],
  "5837": [
    {
      "answer": "Standard Industrial Classification",
      "score": 0.9518628120422363
    },
    {
      "answer": "North American Industry Classification System",
      "score": 0.7726477980613708
    }
  ],
  "5838": [
    {
      "answer": "construction managers",
      "score": 0.9158433675765991
    }
  ],
  "5839": [
    {
      "answer": "Standard Industrial Classification",
      "score": 0.9907830953598022
    },
    {
      "answer": "North American Industry Classification System",
      "score": 0.9841316342353821
    }
  ],
  "5840": [
    {
      "answer": "divided into three subsectors: building construction, heavy and civil engineering construction, and specialty trade contractors",
      "score": 0.9616764783859253
    }
  ],
  "5841": [
    {
      "answer": "building construction",
      "score": 0.9786089062690735
    },
    {
      "answer": "heavy and civil engineering construction",
      "score": 0.9817151427268982
    },
    {
      "answer": "specialty trade contractors",
      "score": 0.9612817168235779
    }
  ],
  "5842": [
    {
      "answer": "direct financial responsibility for completion of the construction project",
      "score": 0.9381282925605774
    }
  ],
  "5843": [
    {
      "answer": "Standard Industrial Classification",
      "score": 0.9636375308036804
    },
    {
      "answer": "North American Industry Classification System",
      "score": 0.819081723690033
    }
  ],
  "5844": [
    {
      "answer": "Building construction",
      "score": 0.9587974548339844
    },
    {
      "answer": "building construction",
      "score": 0.823657751083374
    },
    {
      "answer": "building construction",
      "score": 0.8178806304931641
    }
  ],
  "5845": [
    {
      "answer": "small renovations",
      "score": 0.9869897365570068
    }
  ],
  "5846": [
    {
      "answer": "the owner of the property",
      "score": 0.982377827167511
    }
  ],
  "5847": [
    {
      "answer": "structural collapse",
      "score": 0.9837151765823364
    },
    {
      "answer": "cost overruns",
      "score": 0.9863208532333374
    },
    {
      "answer": "litigation",
      "score": 0.969318151473999
    }
  ],
  "5848": [
    {
      "answer": "make detailed plans",
      "score": 0.9655336141586304
    },
    {
      "answer": "maintain careful oversight",
      "score": 0.9733482599258423
    }
  ],
  "5849": [
    {
      "answer": "renovations",
      "score": 0.9514281749725342
    }
  ],
  "5850": [
    {
      "answer": "structural collapse",
      "score": 0.9741290211677551
    },
    {
      "answer": "cost overruns",
      "score": 0.9768755435943604
    },
    {
      "answer": "litigation",
      "score": 0.9651650786399841
    }
  ],
  "5851": [
    {
      "answer": "detailed plans",
      "score": 0.9527671337127686
    },
    {
      "answer": "maintain careful oversight",
      "score": 0.8912047147750854
    }
  ],
  "5852": [
    {
      "answer": "laborer",
      "score": 0.6280379295349121
    },
    {
      "answer": "design team",
      "score": 0.9619992971420288
    }
  ],
  "5853": [
    {
      "answer": "design",
      "score": 0.9260191917419434
    },
    {
      "answer": "financial",
      "score": 0.9155786037445068
    },
    {
      "answer": "legal considerations",
      "score": 0.9398394823074341
    }
  ],
  "5854": [
    {
      "answer": "careful oversight",
      "score": 0.7504812479019165
    }
  ],
  "5855": [
    {
      "answer": "detailed plans",
      "score": 0.8625494241714478
    }
  ],
  "5856": [
    {
      "answer": "design",
      "score": 0.7456588745117188
    },
    {
      "answer": "financial",
      "score": 0.7607545852661133
    },
    {
      "answer": "estimating",
      "score": 0.7430261969566345
    },
    {
      "answer": "legal considerations",
      "score": 0.7688370943069458
    }
  ],
  "5857": [
    {
      "answer": "design",
      "score": 0.7986835837364197
    },
    {
      "answer": "financial",
      "score": 0.7926197052001953
    },
    {
      "answer": "estimating",
      "score": 0.7497181296348572
    }
  ],
  "5858": [
    {
      "answer": "local building authority regulations and codes of practice",
      "score": 0.9949378371238708
    }
  ],
  "5859": [
    {
      "answer": "Materials readily available in the area",
      "score": 0.9902483224868774
    }
  ],
  "5860": [
    {
      "answer": "waste",
      "score": 0.9854633808135986
    }
  ],
  "5861": [
    {
      "answer": "Cost of construction",
      "score": 0.9841833114624023
    }
  ],
  "5862": [
    {
      "answer": "local building authority regulations and codes of practice",
      "score": 0.95979905128479
    }
  ],
  "5863": [
    {
      "answer": "more expensive to build",
      "score": 0.9755388498306274
    }
  ],
  "5864": [
    {
      "answer": "site conditions",
      "score": 0.9611847996711731
    },
    {
      "answer": "local regulations",
      "score": 0.9152929186820984
    },
    {
      "answer": "economies of scale",
      "score": 0.8885278701782227
    }
  ],
  "5865": [
    {
      "answer": "local building authority regulations and codes of practice",
      "score": 0.8532723784446716
    }
  ],
  "5866": [
    {
      "answer": "Residential construction practices, technologies, and resources must conform to local building authority regulations and codes of practice",
      "score": 0.7685863971710205
    }
  ],
  "5867": [
    {
      "answer": "3D printing",
      "score": 0.9957157373428345
    }
  ],
  "5868": [
    {
      "answer": "20 hours",
      "score": 0.9948875904083252
    }
  ],
  "5869": [
    {
      "answer": "2014",
      "score": 0.9950836896896362
    }
  ],
  "5870": [
    {
      "answer": "2 metres",
      "score": 0.9777919054031372
    }
  ],
  "5871": [
    {
      "answer": "performative architecture 3D-printed building",
      "score": 0.9378010630607605
    }
  ],
  "5872": [
    {
      "answer": "3D printing technology",
      "score": 0.9722615480422974
    }
  ],
  "5873": [
    {
      "answer": "additive manufacturing techniques for manufactured parts",
      "score": 0.917227029800415
    }
  ],
  "5874": [
    {
      "answer": "20 hours",
      "score": 0.9923898577690125
    }
  ],
  "5875": [
    {
      "answer": "2 metres (6 ft 7 in) of building material per hour",
      "score": 0.8372865915298462
    }
  ],
  "5876": [
    {
      "answer": "designs",
      "score": 0.9908570647239685
    }
  ],
  "5877": [
    {
      "answer": "plan the physical proceedings",
      "score": 0.9881368279457092
    },
    {
      "answer": "integrate those proceedings with the other parts",
      "score": 0.8031906485557556
    }
  ],
  "5878": [
    {
      "answer": "property owner",
      "score": 0.9953001737594604
    }
  ],
  "5879": [
    {
      "answer": "quantity surveyor",
      "score": 0.9933339953422546
    }
  ],
  "5880": [
    {
      "answer": "the most cost efficient bidder",
      "score": 0.9819866418838501
    }
  ],
  "5881": [],
  "5882": [
    {
      "answer": "design team",
      "score": 0.5719778537750244
    },
    {
      "answer": "construction companies",
      "score": 0.7995247840881348
    }
  ],
  "5883": [
    {
      "answer": "quantity surveyor",
      "score": 0.9719529747962952
    }
  ],
  "5884": [
    {
      "answer": "bid for the work",
      "score": 0.908733069896698
    }
  ],
  "5885": [
    {
      "answer": "previously separated specialties",
      "score": 0.9941432476043701
    }
  ],
  "5886": [
    {
      "answer": "entirely separate companies",
      "score": 0.9887909293174744
    }
  ],
  "5887": [
    {
      "answer": "one-stop shopping",
      "score": 0.99282306432724
    }
  ],
  "5888": [
    {
      "answer": "design build\"",
      "score": 0.95650315284729
    }
  ],
  "5889": [
    {
      "answer": "integration",
      "score": 0.9848736524581909
    }
  ],
  "5890": [
    {
      "answer": "experts from all related fields",
      "score": 0.9410261511802673
    }
  ],
  "5891": [
    {
      "answer": "one-stop shopping",
      "score": 0.9895268678665161
    }
  ],
  "5892": [
    {
      "answer": "design build",
      "score": 0.9707558155059814
    }
  ],
  "5893": [
    {
      "answer": "architects",
      "score": 0.89653480052948
    },
    {
      "answer": "interior designers",
      "score": 0.9380832314491272
    },
    {
      "answer": "engineers",
      "score": 0.9116336107254028
    },
    {
      "answer": "developers",
      "score": 0.9194402694702148
    },
    {
      "answer": "construction managers",
      "score": 0.9615942239761353
    },
    {
      "answer": "general contractors",
      "score": 0.9358043670654297
    }
  ],
  "5894": [
    {
      "answer": "design-build",
      "score": 0.9761777520179749
    },
    {
      "answer": "partnering",
      "score": 0.9800856709480286
    },
    {
      "answer": "construction management",
      "score": 0.9841082096099854
    }
  ],
  "5895": [
    {
      "answer": "architects",
      "score": 0.9723886251449585
    },
    {
      "answer": "interior designers",
      "score": 0.9800982475280762
    },
    {
      "answer": "engineers",
      "score": 0.9738913178443909
    },
    {
      "answer": "constructors",
      "score": 0.9690527319908142
    }
  ],
  "5896": [
    {
      "answer": "establishing relationships with other necessary participants",
      "score": 0.9735558032989502
    }
  ],
  "5897": [
    {
      "answer": "establishing relationships with other necessary participants",
      "score": 0.9541001319885254
    }
  ],
  "5898": [
    {
      "answer": "design-build",
      "score": 0.9420948028564453
    },
    {
      "answer": "partnering",
      "score": 0.9053072929382324
    },
    {
      "answer": "construction management",
      "score": 0.9100840091705322
    },
    {
      "answer": "design-build",
      "score": 0.6757791638374329
    }
  ],
  "5899": [
    {
      "answer": "architects",
      "score": 0.9581321477890015
    },
    {
      "answer": "interior designers",
      "score": 0.9689016938209534
    },
    {
      "answer": "engineers",
      "score": 0.955431342124939
    }
  ],
  "5900": [
    {
      "answer": "design-build",
      "score": 0.897368311882019
    },
    {
      "answer": "partnering",
      "score": 0.8158776760101318
    },
    {
      "answer": "construction management",
      "score": 0.8320388793945312
    },
    {
      "answer": "design-build",
      "score": 0.6132165789604187
    }
  ],
  "5901": [
    {
      "answer": "establishing relationships with other necessary participants",
      "score": 0.9158055782318115
    }
  ],
  "5902": [
    {
      "answer": "preventable financial problems",
      "score": 0.9648289680480957
    },
    {
      "answer": "Cash flow problems",
      "score": 0.668998122215271
    }
  ],
  "5903": [
    {
      "answer": "Underbids happen when builders ask for too little money to complete the project",
      "score": 0.9172711372375488
    }
  ],
  "5904": [
    {
      "answer": "the present amount of funding cannot cover the current costs for labour and materials",
      "score": 0.9626883268356323
    }
  ],
  "5905": [
    {
      "answer": "Fraud",
      "score": 0.9653693437576294
    }
  ],
  "5906": [
    {
      "answer": "preventable financial problems",
      "score": 0.8355293273925781
    },
    {
      "answer": "Cash flow problems",
      "score": 0.5845612287521362
    }
  ],
  "5907": [
    {
      "answer": "Fraud",
      "score": 0.8869940638542175
    }
  ],
  "5908": [],
  "5909": [
    {
      "answer": "Financial planning",
      "score": 0.8102927207946777
    },
    {
      "answer": "a solid plan with adequate safeguards and contingency plans",
      "score": 0.7032140493392944
    }
  ],
  "5910": [
    {
      "answer": "Underbids",
      "score": 0.9830744862556458
    }
  ],
  "5911": [],
  "5912": [
    {
      "answer": "mortgage banker",
      "score": 0.9840449690818787
    }
  ],
  "5913": [
    {
      "answer": "accountants",
      "score": 0.7064263224601746
    },
    {
      "answer": "Accountants",
      "score": 0.9627277851104736
    }
  ],
  "5914": [
    {
      "answer": "Cost engineers and estimators",
      "score": 0.9593923091888428
    }
  ],
  "5915": [
    {
      "answer": "identified change orders or project changes that increased costs",
      "score": 0.9862052202224731
    }
  ],
  "5916": [
    {
      "answer": "expected monetary flow over the life of the project",
      "score": 0.640254557132721
    }
  ],
  "5917": [
    {
      "answer": "Cost overruns",
      "score": 0.7784186601638794
    },
    {
      "answer": "initial bid",
      "score": 0.6953566670417786
    }
  ],
  "5918": [
    {
      "answer": "change orders or project changes",
      "score": 0.9221316576004028
    }
  ],
  "5919": [
    {
      "answer": "mortgage banker",
      "score": 0.9513856172561646
    }
  ],
  "5920": [
    {
      "answer": "owner's equity in the property",
      "score": 0.9615973234176636
    }
  ],
  "5921": [
    {
      "answer": "zoning and building code requirements",
      "score": 0.996464192867279
    }
  ],
  "5922": [
    {
      "answer": "owner",
      "score": 0.9951831698417664
    }
  ],
  "5923": [
    {
      "answer": "the desire to prevent things that are indisputably bad \u2013 bridge collapses or explosions",
      "score": 0.9080495834350586
    }
  ],
  "5924": [
    {
      "answer": "isolating businesses to a business district and residences to a residential district",
      "score": 0.9731280207633972
    }
  ],
  "5925": [
    {
      "answer": "An attorney",
      "score": 0.9676923751831055
    }
  ],
  "5926": [
    {
      "answer": "zoning and building code requirements",
      "score": 0.9944745898246765
    }
  ],
  "5927": [
    {
      "answer": "owner",
      "score": 0.994096040725708
    }
  ],
  "5928": [
    {
      "answer": "malum in se considerations",
      "score": 0.9944394826889038
    }
  ],
  "5929": [
    {
      "answer": "arguing that a rule is inapplicable",
      "score": 0.9431005716323853
    }
  ],
  "5930": [
    {
      "answer": "malum prohibitum considerations",
      "score": 0.6696815490722656
    },
    {
      "answer": "isolating businesses to a business district and residences to a residential district",
      "score": 0.9518828392028809
    }
  ],
  "5931": [
    {
      "answer": "A construction project",
      "score": 0.9700015783309937
    }
  ],
  "5932": [
    {
      "answer": "contract",
      "score": 0.9770410656929016
    }
  ],
  "5933": [
    {
      "answer": "a delay costs money",
      "score": 0.983950138092041
    }
  ],
  "5934": [
    {
      "answer": "each side is capable of performing the obligations set out",
      "score": 0.9893684387207031
    }
  ],
  "5935": [
    {
      "answer": "poorly drafted contracts",
      "score": 0.9938227534294128
    }
  ],
  "5936": [
    {
      "answer": "construction project",
      "score": 0.9085463285446167
    }
  ],
  "5937": [
    {
      "answer": "delay",
      "score": 0.9602944254875183
    }
  ],
  "5938": [
    {
      "answer": "a delay costs money",
      "score": 0.7680593729019165
    }
  ],
  "5939": [
    {
      "answer": "clear expectations and clear paths to accomplishing those expectations",
      "score": 0.8671668171882629
    }
  ],
  "5940": [
    {
      "answer": "confusion and collapse",
      "score": 0.9853425025939941
    }
  ],
  "5941": [
    {
      "answer": "relationship contracting",
      "score": 0.9874139428138733
    }
  ],
  "5942": [
    {
      "answer": "Public-Private Partnering",
      "score": 0.9770737886428833
    }
  ],
  "5943": [
    {
      "answer": "private finance initiatives (PFIs)",
      "score": 0.855334460735321
    }
  ],
  "5944": [],
  "5945": [
    {
      "answer": "ameliorate the many problems that arise from the often highly competitive and adversarial practices within the construction industry",
      "score": 0.8220809102058411
    }
  ],
  "5946": [
    {
      "answer": "co-operative",
      "score": 0.8824695348739624
    }
  ],
  "5947": [
    {
      "answer": "principal and contractor and other stakeholders",
      "score": 0.8883596658706665
    }
  ],
  "5948": [
    {
      "answer": "competitive",
      "score": 0.949384868144989
    }
  ],
  "5949": [
    {
      "answer": "partnering such as Public-Private Partnering (PPPs) aka private finance initiatives (PFIs)",
      "score": 0.7414763569831848
    },
    {
      "answer": "alliances such as \"pure\" or \"project\" alliances",
      "score": 0.7250345349311829
    }
  ],
  "5950": [
    {
      "answer": "architect or engineer",
      "score": 0.9819350242614746
    }
  ],
  "5951": [],
  "5952": [
    {
      "answer": "main contractor",
      "score": 0.9448001384735107
    }
  ],
  "5953": [
    {
      "answer": "main contractor",
      "score": 0.9919685125350952
    }
  ],
  "5954": [
    {
      "answer": "building is ready to occupy",
      "score": 0.9952406287193298
    }
  ],
  "5955": [
    {
      "answer": "ready to occupy",
      "score": 0.9877324104309082
    }
  ],
  "5956": [
    {
      "answer": "project coordinator",
      "score": 0.8602532148361206
    }
  ],
  "5957": [
    {
      "answer": "design the works",
      "score": 0.9586219787597656
    },
    {
      "answer": "prepare the specifications and produce construction drawings",
      "score": 0.9670708775520325
    },
    {
      "answer": "administer the contract",
      "score": 0.9578587412834167
    },
    {
      "answer": "tender the works",
      "score": 0.9597630500793457
    },
    {
      "answer": "manage the works from inception to completion",
      "score": 0.9621899127960205
    }
  ],
  "5958": [],
  "5959": [
    {
      "answer": "the architect or engineer acts as the project coordinator",
      "score": 0.8480917811393738
    }
  ],
  "5960": [
    {
      "answer": "owner",
      "score": 0.9893219470977783
    }
  ],
  "5961": [
    {
      "answer": "D&B contractors",
      "score": 0.9819251298904419
    }
  ],
  "5962": [
    {
      "answer": "owner",
      "score": 0.8257522583007812
    },
    {
      "answer": "owner",
      "score": 0.9809027910232544
    },
    {
      "answer": "owner",
      "score": 0.7319585680961609
    }
  ],
  "5963": [
    {
      "answer": "contractors",
      "score": 0.9345961809158325
    }
  ],
  "5964": [
    {
      "answer": "As they build phase 1, they design phase 2",
      "score": 0.7485948801040649
    }
  ],
  "5965": [
    {
      "answer": "list of requirements",
      "score": 0.9917702674865723
    }
  ],
  "5966": [
    {
      "answer": "list of requirements",
      "score": 0.9933280348777771
    }
  ],
  "5967": [
    {
      "answer": "present different ideas about how to accomplish these goals",
      "score": 0.9310065507888794
    }
  ],
  "5968": [
    {
      "answer": "contractor",
      "score": 0.7793494462966919
    }
  ],
  "5969": [
    {
      "answer": "Several D&B contractors present different ideas about how to accomplish these goals.",
      "score": 0.6447475552558899
    },
    {
      "answer": "The owner selects the ideas he or she likes best and hires the appropriate contractor.",
      "score": 0.849697470664978
    },
    {
      "answer": "As they build phase 1, they design phase 2.",
      "score": 0.7537894248962402
    }
  ],
  "5970": [
    {
      "answer": "contractors",
      "score": 0.9832648634910583
    }
  ],
  "5971": [
    {
      "answer": "damage to the existing electrical, water, sewage, phone, and cable facilities",
      "score": 0.9848883748054504
    }
  ],
  "5972": [
    {
      "answer": "electrical",
      "score": 0.7518793940544128
    },
    {
      "answer": "water",
      "score": 0.7496016025543213
    },
    {
      "answer": "sewage",
      "score": 0.7499670386314392
    },
    {
      "answer": "phone",
      "score": 0.7184193730354309
    },
    {
      "answer": "cable",
      "score": 0.6915435194969177
    }
  ],
  "5973": [
    {
      "answer": "municipal building inspector",
      "score": 0.982253909111023
    }
  ],
  "5974": [
    {
      "answer": "occupancy permit",
      "score": 0.9903284907341003
    }
  ],
  "5975": [
    {
      "answer": "contractors are typically required to verify and have existing utility lines marked",
      "score": 0.820807933807373
    },
    {
      "answer": "an occupancy permit may be issued",
      "score": 0.8220231533050537
    }
  ],
  "5976": [
    {
      "answer": "verify and have existing utility lines marked",
      "score": 0.8318701386451721
    },
    {
      "answer": "inspects the building periodically to ensure that the construction adheres to the approved plans and the local building code",
      "score": 0.6555508971214294
    }
  ],
  "5977": [
    {
      "answer": "electrical",
      "score": 0.908296525478363
    },
    {
      "answer": "water",
      "score": 0.941597044467926
    },
    {
      "answer": "sewage",
      "score": 0.9256100058555603
    },
    {
      "answer": "phone",
      "score": 0.9068664312362671
    },
    {
      "answer": "cable facilities",
      "score": 0.8195042610168457
    }
  ],
  "5978": [
    {
      "answer": "verify and have existing utility lines marked",
      "score": 0.8080119490623474
    }
  ],
  "5979": [],
  "5980": [
    {
      "answer": "$960 billion",
      "score": 0.9800764918327332
    }
  ],
  "5981": [
    {
      "answer": "$680 billion",
      "score": 0.9443716406822205
    }
  ],
  "5982": [
    {
      "answer": "667,000",
      "score": 0.9845981597900391
    }
  ],
  "5983": [
    {
      "answer": "fewer than 10",
      "score": 0.9844300150871277
    }
  ],
  "5984": [
    {
      "answer": "828",
      "score": 0.9944266080856323
    }
  ],
  "5985": [
    {
      "answer": "13.2%",
      "score": 0.9933357238769531
    }
  ],
  "5986": [
    {
      "answer": "$960 billion",
      "score": 0.9374122619628906
    }
  ],
  "5987": [],
  "5988": [
    {
      "answer": "667,000",
      "score": 0.9668046832084656
    }
  ],
  "5989": [
    {
      "answer": "1 million",
      "score": 0.9840800762176514
    }
  ],
  "5990": [
    {
      "answer": "\u00a342,090",
      "score": 0.984168291091919
    }
  ],
  "5991": [
    {
      "answer": "\u00a326,719",
      "score": 0.9761234521865845
    }
  ],
  "5992": [
    {
      "answer": "US/Canada",
      "score": 0.9852181673049927
    }
  ],
  "5993": [
    {
      "answer": "\u00a342,090",
      "score": 0.985018253326416
    }
  ],
  "5994": [
    {
      "answer": "\u00a343,389",
      "score": 0.990960419178009
    }
  ],
  "5995": [
    {
      "answer": "\u00a343,389",
      "score": 0.9427012205123901
    }
  ],
  "5996": [
    {
      "answer": "The average earning for a professional in the construction industry in the Middle East, across all sectors, job types and levels of experience, is \u00a342,090, compared to \u00a326,719 in the UK",
      "score": 0.8967869281768799
    }
  ],
  "5997": [
    {
      "answer": "more affluent roles are available",
      "score": 0.9701801538467407
    }
  ],
  "5998": [
    {
      "answer": "Construction",
      "score": 0.9691501259803772
    },
    {
      "answer": "construction",
      "score": 0.7976027131080627
    },
    {
      "answer": "construction",
      "score": 0.8270642161369324
    },
    {
      "answer": "construction",
      "score": 0.880943775177002
    },
    {
      "answer": "construction",
      "score": 0.8319355845451355
    }
  ],
  "5999": [
    {
      "answer": "Falls",
      "score": 0.9734435677528381
    }
  ],
  "6000": [
    {
      "answer": "electrocution",
      "score": 0.906590461730957
    },
    {
      "answer": "transportation accidents",
      "score": 0.9540358185768127
    },
    {
      "answer": "trench cave-ins",
      "score": 0.9434564709663391
    }
  ],
  "6001": [
    {
      "answer": "Proper safety equipment such as harnesses and guardrails",
      "score": 0.9643784165382385
    }
  ],
  "6002": [
    {
      "answer": "Construction",
      "score": 0.9036970138549805
    },
    {
      "answer": "construction",
      "score": 0.7356226444244385
    },
    {
      "answer": "construction",
      "score": 0.7411475777626038
    },
    {
      "answer": "construction",
      "score": 0.8255541920661926
    },
    {
      "answer": "construction",
      "score": 0.7462912201881409
    }
  ],
  "6003": [
    {
      "answer": "the fatal occupational injury rate among construction workers in the United States was nearly three times that for all workers",
      "score": 0.8135308623313904
    }
  ],
  "6004": [
    {
      "answer": "safety equipment",
      "score": 0.982150673866272
    }
  ],
  "6005": [
    {
      "answer": "Proper safety equipment such as harnesses and guardrails",
      "score": 0.829747200012207
    },
    {
      "answer": "securing ladders",
      "score": 0.968124270439148
    },
    {
      "answer": "inspecting scaffolding",
      "score": 0.9682700634002686
    }
  ],
  "6006": [
    {
      "answer": "Falls",
      "score": 0.5361518859863281
    },
    {
      "answer": "electrocution",
      "score": 0.8206136226654053
    },
    {
      "answer": "transportation accidents",
      "score": 0.8247545957565308
    },
    {
      "answer": "trench cave-ins",
      "score": 0.7960340976715088
    }
  ],
  "6007": [
    {
      "answer": "independent schools",
      "score": 0.944536030292511
    },
    {
      "answer": "nonstate schools",
      "score": 0.5535586476325989
    }
  ],
  "6008": [
    {
      "answer": "sport scholarship",
      "score": 0.9114353060722351
    },
    {
      "answer": "art scholarship",
      "score": 0.8412139415740967
    },
    {
      "answer": "academic scholarship",
      "score": 0.6573817729949951
    }
  ],
  "6009": [
    {
      "answer": "tuition",
      "score": 0.9825538992881775
    }
  ],
  "6010": [
    {
      "answer": "the right to select their students",
      "score": 0.9424979090690613
    }
  ],
  "6011": [
    {
      "answer": "independent schools",
      "score": 0.8673233985900879
    },
    {
      "answer": "non-governmental",
      "score": 0.6583948731422424
    },
    {
      "answer": "nonstate schools",
      "score": 0.6583940386772156
    }
  ],
  "6012": [
    {
      "answer": "charging their students tuition",
      "score": 0.8006501197814941
    }
  ],
  "6013": [
    {
      "answer": "sport scholarship",
      "score": 0.9296624660491943
    },
    {
      "answer": "art scholarship",
      "score": 0.8932399749755859
    },
    {
      "answer": "academic scholarship",
      "score": 0.873018741607666
    },
    {
      "answer": "financial need",
      "score": 0.5870314836502075
    },
    {
      "answer": "tax credit scholarships",
      "score": 0.5925330519676208
    }
  ],
  "6014": [
    {
      "answer": "talent",
      "score": 0.610001266002655
    },
    {
      "answer": "financial need",
      "score": 0.9418818950653076
    }
  ],
  "6015": [
    {
      "answer": "scholarship",
      "score": 0.6654058694839478
    }
  ],
  "6016": [
    {
      "answer": "$45,000",
      "score": 0.9847750663757324
    }
  ],
  "6017": [],
  "6018": [
    {
      "answer": "United Kingdom",
      "score": 0.7955644726753235
    },
    {
      "answer": "Australia",
      "score": 0.7525879740715027
    },
    {
      "answer": "Canada",
      "score": 0.6252162456512451
    }
  ],
  "6019": [
    {
      "answer": "North America",
      "score": 0.9723595380783081
    }
  ],
  "6020": [
    {
      "answer": "more than $45,000",
      "score": 0.805010974407196
    }
  ],
  "6021": [
    {
      "answer": "primary and secondary educational levels",
      "score": 0.9894073605537415
    }
  ],
  "6022": [
    {
      "answer": "universities and other tertiary institutions",
      "score": 0.9699312448501587
    }
  ],
  "6023": [],
  "6024": [],
  "6025": [
    {
      "answer": "lower sixth",
      "score": 0.9755474925041199
    }
  ],
  "6026": [
    {
      "answer": "upper sixth",
      "score": 0.9544646143913269
    }
  ],
  "6027": [
    {
      "answer": "prep schools",
      "score": 0.9802037477493286
    }
  ],
  "6028": [
    {
      "answer": "location of the school",
      "score": 0.9391518831253052
    },
    {
      "answer": "willingness of parents to pay",
      "score": 0.9601045846939087
    },
    {
      "answer": "peer tuitions",
      "score": 0.9753944873809814
    }
  ],
  "6029": [
    {
      "answer": "the best teachers",
      "score": 0.9461312294006348
    }
  ],
  "6030": [],
  "6031": [],
  "6032": [
    {
      "answer": "High tuition",
      "score": 0.706649661064148
    }
  ],
  "6033": [],
  "6034": [
    {
      "answer": "Roman Catholic",
      "score": 0.9955556392669678
    }
  ],
  "6035": [
    {
      "answer": "Roman Catholic",
      "score": 0.9671142101287842
    }
  ],
  "6036": [
    {
      "answer": "religious education",
      "score": 0.9883785247802734
    }
  ],
  "6037": [
    {
      "answer": "Religiously affiliated and denominational schools",
      "score": 0.852790355682373
    },
    {
      "answer": "private schools",
      "score": 0.6893197298049927
    }
  ],
  "6038": [
    {
      "answer": "religious education",
      "score": 0.6675027012825012
    },
    {
      "answer": "parochial schools",
      "score": 0.6937775015830994
    }
  ],
  "6039": [
    {
      "answer": "to impress their particular faith's beliefs and traditions in the students who attend",
      "score": 0.9016825556755066
    }
  ],
  "6040": [],
  "6041": [
    {
      "answer": "expulsion",
      "score": 0.9777406454086304
    }
  ],
  "6042": [
    {
      "answer": "blazer",
      "score": 0.9812014102935791
    }
  ],
  "6043": [
    {
      "answer": "more expensive than their public counterparts",
      "score": 0.9073638916015625
    }
  ],
  "6044": [
    {
      "answer": "prestige",
      "score": 0.7035788297653198
    },
    {
      "answer": "old school tie",
      "score": 0.8014189600944519
    }
  ],
  "6045": [],
  "6046": [],
  "6047": [
    {
      "answer": "expulsion",
      "score": 0.9904360175132751
    }
  ],
  "6048": [
    {
      "answer": "blazer",
      "score": 0.9916683435440063
    }
  ],
  "6049": [
    {
      "answer": "Anglican Church",
      "score": 0.562019944190979
    },
    {
      "answer": "Uniting Church",
      "score": 0.5272548198699951
    },
    {
      "answer": "Presbyterian Church",
      "score": 0.6578733921051025
    }
  ],
  "6050": [
    {
      "answer": "Anglican Church",
      "score": 0.5823075771331787
    },
    {
      "answer": "Uniting Church",
      "score": 0.5527548789978027
    },
    {
      "answer": "Catholic",
      "score": 0.7752060890197754
    }
  ],
  "6051": [],
  "6052": [
    {
      "answer": "girls",
      "score": 0.9768556356430054
    }
  ],
  "6053": [
    {
      "answer": "Anglican Church",
      "score": 0.8114767670631409
    },
    {
      "answer": "Uniting Church",
      "score": 0.7962579727172852
    },
    {
      "answer": "Presbyterian Church",
      "score": 0.6727393865585327
    }
  ],
  "6054": [],
  "6055": [],
  "6056": [
    {
      "answer": "Anglican Church",
      "score": 0.8224106431007385
    },
    {
      "answer": "Uniting Church",
      "score": 0.7547006607055664
    },
    {
      "answer": "Presbyterian Church",
      "score": 0.6975489854812622
    }
  ],
  "6057": [],
  "6058": [
    {
      "answer": "Article 7",
      "score": 0.9865610599517822
    }
  ],
  "6059": [
    {
      "answer": "a second Gleichschaltung",
      "score": 0.8864703178405762
    }
  ],
  "6060": [
    {
      "answer": "11.1%",
      "score": 0.8358837366104126
    }
  ],
  "6061": [
    {
      "answer": "11.1%",
      "score": 0.9822986125946045
    }
  ],
  "6062": [
    {
      "answer": "6.1%",
      "score": 0.8411743640899658
    },
    {
      "answer": "11.1%",
      "score": 0.7477402687072754
    }
  ],
  "6063": [
    {
      "answer": "Article 7, Paragraph 4 of the Grundgesetz",
      "score": 0.9281268119812012
    }
  ],
  "6064": [],
  "6065": [
    {
      "answer": "to protect these schools from a second Gleichschaltung or similar event",
      "score": 0.9894147515296936
    }
  ],
  "6066": [
    {
      "answer": "7.8%",
      "score": 0.5961470603942871
    },
    {
      "answer": "11.1%",
      "score": 0.8057913780212402
    }
  ],
  "6067": [
    {
      "answer": "11.1%",
      "score": 0.8533281087875366
    }
  ],
  "6068": [
    {
      "answer": "Sonderungsverbot",
      "score": 0.984326183795929
    }
  ],
  "6069": [
    {
      "answer": "Ersatzschulen",
      "score": 0.9017561078071594
    },
    {
      "answer": "Ersatzschulen",
      "score": 0.7731376886367798
    },
    {
      "answer": "Ersatzschulen",
      "score": 0.7306224703788757
    },
    {
      "answer": "Ersatzschulen",
      "score": 0.7594754099845886
    },
    {
      "answer": "Ersatzschulen",
      "score": 0.8313482403755188
    }
  ],
  "6070": [
    {
      "answer": "very low tuition fees",
      "score": 0.9120222926139832
    }
  ],
  "6071": [
    {
      "answer": "Article 7, Paragraph 4 of the Grundgesetz",
      "score": 0.7966580390930176
    }
  ],
  "6072": [
    {
      "answer": "ordinary primary or secondary schools",
      "score": 0.9143900275230408
    }
  ],
  "6073": [
    {
      "answer": "same types of diplomas as public schools",
      "score": 0.7813350558280945
    }
  ],
  "6074": [
    {
      "answer": "Article 7, Paragraph 4 of the Grundgesetz, also forbids segregation of pupils according to the means of their parents",
      "score": 0.6841698884963989
    }
  ],
  "6075": [
    {
      "answer": "very low",
      "score": 0.9577093720436096
    }
  ],
  "6076": [
    {
      "answer": "Erg\u00e4nzungsschulen",
      "score": 0.873963475227356
    },
    {
      "answer": "Erg\u00e4nzungsschulen",
      "score": 0.7396777272224426
    }
  ],
  "6077": [
    {
      "answer": "vocational schools",
      "score": 0.9664288759231567
    },
    {
      "answer": "vocational schools",
      "score": 0.815651535987854
    }
  ],
  "6078": [
    {
      "answer": "charging their students tuition fees",
      "score": 0.9835254549980164
    }
  ],
  "6079": [
    {
      "answer": "religious groups",
      "score": 0.9849908351898193
    }
  ],
  "6080": [
    {
      "answer": "Erg\u00e4nzungsschulen",
      "score": 0.582827627658844
    },
    {
      "answer": "Erg\u00e4nzungsschulen",
      "score": 0.5862069725990295
    }
  ],
  "6081": [
    {
      "answer": "German dual education system",
      "score": 0.9089083075523376
    }
  ],
  "6082": [
    {
      "answer": "government regulation",
      "score": 0.9924095869064331
    }
  ],
  "6083": [
    {
      "answer": "charging their students tuition fees",
      "score": 0.970341682434082
    }
  ],
  "6084": [
    {
      "answer": "religious groups",
      "score": 0.9851223826408386
    }
  ],
  "6085": [],
  "6086": [
    {
      "answer": "CBSE",
      "score": 0.9851430058479309
    }
  ],
  "6087": [
    {
      "answer": "30",
      "score": 0.9952932000160217
    }
  ],
  "6088": [
    {
      "answer": "union government",
      "score": 0.8841482400894165
    },
    {
      "answer": "union government",
      "score": 0.9898608922958374
    }
  ],
  "6089": [],
  "6090": [
    {
      "answer": "aided",
      "score": 0.9414169788360596
    },
    {
      "answer": "unaided school",
      "score": 0.8709105253219604
    }
  ],
  "6091": [
    {
      "answer": "schools",
      "score": 0.6194539070129395
    }
  ],
  "6092": [
    {
      "answer": "30",
      "score": 0.5798287987709045
    }
  ],
  "6093": [
    {
      "answer": "school leaving certificates",
      "score": 0.9903427958488464
    }
  ],
  "6094": [],
  "6095": [
    {
      "answer": "India",
      "score": 0.9583415389060974
    },
    {
      "answer": "India",
      "score": 0.9283547401428223
    }
  ],
  "6096": [
    {
      "answer": "Annual Status of Education Report",
      "score": 0.9418310523033142
    }
  ],
  "6097": [
    {
      "answer": "evaluates learning levels in rural India",
      "score": 0.9510900378227234
    }
  ],
  "6098": [
    {
      "answer": "English",
      "score": 0.9956982135772705
    }
  ],
  "6099": [
    {
      "answer": "non-profit trusts and societies",
      "score": 0.9865177869796753
    }
  ],
  "6100": [
    {
      "answer": "satisfy a number of infrastructure and human resource related criteria to get Recognition",
      "score": 0.9420732855796814
    }
  ],
  "6101": [
    {
      "answer": "an increasing number of private schools",
      "score": 0.8527827262878418
    }
  ],
  "6102": [
    {
      "answer": "poorer academic achievement in government schools than in private schools",
      "score": 0.9405463337898254
    }
  ],
  "6103": [
    {
      "answer": "corruption",
      "score": 0.9762699007987976
    }
  ],
  "6104": [
    {
      "answer": "scoil phr\u00edobh\u00e1ideach",
      "score": 0.8667647838592529
    }
  ],
  "6105": [
    {
      "answer": "a certain number of teacher's salaries are paid by the State",
      "score": 0.8847288489341736
    }
  ],
  "6106": [
    {
      "answer": "\u20ac5,000",
      "score": 0.9809516668319702
    }
  ],
  "6107": [
    {
      "answer": "Society of Jesus",
      "score": 0.9793366193771362
    }
  ],
  "6108": [
    {
      "answer": "\u20ac25,000",
      "score": 0.9844309091567993
    }
  ],
  "6109": [
    {
      "answer": "scoil phr\u00edobh\u00e1ideach",
      "score": 0.5884071588516235
    }
  ],
  "6110": [
    {
      "answer": "relatively low",
      "score": 0.8809950351715088
    }
  ],
  "6111": [
    {
      "answer": "relatively low",
      "score": 0.9850451946258545
    }
  ],
  "6112": [
    {
      "answer": "Junior Certificate",
      "score": 0.9937061667442322
    },
    {
      "answer": "Leaving Certificate",
      "score": 0.9858231544494629
    }
  ],
  "6113": [
    {
      "answer": "\u20ac5,000",
      "score": 0.9745779633522034
    }
  ],
  "6114": [
    {
      "answer": "1957",
      "score": 0.9892226457595825
    }
  ],
  "6115": [
    {
      "answer": "Chinese",
      "score": 0.8672133684158325
    },
    {
      "answer": "Chinese",
      "score": 0.8295289278030396
    },
    {
      "answer": "Chinese",
      "score": 0.9839468002319336
    },
    {
      "answer": "Chinese",
      "score": 0.7805466055870056
    }
  ],
  "6116": [
    {
      "answer": "Chinese",
      "score": 0.5555395483970642
    },
    {
      "answer": "Chinese",
      "score": 0.7867017388343811
    },
    {
      "answer": "Chinese",
      "score": 0.5265983939170837
    }
  ],
  "6117": [],
  "6118": [
    {
      "answer": "Over 60",
      "score": 0.9229358434677124
    }
  ],
  "6119": [
    {
      "answer": "1957",
      "score": 0.9682451486587524
    }
  ],
  "6120": [
    {
      "answer": "Over 60",
      "score": 0.916675329208374
    }
  ],
  "6121": [
    {
      "answer": "the government instructed all schools to surrender their properties and be assimilated into the National School system",
      "score": 0.9196584820747375
    },
    {
      "answer": "the schools would instead become \"National Type\" schools",
      "score": 0.6113216280937195
    }
  ],
  "6122": [
    {
      "answer": "National Type",
      "score": 0.9903307557106018
    },
    {
      "answer": "National Type schools",
      "score": 0.8560206294059753
    }
  ],
  "6123": [
    {
      "answer": "government",
      "score": 0.5442226529121399
    },
    {
      "answer": "schools",
      "score": 0.7756284475326538
    }
  ],
  "6124": [
    {
      "answer": "aided' schools",
      "score": 0.7601050138473511
    }
  ],
  "6125": [
    {
      "answer": "The private 'un-aided' schools are fully funded by private parties.",
      "score": 0.9243671298027039
    },
    {
      "answer": "The standard and the quality of education is quite high.",
      "score": 0.8068349957466125
    }
  ],
  "6126": [
    {
      "answer": "Kathmandu",
      "score": 0.9390567541122437
    }
  ],
  "6127": [
    {
      "answer": "English",
      "score": 0.9458983540534973
    }
  ],
  "6128": [
    {
      "answer": "Nepali",
      "score": 0.9461582899093628
    }
  ],
  "6129": [
    {
      "answer": "middle-class",
      "score": 0.9919090867042542
    }
  ],
  "6130": [
    {
      "answer": "middle-class",
      "score": 0.9824492931365967
    }
  ],
  "6131": [],
  "6132": [],
  "6133": [
    {
      "answer": "private parties",
      "score": 0.9347534775733948
    }
  ],
  "6134": [
    {
      "answer": "88",
      "score": 0.9869425296783447
    }
  ],
  "6135": [
    {
      "answer": "28,000",
      "score": 0.9747650623321533
    }
  ],
  "6136": [
    {
      "answer": "3.7%",
      "score": 0.9869449734687805
    }
  ],
  "6137": [
    {
      "answer": "Catholic",
      "score": 0.957014262676239
    }
  ],
  "6138": [
    {
      "answer": "Auckland",
      "score": 0.9556475281715393
    }
  ],
  "6139": [],
  "6140": [],
  "6141": [
    {
      "answer": "3.7%",
      "score": 0.9727118015289307
    }
  ],
  "6142": [
    {
      "answer": "Private school numbers have been in decline since the mid-1970s",
      "score": 0.8012277483940125
    }
  ],
  "6143": [
    {
      "answer": "many private schools opting to become state-integrated schools",
      "score": 0.9259705543518066
    },
    {
      "answer": "financial difficulties stemming from changes in student numbers and/or the economy",
      "score": 0.8640285134315491
    }
  ],
  "6144": [
    {
      "answer": "Anglican",
      "score": 0.9869909882545471
    }
  ],
  "6145": [],
  "6146": [
    {
      "answer": "Presbyterian",
      "score": 0.9879820942878723
    }
  ],
  "6147": [
    {
      "answer": "Christchurch",
      "score": 0.7032918334007263
    },
    {
      "answer": "Christchurch",
      "score": 0.9537157416343689
    }
  ],
  "6148": [
    {
      "answer": "Society of St Pius X",
      "score": 0.9101216197013855
    }
  ],
  "6149": [
    {
      "answer": "Academic Colleges Group is a recent group of private schools run as a business",
      "score": 0.872536838054657
    }
  ],
  "6150": [],
  "6151": [
    {
      "answer": "Society of St Pius X",
      "score": 0.9712020754814148
    }
  ],
  "6152": [
    {
      "answer": "Anglican",
      "score": 0.9584104418754578
    },
    {
      "answer": "Presbyterian",
      "score": 0.8393132090568542
    }
  ],
  "6153": [
    {
      "answer": "three",
      "score": 0.8672724962234497
    }
  ],
  "6154": [
    {
      "answer": "7.5%",
      "score": 0.9849177598953247
    }
  ],
  "6155": [
    {
      "answer": "32%",
      "score": 0.987867534160614
    }
  ],
  "6156": [
    {
      "answer": "80%",
      "score": 0.9870573282241821
    }
  ],
  "6157": [
    {
      "answer": "August 1992",
      "score": 0.9829562306404114
    }
  ],
  "6158": [
    {
      "answer": "mathematics",
      "score": 0.6911788582801819
    },
    {
      "answer": "natural science",
      "score": 0.9866088628768921
    }
  ],
  "6159": [
    {
      "answer": "7.5%",
      "score": 0.9861168265342712
    }
  ],
  "6160": [
    {
      "answer": "Per unit costs",
      "score": 0.9728729724884033
    }
  ],
  "6161": [
    {
      "answer": "lifting the moratorium on applications for new courses, new schools and conversions",
      "score": 0.9546350836753845
    },
    {
      "answer": "liberalizing tuition fee policy for private schools",
      "score": 0.943764865398407
    },
    {
      "answer": "replacing values education for third and fourth years with English, mathematics and natural science at the option of the school",
      "score": 0.9161496758460999
    },
    {
      "answer": "issuing the revised Manual of Regulations for Private Schools in August 1992",
      "score": 0.8110162019729614
    }
  ],
  "6162": [
    {
      "answer": "August 1992",
      "score": 0.9919277429580688
    }
  ],
  "6163": [
    {
      "answer": "Education Service Contracting scheme",
      "score": 0.8741436004638672
    }
  ],
  "6164": [
    {
      "answer": "Tuition Fee Supplement",
      "score": 0.9897317290306091
    }
  ],
  "6165": [
    {
      "answer": "Private Education Student Financial Assistance",
      "score": 0.9894891977310181
    }
  ],
  "6166": [
    {
      "answer": "enrollment overflows",
      "score": 0.9767972230911255
    }
  ],
  "6167": [
    {
      "answer": "students enrolled in priority courses in post-secondary and non-degree programmes, including vocational and technical courses",
      "score": 0.9231444597244263
    }
  ],
  "6168": [
    {
      "answer": "pursue college/technical education in private colleges and universities",
      "score": 0.9135273098945618
    }
  ],
  "6169": [
    {
      "answer": "Education Service Contracting scheme",
      "score": 0.9770485162734985
    }
  ],
  "6170": [
    {
      "answer": "financial assistance",
      "score": 0.9396793842315674
    }
  ],
  "6171": [
    {
      "answer": "South African Schools Act of 1996",
      "score": 0.9931878447532654
    }
  ],
  "6172": [
    {
      "answer": "1996",
      "score": 0.9948295950889587
    }
  ],
  "6173": [
    {
      "answer": "independent",
      "score": 0.9927767515182495
    }
  ],
  "6174": [
    {
      "answer": "traditional private schools",
      "score": 0.9599565267562866
    }
  ],
  "6175": [
    {
      "answer": "nineteenth",
      "score": 0.9920710921287537
    }
  ],
  "6176": [
    {
      "answer": "nineteenth",
      "score": 0.9811179041862488
    }
  ],
  "6177": [
    {
      "answer": "South African Schools Act of 1996",
      "score": 0.9525458216667175
    }
  ],
  "6178": [
    {
      "answer": "After the abolition of apartheid",
      "score": 0.7404298782348633
    }
  ],
  "6179": [
    {
      "answer": "nineteenth",
      "score": 0.9887856245040894
    }
  ],
  "6180": [],
  "6181": [
    {
      "answer": "government schools formerly reserved for white children",
      "score": 0.9540521502494812
    }
  ],
  "6182": [
    {
      "answer": "better academic results than government schools formerly reserved for other race groups",
      "score": 0.9539715051651001
    }
  ],
  "6183": [
    {
      "answer": "much higher school fees than other public schools",
      "score": 0.895392894744873
    }
  ],
  "6184": [
    {
      "answer": "Model C",
      "score": 0.9777933955192566
    },
    {
      "answer": "Model C",
      "score": 0.6245635747909546
    },
    {
      "answer": "Model C",
      "score": 0.5650954842567444
    },
    {
      "answer": "model C",
      "score": 0.6502187848091125
    }
  ],
  "6185": [
    {
      "answer": "Model C",
      "score": 0.661024808883667
    },
    {
      "answer": "Model C",
      "score": 0.9574825763702393
    },
    {
      "answer": "Model C",
      "score": 0.673454761505127
    },
    {
      "answer": "model C",
      "score": 0.6646279096603394
    }
  ],
  "6186": [
    {
      "answer": "Model C",
      "score": 0.9274652004241943
    },
    {
      "answer": "Model C",
      "score": 0.7794654369354248
    },
    {
      "answer": "Model C",
      "score": 0.7855783700942993
    },
    {
      "answer": "model C",
      "score": 0.7667415142059326
    }
  ],
  "6187": [
    {
      "answer": "better",
      "score": 0.9630477428436279
    }
  ],
  "6188": [
    {
      "answer": "compulsory school fees",
      "score": 0.7472726702690125
    }
  ],
  "6189": [
    {
      "answer": "10%",
      "score": 0.984906792640686
    }
  ],
  "6190": [
    {
      "answer": "10,000",
      "score": 0.9755867719650269
    }
  ],
  "6191": [
    {
      "answer": "700",
      "score": 0.9950181245803833
    }
  ],
  "6192": [
    {
      "answer": "The Knowledge School",
      "score": 0.9833709597587585
    }
  ],
  "6193": [
    {
      "answer": "school voucher",
      "score": 0.9873937368392944
    }
  ],
  "6194": [
    {
      "answer": "Over 10%",
      "score": 0.9216301441192627
    }
  ],
  "6195": [],
  "6196": [
    {
      "answer": "The Knowledge School",
      "score": 0.8769000768661499
    }
  ],
  "6197": [
    {
      "answer": "school voucher model",
      "score": 0.9004173278808594
    }
  ],
  "6198": [
    {
      "answer": "30",
      "score": 0.8278771638870239
    }
  ],
  "6199": [
    {
      "answer": "13",
      "score": 0.9928681254386902
    }
  ],
  "6200": [
    {
      "answer": "public schools",
      "score": 0.760146975517273
    },
    {
      "answer": "public schools",
      "score": 0.9610636234283447
    }
  ],
  "6201": [
    {
      "answer": "9",
      "score": 0.9914666414260864
    }
  ],
  "6202": [
    {
      "answer": "13 per cent",
      "score": 0.9639129638671875
    }
  ],
  "6203": [
    {
      "answer": "\u00a321,000",
      "score": 0.8932058811187744
    }
  ],
  "6204": [
    {
      "answer": "pupils aged up to 13 years old",
      "score": 0.9735866785049438
    }
  ],
  "6205": [
    {
      "answer": "9",
      "score": 0.9647900462150574
    }
  ],
  "6206": [
    {
      "answer": "A-level",
      "score": 0.9877013564109802
    }
  ],
  "6207": [
    {
      "answer": "independent schools",
      "score": 0.6029236912727356
    },
    {
      "answer": "independent schools",
      "score": 0.8938759565353394
    }
  ],
  "6208": [
    {
      "answer": "\u00a327,000",
      "score": 0.9731830954551697
    }
  ],
  "6209": [
    {
      "answer": "Brown v. Board of Education of Topeka",
      "score": 0.9918676018714905
    }
  ],
  "6210": [
    {
      "answer": "segregation academies",
      "score": 0.8577311038970947
    }
  ],
  "6211": [
    {
      "answer": "South",
      "score": 0.9834609031677246
    }
  ],
  "6212": [
    {
      "answer": "white",
      "score": 0.9919973015785217
    }
  ],
  "6213": [
    {
      "answer": "African-American",
      "score": 0.9910405278205872
    }
  ],
  "6214": [
    {
      "answer": "Brown v. Board of Education of Topeka",
      "score": 0.9713903665542603
    }
  ],
  "6215": [
    {
      "answer": "with all deliberate speed",
      "score": 0.9424517154693604
    }
  ],
  "6216": [
    {
      "answer": "private \"Christian academies",
      "score": 0.961810827255249
    }
  ],
  "6217": [
    {
      "answer": "College Preparatory",
      "score": 0.9804437756538391
    }
  ],
  "6218": [
    {
      "answer": "African-American",
      "score": 0.985852837562561
    }
  ],
  "6219": [
    {
      "answer": "religious organizations or private individuals",
      "score": 0.9644953012466431
    }
  ],
  "6220": [
    {
      "answer": "Establishment Clause",
      "score": 0.9487947225570679
    }
  ],
  "6221": [
    {
      "answer": "Establishment Clause of the First Amendment",
      "score": 0.7583639025688171
    },
    {
      "answer": "Blaine Amendments",
      "score": 0.9063339829444885
    }
  ],
  "6222": [
    {
      "answer": "charter",
      "score": 0.992544949054718
    }
  ],
  "6223": [
    {
      "answer": "courts",
      "score": 0.8343484997749329
    }
  ],
  "6224": [],
  "6225": [
    {
      "answer": "Government funding for religious schools is either subject to restrictions or possibly forbidden, according to the courts' interpretation of the Establishment Clause of the First Amendment or individual state Blaine Amendments",
      "score": 0.8595739006996155
    }
  ],
  "6226": [
    {
      "answer": "Establishment Clause of the First Amendment",
      "score": 0.9764103889465332
    }
  ],
  "6227": [
    {
      "answer": "student tuition, endowments, scholarship/voucher funds, and donations and grants from religious organizations or private individuals",
      "score": 0.7034510970115662
    }
  ],
  "6228": [
    {
      "answer": "Massachusetts",
      "score": 0.9955253005027771
    }
  ],
  "6229": [
    {
      "answer": "1852",
      "score": 0.9950454235076904
    }
  ],
  "6230": [
    {
      "answer": "1972",
      "score": 0.9902718663215637
    }
  ],
  "6231": [
    {
      "answer": "268 U.S. 510 (1925)",
      "score": 0.9537586569786072
    }
  ],
  "6232": [
    {
      "answer": "McCrary",
      "score": 0.9883118271827698
    }
  ],
  "6233": [
    {
      "answer": "education",
      "score": 0.9783827662467957
    }
  ],
  "6234": [
    {
      "answer": "Massachusetts",
      "score": 0.9956061244010925
    }
  ],
  "6235": [
    {
      "answer": "states may set standards for educational accomplishment",
      "score": 0.9941381216049194
    }
  ],
  "6236": [
    {
      "answer": "Runyon v. McCrary",
      "score": 0.8692600727081299
    }
  ],
  "6237": [
    {
      "answer": "McCrary",
      "score": 0.9846041798591614
    }
  ],
  "6238": [
    {
      "answer": "$40,000",
      "score": 0.9835160970687866
    }
  ],
  "6239": [
    {
      "answer": "$40,000",
      "score": 0.5740205645561218
    },
    {
      "answer": "$50,000",
      "score": 0.9801763296127319
    }
  ],
  "6240": [
    {
      "answer": "Groton School",
      "score": 0.9696165323257446
    }
  ],
  "6241": [
    {
      "answer": "fundraising drives",
      "score": 0.9879679679870605
    }
  ],
  "6242": [
    {
      "answer": "$40,000",
      "score": 0.9251316785812378
    },
    {
      "answer": "$50,000",
      "score": 0.8566250801086426
    }
  ],
  "6243": [
    {
      "answer": "throughout the country",
      "score": 0.6801028251647949
    },
    {
      "answer": "the globe",
      "score": 0.6293705701828003
    }
  ],
  "6244": [
    {
      "answer": "far exceeds their capacity",
      "score": 0.6582404375076294
    }
  ],
  "6245": [
    {
      "answer": "New York City",
      "score": 0.9914618730545044
    }
  ],
  "6246": [],
  "6247": [
    {
      "answer": "John Harvard",
      "score": 0.9926770925521851
    }
  ],
  "6248": [
    {
      "answer": "1977",
      "score": 0.9891345500946045
    }
  ],
  "6249": [
    {
      "answer": "James Bryant Conant",
      "score": 0.9801234006881714
    }
  ],
  "6250": [
    {
      "answer": "Association of American Universities",
      "score": 0.9808943271636963
    }
  ],
  "6251": [
    {
      "answer": "Charles W. Eliot",
      "score": 0.9940420985221863
    }
  ],
  "6252": [
    {
      "answer": "coeducational",
      "score": 0.9700625538825989
    }
  ],
  "6253": [
    {
      "answer": "Congregationalist and Unitarian clergy",
      "score": 0.7804744243621826
    }
  ],
  "6254": [
    {
      "answer": "18th century",
      "score": 0.9757814407348633
    }
  ],
  "6255": [
    {
      "answer": "central cultural establishment among Boston elites",
      "score": 0.817685604095459
    },
    {
      "answer": "modern research university",
      "score": 0.6794109344482422
    }
  ],
  "6256": [
    {
      "answer": "Charles W. Eliot",
      "score": 0.9919841885566711
    }
  ],
  "6257": [
    {
      "answer": "Harvard Library",
      "score": 0.991445779800415
    }
  ],
  "6258": [
    {
      "answer": "79",
      "score": 0.9935958981513977
    }
  ],
  "6259": [
    {
      "answer": "18 million",
      "score": 0.9592561721801758
    }
  ],
  "6260": [
    {
      "answer": "eight",
      "score": 0.9865818023681641
    }
  ],
  "6261": [
    {
      "answer": "150",
      "score": 0.9920551180839539
    }
  ],
  "6262": [],
  "6263": [
    {
      "answer": "Harvard Library",
      "score": 0.7021224498748779
    }
  ],
  "6264": [
    {
      "answer": "79",
      "score": 0.8672446608543396
    }
  ],
  "6265": [
    {
      "answer": "eight",
      "score": 0.9874897599220276
    }
  ],
  "6266": [
    {
      "answer": "62",
      "score": 0.9926669001579285
    }
  ],
  "6267": [
    {
      "answer": "Boston",
      "score": 0.8687904477119446
    },
    {
      "answer": "Boston",
      "score": 0.7145723700523376
    },
    {
      "answer": "Boston",
      "score": 0.6772300601005554
    }
  ],
  "6268": [
    {
      "answer": "$37.6 billion",
      "score": 0.9806675314903259
    }
  ],
  "6269": [
    {
      "answer": "Charles",
      "score": 0.9910224676132202
    }
  ],
  "6270": [
    {
      "answer": "eleven",
      "score": 0.9928834438323975
    }
  ],
  "6271": [
    {
      "answer": "Harvard Yard",
      "score": 0.8755735158920288
    }
  ],
  "6272": [],
  "6273": [
    {
      "answer": "eleven",
      "score": 0.990805447101593
    }
  ],
  "6274": [],
  "6275": [
    {
      "answer": "Boston",
      "score": 0.7498992085456848
    },
    {
      "answer": "Boston",
      "score": 0.6029999256134033
    }
  ],
  "6276": [
    {
      "answer": "eleven",
      "score": 0.7446192502975464
    }
  ],
  "6277": [
    {
      "answer": "1636",
      "score": 0.9879289269447327
    }
  ],
  "6278": [
    {
      "answer": "Great and General Court of the Massachusetts Bay Colony",
      "score": 0.9867583513259888
    }
  ],
  "6279": [
    {
      "answer": "1638",
      "score": 0.988909900188446
    }
  ],
  "6280": [
    {
      "answer": "1639",
      "score": 0.9910488128662109
    }
  ],
  "6281": [
    {
      "answer": "1650",
      "score": 0.9886393547058105
    }
  ],
  "6282": [
    {
      "answer": "John of London",
      "score": 0.9874724745750427
    }
  ],
  "6283": [
    {
      "answer": "charter creating the Harvard Corporation",
      "score": 0.9156586527824402
    }
  ],
  "6284": [
    {
      "answer": "John Harvard",
      "score": 0.9371621012687683
    }
  ],
  "6285": [
    {
      "answer": "1638",
      "score": 0.9877062439918518
    }
  ],
  "6286": [
    {
      "answer": "University of Cambridge",
      "score": 0.9881808161735535
    }
  ],
  "6287": [
    {
      "answer": "Puritan",
      "score": 0.9934773445129395
    }
  ],
  "6288": [
    {
      "answer": "English",
      "score": 0.9955856800079346
    }
  ],
  "6289": [
    {
      "answer": "It was never affiliated with any particular denomination",
      "score": 0.9503177404403687
    }
  ],
  "6290": [
    {
      "answer": "Puritan ministers",
      "score": 0.9741348028182983
    }
  ],
  "6291": [
    {
      "answer": "1643",
      "score": 0.9945412278175354
    }
  ],
  "6292": [
    {
      "answer": "to advance learning and perpetuate it to posterity",
      "score": 0.9835373759269714
    }
  ],
  "6293": [
    {
      "answer": "clergymen",
      "score": 0.9740650057792664
    }
  ],
  "6294": [
    {
      "answer": "Congregational",
      "score": 0.9815452694892883
    },
    {
      "answer": "Unitarian",
      "score": 0.9771689176559448
    }
  ],
  "6295": [
    {
      "answer": "1804",
      "score": 0.9910619258880615
    }
  ],
  "6296": [
    {
      "answer": "Samuel Webber",
      "score": 0.9959681034088135
    }
  ],
  "6297": [
    {
      "answer": "1805",
      "score": 0.9871312975883484
    }
  ],
  "6298": [
    {
      "answer": "1805",
      "score": 0.9775575399398804
    }
  ],
  "6299": [
    {
      "answer": "Henry Ware was elected to the chair in 1805, and the liberal Samuel Webber was appointed to the presidency of Harvard two years later",
      "score": 0.8613364100456238
    }
  ],
  "6300": [
    {
      "answer": "1803",
      "score": 0.9911903142929077
    }
  ],
  "6301": [
    {
      "answer": "1803",
      "score": 0.6170945167541504
    }
  ],
  "6302": [
    {
      "answer": "Congregationalist",
      "score": 0.9943746328353882
    }
  ],
  "6303": [
    {
      "answer": "Louis Agassiz",
      "score": 0.9940813779830933
    }
  ],
  "6304": [
    {
      "answer": "intuition",
      "score": 0.9922136664390564
    }
  ],
  "6305": [
    {
      "answer": "Thomas Reid",
      "score": 0.9932677745819092
    },
    {
      "answer": "Dugald Stewart",
      "score": 0.9915626049041748
    }
  ],
  "6306": [
    {
      "answer": "New York",
      "score": 0.9797924757003784
    },
    {
      "answer": "Harvard College",
      "score": 0.8081153631210327
    }
  ],
  "6307": [
    {
      "answer": "the writings of Plato and his early modern and Romantic followers were almost as regularly read during the 19th century as those of the \"official philosophy\" of the more empirical and more deistic Scottish school.",
      "score": 0.8470613360404968
    }
  ],
  "6308": [
    {
      "answer": "observation with intuition",
      "score": 0.9647067785263062
    }
  ],
  "6309": [
    {
      "answer": "a person can grasp the \"divine plan\" in all phenomena",
      "score": 0.8144439458847046
    }
  ],
  "6310": [
    {
      "answer": "matters of shape based on a presumed archetype",
      "score": 0.8378807306289673
    }
  ],
  "6311": [
    {
      "answer": "Charles W. Eliot",
      "score": 0.9924267530441284
    }
  ],
  "6312": [
    {
      "answer": "dignity and worth of human nature",
      "score": 0.9779361486434937
    },
    {
      "answer": "right and ability of each person to perceive truth",
      "score": 0.9379414319992065
    }
  ],
  "6313": [
    {
      "answer": "William Ellery Channing",
      "score": 0.9863535761833191
    },
    {
      "answer": "Ralph Waldo Emerson",
      "score": 0.9725197553634644
    }
  ],
  "6314": [
    {
      "answer": "1869",
      "score": 0.6735891103744507
    }
  ],
  "6315": [
    {
      "answer": "student self-direction",
      "score": 0.9684818983078003
    }
  ],
  "6316": [
    {
      "answer": "secularization",
      "score": 0.9901358485221863
    }
  ],
  "6317": [
    {
      "answer": "dignity and worth of human nature",
      "score": 0.9915051460266113
    },
    {
      "answer": "right and ability of each person to perceive truth",
      "score": 0.9884201884269714
    },
    {
      "answer": "indwelling God in each person",
      "score": 0.9752303957939148
    }
  ],
  "6318": [
    {
      "answer": "the dignity and worth of human nature",
      "score": 0.9666817784309387
    },
    {
      "answer": "the right and ability of each person to perceive truth",
      "score": 0.9721305966377258
    },
    {
      "answer": "the indwelling God in each person",
      "score": 0.9453061819076538
    }
  ],
  "6319": [
    {
      "answer": "James Bryant Conant",
      "score": 0.9976021647453308
    }
  ],
  "6320": [
    {
      "answer": "devised programs to identify, recruit, and support talented youth",
      "score": 0.9022105932235718
    }
  ],
  "6321": [
    {
      "answer": "1945",
      "score": 0.9878145456314087
    }
  ],
  "6322": [
    {
      "answer": "James Bryant Conant",
      "score": 0.9904986619949341
    }
  ],
  "6323": [
    {
      "answer": "preeminence",
      "score": 0.7449379563331604
    }
  ],
  "6324": [
    {
      "answer": "opportunity",
      "score": 0.9699862599372864
    }
  ],
  "6325": [
    {
      "answer": "programs",
      "score": 0.9702994227409363
    }
  ],
  "6326": [],
  "6327": [
    {
      "answer": "about four men attending Harvard College for every woman studying at Radcliffe",
      "score": 0.9111040830612183
    }
  ],
  "6328": [
    {
      "answer": "1977",
      "score": 0.9857593774795532
    }
  ],
  "6329": [],
  "6330": [
    {
      "answer": "post-World War II",
      "score": 0.8940522074699402
    }
  ],
  "6331": [
    {
      "answer": "Harvard",
      "score": 0.6275177001953125
    }
  ],
  "6332": [
    {
      "answer": "became more diverse",
      "score": 0.9241461753845215
    }
  ],
  "6333": [
    {
      "answer": "1977",
      "score": 0.9197954535484314
    }
  ],
  "6334": [],
  "6335": [
    {
      "answer": "3 miles",
      "score": 0.9847604036331177
    }
  ],
  "6336": [
    {
      "answer": "twelve",
      "score": 0.9920542240142822
    }
  ],
  "6337": [
    {
      "answer": "Charles River",
      "score": 0.9293863773345947
    }
  ],
  "6338": [
    {
      "answer": "half a mile",
      "score": 0.9886792898178101
    }
  ],
  "6339": [],
  "6340": [
    {
      "answer": "Harvard Square",
      "score": 0.7823984622955322
    },
    {
      "answer": "Quadrangle",
      "score": 0.6578263640403748
    }
  ],
  "6341": [
    {
      "answer": "Radcliffe College students",
      "score": 0.9826343059539795
    }
  ],
  "6342": [
    {
      "answer": "Radcliffe merged its residential system with Harvard",
      "score": 0.9897627830505371
    }
  ],
  "6343": [],
  "6344": [
    {
      "answer": "Allston",
      "score": 0.9418287873268127
    }
  ],
  "6345": [
    {
      "answer": "John W. Weeks Bridge",
      "score": 0.9438567161560059
    }
  ],
  "6346": [
    {
      "answer": "Longwood Medical and Academic Area",
      "score": 0.7518962025642395
    }
  ],
  "6347": [
    {
      "answer": "John W. Weeks Bridge",
      "score": 0.9443349838256836
    }
  ],
  "6348": [
    {
      "answer": "358-acre",
      "score": 0.8515884876251221
    }
  ],
  "6349": [
    {
      "answer": "3.3 miles",
      "score": 0.9319357872009277
    },
    {
      "answer": "3.3 miles",
      "score": 0.9250744581222534
    }
  ],
  "6350": [],
  "6351": [
    {
      "answer": "Harvard Medical School",
      "score": 0.635456383228302
    },
    {
      "answer": "Harvard School of Dental Medicine",
      "score": 0.650473415851593
    }
  ],
  "6352": [
    {
      "answer": "fifty percent",
      "score": 0.9918478727340698
    }
  ],
  "6353": [
    {
      "answer": "new and enlarged bridges",
      "score": 0.9658505916595459
    },
    {
      "answer": "a shuttle service",
      "score": 0.9430923461914062
    },
    {
      "answer": "a tram",
      "score": 0.9343959093093872
    }
  ],
  "6354": [
    {
      "answer": "enhanced transit infrastructure",
      "score": 0.9863349199295044
    },
    {
      "answer": "possible shuttles open to the public",
      "score": 0.9336475133895874
    },
    {
      "answer": "park space which will also be publicly accessible",
      "score": 0.843950629234314
    }
  ],
  "6355": [
    {
      "answer": "tracts of land",
      "score": 0.8177464008331299
    }
  ],
  "6356": [
    {
      "answer": "with the intent of major expansion southward",
      "score": 0.8024581670761108
    }
  ],
  "6357": [
    {
      "answer": "fifty percent",
      "score": 0.9163480401039124
    }
  ],
  "6358": [
    {
      "answer": "surrounding community",
      "score": 0.9791556596755981
    }
  ],
  "6359": [
    {
      "answer": "park land and pedestrian access to the Charles River",
      "score": 0.9109766483306885
    }
  ],
  "6360": [
    {
      "answer": "2,400",
      "score": 0.98956298828125
    }
  ],
  "6361": [
    {
      "answer": "7,200",
      "score": 0.9885307550430298
    }
  ],
  "6362": [
    {
      "answer": "14,000",
      "score": 0.9932481050491333
    }
  ],
  "6363": [
    {
      "answer": "1875",
      "score": 0.985745906829834
    }
  ],
  "6364": [
    {
      "answer": "1858",
      "score": 0.9938347339630127
    }
  ],
  "6365": [
    {
      "answer": "1875",
      "score": 0.8171687126159668
    },
    {
      "answer": "1858",
      "score": 0.5496241450309753
    }
  ],
  "6366": [],
  "6367": [],
  "6368": [
    {
      "answer": "7,200",
      "score": 0.9622399210929871
    },
    {
      "answer": "14,000",
      "score": 0.6883143186569214
    }
  ],
  "6369": [],
  "6370": [
    {
      "answer": "$32 billion",
      "score": 0.9340968132019043
    }
  ],
  "6371": [
    {
      "answer": "about 30%",
      "score": 0.7723469734191895
    }
  ],
  "6372": [
    {
      "answer": "Allston Science Complex",
      "score": 0.9255165457725525
    }
  ],
  "6373": [
    {
      "answer": "$4.093 million",
      "score": 0.969713032245636
    }
  ],
  "6374": [
    {
      "answer": "$159 million",
      "score": 0.974580705165863
    }
  ],
  "6375": [
    {
      "answer": "$159 million",
      "score": 0.9297440052032471
    }
  ],
  "6376": [
    {
      "answer": "$26 billion",
      "score": 0.731046199798584
    },
    {
      "answer": "$12 billion",
      "score": 0.8060471415519714
    }
  ],
  "6377": [
    {
      "answer": "$12 billion",
      "score": 0.9048764705657959
    }
  ],
  "6378": [
    {
      "answer": "Allston Science Complex",
      "score": 0.9526759386062622
    }
  ],
  "6379": [
    {
      "answer": "protests",
      "score": 0.909842848777771
    }
  ],
  "6380": [
    {
      "answer": "late 1980s",
      "score": 0.9757378697395325
    }
  ],
  "6381": [
    {
      "answer": "Duke Kent-Brown",
      "score": 0.9943124651908875
    }
  ],
  "6382": [
    {
      "answer": "$230 million",
      "score": 0.9703820943832397
    }
  ],
  "6383": [
    {
      "answer": "1980s",
      "score": 0.979590892791748
    }
  ],
  "6384": [
    {
      "answer": "shantytown",
      "score": 0.9777562618255615
    }
  ],
  "6385": [
    {
      "answer": "blockaded",
      "score": 0.9800958633422852
    }
  ],
  "6386": [
    {
      "answer": "$230 million",
      "score": 0.9365927577018738
    }
  ],
  "6387": [
    {
      "answer": "$230 million",
      "score": 0.9555343389511108
    }
  ],
  "6388": [
    {
      "answer": "5.3%",
      "score": 0.9942296743392944
    }
  ],
  "6389": [
    {
      "answer": "2007",
      "score": 0.9920349717140198
    }
  ],
  "6390": [
    {
      "answer": "to disadvantage low-income and under-represented minority applicants applying to selective universities",
      "score": 0.9905011653900146
    }
  ],
  "6391": [
    {
      "answer": "2016",
      "score": 0.9882001876831055
    }
  ],
  "6392": [
    {
      "answer": "more selective, lower transfer-in",
      "score": 0.8330634236335754
    }
  ],
  "6393": [
    {
      "answer": "5.3%",
      "score": 0.9918652772903442
    }
  ],
  "6394": [
    {
      "answer": "second lowest",
      "score": 0.9241892099380493
    }
  ],
  "6395": [
    {
      "answer": "2007",
      "score": 0.5835374593734741
    }
  ],
  "6396": [
    {
      "answer": "low-income and under-represented minority applicants",
      "score": 0.9290410876274109
    }
  ],
  "6397": [
    {
      "answer": "seven",
      "score": 0.9921064376831055
    }
  ],
  "6398": [
    {
      "answer": "eight",
      "score": 0.8059919476509094
    }
  ],
  "6399": [
    {
      "answer": "reliance on teaching fellows",
      "score": 0.9835972785949707
    }
  ],
  "6400": [
    {
      "answer": "seven",
      "score": 0.9523707032203674
    }
  ],
  "6401": [],
  "6402": [
    {
      "answer": "arts and sciences",
      "score": 0.9726573824882507
    }
  ],
  "6403": [
    {
      "answer": "eight",
      "score": 0.9274164438247681
    }
  ],
  "6404": [
    {
      "answer": "teaching fellows",
      "score": 0.9933282136917114
    }
  ],
  "6405": [
    {
      "answer": "beginning in early September",
      "score": 0.974294900894165
    }
  ],
  "6406": [
    {
      "answer": "four",
      "score": 0.6387284994125366
    },
    {
      "answer": "four-course",
      "score": 0.9588442444801331
    }
  ],
  "6407": [],
  "6408": [
    {
      "answer": "60%",
      "score": 0.9864870309829712
    }
  ],
  "6409": [
    {
      "answer": "senior thesis",
      "score": 0.9690873622894287
    }
  ],
  "6410": [],
  "6411": [],
  "6412": [
    {
      "answer": "quality of the student body and its motivation",
      "score": 0.8649674654006958
    }
  ],
  "6413": [
    {
      "answer": "John Harvard Scholar",
      "score": 0.9569025039672852
    },
    {
      "answer": "Harvard College Scholar",
      "score": 0.9369685053825378
    }
  ],
  "6414": [
    {
      "answer": "$38,000",
      "score": 0.9918986558914185
    }
  ],
  "6415": [
    {
      "answer": "$57,000",
      "score": 0.9876499772071838
    }
  ],
  "6416": [
    {
      "answer": "nothing",
      "score": 0.9464762806892395
    }
  ],
  "6417": [
    {
      "answer": "$414 million",
      "score": 0.9806351661682129
    }
  ],
  "6418": [
    {
      "answer": "88%",
      "score": 0.9749521613121033
    }
  ],
  "6419": [
    {
      "answer": "$38,000",
      "score": 0.9896503686904907
    }
  ],
  "6420": [
    {
      "answer": "room and board",
      "score": 0.9284273982048035
    }
  ],
  "6421": [
    {
      "answer": "$57,000",
      "score": 0.9826339483261108
    }
  ],
  "6422": [],
  "6423": [
    {
      "answer": "eleven",
      "score": 0.9378763437271118
    }
  ],
  "6424": [
    {
      "answer": "Widener Library",
      "score": 0.9396541118621826
    },
    {
      "answer": "Widener Library",
      "score": 0.6622154712677002
    }
  ],
  "6425": [
    {
      "answer": "18 million",
      "score": 0.9292296767234802
    }
  ],
  "6426": [
    {
      "answer": "Cabot Science Library",
      "score": 0.9395999312400818
    },
    {
      "answer": "Lamont Library",
      "score": 0.9587676525115967
    },
    {
      "answer": "Widener Library",
      "score": 0.9186930060386658
    }
  ],
  "6427": [
    {
      "answer": "Pusey Library",
      "score": 0.9755002856254578
    }
  ],
  "6428": [],
  "6429": [
    {
      "answer": "18 million",
      "score": 0.9100216627120972
    }
  ],
  "6430": [],
  "6431": [
    {
      "answer": "rare and unique materials",
      "score": 0.9420471787452698
    }
  ],
  "6432": [
    {
      "answer": "easy access and central locations",
      "score": 0.6192578673362732
    }
  ],
  "6433": [
    {
      "answer": "three",
      "score": 0.9932007193565369
    }
  ],
  "6434": [
    {
      "answer": "Western art from the Middle Ages to the present",
      "score": 0.9680455327033997
    }
  ],
  "6435": [
    {
      "answer": "Peabody Museum of Archaeology and Ethnology",
      "score": 0.9909500479698181
    }
  ],
  "6436": [
    {
      "answer": "Germanic Museum",
      "score": 0.930856466293335
    }
  ],
  "6437": [
    {
      "answer": "three",
      "score": 0.9748581051826477
    }
  ],
  "6438": [
    {
      "answer": "Le Corbusier",
      "score": 0.6512645483016968
    }
  ],
  "6439": [
    {
      "answer": "ancient, Asian, Islamic and later Indian art",
      "score": 0.9142731428146362
    }
  ],
  "6440": [
    {
      "answer": "Blaschka",
      "score": 0.9906387329101562
    }
  ],
  "6441": [
    {
      "answer": "2003",
      "score": 0.9829733371734619
    }
  ],
  "6442": [
    {
      "answer": "2011",
      "score": 0.9838437438011169
    },
    {
      "answer": "2011",
      "score": 0.8841405510902405
    }
  ],
  "6443": [],
  "6444": [
    {
      "answer": "2003",
      "score": 0.9852641820907593
    }
  ],
  "6445": [
    {
      "answer": "2009",
      "score": 0.7168503403663635
    }
  ],
  "6446": [
    {
      "answer": "U.S. News & World Report",
      "score": 0.5991076827049255
    }
  ],
  "6447": [
    {
      "answer": "second most commonly named \"dream college\"",
      "score": 0.8665778040885925
    }
  ],
  "6448": [
    {
      "answer": "1st",
      "score": 0.9847257733345032
    }
  ],
  "6449": [
    {
      "answer": "42",
      "score": 0.9948987364768982
    }
  ],
  "6450": [
    {
      "answer": "Yale University",
      "score": 0.9798094630241394
    }
  ],
  "6451": [
    {
      "answer": "every two years",
      "score": 0.9770717024803162
    }
  ],
  "6452": [
    {
      "answer": "42",
      "score": 0.941403865814209
    }
  ],
  "6453": [],
  "6454": [
    {
      "answer": "The Game",
      "score": 0.9739083051681519
    }
  ],
  "6455": [
    {
      "answer": "every two years",
      "score": 0.9945927858352661
    }
  ],
  "6456": [
    {
      "answer": "oldest continuous international amateur competition in the world",
      "score": 0.7844406366348267
    }
  ],
  "6457": [
    {
      "answer": "1875",
      "score": 0.9647003412246704
    }
  ],
  "6458": [
    {
      "answer": "1903",
      "score": 0.9843562245368958
    }
  ],
  "6459": [
    {
      "answer": "1906",
      "score": 0.9843950271606445
    }
  ],
  "6460": [
    {
      "answer": "Yale",
      "score": 0.7395102381706238
    },
    {
      "answer": "Yale",
      "score": 0.7034887671470642
    },
    {
      "answer": "Yale",
      "score": 0.9718016982078552
    }
  ],
  "6461": [
    {
      "answer": "Rose Bowl",
      "score": 0.9374215602874756
    }
  ],
  "6462": [
    {
      "answer": "Harvard Stadium",
      "score": 0.9777877926826477
    }
  ],
  "6463": [
    {
      "answer": "Harvard Stadium",
      "score": 0.9487501978874207
    }
  ],
  "6464": [
    {
      "answer": "captain",
      "score": 0.953565776348114
    }
  ],
  "6465": [
    {
      "answer": "forward pass",
      "score": 0.9525399208068848
    }
  ],
  "6466": [],
  "6467": [
    {
      "answer": "Malkin Athletic Center",
      "score": 0.7716916799545288
    }
  ],
  "6468": [
    {
      "answer": "three",
      "score": 0.9859464764595032
    }
  ],
  "6469": [
    {
      "answer": "Malkin Athletic Center",
      "score": 0.9845184087753296
    }
  ],
  "6470": [],
  "6471": [
    {
      "answer": "five-story",
      "score": 0.9802565574645996
    }
  ],
  "6472": [
    {
      "answer": "two",
      "score": 0.9903984069824219
    }
  ],
  "6473": [
    {
      "answer": "Olympic-size",
      "score": 0.9898629188537598
    }
  ],
  "6474": [
    {
      "answer": "23",
      "score": 0.9942341446876526
    }
  ],
  "6475": [
    {
      "answer": "Thames River",
      "score": 0.9864345192909241
    }
  ],
  "6476": [
    {
      "answer": "Cornell",
      "score": 0.9868544340133667
    }
  ],
  "6477": [
    {
      "answer": "2003",
      "score": 0.9887690544128418
    }
  ],
  "6478": [
    {
      "answer": "Connecticut",
      "score": 0.9926251769065857
    }
  ],
  "6479": [
    {
      "answer": "Thames River",
      "score": 0.9683146476745605
    }
  ],
  "6480": [
    {
      "answer": "one of the top teams in the country",
      "score": 0.9306340217590332
    }
  ],
  "6481": [],
  "6482": [
    {
      "answer": "June",
      "score": 0.9909267425537109
    }
  ],
  "6483": [
    {
      "answer": "Ban Ki-moon",
      "score": 0.9808131456375122
    }
  ],
  "6484": [
    {
      "answer": "Juan Manuel Santos",
      "score": 0.9946906566619873
    }
  ],
  "6485": [
    {
      "answer": "Jos\u00e9 Mar\u00eda Figueres",
      "score": 0.9963153600692749
    }
  ],
  "6486": [],
  "6487": [],
  "6488": [
    {
      "answer": "Secretary General",
      "score": 0.6034932136535645
    }
  ],
  "6489": [
    {
      "answer": "President",
      "score": 0.6481017470359802
    },
    {
      "answer": "President",
      "score": 0.6728432774543762
    },
    {
      "answer": "President",
      "score": 0.6097167134284973
    },
    {
      "answer": "President",
      "score": 0.5861378312110901
    }
  ],
  "6490": [],
  "6491": [
    {
      "answer": "Greek",
      "score": 0.9686236381530762
    }
  ],
  "6492": [
    {
      "answer": "Conan O'Brien",
      "score": 0.9830633401870728
    }
  ],
  "6493": [
    {
      "answer": "Leonard Bernstein",
      "score": 0.9976848363876343
    }
  ],
  "6494": [
    {
      "answer": "Yo Yo Ma",
      "score": 0.9856476783752441
    }
  ],
  "6495": [
    {
      "answer": "W. E. B. Du Bois",
      "score": 0.9850119352340698
    }
  ],
  "6496": [
    {
      "answer": "Conan O'Brien",
      "score": 0.7782368659973145
    }
  ],
  "6497": [
    {
      "answer": "Matt Damon",
      "score": 0.9873601198196411
    }
  ],
  "6498": [
    {
      "answer": "Ryan Fitzpatrick",
      "score": 0.9700725078582764
    }
  ],
  "6499": [
    {
      "answer": "Matt Damon",
      "score": 0.9834797382354736
    }
  ],
  "6500": [
    {
      "answer": "Darren Aronofsky",
      "score": 0.900090217590332
    },
    {
      "answer": "Terrence Malick",
      "score": 0.8477185368537903
    },
    {
      "answer": "Mira Nair",
      "score": 0.7372931241989136
    }
  ],
  "6501": [
    {
      "answer": "Shing-Tung Yau",
      "score": 0.9929533004760742
    }
  ],
  "6502": [
    {
      "answer": "Alan Dershowitz",
      "score": 0.9598212242126465
    },
    {
      "answer": "Lawrence Lessig",
      "score": 0.9705678224563599
    }
  ],
  "6503": [
    {
      "answer": "Stephen Greenblatt",
      "score": 0.9937187433242798
    }
  ],
  "6504": [
    {
      "answer": "E. O. Wilson",
      "score": 0.8510937094688416
    },
    {
      "answer": "Steven Pinker",
      "score": 0.5891270637512207
    }
  ],
  "6505": [
    {
      "answer": "Elias Corey",
      "score": 0.9566805958747864
    }
  ],
  "6506": [
    {
      "answer": "Louis Menand",
      "score": 0.9809024333953857
    }
  ],
  "6507": [],
  "6508": [
    {
      "answer": "Robert Putnam",
      "score": 0.7901206612586975
    },
    {
      "answer": "Joseph Nye",
      "score": 0.9207408428192139
    }
  ],
  "6509": [
    {
      "answer": "Jacksonville",
      "score": 0.9106530547142029
    },
    {
      "answer": "Jacksonville",
      "score": 0.9061505198478699
    },
    {
      "answer": "Jacksonville",
      "score": 0.8838106393814087
    },
    {
      "answer": "Jacksonville",
      "score": 0.9285755157470703
    }
  ],
  "6510": [],
  "6511": [
    {
      "answer": "12th",
      "score": 0.9894570708274841
    }
  ],
  "6512": [
    {
      "answer": "Duval",
      "score": 0.9910673499107361
    }
  ],
  "6513": [
    {
      "answer": "1968",
      "score": 0.9928629994392395
    }
  ],
  "6514": [
    {
      "answer": "Jacksonville",
      "score": 0.5461031794548035
    },
    {
      "answer": "Jacksonville",
      "score": 0.7731971740722656
    },
    {
      "answer": "Jacksonville",
      "score": 0.7426353693008423
    },
    {
      "answer": "Jacksonville",
      "score": 0.8362967371940613
    }
  ],
  "6515": [
    {
      "answer": "Duval",
      "score": 0.951893150806427
    }
  ],
  "6516": [
    {
      "answer": "1968",
      "score": 0.9936987161636353
    }
  ],
  "6517": [
    {
      "answer": "Jacksonville",
      "score": 0.9592403769493103
    }
  ],
  "6518": [
    {
      "answer": "Jacksonville",
      "score": 0.6378663182258606
    },
    {
      "answer": "Jacksonville",
      "score": 0.7607198357582092
    },
    {
      "answer": "Jacksonville",
      "score": 0.7774394154548645
    }
  ],
  "6519": [
    {
      "answer": "St. Johns River",
      "score": 0.9802654981613159
    }
  ],
  "6520": [
    {
      "answer": "340 miles",
      "score": 0.9732876420021057
    }
  ],
  "6521": [
    {
      "answer": "Fort Caroline",
      "score": 0.9559850096702576
    }
  ],
  "6522": [
    {
      "answer": "Timucua",
      "score": 0.9952484965324402
    }
  ],
  "6523": [
    {
      "answer": "Andrew Jackson",
      "score": 0.9925535917282104
    }
  ],
  "6524": [
    {
      "answer": "Miami",
      "score": 0.921127200126648
    }
  ],
  "6525": [
    {
      "answer": "1564",
      "score": 0.9944381713867188
    }
  ],
  "6526": [
    {
      "answer": "French colony of Fort Caroline",
      "score": 0.8751047253608704
    }
  ],
  "6527": [
    {
      "answer": "settlement",
      "score": 0.8630905151367188
    }
  ],
  "6528": [
    {
      "answer": "third largest",
      "score": 0.9589260816574097
    }
  ],
  "6529": [
    {
      "answer": "golf",
      "score": 0.9951997995376587
    }
  ],
  "6530": [
    {
      "answer": "two",
      "score": 0.9598474502563477
    },
    {
      "answer": "two",
      "score": 0.9290687441825867
    }
  ],
  "6531": [
    {
      "answer": "Jacksonvillians",
      "score": 0.7109235525131226
    },
    {
      "answer": "Jaxsons",
      "score": 0.9472326636314392
    }
  ],
  "6532": [
    {
      "answer": "Harbor improvements",
      "score": 0.9803808927536011
    }
  ],
  "6533": [
    {
      "answer": "two",
      "score": 0.8779470920562744
    },
    {
      "answer": "two",
      "score": 0.8761807680130005
    }
  ],
  "6534": [
    {
      "answer": "Jacksonvillians",
      "score": 0.7247971296310425
    },
    {
      "answer": "Jaxsons",
      "score": 0.9579728245735168
    }
  ],
  "6535": [
    {
      "answer": "Port of Jacksonville",
      "score": 0.9918279647827148
    }
  ],
  "6536": [
    {
      "answer": "banking, insurance, healthcare and logistics",
      "score": 0.8852388858795166
    }
  ],
  "6537": [
    {
      "answer": "thousands of years",
      "score": 0.9605090022087097
    }
  ],
  "6538": [
    {
      "answer": "University of North Florida",
      "score": 0.9888759851455688
    }
  ],
  "6539": [
    {
      "answer": "Mocama",
      "score": 0.9536945819854736
    },
    {
      "answer": "Mocama",
      "score": 0.8055433630943298
    }
  ],
  "6540": [
    {
      "answer": "historical era",
      "score": 0.9927295446395874
    }
  ],
  "6541": [
    {
      "answer": "Ossachite",
      "score": 0.9293820261955261
    }
  ],
  "6542": [],
  "6543": [
    {
      "answer": "some of the oldest remnants of pottery in the United States",
      "score": 0.8020154237747192
    }
  ],
  "6544": [
    {
      "answer": "some of the oldest remnants of pottery",
      "score": 0.964926540851593
    }
  ],
  "6545": [
    {
      "answer": "the region",
      "score": 0.5652950406074524
    }
  ],
  "6546": [
    {
      "answer": "Ossachite",
      "score": 0.9527811408042908
    }
  ],
  "6547": [
    {
      "answer": "Jean Ribault",
      "score": 0.9953035116195679
    }
  ],
  "6548": [
    {
      "answer": "France",
      "score": 0.9741252064704895
    }
  ],
  "6549": [
    {
      "answer": "Philip II of Spain",
      "score": 0.6137573719024658
    },
    {
      "answer": "Pedro Men\u00e9ndez de Avil\u00e9s",
      "score": 0.8247663378715515
    }
  ],
  "6550": [
    {
      "answer": "San Mateo",
      "score": 0.9891785979270935
    }
  ],
  "6551": [
    {
      "answer": "Fort Caroline",
      "score": 0.6762175559997559
    },
    {
      "answer": "Fort Caroline",
      "score": 0.7396267056465149
    },
    {
      "answer": "Fort Caroline",
      "score": 0.6895373463630676
    },
    {
      "answer": "Fort Caroline",
      "score": 0.9480225443840027
    }
  ],
  "6552": [
    {
      "answer": "Jean Ribault",
      "score": 0.9507031440734863
    }
  ],
  "6553": [
    {
      "answer": "present-day Jacksonville",
      "score": 0.9582802653312683
    }
  ],
  "6554": [
    {
      "answer": "he discovered it in May",
      "score": 0.9518051147460938
    }
  ],
  "6555": [
    {
      "answer": "Pedro Men\u00e9ndez de Avil\u00e9s",
      "score": 0.9090901613235474
    }
  ],
  "6556": [
    {
      "answer": "1964",
      "score": 0.9934572577476501
    }
  ],
  "6557": [
    {
      "answer": "French and Indian War",
      "score": 0.9943341612815857
    }
  ],
  "6558": [],
  "6559": [
    {
      "answer": "these names ostensibly reflect the fact that cattle were brought across the river there",
      "score": 0.8571851253509521
    }
  ],
  "6560": [
    {
      "answer": "British",
      "score": 0.6002745628356934
    },
    {
      "answer": "Britain",
      "score": 0.7295224666595459
    },
    {
      "answer": "Spain",
      "score": 0.8537620902061462
    }
  ],
  "6561": [
    {
      "answer": "February 9, 1832",
      "score": 0.9852259159088135
    }
  ],
  "6562": [
    {
      "answer": "1763",
      "score": 0.9931459426879883
    }
  ],
  "6563": [
    {
      "answer": "King's Road",
      "score": 0.9603604674339294
    }
  ],
  "6564": [
    {
      "answer": "Jacksonville",
      "score": 0.9518967270851135
    }
  ],
  "6565": [
    {
      "answer": "Confederate",
      "score": 0.9948930740356445
    },
    {
      "answer": "Confederate",
      "score": 0.6984487175941467
    },
    {
      "answer": "Confederate",
      "score": 0.7134323716163635
    },
    {
      "answer": "Confederate",
      "score": 0.5535557270050049
    },
    {
      "answer": "Confederate",
      "score": 0.5415696501731873
    },
    {
      "answer": "Confederate",
      "score": 0.6977891325950623
    }
  ],
  "6566": [
    {
      "answer": "Skirmish of the Brick Church",
      "score": 0.9626221060752869
    }
  ],
  "6567": [
    {
      "answer": "Battle of Olustee",
      "score": 0.9581341743469238
    }
  ],
  "6568": [
    {
      "answer": "Warfare",
      "score": 0.9796517491340637
    }
  ],
  "6569": [
    {
      "answer": "1864",
      "score": 0.9217720031738281
    },
    {
      "answer": "1864",
      "score": 0.9865524172782898
    }
  ],
  "6570": [
    {
      "answer": "Confederate",
      "score": 0.9906960725784302
    },
    {
      "answer": "Confederate",
      "score": 0.5806498527526855
    },
    {
      "answer": "Confederate",
      "score": 0.5338859558105469
    },
    {
      "answer": "Confederate",
      "score": 0.6235897541046143
    }
  ],
  "6571": [
    {
      "answer": "Skirmish of the Brick Church",
      "score": 0.9159037470817566
    }
  ],
  "6572": [
    {
      "answer": "Battle of Olustee",
      "score": 0.9748115539550781
    }
  ],
  "6573": [
    {
      "answer": "Skirmish of the Brick Church",
      "score": 0.9854041337966919
    }
  ],
  "6574": [
    {
      "answer": "American Civil War",
      "score": 0.9863181114196777
    }
  ],
  "6575": [
    {
      "answer": "Reconstruction",
      "score": 0.9776365160942078
    }
  ],
  "6576": [
    {
      "answer": "Grover Cleveland",
      "score": 0.9976499080657959
    }
  ],
  "6577": [
    {
      "answer": "yellow fever outbreaks",
      "score": 0.9923816919326782
    }
  ],
  "6578": [
    {
      "answer": "extension of the Florida East Coast Railway",
      "score": 0.9895552396774292
    }
  ],
  "6579": [
    {
      "answer": "railroad",
      "score": 0.9936710596084595
    }
  ],
  "6580": [
    {
      "answer": "19th century",
      "score": 0.9387460947036743
    }
  ],
  "6581": [
    {
      "answer": "Grover Cleveland",
      "score": 0.9961731433868408
    }
  ],
  "6582": [
    {
      "answer": "yellow fever outbreaks",
      "score": 0.9850770831108093
    }
  ],
  "6583": [
    {
      "answer": "extension of the Florida East Coast Railway",
      "score": 0.9556001424789429
    }
  ],
  "6584": [
    {
      "answer": "railroad",
      "score": 0.6163626313209534
    },
    {
      "answer": "extension of the Florida East Coast Railway",
      "score": 0.8830997347831726
    }
  ],
  "6585": [
    {
      "answer": "Spanish moss at a nearby mattress factory",
      "score": 0.9435383081436157
    }
  ],
  "6586": [
    {
      "answer": "2,000",
      "score": 0.9910494089126587
    }
  ],
  "6587": [
    {
      "answer": "declare martial law",
      "score": 0.9853503108024597
    }
  ],
  "6588": [
    {
      "answer": "Great Fire of 1901",
      "score": 0.9929956197738647
    }
  ],
  "6589": [
    {
      "answer": "Confederate Monument in Hemming Park",
      "score": 0.7038807272911072
    }
  ],
  "6590": [
    {
      "answer": "May 3, 1901",
      "score": 0.9399764537811279
    }
  ],
  "6591": [
    {
      "answer": "Great Fire of 1901",
      "score": 0.979215145111084
    }
  ],
  "6592": [
    {
      "answer": "Great Fire of 1901",
      "score": 0.9755623936653137
    }
  ],
  "6593": [
    {
      "answer": "Henry John Klutho",
      "score": 0.9908380508422852
    }
  ],
  "6594": [
    {
      "answer": "New York\u2013based filmmakers",
      "score": 0.8951026797294617
    }
  ],
  "6595": [
    {
      "answer": "silent film",
      "score": 0.9294378757476807
    }
  ],
  "6596": [
    {
      "answer": "Winter Film Capital of the World",
      "score": 0.9949177503585815
    }
  ],
  "6597": [
    {
      "answer": "emergence of Hollywood as a major film production center",
      "score": 0.985087513923645
    }
  ],
  "6598": [
    {
      "answer": "silent film",
      "score": 0.9144105911254883
    }
  ],
  "6599": [
    {
      "answer": "Hollywood",
      "score": 0.9071242809295654
    }
  ],
  "6600": [
    {
      "answer": "Winter Film Capital of the World",
      "score": 0.9304255247116089
    }
  ],
  "6601": [
    {
      "answer": "Norman Studios",
      "score": 0.9234890937805176
    },
    {
      "answer": "Norman Studios",
      "score": 0.685702919960022
    }
  ],
  "6602": [
    {
      "answer": "construction of highways",
      "score": 0.9932779669761658
    }
  ],
  "6603": [
    {
      "answer": "55.1",
      "score": 0.979947566986084
    }
  ],
  "6604": [
    {
      "answer": "white flight",
      "score": 0.987949788570404
    }
  ],
  "6605": [
    {
      "answer": "W. Haydon Burns",
      "score": 0.982955276966095
    }
  ],
  "6606": [
    {
      "answer": "World War II",
      "score": 0.9972705245018005
    },
    {
      "answer": "World War II",
      "score": 0.9759893417358398
    }
  ],
  "6607": [
    {
      "answer": "negative effects of rapid urban sprawl",
      "score": 0.9710351228713989
    }
  ],
  "6608": [
    {
      "answer": "highways",
      "score": 0.9954462051391602
    }
  ],
  "6609": [
    {
      "answer": "55.1",
      "score": 0.9845902919769287
    }
  ],
  "6610": [
    {
      "answer": "The city's most populous ethnic group, non-Hispanic white",
      "score": 0.6634129285812378
    }
  ],
  "6611": [
    {
      "answer": "white flight",
      "score": 0.9750880002975464
    }
  ],
  "6612": [
    {
      "answer": "tax base dissipated",
      "score": 0.9324592351913452
    }
  ],
  "6613": [
    {
      "answer": "unincorporated suburbs",
      "score": 0.9864835739135742
    }
  ],
  "6614": [
    {
      "answer": "annexing outlying communities",
      "score": 0.9183121919631958
    }
  ],
  "6615": [
    {
      "answer": "Voters",
      "score": 0.9856002330780029
    }
  ],
  "6616": [
    {
      "answer": "tax base dissipated",
      "score": 0.6841556429862976
    },
    {
      "answer": "problems with funding education, sanitation, and traffic control within the city limits",
      "score": 0.7917534112930298
    }
  ],
  "6617": [
    {
      "answer": "within the city limits",
      "score": 0.7248603701591492
    },
    {
      "answer": "unincorporated suburbs",
      "score": 0.6002371311187744
    }
  ],
  "6618": [
    {
      "answer": "1958",
      "score": 0.9894841313362122
    }
  ],
  "6619": [
    {
      "answer": "Voters",
      "score": 0.938349723815918
    }
  ],
  "6620": [
    {
      "answer": "traditional old boy network",
      "score": 0.9841290712356567
    }
  ],
  "6621": [
    {
      "answer": "11",
      "score": 0.9929218888282776
    }
  ],
  "6622": [
    {
      "answer": "Jacksonville Consolidation",
      "score": 0.989504873752594
    }
  ],
  "6623": [
    {
      "answer": "corruption scandals",
      "score": 0.957103967666626
    }
  ],
  "6624": [
    {
      "answer": "traditional old boy network",
      "score": 0.9607077836990356
    }
  ],
  "6625": [
    {
      "answer": "11",
      "score": 0.9897689819335938
    }
  ],
  "6626": [
    {
      "answer": "Jacksonville Consolidation",
      "score": 0.9820224046707153
    }
  ],
  "6627": [
    {
      "answer": "In 1964 all 15 of Duval County's public high schools lost their accreditation.",
      "score": 0.9163775444030762
    }
  ],
  "6628": [
    {
      "answer": "Lower taxes",
      "score": 0.9499820470809937
    },
    {
      "answer": "increased economic development",
      "score": 0.975077748298645
    },
    {
      "answer": "unification of the community",
      "score": 0.9753347039222717
    },
    {
      "answer": "better public spending",
      "score": 0.972115695476532
    },
    {
      "answer": "effective administration by a more central authority",
      "score": 0.9696412086486816
    }
  ],
  "6629": [
    {
      "answer": "voters approved the plan",
      "score": 0.9658184051513672
    }
  ],
  "6630": [
    {
      "answer": "Hans Tanzler",
      "score": 0.9909634590148926
    }
  ],
  "6631": [
    {
      "answer": "Bold New City of the South",
      "score": 0.9895550608634949
    }
  ],
  "6632": [
    {
      "answer": "Better Jacksonville Plan",
      "score": 0.9675342440605164
    }
  ],
  "6633": [
    {
      "answer": "a half-penny sales tax",
      "score": 0.9781283736228943
    }
  ],
  "6634": [
    {
      "answer": "consolidation referendum",
      "score": 0.6806558966636658
    }
  ],
  "6635": [
    {
      "answer": "Consolidated City of Jacksonville",
      "score": 0.9610486030578613
    }
  ],
  "6636": [],
  "6637": [
    {
      "answer": "Bold New City of the South",
      "score": 0.937481164932251
    }
  ],
  "6638": [
    {
      "answer": "874.3 square miles",
      "score": 0.991137683391571
    }
  ],
  "6639": [
    {
      "answer": "St. Johns River",
      "score": 0.9789136648178101
    },
    {
      "answer": "St. Johns River",
      "score": 0.9382827877998352
    }
  ],
  "6640": [
    {
      "answer": "Trout River",
      "score": 0.9504460096359253
    }
  ],
  "6641": [
    {
      "answer": "13.34%",
      "score": 0.9772982597351074
    },
    {
      "answer": "116.7 sq mi",
      "score": 0.8749846816062927
    }
  ],
  "6642": [
    {
      "answer": "Baldwin",
      "score": 0.9210225343704224
    }
  ],
  "6643": [
    {
      "answer": "2,264",
      "score": 0.875775933265686
    }
  ],
  "6644": [
    {
      "answer": "St. Johns River",
      "score": 0.822888970375061
    },
    {
      "answer": "St. Johns River",
      "score": 0.9226809740066528
    }
  ],
  "6645": [
    {
      "answer": "water",
      "score": 0.8769460320472717
    }
  ],
  "6646": [
    {
      "answer": "Trout River",
      "score": 0.73871910572052
    }
  ],
  "6647": [
    {
      "answer": "Baldwin",
      "score": 0.9803254008293152
    }
  ],
  "6648": [
    {
      "answer": "tallest building",
      "score": 0.9440798759460449
    }
  ],
  "6649": [
    {
      "answer": "Barnett Center",
      "score": 0.9965876340866089
    }
  ],
  "6650": [
    {
      "answer": "617 ft",
      "score": 0.9754949808120728
    }
  ],
  "6651": [
    {
      "answer": "28",
      "score": 0.9859678149223328
    }
  ],
  "6652": [
    {
      "answer": "flared base",
      "score": 0.9835193157196045
    }
  ],
  "6653": [
    {
      "answer": "Bank of America Tower",
      "score": 0.6192072629928589
    }
  ],
  "6654": [
    {
      "answer": "Bank of America Tower",
      "score": 0.8867864608764648
    }
  ],
  "6655": [
    {
      "answer": "Wells Fargo Center",
      "score": 0.9729650020599365
    }
  ],
  "6656": [
    {
      "answer": "42",
      "score": 0.9938742518424988
    }
  ],
  "6657": [
    {
      "answer": "humid subtropical",
      "score": 0.9883195757865906
    }
  ],
  "6658": [
    {
      "answer": "May through September",
      "score": 0.9671027660369873
    }
  ],
  "6659": [
    {
      "answer": "mild and sunny",
      "score": 0.9465174674987793
    }
  ],
  "6660": [
    {
      "answer": "low latitude",
      "score": 0.9596367478370667
    },
    {
      "answer": "coastal location",
      "score": 0.9207301139831543
    }
  ],
  "6661": [
    {
      "answer": "Jacksonville",
      "score": 0.7699716687202454
    }
  ],
  "6662": [
    {
      "answer": "mild",
      "score": 0.90688556432724
    },
    {
      "answer": "mild and sunny",
      "score": 0.774864673614502
    }
  ],
  "6663": [
    {
      "answer": "Seasonal rainfall",
      "score": 0.9590053558349609
    }
  ],
  "6664": [],
  "6665": [
    {
      "answer": "104 \u00b0F",
      "score": 0.9624044299125671
    }
  ],
  "6666": [
    {
      "answer": "thunderstorms to erupt",
      "score": 0.8107351064682007
    }
  ],
  "6667": [
    {
      "answer": "rapid heating of the land relative to the water",
      "score": 0.7657240033149719
    },
    {
      "answer": "extremely high humidity",
      "score": 0.8219987750053406
    }
  ],
  "6668": [
    {
      "answer": "January",
      "score": 0.6313449144363403
    },
    {
      "answer": "July",
      "score": 0.8647957444190979
    },
    {
      "answer": "July",
      "score": 0.6535265445709229
    },
    {
      "answer": "July",
      "score": 0.5802692174911499
    }
  ],
  "6669": [
    {
      "answer": "104 \u00b0F",
      "score": 0.9528713226318359
    }
  ],
  "6670": [
    {
      "answer": "thunderstorms to erupt during a typical summer afternoon",
      "score": 0.7300153970718384
    }
  ],
  "6671": [
    {
      "answer": "rapid heating of the land relative to the water",
      "score": 0.8984709978103638
    }
  ],
  "6672": [
    {
      "answer": "January",
      "score": 0.8530141711235046
    }
  ],
  "6673": [
    {
      "answer": "Hurricane Dora",
      "score": 0.9784554839134216
    }
  ],
  "6674": [
    {
      "answer": "110 mph",
      "score": 0.9849966168403625
    }
  ],
  "6675": [],
  "6676": [
    {
      "answer": "Saffir-Simpson Scale",
      "score": 0.9617530703544617
    }
  ],
  "6677": [
    {
      "answer": "2008",
      "score": 0.9928245544433594
    }
  ],
  "6678": [
    {
      "answer": "Hurricane Dora",
      "score": 0.8553662896156311
    }
  ],
  "6679": [
    {
      "answer": "110 mph",
      "score": 0.9437301754951477
    }
  ],
  "6680": [
    {
      "answer": "Hurricane Dora",
      "score": 0.9071667194366455
    }
  ],
  "6681": [],
  "6682": [
    {
      "answer": "minor tornado",
      "score": 0.6256303787231445
    }
  ],
  "6683": [
    {
      "answer": "Arab",
      "score": 0.9868209958076477
    }
  ],
  "6684": [
    {
      "answer": "821,784",
      "score": 0.9709084033966064
    }
  ],
  "6685": [
    {
      "answer": "largest Filipino American community",
      "score": 0.7712441682815552
    }
  ],
  "6686": [
    {
      "answer": "Filipino",
      "score": 0.9635655283927917
    }
  ],
  "6687": [
    {
      "answer": "Jacksonville",
      "score": 0.8660492897033691
    },
    {
      "answer": "Jacksonville",
      "score": 0.8828000426292419
    },
    {
      "answer": "Jacksonville",
      "score": 0.833226203918457
    },
    {
      "answer": "Jacksonville",
      "score": 0.861285924911499
    }
  ],
  "6688": [
    {
      "answer": "2000",
      "score": 0.917619526386261
    }
  ],
  "6689": [],
  "6690": [
    {
      "answer": "2000",
      "score": 0.7528366446495056
    }
  ],
  "6691": [
    {
      "answer": "United States Navy",
      "score": 0.994064211845398
    }
  ],
  "6692": [
    {
      "answer": "29.7%",
      "score": 0.9404025673866272
    }
  ],
  "6693": [
    {
      "answer": "23",
      "score": 0.9851227402687073
    }
  ],
  "6694": [
    {
      "answer": "males",
      "score": 0.6424412727355957
    },
    {
      "answer": "males",
      "score": 0.6224616169929504
    }
  ],
  "6695": [
    {
      "answer": "94.1",
      "score": 0.8178500533103943
    },
    {
      "answer": "91.3",
      "score": 0.7078948020935059
    }
  ],
  "6696": [
    {
      "answer": "2010",
      "score": 0.9885082840919495
    }
  ],
  "6697": [
    {
      "answer": "10.9%",
      "score": 0.9391499161720276
    }
  ],
  "6698": [
    {
      "answer": "91.3",
      "score": 0.9184765219688416
    }
  ],
  "6699": [],
  "6700": [
    {
      "answer": "43.8%",
      "score": 0.9679403305053711
    }
  ],
  "6701": [
    {
      "answer": "40%",
      "score": 0.7860140800476074
    },
    {
      "answer": "46%",
      "score": 0.757828414440155
    }
  ],
  "6702": [
    {
      "answer": "3.5 billion people",
      "score": 0.8831619620323181
    }
  ],
  "6703": [],
  "6704": [
    {
      "answer": "methodology used: by using net wealth (adding up assets and subtracting debts), the Oxfam report, for instance, finds that there are more poor people in the United States and Western Europe than in China (due to a greater tendency to take on debts)",
      "score": 0.7884203195571899
    }
  ],
  "6705": [],
  "6706": [
    {
      "answer": "40",
      "score": 0.9943106174468994
    }
  ],
  "6707": [
    {
      "answer": "financial assets",
      "score": 0.9773131608963013
    }
  ],
  "6708": [
    {
      "answer": "$41 trillion",
      "score": 0.9331239461898804
    }
  ],
  "6709": [
    {
      "answer": "more than half",
      "score": 0.9666935205459595
    }
  ],
  "6710": [
    {
      "answer": "a greater tendency to take on debts",
      "score": 0.983392059803009
    }
  ],
  "6711": [
    {
      "answer": "40%",
      "score": 0.6032766699790955
    }
  ],
  "6712": [],
  "6713": [],
  "6714": [
    {
      "answer": "the methodology used: by using net wealth (adding up assets and subtracting debts), the Oxfam report, for instance, finds that there are more poor people in the United States and Western Europe than in China (due to a greater tendency to take on debts)",
      "score": 0.7591844201087952
    }
  ],
  "6715": [],
  "6716": [
    {
      "answer": "400",
      "score": 0.9744085073471069
    },
    {
      "answer": "400",
      "score": 0.7139649391174316
    }
  ],
  "6717": [
    {
      "answer": "New York Times",
      "score": 0.9928618669509888
    }
  ],
  "6718": [
    {
      "answer": "Inherited wealth",
      "score": 0.9934791922569275
    }
  ],
  "6719": [
    {
      "answer": "Inherited wealth",
      "score": 0.9026325941085815
    }
  ],
  "6720": [
    {
      "answer": "wealth",
      "score": 0.9771347641944885
    },
    {
      "answer": "wealth",
      "score": 0.70283043384552
    },
    {
      "answer": "wealth",
      "score": 0.6668379902839661
    }
  ],
  "6721": [
    {
      "answer": "richest 1 percent",
      "score": 0.9519640803337097
    }
  ],
  "6722": [
    {
      "answer": "Inherited wealth",
      "score": 0.9978170394897461
    }
  ],
  "6723": [
    {
      "answer": "over 60 percent",
      "score": 0.9751949310302734
    }
  ],
  "6724": [
    {
      "answer": "Institute for Policy Studies",
      "score": 0.9900877475738525
    }
  ],
  "6725": [
    {
      "answer": "400",
      "score": 0.9734775424003601
    },
    {
      "answer": "400",
      "score": 0.7392314076423645
    }
  ],
  "6726": [
    {
      "answer": "New York Times",
      "score": 0.9926954507827759
    }
  ],
  "6727": [
    {
      "answer": "Inherited wealth",
      "score": 0.9850324988365173
    }
  ],
  "6728": [
    {
      "answer": "Inherited wealth",
      "score": 0.9619849920272827
    }
  ],
  "6729": [
    {
      "answer": "wealth",
      "score": 0.9723366498947144
    }
  ],
  "6730": [
    {
      "answer": "Neoclassical economics",
      "score": 0.9903333783149719
    }
  ],
  "6731": [
    {
      "answer": "differences in value added by labor, capital and land",
      "score": 0.9262927174568176
    }
  ],
  "6732": [
    {
      "answer": "differences in value added by labor, capital and land",
      "score": 0.6185961365699768
    },
    {
      "answer": "differences in value added by different classifications of workers",
      "score": 0.6441095471382141
    }
  ],
  "6733": [
    {
      "answer": "productivity gap",
      "score": 0.9495338201522827
    }
  ],
  "6734": [
    {
      "answer": "wages and profits are determined by the marginal value added of each economic actor (worker, capitalist/business owner, landlord)",
      "score": 0.8820796012878418
    }
  ],
  "6735": [
    {
      "answer": "differences in value added by labor, capital and land",
      "score": 0.9817520380020142
    }
  ],
  "6736": [
    {
      "answer": "value added by labor, capital and land",
      "score": 0.6973415613174438
    },
    {
      "answer": "value added by different classifications of workers",
      "score": 0.9106295704841614
    }
  ],
  "6737": [
    {
      "answer": "wages and profits",
      "score": 0.9897749423980713
    }
  ],
  "6738": [
    {
      "answer": "worker",
      "score": 0.8571730256080627
    },
    {
      "answer": "capitalist/business owner",
      "score": 0.897559404373169
    },
    {
      "answer": "landlord",
      "score": 0.8949929475784302
    }
  ],
  "6739": [
    {
      "answer": "productivity gap between highly-paid professions and lower-paid professions",
      "score": 0.9356004595756531
    }
  ],
  "6740": [
    {
      "answer": "Neoclassical economics",
      "score": 0.9880579710006714
    }
  ],
  "6741": [
    {
      "answer": "differences in value added by labor, capital and land",
      "score": 0.7665554881095886
    },
    {
      "answer": "productivity gap",
      "score": 0.6545398235321045
    }
  ],
  "6742": [],
  "6743": [
    {
      "answer": "productivity gap",
      "score": 0.7444096803665161
    }
  ],
  "6744": [
    {
      "answer": "wages and profits are determined by the marginal value added of each economic actor (worker, capitalist/business owner, landlord)",
      "score": 0.8830927610397339
    }
  ],
  "6745": [
    {
      "answer": "competitive pressure",
      "score": 0.9469401836395264
    },
    {
      "answer": "reduce costs and maximize profits",
      "score": 0.8853171467781067
    }
  ],
  "6746": [
    {
      "answer": "The substitution of capital equipment for labor (mechanization and automation) raises the productivity of each worker",
      "score": 0.6757007241249084
    }
  ],
  "6747": [
    {
      "answer": "increasing unemployment",
      "score": 0.9204018115997314
    }
  ],
  "6748": [
    {
      "answer": "downward pressure on wages",
      "score": 0.7211629152297974
    }
  ],
  "6749": [
    {
      "answer": "labor",
      "score": 0.8672763109207153
    }
  ],
  "6750": [
    {
      "answer": "to reduce costs and maximize profits",
      "score": 0.9760538935661316
    }
  ],
  "6751": [
    {
      "answer": "substitute capital equipment for labor inputs",
      "score": 0.9482130408287048
    }
  ],
  "6752": [
    {
      "answer": "productivity",
      "score": 0.9863924384117126
    }
  ],
  "6753": [
    {
      "answer": "stagnant",
      "score": 0.9365472793579102
    }
  ],
  "6754": [
    {
      "answer": "competitive pressure",
      "score": 0.9550113677978516
    }
  ],
  "6755": [
    {
      "answer": "downward pressure on wages",
      "score": 0.8686069846153259
    }
  ],
  "6756": [
    {
      "answer": "increasing unemployment",
      "score": 0.7309094667434692
    }
  ],
  "6757": [
    {
      "answer": "downward pressure on wages",
      "score": 0.8193480372428894
    }
  ],
  "6758": [],
  "6759": [
    {
      "answer": "wages",
      "score": 0.9738684892654419
    }
  ],
  "6760": [
    {
      "answer": "supply and demand",
      "score": 0.991572380065918
    }
  ],
  "6761": [
    {
      "answer": "Employers who offer a below market wage will find that their business is chronically understaffed.",
      "score": 0.8712746500968933
    },
    {
      "answer": "Their competitors will take advantage of the situation by offering a higher wage the best of their labor.",
      "score": 0.9469727277755737
    }
  ],
  "6762": [
    {
      "answer": "Their competitors will take advantage of the situation by offering a higher wage the best of their labor",
      "score": 0.8584570288658142
    }
  ],
  "6763": [
    {
      "answer": "Markets, by themselves, even when they are stable, often lead to high levels of inequality, outcomes that are widely viewed as unfair",
      "score": 0.7086920142173767
    }
  ],
  "6764": [
    {
      "answer": "the market",
      "score": 0.9815526008605957
    }
  ],
  "6765": [
    {
      "answer": "prices",
      "score": 0.9418424963951111
    }
  ],
  "6766": [
    {
      "answer": "wages",
      "score": 0.7059197425842285
    },
    {
      "answer": "wages",
      "score": 0.8470950722694397
    },
    {
      "answer": "wages",
      "score": 0.8443852663040161
    }
  ],
  "6767": [
    {
      "answer": "markets",
      "score": 0.9707291126251221
    }
  ],
  "6768": [
    {
      "answer": "pass environmental costs on to society",
      "score": 0.5688673257827759
    },
    {
      "answer": "abuse workers and consumers",
      "score": 0.6258929967880249
    },
    {
      "answer": "high levels of inequality",
      "score": 0.9426743388175964
    }
  ],
  "6769": [
    {
      "answer": "workers wages",
      "score": 0.921648383140564
    }
  ],
  "6770": [
    {
      "answer": "Employers who offer a below market wage will find that their business is chronically understaffed.",
      "score": 0.8729870319366455
    },
    {
      "answer": "Their competitors will take advantage of the situation by offering a higher wage the best of their labor.",
      "score": 0.9203376770019531
    }
  ],
  "6771": [
    {
      "answer": "supply and demand",
      "score": 0.9908525347709656
    }
  ],
  "6772": [
    {
      "answer": "Their competitors will take advantage of the situation by offering a higher wage the best of their labor",
      "score": 0.862865149974823
    }
  ],
  "6773": [
    {
      "answer": "unfair",
      "score": 0.8721759915351868
    }
  ],
  "6774": [
    {
      "answer": "competition between employers",
      "score": 0.9499208331108093
    },
    {
      "answer": "Competition amongst employers",
      "score": 0.9114730358123779
    }
  ],
  "6775": [
    {
      "answer": "low wage",
      "score": 0.976104736328125
    }
  ],
  "6776": [
    {
      "answer": "low wage",
      "score": 0.5754595398902893
    },
    {
      "answer": "high wages",
      "score": 0.7009832859039307
    }
  ],
  "6777": [
    {
      "answer": "limit the supply of workers",
      "score": 0.8495647311210632
    },
    {
      "answer": "collective bargaining",
      "score": 0.8632490634918213
    },
    {
      "answer": "political influence",
      "score": 0.8341144323348999
    },
    {
      "answer": "corruption",
      "score": 0.8823584914207458
    }
  ],
  "6778": [
    {
      "answer": "employers",
      "score": 0.953275203704834
    },
    {
      "answer": "employers",
      "score": 0.8675561547279358
    }
  ],
  "6779": [
    {
      "answer": "low wage",
      "score": 0.9892745018005371
    }
  ],
  "6780": [
    {
      "answer": "competition between workers",
      "score": 0.9894284009933472
    },
    {
      "answer": "Competition amongst workers",
      "score": 0.806715726852417
    }
  ],
  "6781": [
    {
      "answer": "the expendable nature of the worker in relation to his or her particular job",
      "score": 0.9607135057449341
    }
  ],
  "6782": [
    {
      "answer": "low wage",
      "score": 0.9167724847793579
    }
  ],
  "6783": [
    {
      "answer": "employers",
      "score": 0.9106051921844482
    },
    {
      "answer": "employers",
      "score": 0.8396247029304504
    }
  ],
  "6784": [
    {
      "answer": "competition between workers",
      "score": 0.9604820609092712
    },
    {
      "answer": "Competition amongst workers",
      "score": 0.9059146642684937
    }
  ],
  "6785": [
    {
      "answer": "low wage",
      "score": 0.9685547351837158
    }
  ],
  "6786": [
    {
      "answer": "high wages",
      "score": 0.6588305234909058
    }
  ],
  "6787": [
    {
      "answer": "competition between workers",
      "score": 0.7914954423904419
    },
    {
      "answer": "limit the supply of workers",
      "score": 0.7237545251846313
    }
  ],
  "6788": [
    {
      "answer": "competition between workers",
      "score": 0.9772980213165283
    }
  ],
  "6789": [
    {
      "answer": "entrepreneurship",
      "score": 0.9328627586364746
    },
    {
      "answer": "entrepreneurship",
      "score": 0.5969577431678772
    },
    {
      "answer": "entrepreneurship",
      "score": 0.6201322674751282
    }
  ],
  "6790": [
    {
      "answer": "survival",
      "score": 0.7758099436759949
    }
  ],
  "6791": [
    {
      "answer": "survival needs",
      "score": 0.9380810260772705
    }
  ],
  "6792": [
    {
      "answer": "achievement-oriented motivations",
      "score": 0.6055586934089661
    }
  ],
  "6793": [
    {
      "answer": "opportunity-based entrepreneurship",
      "score": 0.9479595422744751
    }
  ],
  "6794": [
    {
      "answer": "economic inequality",
      "score": 0.9901784658432007
    }
  ],
  "6795": [
    {
      "answer": "necessity",
      "score": 0.9663869738578796
    }
  ],
  "6796": [
    {
      "answer": "Necessity-based",
      "score": 0.9915714263916016
    }
  ],
  "6797": [
    {
      "answer": "achievement-oriented motivations",
      "score": 0.9687873721122742
    }
  ],
  "6798": [
    {
      "answer": "redistributive",
      "score": 0.5718743801116943
    },
    {
      "answer": "positive",
      "score": 0.8114226460456848
    }
  ],
  "6799": [],
  "6800": [],
  "6801": [
    {
      "answer": "survival needs",
      "score": 0.7809448838233948
    },
    {
      "answer": "achievement-oriented motivations",
      "score": 0.8809237480163574
    }
  ],
  "6802": [
    {
      "answer": "achievement-oriented motivations",
      "score": 0.6453356742858887
    }
  ],
  "6803": [
    {
      "answer": "Necessity-based entrepreneurship",
      "score": 0.8680152893066406
    },
    {
      "answer": "opportunity-based entrepreneurship",
      "score": 0.6069515943527222
    }
  ],
  "6804": [
    {
      "answer": "progressive tax",
      "score": 0.992716908454895
    },
    {
      "answer": "progressive tax",
      "score": 0.8553302884101868
    }
  ],
  "6805": [
    {
      "answer": "top",
      "score": 0.9929903745651245
    }
  ],
  "6806": [
    {
      "answer": "steeper tax progressivity applied to social spending",
      "score": 0.63458651304245
    }
  ],
  "6807": [
    {
      "answer": "progressive tax",
      "score": 0.8829653263092041
    }
  ],
  "6808": [
    {
      "answer": "tax rate",
      "score": 0.9897463321685791
    }
  ],
  "6809": [
    {
      "answer": "level of the top tax rate",
      "score": 0.948087215423584
    }
  ],
  "6810": [
    {
      "answer": "steeper tax progressivity",
      "score": 0.97432941198349
    }
  ],
  "6811": [
    {
      "answer": "The difference between the Gini index",
      "score": 0.8535816073417664
    }
  ],
  "6812": [
    {
      "answer": "progressive tax",
      "score": 0.9406607151031494
    },
    {
      "answer": "progressive tax",
      "score": 0.8287317156791687
    }
  ],
  "6813": [
    {
      "answer": "top",
      "score": 0.9917004704475403
    }
  ],
  "6814": [],
  "6815": [
    {
      "answer": "progressive tax",
      "score": 0.8506060838699341
    },
    {
      "answer": "progressive tax",
      "score": 0.8590224981307983
    }
  ],
  "6816": [
    {
      "answer": "tax rate",
      "score": 0.9875631928443909
    }
  ],
  "6817": [
    {
      "answer": "education",
      "score": 0.5599648952484131
    },
    {
      "answer": "Education",
      "score": 0.541152834892273
    },
    {
      "answer": "education",
      "score": 0.5666572451591492
    },
    {
      "answer": "education",
      "score": 0.6034097075462341
    }
  ],
  "6818": [
    {
      "answer": "education",
      "score": 0.8543667793273926
    },
    {
      "answer": "education",
      "score": 0.6422219276428223
    },
    {
      "answer": "education",
      "score": 0.7441366910934448
    },
    {
      "answer": "education",
      "score": 0.6292151212692261
    },
    {
      "answer": "education",
      "score": 0.7798117995262146
    },
    {
      "answer": "education",
      "score": 0.5669988393783569
    }
  ],
  "6819": [
    {
      "answer": "lower incomes",
      "score": 0.9886264204978943
    },
    {
      "answer": "lower aggregate savings and investment",
      "score": 0.7223637104034424
    }
  ],
  "6820": [
    {
      "answer": "poor",
      "score": 0.9863395690917969
    }
  ],
  "6821": [
    {
      "answer": "education",
      "score": 0.7112775444984436
    }
  ],
  "6822": [
    {
      "answer": "variation in individuals' access to education",
      "score": 0.8920828104019165
    }
  ],
  "6823": [
    {
      "answer": "high wages",
      "score": 0.9801555871963501
    }
  ],
  "6824": [
    {
      "answer": "lower",
      "score": 0.9900619983673096
    }
  ],
  "6825": [
    {
      "answer": "lower incomes",
      "score": 0.9928399324417114
    },
    {
      "answer": "lower aggregate savings and investment",
      "score": 0.6322718858718872
    }
  ],
  "6826": [
    {
      "answer": "education",
      "score": 0.6558011174201965
    },
    {
      "answer": "education",
      "score": 0.5914738774299622
    },
    {
      "answer": "education",
      "score": 0.5792712569236755
    },
    {
      "answer": "education",
      "score": 0.5545566082000732
    },
    {
      "answer": "education",
      "score": 0.6327401399612427
    },
    {
      "answer": "education",
      "score": 0.6614387035369873
    },
    {
      "answer": "education",
      "score": 0.941395103931427
    }
  ],
  "6827": [],
  "6828": [
    {
      "answer": "education",
      "score": 0.9108362793922424
    },
    {
      "answer": "education",
      "score": 0.6775838136672974
    },
    {
      "answer": "education",
      "score": 0.7367627620697021
    },
    {
      "answer": "education",
      "score": 0.6237688660621643
    },
    {
      "answer": "education",
      "score": 0.7451888918876648
    },
    {
      "answer": "education",
      "score": 0.5948953032493591
    }
  ],
  "6829": [
    {
      "answer": "lower incomes",
      "score": 0.6781048774719238
    },
    {
      "answer": "lower aggregate savings and investment",
      "score": 0.5747941732406616
    }
  ],
  "6830": [
    {
      "answer": "poor",
      "score": 0.9855491518974304
    }
  ],
  "6831": [
    {
      "answer": "education",
      "score": 0.7339932918548584
    },
    {
      "answer": "education",
      "score": 0.570080041885376
    },
    {
      "answer": "education",
      "score": 0.5458811521530151
    },
    {
      "answer": "education",
      "score": 0.7776615023612976
    },
    {
      "answer": "education",
      "score": 0.7312356233596802
    }
  ],
  "6832": [
    {
      "answer": "increasing access to education",
      "score": 0.9958592653274536
    }
  ],
  "6833": [
    {
      "answer": "$105 billion",
      "score": 0.9512077569961548
    }
  ],
  "6834": [
    {
      "answer": "boom-and-bust cycles",
      "score": 0.9576142430305481
    }
  ],
  "6835": [
    {
      "answer": "Standard & Poor",
      "score": 0.9747079610824585
    }
  ],
  "6836": [
    {
      "answer": "2014",
      "score": 0.9852295517921448
    }
  ],
  "6837": [
    {
      "answer": "2014",
      "score": 0.9358490109443665
    }
  ],
  "6838": [
    {
      "answer": "increasing access to education",
      "score": 0.9972232580184937
    }
  ],
  "6839": [
    {
      "answer": "$105 billion",
      "score": 0.9755524396896362
    }
  ],
  "6840": [
    {
      "answer": "boom-and-bust cycles",
      "score": 0.9954383969306946
    }
  ],
  "6841": [
    {
      "answer": "increasing access to education",
      "score": 0.9956597685813904
    }
  ],
  "6842": [
    {
      "answer": "$105 billion",
      "score": 0.9477431178092957
    }
  ],
  "6843": [
    {
      "answer": "boom-and-bust cycles",
      "score": 0.9446373581886292
    }
  ],
  "6844": [
    {
      "answer": "Standard & Poor",
      "score": 0.9723684787750244
    }
  ],
  "6845": [
    {
      "answer": "2014",
      "score": 0.9887275695800781
    }
  ],
  "6846": [
    {
      "answer": "1910",
      "score": 0.9845593571662903
    }
  ],
  "6847": [
    {
      "answer": "an increase in skilled workers",
      "score": 0.6764678359031677
    },
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.8663240075111389
    }
  ],
  "6848": [
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.8068627715110779
    }
  ],
  "6849": [],
  "6850": [
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.7358351945877075
    },
    {
      "answer": "decrease in wages",
      "score": 0.7981313467025757
    }
  ],
  "6851": [
    {
      "answer": "1910\u20131940",
      "score": 0.9689108729362488
    }
  ],
  "6852": [
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.9833671450614929
    }
  ],
  "6853": [
    {
      "answer": "it differs from the present high school education, which is regarded as a stepping-stone to acquire college and advanced degrees",
      "score": 0.8217542767524719
    }
  ],
  "6854": [
    {
      "answer": "education",
      "score": 0.6059990525245667
    },
    {
      "answer": "Education",
      "score": 0.964043378829956
    },
    {
      "answer": "education",
      "score": 0.60194993019104
    }
  ],
  "6855": [
    {
      "answer": "gender inequality in education",
      "score": 0.8742305040359497
    },
    {
      "answer": "gender inequality in education",
      "score": 0.8676409721374512
    }
  ],
  "6856": [
    {
      "answer": "1910",
      "score": 0.9722983241081238
    }
  ],
  "6857": [
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.7336333394050598
    },
    {
      "answer": "This decrease in wages caused a period of compression and decreased inequality between skilled and unskilled workers",
      "score": 0.7684300541877747
    }
  ],
  "6858": [
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.6469358801841736
    },
    {
      "answer": "decrease in wages caused a period of compression and decreased inequality between skilled and unskilled workers",
      "score": 0.7438879609107971
    }
  ],
  "6859": [],
  "6860": [
    {
      "answer": "decrease in the price of skilled labor",
      "score": 0.8346890807151794
    },
    {
      "answer": "decrease in wages",
      "score": 0.6244073510169983
    }
  ],
  "6861": [
    {
      "answer": "union",
      "score": 0.9817495346069336
    }
  ],
  "6862": [
    {
      "answer": "continental European",
      "score": 0.6577503681182861
    },
    {
      "answer": "continental European",
      "score": 0.9410415887832642
    }
  ],
  "6863": [
    {
      "answer": "economic liberalism",
      "score": 0.7454755902290344
    },
    {
      "answer": "reduction of business regulation",
      "score": 0.7049146890640259
    }
  ],
  "6864": [],
  "6865": [
    {
      "answer": "economic inequality",
      "score": 0.9906355142593384
    }
  ],
  "6866": [
    {
      "answer": "social exclusion",
      "score": 0.9744125008583069
    }
  ],
  "6867": [
    {
      "answer": "CEPR",
      "score": 0.9911777377128601
    }
  ],
  "6868": [
    {
      "answer": "little",
      "score": 0.9349969029426575
    }
  ],
  "6869": [],
  "6870": [
    {
      "answer": "union",
      "score": 0.9839209318161011
    }
  ],
  "6871": [
    {
      "answer": "continental European",
      "score": 0.5685009956359863
    },
    {
      "answer": "continental European",
      "score": 0.9563992619514465
    }
  ],
  "6872": [
    {
      "answer": "economic liberalism",
      "score": 0.9564199447631836
    },
    {
      "answer": "reduction of business regulation",
      "score": 0.9103485941886902
    }
  ],
  "6873": [],
  "6874": [
    {
      "answer": "economic inequality",
      "score": 0.920723557472229
    }
  ],
  "6875": [
    {
      "answer": "United States",
      "score": 0.9849413633346558
    }
  ],
  "6876": [
    {
      "answer": "high inequality",
      "score": 0.922874927520752
    }
  ],
  "6877": [
    {
      "answer": "decline of organized labor",
      "score": 0.9767820835113525
    }
  ],
  "6878": [
    {
      "answer": "decline of organized labor",
      "score": 0.9776973128318787
    }
  ],
  "6879": [
    {
      "answer": "Sociologist",
      "score": 0.978423535823822
    }
  ],
  "6880": [
    {
      "answer": "University of Washington",
      "score": 0.9945114850997925
    }
  ],
  "6881": [
    {
      "answer": "decline of organized labor",
      "score": 0.9816110134124756
    }
  ],
  "6882": [
    {
      "answer": "high",
      "score": 0.9544861912727356
    }
  ],
  "6883": [
    {
      "answer": "weak labor movements",
      "score": 0.9957600831985474
    }
  ],
  "6884": [
    {
      "answer": "United States",
      "score": 0.9920080900192261
    }
  ],
  "6885": [
    {
      "answer": "low levels of inequality",
      "score": 0.837855875492096
    }
  ],
  "6886": [
    {
      "answer": "decline of organized labor",
      "score": 0.9695469737052917
    }
  ],
  "6887": [
    {
      "answer": "decline of organized labor",
      "score": 0.9692906737327576
    }
  ],
  "6888": [
    {
      "answer": "Sociologist",
      "score": 0.9656684398651123
    }
  ],
  "6889": [
    {
      "answer": "reduced wages",
      "score": 0.9751401543617249
    }
  ],
  "6890": [
    {
      "answer": "reduced wages",
      "score": 0.8339524269104004
    }
  ],
  "6891": [
    {
      "answer": "technological innovation",
      "score": 0.9924226999282837
    },
    {
      "answer": "technological innovation",
      "score": 0.9076999425888062
    }
  ],
  "6892": [
    {
      "answer": "machine labor",
      "score": 0.9923291206359863
    }
  ],
  "6893": [
    {
      "answer": "global",
      "score": 0.9720174670219421
    },
    {
      "answer": "domestic",
      "score": 0.904622495174408
    }
  ],
  "6894": [],
  "6895": [
    {
      "answer": "trade liberalisation",
      "score": 0.9066171646118164
    },
    {
      "answer": "increased trade with poor countries and the fragmentation of the means of production",
      "score": 0.9070633053779602
    }
  ],
  "6896": [
    {
      "answer": "minor",
      "score": 0.9224361181259155
    },
    {
      "answer": "technological innovation",
      "score": 0.6456577777862549
    }
  ],
  "6897": [
    {
      "answer": "machine labor",
      "score": 0.9953926801681519
    }
  ],
  "6898": [],
  "6899": [
    {
      "answer": "technological innovation",
      "score": 0.9941576719284058
    },
    {
      "answer": "technological innovation",
      "score": 0.8945030570030212
    }
  ],
  "6900": [
    {
      "answer": "machine labor",
      "score": 0.991234540939331
    }
  ],
  "6901": [
    {
      "answer": "global",
      "score": 0.9443946480751038
    },
    {
      "answer": "domestic",
      "score": 0.760463297367096
    }
  ],
  "6902": [
    {
      "answer": "53%",
      "score": 0.9708616733551025
    }
  ],
  "6903": [
    {
      "answer": "-40%",
      "score": 0.9192346930503845
    }
  ],
  "6904": [
    {
      "answer": "Gender pay gap",
      "score": 0.7623400092124939
    }
  ],
  "6905": [
    {
      "answer": "males",
      "score": 0.9881747961044312
    }
  ],
  "6906": [
    {
      "answer": "Gender pay gap",
      "score": 0.9291025400161743
    }
  ],
  "6907": [
    {
      "answer": "males",
      "score": 0.9921976923942566
    }
  ],
  "6908": [
    {
      "answer": "women",
      "score": 0.9839844107627869
    },
    {
      "answer": "women",
      "score": 0.6270432472229004
    },
    {
      "answer": "women",
      "score": 0.7656970024108887
    }
  ],
  "6909": [
    {
      "answer": "Thomas Sowell",
      "score": 0.9960501194000244
    }
  ],
  "6910": [
    {
      "answer": "in US once other factors are accounted for there is still a difference in earnings between women and men",
      "score": 0.8749474287033081
    }
  ],
  "6911": [
    {
      "answer": "53%",
      "score": 0.92308109998703
    }
  ],
  "6912": [
    {
      "answer": "-40%",
      "score": 0.880570113658905
    }
  ],
  "6913": [
    {
      "answer": "Gender pay gap",
      "score": 0.7458342909812927
    }
  ],
  "6914": [
    {
      "answer": "women",
      "score": 0.8061279654502869
    },
    {
      "answer": "women",
      "score": 0.6423259377479553
    }
  ],
  "6915": [
    {
      "answer": "Gender pay gap",
      "score": 0.9060211181640625
    }
  ],
  "6916": [
    {
      "answer": "social welfare",
      "score": 0.9964182376861572
    }
  ],
  "6917": [],
  "6918": [
    {
      "answer": "acquires more capital",
      "score": 0.7107311487197876
    },
    {
      "answer": "the owners of this capital",
      "score": 0.7540775537490845
    }
  ],
  "6919": [
    {
      "answer": "social welfare programs",
      "score": 0.9549731612205505
    }
  ],
  "6920": [
    {
      "answer": "Economist",
      "score": 0.9804471731185913
    }
  ],
  "6921": [
    {
      "answer": "economic inequality",
      "score": 0.987779974937439
    }
  ],
  "6922": [
    {
      "answer": "capital",
      "score": 0.9904072880744934
    }
  ],
  "6923": [
    {
      "answer": "more wealth and income",
      "score": 0.9270194172859192
    }
  ],
  "6924": [
    {
      "answer": "lower levels of inequality",
      "score": 0.9340586066246033
    }
  ],
  "6925": [
    {
      "answer": "social welfare",
      "score": 0.9958674311637878
    }
  ],
  "6926": [],
  "6927": [
    {
      "answer": "capital",
      "score": 0.7798358201980591
    },
    {
      "answer": "capital",
      "score": 0.6244064569473267
    },
    {
      "answer": "social welfare programs",
      "score": 0.5696489214897156
    }
  ],
  "6928": [
    {
      "answer": "acquires more capital",
      "score": 0.9197871685028076
    }
  ],
  "6929": [
    {
      "answer": "Economist",
      "score": 0.9581692814826965
    }
  ],
  "6930": [
    {
      "answer": "1910 to 1940",
      "score": 0.9330045580863953
    }
  ],
  "6931": [
    {
      "answer": "1970s",
      "score": 0.9945817589759827
    }
  ],
  "6932": [
    {
      "answer": "service sector",
      "score": 0.955232560634613
    }
  ],
  "6933": [
    {
      "answer": "service sector",
      "score": 0.9509356021881104
    }
  ],
  "6934": [
    {
      "answer": "Kuznets",
      "score": 0.9826610684394836
    },
    {
      "answer": "Kuznets",
      "score": 0.9410179853439331
    },
    {
      "answer": "Kuznets",
      "score": 0.9216645956039429
    },
    {
      "answer": "Kuznets",
      "score": 0.8255460858345032
    },
    {
      "answer": "Kuznets",
      "score": 0.8634052276611328
    },
    {
      "answer": "Kuznets",
      "score": 0.817849338054657
    },
    {
      "answer": "Kuznets",
      "score": 0.8124185800552368
    }
  ],
  "6935": [
    {
      "answer": "Kuznets curve",
      "score": 0.9861410856246948
    }
  ],
  "6936": [
    {
      "answer": "very weak",
      "score": 0.9899299144744873
    }
  ],
  "6937": [
    {
      "answer": "income inequality will eventually decrease",
      "score": 0.8594862222671509
    }
  ],
  "6938": [],
  "6939": [
    {
      "answer": "1970s",
      "score": 0.9862692952156067
    }
  ],
  "6940": [
    {
      "answer": "1970s",
      "score": 0.981105387210846
    }
  ],
  "6941": [
    {
      "answer": "service sector",
      "score": 0.9509356021881104
    }
  ],
  "6942": [
    {
      "answer": "service sector",
      "score": 0.955232560634613
    }
  ],
  "6943": [
    {
      "answer": "Kuznets",
      "score": 0.9723754525184631
    },
    {
      "answer": "Kuznets",
      "score": 0.91117262840271
    },
    {
      "answer": "Kuznets",
      "score": 0.869305431842804
    },
    {
      "answer": "Kuznets",
      "score": 0.7772789597511292
    },
    {
      "answer": "Kuznets",
      "score": 0.8007926344871521
    },
    {
      "answer": "Kuznets",
      "score": 0.7340700626373291
    },
    {
      "answer": "Kuznets",
      "score": 0.7263050079345703
    }
  ],
  "6944": [
    {
      "answer": "Wealth concentration",
      "score": 0.9659053087234497
    }
  ],
  "6945": [
    {
      "answer": "those who already hold wealth have the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth",
      "score": 0.8893606662750244
    }
  ],
  "6946": [
    {
      "answer": "return of capital (r)",
      "score": 0.8747984766960144
    }
  ],
  "6947": [
    {
      "answer": "return of capital",
      "score": 0.9575642347335815
    }
  ],
  "6948": [
    {
      "answer": "in the possession of already-wealthy individuals or entities",
      "score": 0.9297006130218506
    }
  ],
  "6949": [
    {
      "answer": "those who already hold wealth",
      "score": 0.866598904132843
    }
  ],
  "6950": [
    {
      "answer": "wealth condensation",
      "score": 0.9918595552444458
    }
  ],
  "6951": [
    {
      "answer": "Thomas Piketty",
      "score": 0.9962813854217529
    }
  ],
  "6952": [
    {
      "answer": "higher returns",
      "score": 0.9764795303344727
    }
  ],
  "6953": [
    {
      "answer": "Wealth concentration",
      "score": 0.9444048404693604
    }
  ],
  "6954": [],
  "6955": [
    {
      "answer": "wealth condensation",
      "score": 0.728165864944458
    }
  ],
  "6956": [
    {
      "answer": "wealth condensation",
      "score": 0.6420503854751587
    }
  ],
  "6957": [
    {
      "answer": "in the possession of already-wealthy individuals or entities",
      "score": 0.8924289345741272
    }
  ],
  "6958": [
    {
      "answer": "Economist",
      "score": 0.9537419676780701
    }
  ],
  "6959": [
    {
      "answer": "market forces",
      "score": 0.9812415838241577
    }
  ],
  "6960": [
    {
      "answer": "rare and desired skills",
      "score": 0.8410356044769287
    },
    {
      "answer": "wealth creation",
      "score": 0.8893088102340698
    }
  ],
  "6961": [
    {
      "answer": "political power",
      "score": 0.9927773475646973
    }
  ],
  "6962": [
    {
      "answer": "rent-seeking",
      "score": 0.7024628520011902
    },
    {
      "answer": "rent-seeking",
      "score": 0.9581316113471985
    }
  ],
  "6963": [
    {
      "answer": "Economist",
      "score": 0.9140844941139221
    }
  ],
  "6964": [
    {
      "answer": "market forces",
      "score": 0.9585256576538086
    },
    {
      "answer": "rent-seeking",
      "score": 0.5658481121063232
    }
  ],
  "6965": [
    {
      "answer": "wealth creation, greater productivity",
      "score": 0.632733166217804
    }
  ],
  "6966": [
    {
      "answer": "political power",
      "score": 0.9931468963623047
    }
  ],
  "6967": [
    {
      "answer": "rent-seeking",
      "score": 0.6971754431724548
    },
    {
      "answer": "rent-seeking",
      "score": 0.9653494954109192
    }
  ],
  "6968": [
    {
      "answer": "inequality",
      "score": 0.9790315628051758
    }
  ],
  "6969": [
    {
      "answer": "higher rates of health and social problems",
      "score": 0.6442402601242065
    }
  ],
  "6970": [
    {
      "answer": "life expectancy",
      "score": 0.993880569934845
    }
  ],
  "6971": [
    {
      "answer": "inequality",
      "score": 0.9835372567176819
    }
  ],
  "6972": [
    {
      "answer": "lower",
      "score": 0.7476912140846252
    }
  ],
  "6973": [
    {
      "answer": "inequality",
      "score": 0.9753814339637756
    }
  ],
  "6974": [],
  "6975": [
    {
      "answer": "life expectancy",
      "score": 0.988703191280365
    }
  ],
  "6976": [
    {
      "answer": "inequality",
      "score": 0.9640113711357117
    }
  ],
  "6977": [
    {
      "answer": "lower",
      "score": 0.7549451589584351
    }
  ],
  "6978": [
    {
      "answer": "2013",
      "score": 0.9840046167373657
    }
  ],
  "6979": [
    {
      "answer": "rising inequality",
      "score": 0.9785939455032349
    }
  ],
  "6980": [
    {
      "answer": "negative",
      "score": 0.9860600233078003
    }
  ],
  "6981": [
    {
      "answer": "Unemployment",
      "score": 0.7336506843566895
    }
  ],
  "6982": [
    {
      "answer": "economic growth",
      "score": 0.6152774095535278
    },
    {
      "answer": "economic growth",
      "score": 0.9861955642700195
    }
  ],
  "6983": [
    {
      "answer": "2013",
      "score": 0.9809184074401855
    }
  ],
  "6984": [
    {
      "answer": "inequality",
      "score": 0.9862046241760254
    },
    {
      "answer": "inequality",
      "score": 0.6518827080726624
    }
  ],
  "6985": [
    {
      "answer": "self-esteem",
      "score": 0.7172641754150391
    }
  ],
  "6986": [
    {
      "answer": "negative",
      "score": 0.9791393280029297
    }
  ],
  "6987": [
    {
      "answer": "economic growth",
      "score": 0.7452561855316162
    },
    {
      "answer": "economic growth",
      "score": 0.9481228590011597
    }
  ],
  "6988": [
    {
      "answer": "British",
      "score": 0.9703008532524109
    }
  ],
  "6989": [
    {
      "answer": "obesity, mental illness, homicides, teenage births, incarceration, child conflict, drug use",
      "score": 0.8031384944915771
    }
  ],
  "6990": [
    {
      "answer": "lower",
      "score": 0.925493597984314
    }
  ],
  "6991": [
    {
      "answer": "equality",
      "score": 0.7555986642837524
    }
  ],
  "6992": [
    {
      "answer": "23",
      "score": 0.9920430779457092
    }
  ],
  "6993": [
    {
      "answer": "British",
      "score": 0.9444077014923096
    }
  ],
  "6994": [
    {
      "answer": "obesity, mental illness, homicides, teenage births, incarceration, child conflict, drug use",
      "score": 0.6240543127059937
    }
  ],
  "6995": [],
  "6996": [
    {
      "answer": "social problems",
      "score": 0.6649086475372314
    }
  ],
  "6997": [
    {
      "answer": "23",
      "score": 0.9923478364944458
    }
  ],
  "6998": [
    {
      "answer": "better health",
      "score": 0.9904782176017761
    }
  ],
  "6999": [
    {
      "answer": "poorer countries",
      "score": 0.9780533909797668
    }
  ],
  "7000": [
    {
      "answer": "life expectancy",
      "score": 0.9924265146255493
    },
    {
      "answer": "Life expectancy",
      "score": 0.7404263019561768
    }
  ],
  "7001": [
    {
      "answer": "Americans",
      "score": 0.9933783411979675
    }
  ],
  "7002": [
    {
      "answer": "income was more equally distributed",
      "score": 0.8148870468139648
    }
  ],
  "7003": [
    {
      "answer": "better health",
      "score": 0.9862716197967529
    }
  ],
  "7004": [
    {
      "answer": "poorer countries",
      "score": 0.9714296460151672
    }
  ],
  "7005": [
    {
      "answer": "life expectancy",
      "score": 0.9821145534515381
    },
    {
      "answer": "Life expectancy",
      "score": 0.7053067684173584
    }
  ],
  "7006": [
    {
      "answer": "Americans",
      "score": 0.990166425704956
    }
  ],
  "7007": [],
  "7008": [
    {
      "answer": "income inequality",
      "score": 0.993471622467041
    }
  ],
  "7009": [
    {
      "answer": "Richard Wilkinson",
      "score": 0.9914243221282959
    }
  ],
  "7010": [
    {
      "answer": "nine",
      "score": 0.987649142742157
    }
  ],
  "7011": [
    {
      "answer": "states in the US",
      "score": 0.698809802532196
    }
  ],
  "7012": [
    {
      "answer": "income inequality",
      "score": 0.6923476457595825
    }
  ],
  "7013": [
    {
      "answer": "income inequality",
      "score": 0.988854169845581
    }
  ],
  "7014": [
    {
      "answer": "Richard Wilkinson and Kate Pickett",
      "score": 0.6938115954399109
    },
    {
      "answer": "UNICEF",
      "score": 0.7179445624351501
    }
  ],
  "7015": [
    {
      "answer": "nine",
      "score": 0.9783404469490051
    }
  ],
  "7016": [],
  "7017": [
    {
      "answer": "income inequality",
      "score": 0.832388162612915
    }
  ],
  "7018": [
    {
      "answer": "inequality",
      "score": 0.9762499332427979
    },
    {
      "answer": "inequality",
      "score": 0.5960714817047119
    }
  ],
  "7019": [
    {
      "answer": "homicides",
      "score": 0.6703329682350159
    },
    {
      "answer": "homicides",
      "score": 0.8995954394340515
    }
  ],
  "7020": [
    {
      "answer": "fifty",
      "score": 0.9895505309104919
    }
  ],
  "7021": [
    {
      "answer": "tenfold",
      "score": 0.9662004113197327
    }
  ],
  "7022": [
    {
      "answer": "differences in the amount of inequality in each province or state",
      "score": 0.9394614696502686
    }
  ],
  "7023": [
    {
      "answer": "inequality",
      "score": 0.9433110952377319
    }
  ],
  "7024": [
    {
      "answer": "homicides",
      "score": 0.7438949942588806
    }
  ],
  "7025": [
    {
      "answer": "fifty",
      "score": 0.9861927628517151
    }
  ],
  "7026": [
    {
      "answer": "tenfold",
      "score": 0.8785911202430725
    }
  ],
  "7027": [
    {
      "answer": "differences in the amount of inequality",
      "score": 0.9341172575950623
    }
  ],
  "7028": [
    {
      "answer": "the greatest good",
      "score": 0.9770158529281616
    }
  ],
  "7029": [
    {
      "answer": "distributive efficiency",
      "score": 0.996219277381897
    }
  ],
  "7030": [
    {
      "answer": "food, water",
      "score": 0.8849395513534546
    }
  ],
  "7031": [
    {
      "answer": "decreases",
      "score": 0.5752666592597961
    },
    {
      "answer": "decreases",
      "score": 0.9894870519638062
    }
  ],
  "7032": [
    {
      "answer": "higher aggregate utility",
      "score": 0.9944011569023132
    }
  ],
  "7033": [
    {
      "answer": "the greatest good",
      "score": 0.9788509607315063
    }
  ],
  "7034": [
    {
      "answer": "distributive efficiency",
      "score": 0.9962990283966064
    }
  ],
  "7035": [
    {
      "answer": "luxury items",
      "score": 0.9798089861869812
    }
  ],
  "7036": [
    {
      "answer": "decreases",
      "score": 0.5957757234573364
    },
    {
      "answer": "decreases",
      "score": 0.9729347229003906
    }
  ],
  "7037": [
    {
      "answer": "higher aggregate utility",
      "score": 0.9930631518363953
    }
  ],
  "7038": [
    {
      "answer": "consumption",
      "score": 0.9881477952003479
    },
    {
      "answer": "consumption",
      "score": 0.8852434754371643
    },
    {
      "answer": "consumption",
      "score": 0.8604264259338379
    },
    {
      "answer": "consumption",
      "score": 0.8152316212654114
    },
    {
      "answer": "consumption",
      "score": 0.8809869289398193
    },
    {
      "answer": "consumption",
      "score": 0.8771599531173706
    },
    {
      "answer": "consumption",
      "score": 0.8481136560440063
    },
    {
      "answer": "consumption",
      "score": 0.7292336821556091
    },
    {
      "answer": "consumption",
      "score": 0.836395800113678
    }
  ],
  "7039": [
    {
      "answer": "libertarian",
      "score": 0.9938564896583557
    }
  ],
  "7040": [
    {
      "answer": "2001",
      "score": 0.9895832538604736
    }
  ],
  "7041": [
    {
      "answer": "Thomas B. Edsall",
      "score": 0.9919319748878479
    }
  ],
  "7042": [
    {
      "answer": "journalist",
      "score": 0.9897903800010681
    }
  ],
  "7043": [
    {
      "answer": "consumption",
      "score": 0.8523306846618652
    },
    {
      "answer": "consumption",
      "score": 0.737399160861969
    },
    {
      "answer": "consumption",
      "score": 0.7691754102706909
    },
    {
      "answer": "consumption",
      "score": 0.6655483245849609
    },
    {
      "answer": "consumption",
      "score": 0.7715471386909485
    },
    {
      "answer": "consumption",
      "score": 0.7698063254356384
    },
    {
      "answer": "consumption",
      "score": 0.7068566679954529
    },
    {
      "answer": "consumption",
      "score": 0.6320229768753052
    },
    {
      "answer": "consumption",
      "score": 0.6991046071052551
    }
  ],
  "7044": [
    {
      "answer": "libertarian",
      "score": 0.9923871755599976
    }
  ],
  "7045": [
    {
      "answer": "2001",
      "score": 0.9456754326820374
    }
  ],
  "7046": [
    {
      "answer": "Thomas B. Edsall",
      "score": 0.9883061647415161
    }
  ],
  "7047": [
    {
      "answer": "journalist",
      "score": 0.9908097982406616
    }
  ],
  "7048": [
    {
      "answer": "Central Banking economist",
      "score": 0.6257400512695312
    }
  ],
  "7049": [
    {
      "answer": "systematic economic inequalities",
      "score": 0.9917196035385132
    }
  ],
  "7050": [
    {
      "answer": "Financial crisis of 2007\u201308",
      "score": 0.994860053062439
    }
  ],
  "7051": [
    {
      "answer": "easier credit",
      "score": 0.9849054217338562
    }
  ],
  "7052": [
    {
      "answer": "unsustainable monetary stimulation",
      "score": 0.974435567855835
    }
  ],
  "7053": [],
  "7054": [
    {
      "answer": "systematic economic inequalities",
      "score": 0.9784242510795593
    }
  ],
  "7055": [
    {
      "answer": "Financial crisis of 2007\u201308",
      "score": 0.974450945854187
    }
  ],
  "7056": [
    {
      "answer": "easier credit",
      "score": 0.9252012968063354
    }
  ],
  "7057": [
    {
      "answer": "unsustainable monetary stimulation",
      "score": 0.9298959970474243
    }
  ],
  "7058": [
    {
      "answer": "inequality in wealth and income",
      "score": 0.98359215259552
    }
  ],
  "7059": [
    {
      "answer": "quality of a country's institutions",
      "score": 0.9644169807434082
    },
    {
      "answer": "high levels of education",
      "score": 0.9776383638381958
    }
  ],
  "7060": [
    {
      "answer": "declines",
      "score": 0.992445170879364
    }
  ],
  "7061": [
    {
      "answer": "higher GDP growth",
      "score": 0.9795291423797607
    }
  ],
  "7062": [
    {
      "answer": "The poor and the middle class",
      "score": 0.9727277159690857
    }
  ],
  "7063": [
    {
      "answer": "inequality in wealth and income",
      "score": 0.8492242693901062
    }
  ],
  "7064": [
    {
      "answer": "quality of a country's institutions",
      "score": 0.9633556008338928
    },
    {
      "answer": "high levels of education",
      "score": 0.975550651550293
    }
  ],
  "7065": [
    {
      "answer": "declines",
      "score": 0.98529052734375
    }
  ],
  "7066": [
    {
      "answer": "higher GDP growth",
      "score": 0.966489315032959
    }
  ],
  "7067": [
    {
      "answer": "poor and the middle class",
      "score": 0.9547802209854126
    }
  ],
  "7068": [
    {
      "answer": "economists",
      "score": 0.851636528968811
    }
  ],
  "7069": [
    {
      "answer": "economic growth",
      "score": 0.9750287532806396
    },
    {
      "answer": "economic growth",
      "score": 0.7814643979072571
    },
    {
      "answer": "economic growth",
      "score": 0.8092819452285767
    }
  ],
  "7070": [
    {
      "answer": "subsequent long-run economic growth",
      "score": 0.9513858556747437
    }
  ],
  "7071": [
    {
      "answer": "it is a waste of resources",
      "score": 0.8623155355453491
    },
    {
      "answer": "generates redistributive pressures and subsequent distortions",
      "score": 0.9581443071365356
    },
    {
      "answer": "drives people to poverty",
      "score": 0.916092574596405
    },
    {
      "answer": "constrains liquidity limiting labor mobility",
      "score": 0.9405576586723328
    },
    {
      "answer": "erodes self-esteem promoting social dislocation, unrest and conflict",
      "score": 0.9290411472320557
    }
  ],
  "7072": [
    {
      "answer": "inequality-associated effects",
      "score": 0.9337158203125
    }
  ],
  "7073": [],
  "7074": [
    {
      "answer": "economic growth",
      "score": 0.9451453685760498
    },
    {
      "answer": "economic growth",
      "score": 0.752395510673523
    },
    {
      "answer": "economic growth",
      "score": 0.7818567752838135
    }
  ],
  "7075": [
    {
      "answer": "economic growth",
      "score": 0.9368386268615723
    }
  ],
  "7076": [
    {
      "answer": "generates redistributive pressures and subsequent distortions",
      "score": 0.9175602793693542
    },
    {
      "answer": "drives people to poverty",
      "score": 0.8521550893783569
    },
    {
      "answer": "constrains liquidity limiting labor mobility",
      "score": 0.872006893157959
    },
    {
      "answer": "erodes self-esteem promoting social dislocation, unrest and conflict",
      "score": 0.8693668842315674
    }
  ],
  "7077": [
    {
      "answer": "unemployment",
      "score": 0.652151346206665
    },
    {
      "answer": "Unemployment",
      "score": 0.5575290322303772
    },
    {
      "answer": "unemployment",
      "score": 0.897039532661438
    }
  ],
  "7078": [
    {
      "answer": "both global inequality and inequality within countries prevent growth by limiting aggregate demand",
      "score": 0.9355291128158569
    }
  ],
  "7079": [
    {
      "answer": "limiting aggregate demand",
      "score": 0.9870674014091492
    }
  ],
  "7080": [
    {
      "answer": "human capital",
      "score": 0.6299152374267578
    },
    {
      "answer": "human capital",
      "score": 0.6405768394470215
    }
  ],
  "7081": [
    {
      "answer": "increasing importance of human capital in development",
      "score": 0.9682004451751709
    }
  ],
  "7082": [
    {
      "answer": "education",
      "score": 0.9934868812561035
    }
  ],
  "7083": [],
  "7084": [],
  "7085": [
    {
      "answer": "global inequality",
      "score": 0.5910602807998657
    },
    {
      "answer": "human capital",
      "score": 0.6205265522003174
    }
  ],
  "7086": [
    {
      "answer": "increasing importance of human capital",
      "score": 0.973981499671936
    }
  ],
  "7087": [
    {
      "answer": "1993",
      "score": 0.9902294278144836
    }
  ],
  "7088": [
    {
      "answer": "detrimental",
      "score": 0.9797358512878418
    }
  ],
  "7089": [
    {
      "answer": "channels through which inequality may affect economic growth",
      "score": 0.8172997832298279
    }
  ],
  "7090": [
    {
      "answer": "fertility",
      "score": 0.6029950380325317
    },
    {
      "answer": "redistributive taxation",
      "score": 0.9181126952171326
    }
  ],
  "7091": [
    {
      "answer": "politically and socially unstable",
      "score": 0.9853156805038452
    }
  ],
  "7092": [
    {
      "answer": "1993",
      "score": 0.9911342859268188
    }
  ],
  "7093": [
    {
      "answer": "detrimental",
      "score": 0.97687166929245
    }
  ],
  "7094": [
    {
      "answer": "channels through which inequality may affect economic growth",
      "score": 0.8321028351783752
    }
  ],
  "7095": [
    {
      "answer": "human capital formation",
      "score": 0.6713680624961853
    },
    {
      "answer": "human capital formation",
      "score": 0.8806805610656738
    },
    {
      "answer": "education, experience, and apprenticeship",
      "score": 0.7250263690948486
    }
  ],
  "7096": [
    {
      "answer": "politically and socially unstable",
      "score": 0.9826594591140747
    }
  ],
  "7097": [
    {
      "answer": "Harvard",
      "score": 0.9952986836433411
    }
  ],
  "7098": [
    {
      "answer": "growth",
      "score": 0.9789053201675415
    }
  ],
  "7099": [
    {
      "answer": "reduce growth",
      "score": 0.9728854894638062
    }
  ],
  "7100": [
    {
      "answer": "encourage growth",
      "score": 0.9563841819763184
    }
  ],
  "7101": [
    {
      "answer": "1960",
      "score": 0.9895139932632446
    }
  ],
  "7102": [
    {
      "answer": "Harvard",
      "score": 0.9876536726951599
    }
  ],
  "7103": [
    {
      "answer": "growth",
      "score": 0.9419419169425964
    }
  ],
  "7104": [
    {
      "answer": "encourage growth",
      "score": 0.9285093545913696
    }
  ],
  "7105": [
    {
      "answer": "encourage growth",
      "score": 0.9371358156204224
    }
  ],
  "7106": [
    {
      "answer": "1960",
      "score": 0.9757422208786011
    }
  ],
  "7107": [
    {
      "answer": "Kuznets curve hypothesis",
      "score": 0.991966724395752
    },
    {
      "answer": "Kuznets curve hypothesis",
      "score": 0.6639982461929321
    }
  ],
  "7108": [
    {
      "answer": "increases",
      "score": 0.9589340090751648
    }
  ],
  "7109": [
    {
      "answer": "Thomas Piketty",
      "score": 0.9958562850952148
    }
  ],
  "7110": [
    {
      "answer": "Economist",
      "score": 0.9886922836303711
    }
  ],
  "7111": [
    {
      "answer": "violent economic and political shocks",
      "score": 0.9728652834892273
    }
  ],
  "7112": [
    {
      "answer": "Kuznets curve hypothesis",
      "score": 0.9665307998657227
    },
    {
      "answer": "Kuznets curve hypothesis",
      "score": 0.6320830583572388
    }
  ],
  "7113": [
    {
      "answer": "decreases",
      "score": 0.9925414323806763
    }
  ],
  "7114": [
    {
      "answer": "Thomas Piketty",
      "score": 0.958196759223938
    }
  ],
  "7115": [
    {
      "answer": "Economist",
      "score": 0.9833425283432007
    }
  ],
  "7116": [
    {
      "answer": "violent economic and political shocks",
      "score": 0.9725396037101746
    }
  ],
  "7117": [
    {
      "answer": "1970s",
      "score": 0.9890483021736145
    }
  ],
  "7118": [
    {
      "answer": "reduced consumer demand",
      "score": 0.9961587190628052
    }
  ],
  "7119": [
    {
      "answer": "growth has risen with increased income inequality",
      "score": 0.89766526222229
    }
  ],
  "7120": [
    {
      "answer": "several years",
      "score": 0.9898267984390259
    }
  ],
  "7121": [
    {
      "answer": "equality in the income distribution",
      "score": 0.9837333559989929
    }
  ],
  "7122": [
    {
      "answer": "1970s",
      "score": 0.9895087480545044
    }
  ],
  "7123": [
    {
      "answer": "reduced consumer demand",
      "score": 0.9964338541030884
    }
  ],
  "7124": [
    {
      "answer": "growth has risen with increased income inequality",
      "score": 0.8846385478973389
    }
  ],
  "7125": [
    {
      "answer": "several years",
      "score": 0.9874197840690613
    }
  ],
  "7126": [
    {
      "answer": "equality in the income distribution",
      "score": 0.9728372693061829
    }
  ],
  "7127": [
    {
      "answer": "special efforts",
      "score": 0.98907470703125
    }
  ],
  "7128": [
    {
      "answer": "existing level of inequality",
      "score": 0.9750376343727112
    }
  ],
  "7129": [
    {
      "answer": "60 years",
      "score": 0.9790430068969727
    }
  ],
  "7130": [
    {
      "answer": "United Nations",
      "score": 0.9864987134933472
    }
  ],
  "7131": [
    {
      "answer": "reducing poverty",
      "score": 0.9819338917732239
    }
  ],
  "7132": [
    {
      "answer": "special efforts",
      "score": 0.9807752370834351
    }
  ],
  "7133": [
    {
      "answer": "existing level of inequality",
      "score": 0.8768316507339478
    }
  ],
  "7134": [
    {
      "answer": "60 years",
      "score": 0.9166305661201477
    }
  ],
  "7135": [
    {
      "answer": "United Nations",
      "score": 0.963146448135376
    }
  ],
  "7136": [
    {
      "answer": "reducing poverty",
      "score": 0.9798257350921631
    }
  ],
  "7137": [
    {
      "answer": "land and housing",
      "score": 0.9783194065093994
    }
  ],
  "7138": [
    {
      "answer": "various associations and other arrangements",
      "score": 0.9855653047561646
    }
  ],
  "7139": [
    {
      "answer": "extra-legal",
      "score": 0.9881097078323364
    }
  ],
  "7140": [
    {
      "answer": "200",
      "score": 0.9917832612991333
    }
  ],
  "7141": [
    {
      "answer": "government land",
      "score": 0.9543106555938721
    }
  ],
  "7142": [
    {
      "answer": "land and housing",
      "score": 0.9400843381881714
    }
  ],
  "7143": [
    {
      "answer": "various associations and other arrangements",
      "score": 0.9828157424926758
    }
  ],
  "7144": [
    {
      "answer": "extra-legal",
      "score": 0.9865092635154724
    }
  ],
  "7145": [
    {
      "answer": "200",
      "score": 0.9923708438873291
    }
  ],
  "7146": [
    {
      "answer": "government land",
      "score": 0.9687317609786987
    }
  ],
  "7147": [
    {
      "answer": "affordable housing",
      "score": 0.9840330481529236
    }
  ],
  "7148": [
    {
      "answer": "quality rental units",
      "score": 0.9864603281021118
    }
  ],
  "7149": [],
  "7150": [
    {
      "answer": "gentrification",
      "score": 0.7926633358001709
    }
  ],
  "7151": [
    {
      "answer": "ad valorem property tax policy",
      "score": 0.9943642020225525
    }
  ],
  "7152": [
    {
      "answer": "affordable housing",
      "score": 0.9798977375030518
    }
  ],
  "7153": [
    {
      "answer": "quality rental units",
      "score": 0.9835546016693115
    }
  ],
  "7154": [
    {
      "answer": "income inequality",
      "score": 0.9713301658630371
    }
  ],
  "7155": [
    {
      "answer": "income inequality",
      "score": 0.5119791030883789
    },
    {
      "answer": "gentrification",
      "score": 0.6254624724388123
    }
  ],
  "7156": [
    {
      "answer": "ad valorem property tax policy",
      "score": 0.9927770495414734
    }
  ],
  "7157": [
    {
      "answer": "shared by everyone",
      "score": 0.9831240177154541
    }
  ],
  "7158": [
    {
      "answer": "finances",
      "score": 0.9648697972297668
    }
  ],
  "7159": [
    {
      "answer": "aspirational consumption",
      "score": 0.9907207489013672
    }
  ],
  "7160": [
    {
      "answer": "taking on debt",
      "score": 0.9854772090911865
    }
  ],
  "7161": [
    {
      "answer": "economic instability",
      "score": 0.976101279258728
    }
  ],
  "7162": [
    {
      "answer": "shared by everyone",
      "score": 0.9783927798271179
    }
  ],
  "7163": [
    {
      "answer": "finances",
      "score": 0.9399226903915405
    }
  ],
  "7164": [
    {
      "answer": "aspirational consumption",
      "score": 0.9840825796127319
    }
  ],
  "7165": [
    {
      "answer": "taking on debt",
      "score": 0.9752072095870972
    }
  ],
  "7166": [
    {
      "answer": "even greater inequality and potential economic instability",
      "score": 0.9009221196174622
    }
  ],
  "7167": [],
  "7168": [
    {
      "answer": "multiplier",
      "score": 0.9324167966842651
    },
    {
      "answer": "the amount of environmental degradation",
      "score": 0.7980374693870544
    }
  ],
  "7169": [
    {
      "answer": "this",
      "score": 0.7967666387557983
    }
  ],
  "7170": [
    {
      "answer": "If (as WWF argued), population levels would start to drop to a sustainable level (1/3 of current levels, so about 2 billion people), human inequality can be addressed/corrected, while still not resulting in an increase of environmental damage.",
      "score": 0.8685061931610107
    }
  ],
  "7171": [],
  "7172": [
    {
      "answer": "lower",
      "score": 0.8966420292854309
    },
    {
      "answer": "lower",
      "score": 0.8480982780456543
    }
  ],
  "7173": [
    {
      "answer": "this as well",
      "score": 0.6433180570602417
    }
  ],
  "7174": [],
  "7175": [
    {
      "answer": "If (as WWF argued), population levels would start to drop to a sustainable level (1/3 of current levels, so about 2 billion people), human inequality can be addressed/corrected, while still not resulting in an increase of environmental damage.",
      "score": 0.8956056833267212
    }
  ],
  "7176": [
    {
      "answer": "private ownership of the means of production",
      "score": 0.9887529611587524
    }
  ],
  "7177": [
    {
      "answer": "vast disparities in wealth",
      "score": 0.9187060594558716
    }
  ],
  "7178": [
    {
      "answer": "wage or salary",
      "score": 0.9823040962219238
    }
  ],
  "7179": [
    {
      "answer": "socially",
      "score": 0.9893497824668884
    }
  ],
  "7180": [
    {
      "answer": "reflective of individual contributions to the social product",
      "score": 0.5903756022453308
    }
  ],
  "7181": [
    {
      "answer": "private ownership of the means of production",
      "score": 0.9651056528091431
    }
  ],
  "7182": [
    {
      "answer": "disparities in wealth",
      "score": 0.9450797438621521
    }
  ],
  "7183": [
    {
      "answer": "wage or salary",
      "score": 0.9080440998077393
    }
  ],
  "7184": [
    {
      "answer": "socially",
      "score": 0.9870014190673828
    }
  ],
  "7185": [
    {
      "answer": "reflective of individual contributions to the social product",
      "score": 0.7239812612533569
    }
  ],
  "7186": [
    {
      "answer": "Robert Nozick",
      "score": 0.9943554997444153
    }
  ],
  "7187": [
    {
      "answer": "taxation",
      "score": 0.9684827327728271
    }
  ],
  "7188": [
    {
      "answer": "force",
      "score": 0.7345031499862671
    },
    {
      "answer": "force",
      "score": 0.9857995510101318
    },
    {
      "answer": "force",
      "score": 0.6143736243247986
    }
  ],
  "7189": [
    {
      "answer": "forceful taking of property",
      "score": 0.9948832988739014
    }
  ],
  "7190": [
    {
      "answer": "when they improve society as a whole",
      "score": 0.9490530490875244
    }
  ],
  "7191": [
    {
      "answer": "Robert Nozick",
      "score": 0.9925082921981812
    }
  ],
  "7192": [
    {
      "answer": "force",
      "score": 0.7083836793899536
    },
    {
      "answer": "taxation",
      "score": 0.8270584940910339
    },
    {
      "answer": "force",
      "score": 0.5305894017219543
    },
    {
      "answer": "force",
      "score": 0.6071445345878601
    }
  ],
  "7193": [
    {
      "answer": "force",
      "score": 0.764529287815094
    },
    {
      "answer": "force",
      "score": 0.9846301674842834
    },
    {
      "answer": "force",
      "score": 0.6399039030075073
    }
  ],
  "7194": [
    {
      "answer": "forceful taking of property",
      "score": 0.9909162521362305
    }
  ],
  "7195": [
    {
      "answer": "when they improve society as a whole",
      "score": 0.9540706872940063
    }
  ],
  "7196": [
    {
      "answer": "capability deprivation",
      "score": 0.9950284957885742
    }
  ],
  "7197": [
    {
      "answer": "the end itself",
      "score": 0.597719669342041
    }
  ],
  "7198": [
    {
      "answer": "to \u201cwid[en] people\u2019s choices and the level of their achieved well-being",
      "score": 0.92499840259552
    }
  ],
  "7199": [
    {
      "answer": "increasing functionings",
      "score": 0.8966023921966553
    }
  ],
  "7200": [
    {
      "answer": "the ability to pursue valued goals",
      "score": 0.9824850559234619
    }
  ],
  "7201": [
    {
      "answer": "capability deprivation",
      "score": 0.9958759546279907
    }
  ],
  "7202": [
    {
      "answer": "the end itself",
      "score": 0.6744064688682556
    }
  ],
  "7203": [
    {
      "answer": "to \u201cwid[en] people\u2019s choices and the level of their achieved well-being",
      "score": 0.9206790924072266
    }
  ],
  "7204": [],
  "7205": [
    {
      "answer": "the ability to pursue valued goals",
      "score": 0.9854380488395691
    }
  ],
  "7206": [
    {
      "answer": "deprived of earning as much income as they would otherwise",
      "score": 0.9171454310417175
    }
  ],
  "7207": [
    {
      "answer": "earn as much as a healthy young man",
      "score": 0.9040663838386536
    }
  ],
  "7208": [
    {
      "answer": "gender roles and customs",
      "score": 0.9867076873779297
    }
  ],
  "7209": [
    {
      "answer": "fear of their lives",
      "score": 0.9735746383666992
    }
  ],
  "7210": [
    {
      "answer": "better relevant income",
      "score": 0.9796401858329773
    }
  ],
  "7211": [
    {
      "answer": "deprived of earning as much income as they would otherwise",
      "score": 0.8187527060508728
    }
  ],
  "7212": [
    {
      "answer": "earn as much as a healthy young man",
      "score": 0.7265182733535767
    }
  ],
  "7213": [
    {
      "answer": "gender roles and customs",
      "score": 0.9434470534324646
    }
  ],
  "7214": [
    {
      "answer": "fear of their lives",
      "score": 0.8732821941375732
    }
  ],
  "7215": [
    {
      "answer": "better relevant income",
      "score": 0.9786784052848816
    }
  ],
  "7216": [
    {
      "answer": "private research",
      "score": 0.9913560152053833
    }
  ],
  "7217": [
    {
      "answer": "1890",
      "score": 0.9872497916221619
    }
  ],
  "7218": [
    {
      "answer": "seven",
      "score": 0.9930459856987
    }
  ],
  "7219": [
    {
      "answer": "four",
      "score": 0.9906687140464783
    }
  ],
  "7220": [
    {
      "answer": "5,000",
      "score": 0.9169296026229858
    },
    {
      "answer": "15,000",
      "score": 0.8733940124511719
    }
  ],
  "7221": [
    {
      "answer": "University of Chicago",
      "score": 0.9841985702514648
    },
    {
      "answer": "University of Chicago",
      "score": 0.9627645015716553
    }
  ],
  "7222": [
    {
      "answer": "College",
      "score": 0.935810387134552
    }
  ],
  "7223": [],
  "7224": [
    {
      "answer": "University of Chicago",
      "score": 0.8269819617271423
    }
  ],
  "7225": [
    {
      "answer": "Pritzker School of Medicine",
      "score": 0.8610846996307373
    },
    {
      "answer": "University of Chicago Booth School of Business",
      "score": 0.8617421388626099
    },
    {
      "answer": "Law School",
      "score": 0.8325269818305969
    },
    {
      "answer": "School of Social Service Administration",
      "score": 0.8052310943603516
    },
    {
      "answer": "Harris School of Public Policy Studies",
      "score": 0.9027523994445801
    },
    {
      "answer": "Graham School of Continuing Liberal and Professional Studies",
      "score": 0.8299712538719177
    },
    {
      "answer": "Divinity School",
      "score": 0.8398107290267944
    }
  ],
  "7226": [
    {
      "answer": "Chicago school of economics",
      "score": 0.9683672189712524
    },
    {
      "answer": "Chicago school of sociology",
      "score": 0.9699225425720215
    },
    {
      "answer": "law and economics movement in legal analysis",
      "score": 0.9695817828178406
    },
    {
      "answer": "Chicago school of literary criticism",
      "score": 0.9662702679634094
    },
    {
      "answer": "Chicago school of religion",
      "score": 0.9544937610626221
    },
    {
      "answer": "behavioralism school of political science",
      "score": 0.9286506772041321
    }
  ],
  "7227": [
    {
      "answer": "Chicago's physics department",
      "score": 0.9229028820991516
    }
  ],
  "7228": [
    {
      "answer": "Chicago",
      "score": 0.73200523853302
    },
    {
      "answer": "Chicago",
      "score": 0.6012401580810547
    },
    {
      "answer": "Chicago",
      "score": 0.5989519357681274
    },
    {
      "answer": "Chicago",
      "score": 0.5908172130584717
    },
    {
      "answer": "Chicago",
      "score": 0.5777156352996826
    },
    {
      "answer": "Chicago",
      "score": 0.7695231437683105
    }
  ],
  "7229": [
    {
      "answer": "University of Chicago",
      "score": 0.9807421565055847
    }
  ],
  "7230": [
    {
      "answer": "2020",
      "score": 0.9931974411010742
    }
  ],
  "7231": [
    {
      "answer": "the world's first man-made, self-sustaining nuclear reaction",
      "score": 0.7856794595718384
    }
  ],
  "7232": [
    {
      "answer": "nuclear reaction",
      "score": 0.9644002318382263
    }
  ],
  "7233": [
    {
      "answer": "physics",
      "score": 0.9813515543937683
    }
  ],
  "7234": [
    {
      "answer": "University of Chicago",
      "score": 0.9654909372329712
    }
  ],
  "7235": [
    {
      "answer": "2020",
      "score": 0.9945657253265381
    }
  ],
  "7236": [
    {
      "answer": "American Baptist Education Society",
      "score": 0.9943825006484985
    }
  ],
  "7237": [
    {
      "answer": "John D. Rockefeller",
      "score": 0.985999584197998
    }
  ],
  "7238": [
    {
      "answer": "William Rainey Harper",
      "score": 0.9934134483337402
    }
  ],
  "7239": [
    {
      "answer": "1891",
      "score": 0.984771192073822
    }
  ],
  "7240": [
    {
      "answer": "1892",
      "score": 0.9891258478164673
    }
  ],
  "7241": [
    {
      "answer": "John D. Rockefeller",
      "score": 0.6865147352218628
    }
  ],
  "7242": [
    {
      "answer": "1890",
      "score": 0.992669939994812
    }
  ],
  "7243": [
    {
      "answer": "1891",
      "score": 0.9834295511245728
    }
  ],
  "7244": [
    {
      "answer": "1900",
      "score": 0.9883667826652527
    }
  ],
  "7245": [
    {
      "answer": "1892",
      "score": 0.9429832100868225
    }
  ],
  "7246": [
    {
      "answer": "Marshall Field",
      "score": 0.9878162145614624
    },
    {
      "answer": "Marshall Field",
      "score": 0.929093599319458
    }
  ],
  "7247": [
    {
      "answer": "Silas B. Cobb",
      "score": 0.9936739206314087
    }
  ],
  "7248": [
    {
      "answer": "Cobb Lecture Hall",
      "score": 0.9863407015800476
    }
  ],
  "7249": [
    {
      "answer": "$100,000",
      "score": 0.9757580757141113
    }
  ],
  "7250": [
    {
      "answer": "Charles L. Hutchinson",
      "score": 0.9509457945823669
    }
  ],
  "7251": [
    {
      "answer": "1890",
      "score": 0.9859125018119812
    }
  ],
  "7252": [
    {
      "answer": "1890",
      "score": 0.9874808192253113
    }
  ],
  "7253": [
    {
      "answer": "Silas B. Cobb",
      "score": 0.9789811968803406
    }
  ],
  "7254": [
    {
      "answer": "Hutchinson Commons",
      "score": 0.5523083209991455
    },
    {
      "answer": "Walker Museum",
      "score": 0.9321601390838623
    }
  ],
  "7255": [
    {
      "answer": "John D. Rockefeller",
      "score": 0.9540534615516663
    }
  ],
  "7256": [
    {
      "answer": "Des Moines College",
      "score": 0.9465915560722351
    },
    {
      "answer": "Kalamazoo College",
      "score": 0.9440698623657227
    },
    {
      "answer": "Butler University",
      "score": 0.9423209428787231
    },
    {
      "answer": "Stetson University",
      "score": 0.93415367603302
    }
  ],
  "7257": [
    {
      "answer": "1896",
      "score": 0.9901238083839417
    }
  ],
  "7258": [],
  "7259": [
    {
      "answer": "Several University of Chicago professors",
      "score": 0.9665945172309875
    }
  ],
  "7260": [
    {
      "answer": "1910",
      "score": 0.9927988052368164
    }
  ],
  "7261": [
    {
      "answer": "1890s",
      "score": 0.9914084076881409
    }
  ],
  "7262": [
    {
      "answer": "Mount Carroll",
      "score": 0.9935212135314941
    }
  ],
  "7263": [
    {
      "answer": "Des Moines College",
      "score": 0.6966156959533691
    },
    {
      "answer": "Kalamazoo College",
      "score": 0.6794014573097229
    },
    {
      "answer": "Butler University",
      "score": 0.6831302642822266
    },
    {
      "answer": "Stetson University",
      "score": 0.6842333078384399
    }
  ],
  "7264": [
    {
      "answer": "1896",
      "score": 0.9683259725570679
    }
  ],
  "7265": [
    {
      "answer": "Robert Maynard Hutchins",
      "score": 0.9852685332298279
    }
  ],
  "7266": [
    {
      "answer": "1929",
      "score": 0.9735062718391418
    }
  ],
  "7267": [
    {
      "answer": "24-year",
      "score": 0.9945724606513977
    }
  ],
  "7268": [
    {
      "answer": "to emphasize academics over athletics",
      "score": 0.9688240885734558
    }
  ],
  "7269": [
    {
      "answer": "Common Core",
      "score": 0.9447267055511475
    }
  ],
  "7270": [
    {
      "answer": "1929",
      "score": 0.9685620069503784
    }
  ],
  "7271": [],
  "7272": [
    {
      "answer": "in an attempt to emphasize academics over athletics",
      "score": 0.9271491169929504
    }
  ],
  "7273": [
    {
      "answer": "1933",
      "score": 0.9905118346214294
    }
  ],
  "7274": [
    {
      "answer": "Robert Maynard Hutchins",
      "score": 0.9859579801559448
    }
  ],
  "7275": [
    {
      "answer": "1950s",
      "score": 0.9893075823783875
    }
  ],
  "7276": [
    {
      "answer": "increasing crime and poverty",
      "score": 0.990816593170166
    }
  ],
  "7277": [
    {
      "answer": "after their second year",
      "score": 0.913905143737793
    }
  ],
  "7278": [
    {
      "answer": "Hyde Park",
      "score": 0.9831619262695312
    },
    {
      "answer": "Hyde Park",
      "score": 0.710504412651062
    }
  ],
  "7279": [
    {
      "answer": "allowed very young students to attend college",
      "score": 0.9515328407287598
    },
    {
      "answer": "enabled to transfer automatically to the University of Chicago after their second year",
      "score": 0.7066419124603271
    }
  ],
  "7280": [
    {
      "answer": "1950s",
      "score": 0.9845989942550659
    }
  ],
  "7281": [
    {
      "answer": "increasing crime and poverty",
      "score": 0.9641687273979187
    }
  ],
  "7282": [
    {
      "answer": "declined",
      "score": 0.9793256521224976
    }
  ],
  "7283": [
    {
      "answer": "Hyde Park",
      "score": 0.9950780272483826
    },
    {
      "answer": "Hyde Park",
      "score": 0.8120911121368408
    }
  ],
  "7284": [
    {
      "answer": "early entrant program",
      "score": 0.9908093810081482
    }
  ],
  "7285": [
    {
      "answer": "1962",
      "score": 0.9872093200683594
    }
  ],
  "7286": [
    {
      "answer": "the university's off-campus rental policies",
      "score": 0.9450036883354187
    }
  ],
  "7287": [
    {
      "answer": "1967",
      "score": 0.986397922039032
    }
  ],
  "7288": [
    {
      "answer": "two-page",
      "score": 0.9945555925369263
    }
  ],
  "7289": [
    {
      "answer": "social and political action",
      "score": 0.6200566291809082
    },
    {
      "answer": "To perform its mission in the society, a university must sustain an extraordinary environment of freedom of inquiry and maintain an independence from political fashions, passions, and pressures",
      "score": 0.8129011392593384
    }
  ],
  "7290": [
    {
      "answer": "1960s",
      "score": 0.9950438737869263
    }
  ],
  "7291": [
    {
      "answer": "George Beadle",
      "score": 0.9711440205574036
    }
  ],
  "7292": [
    {
      "answer": "George Beadle",
      "score": 0.9840840101242065
    }
  ],
  "7293": [
    {
      "answer": "1967",
      "score": 0.6807719469070435
    },
    {
      "answer": "2000s",
      "score": 0.765771746635437
    }
  ],
  "7294": [
    {
      "answer": "1967",
      "score": 0.9924525618553162
    }
  ],
  "7295": [
    {
      "answer": "mid-2000s",
      "score": 0.9792596101760864
    }
  ],
  "7296": [
    {
      "answer": "Milton Friedman Institute",
      "score": 0.9731040000915527
    }
  ],
  "7297": [
    {
      "answer": "$200 million",
      "score": 0.9697549343109131
    }
  ],
  "7298": [
    {
      "answer": "Chicago Theological Seminary",
      "score": 0.9534128904342651
    }
  ],
  "7299": [
    {
      "answer": "David G. Booth",
      "score": 0.9938929080963135
    }
  ],
  "7300": [
    {
      "answer": "mid-2000s",
      "score": 0.557128369808197
    }
  ],
  "7301": [
    {
      "answer": "2008",
      "score": 0.9842243194580078
    }
  ],
  "7302": [
    {
      "answer": "$200 million",
      "score": 0.9628998637199402
    }
  ],
  "7303": [
    {
      "answer": "David G. Booth",
      "score": 0.9673346281051636
    }
  ],
  "7304": [
    {
      "answer": "2008",
      "score": 0.9826670289039612
    }
  ],
  "7305": [
    {
      "answer": "Main Quadrangles",
      "score": 0.9337221384048462
    },
    {
      "answer": "Main Quadrangles",
      "score": 0.8285516500473022
    },
    {
      "answer": "Main Quadrangles",
      "score": 0.8513681888580322
    }
  ],
  "7306": [
    {
      "answer": "six",
      "score": 0.993567168712616
    }
  ],
  "7307": [
    {
      "answer": "Shepley, Rutan and Coolidge",
      "score": 0.929013192653656
    },
    {
      "answer": "Holabird & Roche",
      "score": 0.9228748083114624
    }
  ],
  "7308": [
    {
      "answer": "Magdalen Tower",
      "score": 0.9775946140289307
    }
  ],
  "7309": [
    {
      "answer": "Christ Church Hall",
      "score": 0.9776172637939453
    }
  ],
  "7310": [
    {
      "answer": "Main Quadrangles",
      "score": 0.696726381778717
    },
    {
      "answer": "Main Quadrangles",
      "score": 0.8946189880371094
    },
    {
      "answer": "Main Quadrangles",
      "score": 0.9399212598800659
    }
  ],
  "7311": [
    {
      "answer": "Cobb",
      "score": 0.6631715297698975
    },
    {
      "answer": "Cobb",
      "score": 0.887825608253479
    },
    {
      "answer": "Shepley",
      "score": 0.9582346081733704
    },
    {
      "answer": "Rutan and Coolidge",
      "score": 0.9529814720153809
    },
    {
      "answer": "Holabird & Roche",
      "score": 0.9357144236564636
    }
  ],
  "7312": [
    {
      "answer": "Main Quadrangles",
      "score": 0.9706476330757141
    },
    {
      "answer": "Main Quadrangles",
      "score": 0.9173988103866577
    },
    {
      "answer": "Main Quadrangles",
      "score": 0.9372726678848267
    }
  ],
  "7313": [
    {
      "answer": "two",
      "score": 0.9912403225898743
    }
  ],
  "7314": [
    {
      "answer": "1940s",
      "score": 0.9921544194221497
    }
  ],
  "7315": [
    {
      "answer": "Eero Saarinen",
      "score": 0.9919030666351318
    }
  ],
  "7316": [
    {
      "answer": "School of Social Service Administration",
      "score": 0.9325664639472961
    }
  ],
  "7317": [
    {
      "answer": "Harris School of Public Policy Studies",
      "score": 0.7310962080955505
    }
  ],
  "7318": [
    {
      "answer": "2003",
      "score": 0.9742063283920288
    }
  ],
  "7319": [
    {
      "answer": "1940s",
      "score": 0.9902672171592712
    }
  ],
  "7320": [
    {
      "answer": "1955",
      "score": 0.9673855304718018
    }
  ],
  "7321": [],
  "7322": [
    {
      "answer": "north and south of the Midway",
      "score": 0.9426347613334656
    }
  ],
  "7323": [
    {
      "answer": "2001",
      "score": 0.9838696122169495
    }
  ],
  "7324": [
    {
      "answer": "Singapore",
      "score": 0.9152397513389587
    },
    {
      "answer": "London",
      "score": 0.9178423285484314
    },
    {
      "answer": "downtown Streeterville neighborhood of Chicago",
      "score": 0.8574430346488953
    },
    {
      "answer": "Beijing",
      "score": 0.7469135522842407
    }
  ],
  "7325": [
    {
      "answer": "Seine",
      "score": 0.9932548999786377
    }
  ],
  "7326": [
    {
      "answer": "2010",
      "score": 0.9917795062065125
    }
  ],
  "7327": [
    {
      "answer": "Renmin University",
      "score": 0.9802407026290894
    }
  ],
  "7328": [
    {
      "answer": "2015",
      "score": 0.9699417352676392
    }
  ],
  "7329": [
    {
      "answer": "Singapore",
      "score": 0.7821632027626038
    },
    {
      "answer": "London",
      "score": 0.7819865942001343
    },
    {
      "answer": "Beijing",
      "score": 0.6152795553207397
    },
    {
      "answer": "New Delhi, India",
      "score": 0.5682313442230225
    }
  ],
  "7330": [
    {
      "answer": "The Center in Paris",
      "score": 0.9539702534675598
    }
  ],
  "7331": [
    {
      "answer": "Center in Paris",
      "score": 0.9920477867126465
    }
  ],
  "7332": [
    {
      "answer": "2014",
      "score": 0.9858958125114441
    }
  ],
  "7333": [
    {
      "answer": "2015",
      "score": 0.976291298866272
    }
  ],
  "7334": [
    {
      "answer": "board of trustees",
      "score": 0.963768482208252
    },
    {
      "answer": "Board of Trustees",
      "score": 0.8354707956314087
    },
    {
      "answer": "Board of Trustees",
      "score": 0.7671971321105957
    }
  ],
  "7335": [
    {
      "answer": "50",
      "score": 0.9932945370674133
    }
  ],
  "7336": [
    {
      "answer": "fourteen",
      "score": 0.9947659969329834
    }
  ],
  "7337": [
    {
      "answer": "Andrew Alper",
      "score": 0.9942107200622559
    }
  ],
  "7338": [
    {
      "answer": "Daniel Diermeier",
      "score": 0.993648886680603
    }
  ],
  "7339": [
    {
      "answer": "board of trustees",
      "score": 0.9840633273124695
    },
    {
      "answer": "Board of Trustees",
      "score": 0.8859540820121765
    },
    {
      "answer": "Board of Trustees",
      "score": 0.9061238765716553
    }
  ],
  "7340": [
    {
      "answer": "long-term development and plans of the university",
      "score": 0.9835518598556519
    },
    {
      "answer": "manages fundraising efforts",
      "score": 0.891284704208374
    }
  ],
  "7341": [
    {
      "answer": "oversees the long-term development and plans of the university",
      "score": 0.9534966349601746
    },
    {
      "answer": "manages fundraising efforts",
      "score": 0.9785557985305786
    }
  ],
  "7342": [
    {
      "answer": "board of trustees",
      "score": 0.8457664847373962
    },
    {
      "answer": "Board of Trustees",
      "score": 0.9615718126296997
    },
    {
      "answer": "Board of Trustees",
      "score": 0.9746447801589966
    }
  ],
  "7343": [
    {
      "answer": "Daniel Diermeier",
      "score": 0.819022536277771
    }
  ],
  "7344": [
    {
      "answer": "The Higher Learning Commission",
      "score": 0.993413507938385
    }
  ],
  "7345": [
    {
      "answer": "four",
      "score": 0.9922056794166565
    }
  ],
  "7346": [
    {
      "answer": "seven",
      "score": 0.9914947748184204
    }
  ],
  "7347": [
    {
      "answer": "four",
      "score": 0.991378664970398
    }
  ],
  "7348": [
    {
      "answer": "seven",
      "score": 0.9920702576637268
    }
  ],
  "7349": [
    {
      "answer": "Argonne National Laboratory",
      "score": 0.9755184650421143
    }
  ],
  "7350": [
    {
      "answer": "Higher Learning Commission",
      "score": 0.9934478998184204
    }
  ],
  "7351": [
    {
      "answer": "the College, four divisions of graduate research",
      "score": 0.7410592436790466
    }
  ],
  "7352": [
    {
      "answer": "50",
      "score": 0.9933692812919617
    }
  ],
  "7353": [
    {
      "answer": "28",
      "score": 0.9932124614715576
    }
  ],
  "7354": [
    {
      "answer": "five",
      "score": 0.9922758936882019
    }
  ],
  "7355": [
    {
      "answer": "New Collegiate Division",
      "score": 0.7079424858093262
    },
    {
      "answer": "New Collegiate Division",
      "score": 0.9951581954956055
    }
  ],
  "7356": [
    {
      "answer": "28",
      "score": 0.9903948903083801
    }
  ],
  "7357": [
    {
      "answer": "50",
      "score": 0.9611392617225647
    },
    {
      "answer": "28",
      "score": 0.9468783140182495
    }
  ],
  "7358": [
    {
      "answer": "University of Chicago",
      "score": 0.9871544241905212
    }
  ],
  "7359": [
    {
      "answer": "University of Chicago",
      "score": 0.9889816641807556
    }
  ],
  "7360": [
    {
      "answer": "five",
      "score": 0.9942896366119385
    }
  ],
  "7361": [
    {
      "answer": "Common Core",
      "score": 0.986236572265625
    }
  ],
  "7362": [
    {
      "answer": "17",
      "score": 0.9929296374320984
    }
  ],
  "7363": [
    {
      "answer": "rigorous, intense",
      "score": 0.9198973178863525
    }
  ],
  "7364": [
    {
      "answer": "demanding standards",
      "score": 0.9511454105377197
    }
  ],
  "7365": [
    {
      "answer": "15 courses",
      "score": 0.8411722183227539
    },
    {
      "answer": "demonstrated proficiency in a foreign language",
      "score": 0.8818413615226746
    }
  ],
  "7366": [
    {
      "answer": "2012-2013",
      "score": 0.9935865998268127
    }
  ],
  "7367": [
    {
      "answer": "15",
      "score": 0.9917631149291992
    }
  ],
  "7368": [
    {
      "answer": "demonstrated proficiency in a foreign language",
      "score": 0.983814001083374
    }
  ],
  "7369": [
    {
      "answer": "demanding standards",
      "score": 0.9668971300125122
    },
    {
      "answer": "heavy workload",
      "score": 0.9700417518615723
    },
    {
      "answer": "academic difficulty",
      "score": 0.9737138748168945
    }
  ],
  "7370": [
    {
      "answer": "University of Chicago Laboratory Schools",
      "score": 0.928997814655304
    }
  ],
  "7371": [
    {
      "answer": "Sonia Shankman Orthogenic School",
      "score": 0.8903878927230835
    }
  ],
  "7372": [
    {
      "answer": "four",
      "score": 0.9935530424118042
    }
  ],
  "7373": [
    {
      "answer": "four public charter schools",
      "score": 0.9311060905456543
    }
  ],
  "7374": [
    {
      "answer": "University of Chicago campus",
      "score": 0.93379807472229
    }
  ],
  "7375": [
    {
      "answer": "University of Chicago Laboratory Schools",
      "score": 0.9624534845352173
    },
    {
      "answer": "Sonia Shankman Orthogenic School",
      "score": 0.9303995370864868
    },
    {
      "answer": "four public charter schools on the South Side of Chicago",
      "score": 0.9130216836929321
    },
    {
      "answer": "Hyde Park Day School",
      "score": 0.8029794096946716
    }
  ],
  "7376": [
    {
      "answer": "University of Chicago Laboratory Schools",
      "score": 0.9513824582099915
    }
  ],
  "7377": [
    {
      "answer": "University of Chicago School Mathematics Project",
      "score": 0.9589645266532898
    }
  ],
  "7378": [
    {
      "answer": "University of Chicago School Mathematics Project",
      "score": 0.8860219717025757
    }
  ],
  "7379": [
    {
      "answer": "University of Chicago",
      "score": 0.7495743632316589
    },
    {
      "answer": "University of Chicago",
      "score": 0.990262508392334
    }
  ],
  "7380": [
    {
      "answer": "six",
      "score": 0.9917100071907043
    }
  ],
  "7381": [
    {
      "answer": "9.8 million",
      "score": 0.9883949160575867
    }
  ],
  "7382": [
    {
      "answer": "Regenstein Library",
      "score": 0.880286455154419
    }
  ],
  "7383": [
    {
      "answer": "2011",
      "score": 0.9889034628868103
    }
  ],
  "7384": [
    {
      "answer": "1.3 million",
      "score": 0.9595222473144531
    }
  ],
  "7385": [
    {
      "answer": "University of Chicago",
      "score": 0.9793127775192261
    }
  ],
  "7386": [
    {
      "answer": "University of Chicago",
      "score": 0.9919501543045044
    }
  ],
  "7387": [
    {
      "answer": "University of Chicago",
      "score": 0.9903192520141602
    }
  ],
  "7388": [
    {
      "answer": "2011",
      "score": 0.9912689924240112
    }
  ],
  "7389": [
    {
      "answer": "12",
      "score": 0.9891785383224487
    }
  ],
  "7390": [
    {
      "answer": "113",
      "score": 0.9895904660224915
    }
  ],
  "7391": [
    {
      "answer": "Oriental Institute",
      "score": 0.942175030708313
    }
  ],
  "7392": [
    {
      "answer": "Fermilab",
      "score": 0.9443516731262207
    }
  ],
  "7393": [
    {
      "answer": "Sunspot, New Mexico",
      "score": 0.974554181098938
    }
  ],
  "7394": [
    {
      "answer": "113",
      "score": 0.978520393371582
    }
  ],
  "7395": [
    {
      "answer": "12",
      "score": 0.9805046916007996
    }
  ],
  "7396": [
    {
      "answer": "Oriental Institute",
      "score": 0.988868236541748
    }
  ],
  "7397": [
    {
      "answer": "Woods Hole, Mass",
      "score": 0.9337728023529053
    }
  ],
  "7398": [
    {
      "answer": "Chicago",
      "score": 0.581848680973053
    },
    {
      "answer": "Chicago",
      "score": 0.6474749445915222
    },
    {
      "answer": "Chicago",
      "score": 0.9421801567077637
    }
  ],
  "7399": [
    {
      "answer": "shaping ideas about the free market",
      "score": 0.9468059539794922
    }
  ],
  "7400": [
    {
      "answer": "Chicago Pile-1",
      "score": 0.984858512878418
    }
  ],
  "7401": [
    {
      "answer": "Miller\u2013Urey experiment",
      "score": 0.9740910530090332
    }
  ],
  "7402": [
    {
      "answer": "1953",
      "score": 0.9894310235977173
    }
  ],
  "7403": [
    {
      "answer": "REM sleep was discovered",
      "score": 0.9124594926834106
    }
  ],
  "7404": [
    {
      "answer": "1947",
      "score": 0.9875143766403198
    }
  ],
  "7405": [
    {
      "answer": "radiocarbon dating",
      "score": 0.9121533632278442
    }
  ],
  "7406": [
    {
      "answer": "Miller\u2013Urey experiment",
      "score": 0.9876742362976074
    }
  ],
  "7407": [
    {
      "answer": "The university's sociology department",
      "score": 0.6775170564651489
    },
    {
      "answer": "Chicago school of sociology",
      "score": 0.6507102847099304
    }
  ],
  "7408": [
    {
      "answer": "1933",
      "score": 0.9851654767990112
    }
  ],
  "7409": [
    {
      "answer": "2000",
      "score": 0.9802733659744263
    },
    {
      "answer": "2000",
      "score": 0.8264482021331787
    }
  ],
  "7410": [
    {
      "answer": "1996",
      "score": 0.987448513507843
    }
  ],
  "7411": [
    {
      "answer": "2002",
      "score": 0.9757903218269348
    }
  ],
  "7412": [
    {
      "answer": "Several thousand",
      "score": 0.9869931936264038
    }
  ],
  "7413": [
    {
      "answer": "music composition",
      "score": 0.6141811609268188
    },
    {
      "answer": "Cinema & Media studies",
      "score": 0.7261949777603149
    },
    {
      "answer": "Cinema & Media studies",
      "score": 0.8485151529312134
    }
  ],
  "7414": [
    {
      "answer": "art history",
      "score": 0.9030115604400635
    },
    {
      "answer": "Cinema & Media studies",
      "score": 0.7917102575302124
    },
    {
      "answer": "theater & performance studies",
      "score": 0.8176668286323547
    }
  ],
  "7415": [
    {
      "answer": "art history",
      "score": 0.9163384437561035
    },
    {
      "answer": "Cinema & Media studies",
      "score": 0.7693399786949158
    },
    {
      "answer": "theater & performance studies",
      "score": 0.8303471803665161
    }
  ],
  "7416": [
    {
      "answer": "dramatic, music, and visual arts",
      "score": 0.9875702857971191
    }
  ],
  "7417": [
    {
      "answer": "2012",
      "score": 0.9899641871452332
    }
  ],
  "7418": [
    {
      "answer": "5,792",
      "score": 0.993869960308075
    }
  ],
  "7419": [
    {
      "answer": "3,468",
      "score": 0.9809715151786804
    }
  ],
  "7420": [
    {
      "answer": "5,984",
      "score": 0.9834176898002625
    }
  ],
  "7421": [
    {
      "answer": "5,792",
      "score": 0.9235439300537109
    },
    {
      "answer": "15,244",
      "score": 0.862461268901825
    }
  ],
  "7422": [
    {
      "answer": "international students",
      "score": 0.9730366468429565
    }
  ],
  "7423": [
    {
      "answer": "5,792",
      "score": 0.99132239818573
    }
  ],
  "7424": [
    {
      "answer": "3,468",
      "score": 0.9702047109603882
    }
  ],
  "7425": [
    {
      "answer": "3,468",
      "score": 0.9745801687240601
    }
  ],
  "7426": [
    {
      "answer": "5,984",
      "score": 0.9605730772018433
    }
  ],
  "7427": [
    {
      "answer": "2015",
      "score": 0.745621919631958
    },
    {
      "answer": "2015",
      "score": 0.9688664078712463
    }
  ],
  "7428": [
    {
      "answer": "University Athletic Association",
      "score": 0.9820458292961121
    }
  ],
  "7429": [
    {
      "answer": "Division III",
      "score": 0.9780577421188354
    },
    {
      "answer": "Division III",
      "score": 0.9040207862854004
    }
  ],
  "7430": [
    {
      "answer": "Big Ten",
      "score": 0.9972395896911621
    }
  ],
  "7431": [
    {
      "answer": "Jay Berwanger",
      "score": 0.9935939908027649
    }
  ],
  "7432": [
    {
      "answer": "University President Robert Maynard Hutchins de-emphasized varsity athletics in 1939 and dropped football",
      "score": 0.9813076257705688
    }
  ],
  "7433": [
    {
      "answer": "founding member",
      "score": 0.801037073135376
    }
  ],
  "7434": [
    {
      "answer": "1935",
      "score": 0.979814887046814
    },
    {
      "answer": "1935",
      "score": 0.8507997393608093
    }
  ],
  "7435": [
    {
      "answer": "1935",
      "score": 0.7762200832366943
    },
    {
      "answer": "1935",
      "score": 0.8596518039703369
    }
  ],
  "7436": [
    {
      "answer": "1935",
      "score": 0.8152925968170166
    },
    {
      "answer": "1935",
      "score": 0.9529644846916199
    }
  ],
  "7437": [
    {
      "answer": "1939",
      "score": 0.9734488725662231
    }
  ],
  "7438": [
    {
      "answer": "400",
      "score": 0.9906116127967834
    }
  ],
  "7439": [],
  "7440": [
    {
      "answer": "University of Chicago College Bowl Team",
      "score": 0.9648188352584839
    }
  ],
  "7441": [
    {
      "answer": "Doc Films",
      "score": 0.9759207367897034
    }
  ],
  "7442": [
    {
      "answer": "Off-Off Campus",
      "score": 0.9884888529777527
    }
  ],
  "7443": [
    {
      "answer": "400",
      "score": 0.9897311329841614
    }
  ],
  "7444": [
    {
      "answer": "Recognized Student Organizations",
      "score": 0.9341204166412354
    }
  ],
  "7445": [
    {
      "answer": "2013-14",
      "score": 0.9554789066314697
    },
    {
      "answer": "2014-2015",
      "score": 0.9371546506881714
    }
  ],
  "7446": [
    {
      "answer": "2013-14",
      "score": 0.903468668460846
    },
    {
      "answer": "2014-2015",
      "score": 0.8920444250106812
    }
  ],
  "7447": [
    {
      "answer": "2013-14",
      "score": 0.971916913986206
    },
    {
      "answer": "2014-2015",
      "score": 0.9698761105537415
    }
  ],
  "7448": [
    {
      "answer": "graduate and undergraduate students",
      "score": 0.9855835437774658
    }
  ],
  "7449": [
    {
      "answer": "President",
      "score": 0.9426073431968689
    }
  ],
  "7450": [
    {
      "answer": "two",
      "score": 0.9910544753074646
    }
  ],
  "7451": [
    {
      "answer": "$2 million",
      "score": 0.9783685207366943
    }
  ],
  "7452": [
    {
      "answer": "University of Chicago Scavenger Hunt",
      "score": 0.9169012308120728
    },
    {
      "answer": "Model UN",
      "score": 0.9274173378944397
    },
    {
      "answer": "academic teams",
      "score": 0.8661395311355591
    },
    {
      "answer": "sports club",
      "score": 0.8785533905029297
    },
    {
      "answer": "arts groups",
      "score": 0.861039400100708
    }
  ],
  "7453": [
    {
      "answer": "graduate and undergraduate",
      "score": 0.9934755563735962
    }
  ],
  "7454": [
    {
      "answer": "graduate and undergraduate students",
      "score": 0.5939478874206543
    },
    {
      "answer": "members from their respective academic unit",
      "score": 0.7816436290740967
    }
  ],
  "7455": [
    {
      "answer": "President",
      "score": 0.9642714262008667
    }
  ],
  "7456": [
    {
      "answer": "greater than $2 million",
      "score": 0.9648393988609314
    }
  ],
  "7457": [
    {
      "answer": "fifteen",
      "score": 0.9902641773223877
    }
  ],
  "7458": [
    {
      "answer": "seven",
      "score": 0.9903087019920349
    }
  ],
  "7459": [
    {
      "answer": "Alpha Phi Omega",
      "score": 0.9358975291252136
    }
  ],
  "7460": [
    {
      "answer": "Four",
      "score": 0.9931309819221497
    }
  ],
  "7461": [
    {
      "answer": "ten",
      "score": 0.9922284483909607
    }
  ],
  "7462": [
    {
      "answer": "fifteen",
      "score": 0.9647454023361206
    }
  ],
  "7463": [
    {
      "answer": "seven",
      "score": 0.9812244176864624
    }
  ],
  "7464": [
    {
      "answer": "University of Chicago Interfraternity Council",
      "score": 0.9679767489433289
    }
  ],
  "7465": [
    {
      "answer": "National Panhellenic Conference",
      "score": 0.9268082976341248
    },
    {
      "answer": "University of Chicago Interfraternity Council",
      "score": 0.6715172529220581
    }
  ],
  "7466": [
    {
      "answer": "2002",
      "score": 0.9804938435554504
    }
  ],
  "7467": [
    {
      "answer": "May",
      "score": 0.9855288863182068
    }
  ],
  "7468": [
    {
      "answer": "1987",
      "score": 0.9932745695114136
    }
  ],
  "7469": [
    {
      "answer": "Festival of the Arts",
      "score": 0.9882305860519409
    }
  ],
  "7470": [
    {
      "answer": "Kuviasungnerk/Kangeiko",
      "score": 0.9461662173271179
    }
  ],
  "7471": [
    {
      "answer": "Summer Breeze",
      "score": 0.9659996032714844
    }
  ],
  "7472": [
    {
      "answer": "Festival of the Arts (FOTA)",
      "score": 0.9232437014579773
    }
  ],
  "7473": [
    {
      "answer": "Festival of the Arts",
      "score": 0.9751519560813904
    }
  ],
  "7474": [
    {
      "answer": "University of Chicago Scavenger Hunt",
      "score": 0.6591882109642029
    },
    {
      "answer": "Kuviasungnerk/Kangeiko",
      "score": 0.8033296465873718
    }
  ],
  "7475": [
    {
      "answer": "Summer Breeze",
      "score": 0.9611438512802124
    }
  ],
  "7476": [
    {
      "answer": "Latke-Hamantash",
      "score": 0.988150954246521
    }
  ],
  "7477": [
    {
      "answer": "Satya Nadella",
      "score": 0.9929848313331604
    }
  ],
  "7478": [
    {
      "answer": "Larry Ellison",
      "score": 0.9957805275917053
    }
  ],
  "7479": [
    {
      "answer": "Larry Ellison",
      "score": 0.9956060647964478
    }
  ],
  "7480": [
    {
      "answer": "Larry Ellison",
      "score": 0.9815536737442017
    }
  ],
  "7481": [
    {
      "answer": "Jon Corzine",
      "score": 0.8544567823410034
    },
    {
      "answer": "James O. McKinsey",
      "score": 0.9234822988510132
    }
  ],
  "7482": [
    {
      "answer": "Larry Ellison",
      "score": 0.9961093068122864
    }
  ],
  "7483": [
    {
      "answer": "Satya Nadella",
      "score": 0.9568571448326111
    },
    {
      "answer": "Jon Corzine",
      "score": 0.917975902557373
    }
  ],
  "7484": [
    {
      "answer": "Jon Corzine",
      "score": 0.9231659770011902
    }
  ],
  "7485": [
    {
      "answer": "Adam Silver",
      "score": 0.9935907125473022
    }
  ],
  "7486": [
    {
      "answer": "Satya Nadella",
      "score": 0.8873703479766846
    },
    {
      "answer": "Larry Ellison",
      "score": 0.9833796620368958
    }
  ],
  "7487": [
    {
      "answer": "Saul Alinsky",
      "score": 0.9947302341461182
    }
  ],
  "7488": [
    {
      "answer": "Saul Alinsky",
      "score": 0.9863736033439636
    }
  ],
  "7489": [
    {
      "answer": "David Axelrod",
      "score": 0.9932305812835693
    }
  ],
  "7490": [
    {
      "answer": "Marek Belka",
      "score": 0.9856502413749695
    }
  ],
  "7491": [
    {
      "answer": "Eliot Ness",
      "score": 0.994770884513855
    }
  ],
  "7492": [
    {
      "answer": "David Axelrod",
      "score": 0.9065064191818237
    }
  ],
  "7493": [
    {
      "answer": "David Axelrod",
      "score": 0.9875118732452393
    }
  ],
  "7494": [
    {
      "answer": "William Lyon Mackenzie King",
      "score": 0.9839990139007568
    }
  ],
  "7495": [
    {
      "answer": "Marek Belka",
      "score": 0.9870303869247437
    }
  ],
  "7496": [
    {
      "answer": "Masaaki Shirakawa",
      "score": 0.9662961959838867
    }
  ],
  "7497": [
    {
      "answer": "Lauren Oliver",
      "score": 0.9867149591445923
    },
    {
      "answer": "Philip Roth",
      "score": 0.6112335920333862
    }
  ],
  "7498": [
    {
      "answer": "Philip Roth",
      "score": 0.9821186065673828
    }
  ],
  "7499": [
    {
      "answer": "Allan Bloom",
      "score": 0.9914870858192444
    }
  ],
  "7500": [
    {
      "answer": "Studs Terkel",
      "score": 0.9939249753952026
    }
  ],
  "7501": [
    {
      "answer": "Kurt Vonnegut",
      "score": 0.9845995903015137
    }
  ],
  "7502": [
    {
      "answer": "Saul Bellow",
      "score": 0.9868699312210083
    }
  ],
  "7503": [
    {
      "answer": "Allan Bloom",
      "score": 0.9868460893630981
    }
  ],
  "7504": [
    {
      "answer": "Studs Terkel",
      "score": 0.9897460341453552
    }
  ],
  "7505": [
    {
      "answer": "Lauren Oliver",
      "score": 0.9934537410736084
    }
  ],
  "7506": [
    {
      "answer": "Studs Terkel",
      "score": 0.9695348739624023
    }
  ],
  "7507": [
    {
      "answer": "Philip Glass",
      "score": 0.9934622049331665
    }
  ],
  "7508": [
    {
      "answer": "Katherine Dunham",
      "score": 0.9778724312782288
    }
  ],
  "7509": [
    {
      "answer": "Halo",
      "score": 0.988224983215332
    }
  ],
  "7510": [
    {
      "answer": "Alex Seropian",
      "score": 0.8644577264785767
    }
  ],
  "7511": [
    {
      "answer": "Roger Ebert",
      "score": 0.9885224103927612
    }
  ],
  "7512": [
    {
      "answer": "Katherine Dunham",
      "score": 0.9905762672424316
    }
  ],
  "7513": [
    {
      "answer": "Sarah Koenig",
      "score": 0.9379161596298218
    }
  ],
  "7514": [
    {
      "answer": "Carl Van Vechten",
      "score": 0.9927161931991577
    }
  ],
  "7515": [
    {
      "answer": "Mike Nichols",
      "score": 0.645392894744873
    }
  ],
  "7516": [
    {
      "answer": "Stanton Friedman",
      "score": 0.87095046043396
    }
  ],
  "7517": [
    {
      "answer": "John M. Grunsfeld",
      "score": 0.9795507192611694
    }
  ],
  "7518": [
    {
      "answer": "David Suzuki",
      "score": 0.9771261215209961
    }
  ],
  "7519": [
    {
      "answer": "John B. Goodenough",
      "score": 0.9938100576400757
    }
  ],
  "7520": [
    {
      "answer": "Clair Cameron Patterson",
      "score": 0.9927535057067871
    }
  ],
  "7521": [
    {
      "answer": "Carl Sagan",
      "score": 0.5656050443649292
    },
    {
      "answer": "Edwin Hubble",
      "score": 0.5602920055389404
    }
  ],
  "7522": [
    {
      "answer": "John M. Grunsfeld",
      "score": 0.9849838018417358
    }
  ],
  "7523": [
    {
      "answer": "John B. Goodenough",
      "score": 0.9845520257949829
    }
  ],
  "7524": [
    {
      "answer": "John B. Goodenough",
      "score": 0.993890643119812
    }
  ],
  "7525": [
    {
      "answer": "Paul Samuelson",
      "score": 0.974520742893219
    }
  ],
  "7526": [
    {
      "answer": "Milton Friedman",
      "score": 0.9516360759735107
    },
    {
      "answer": "Margaret Thatcher",
      "score": 0.8562447428703308
    }
  ],
  "7527": [
    {
      "answer": "Paul Samuelson",
      "score": 0.9960135221481323
    }
  ],
  "7528": [
    {
      "answer": "Eugene Fama",
      "score": 0.9954830408096313
    }
  ],
  "7529": [],
  "7530": [
    {
      "answer": "Ronald Reagan",
      "score": 0.9832947254180908
    }
  ],
  "7531": [
    {
      "answer": "Eugene Fama",
      "score": 0.9915326833724976
    }
  ],
  "7532": [
    {
      "answer": "Thomas Sowell",
      "score": 0.9633380770683289
    }
  ],
  "7533": [
    {
      "answer": "Herbert A. Simon",
      "score": 0.9903302192687988
    }
  ],
  "7534": [
    {
      "answer": "David Graeber",
      "score": 0.9748457670211792
    },
    {
      "answer": "Donald Johanson",
      "score": 0.9823775887489319
    }
  ],
  "7535": [
    {
      "answer": "Samuel Reshevsky",
      "score": 0.9898004531860352
    }
  ],
  "7536": [
    {
      "answer": "Samuel P. Huntington",
      "score": 0.9955095052719116
    }
  ],
  "7537": [
    {
      "answer": "David Graeber",
      "score": 0.8193224668502808
    },
    {
      "answer": "Donald Johanson",
      "score": 0.9806457757949829
    }
  ],
  "7538": [
    {
      "answer": "female hominid australopithecine",
      "score": 0.7356351613998413
    },
    {
      "answer": "Lucy",
      "score": 0.7256708741188049
    }
  ],
  "7539": [
    {
      "answer": "Donald Johanson",
      "score": 0.9929799437522888
    }
  ],
  "7540": [
    {
      "answer": "Samuel P. Huntington",
      "score": 0.9905984997749329
    }
  ],
  "7541": [
    {
      "answer": "John B. Watson",
      "score": 0.9933522939682007
    }
  ],
  "7542": [
    {
      "answer": "A. A. Michelson",
      "score": 0.9874945878982544
    }
  ],
  "7543": [
    {
      "answer": "Robert A. Millikan",
      "score": 0.9697625637054443
    }
  ],
  "7544": [
    {
      "answer": "Arthur H. Compton",
      "score": 0.9884727597236633
    }
  ],
  "7545": [
    {
      "answer": "Enrico Fermi",
      "score": 0.9475579857826233
    }
  ],
  "7546": [
    {
      "answer": "Maria Goeppert-Mayer",
      "score": 0.9942538738250732
    }
  ],
  "7547": [
    {
      "answer": "A. A. Michelson",
      "score": 0.9721822738647461
    }
  ],
  "7548": [
    {
      "answer": "A. A. Michelson",
      "score": 0.8510317206382751
    },
    {
      "answer": "Robert A. Millikan",
      "score": 0.5774297118186951
    }
  ],
  "7549": [
    {
      "answer": "Robert A. Millikan",
      "score": 0.9814128875732422
    }
  ],
  "7550": [
    {
      "answer": "Enrico Fermi",
      "score": 0.99007248878479
    }
  ],
  "7551": [
    {
      "answer": "Maria Goeppert-Mayer",
      "score": 0.5432054996490479
    }
  ],
  "7552": [
    {
      "answer": "James Henry Breasted",
      "score": 0.9926718473434448
    }
  ],
  "7553": [
    {
      "answer": "Alberto Calder\u00f3n",
      "score": 0.9943521022796631
    }
  ],
  "7554": [
    {
      "answer": "Ted Fujita",
      "score": 0.9879260063171387
    }
  ],
  "7555": [
    {
      "answer": "Glenn T. Seaborg",
      "score": 0.872748851776123
    },
    {
      "answer": "Yuan T. Lee",
      "score": 0.9008833169937134
    }
  ],
  "7556": [
    {
      "answer": "Charles Brenton Huggins",
      "score": 0.9445552825927734
    },
    {
      "answer": "Janet Rowley",
      "score": 0.9342212677001953
    }
  ],
  "7557": [
    {
      "answer": "Saul Bellow",
      "score": 0.9895633459091187
    }
  ],
  "7558": [
    {
      "answer": "James O. McKinsey",
      "score": 0.9897441864013672
    }
  ],
  "7559": [
    {
      "answer": "Yuan T. Lee",
      "score": 0.9479359984397888
    }
  ],
  "7560": [
    {
      "answer": "Yuan T. Lee",
      "score": 0.5919097661972046
    },
    {
      "answer": "Janet Rowley",
      "score": 0.9259864091873169
    }
  ],
  "7561": [
    {
      "answer": "Allan Bloom",
      "score": 0.9935011267662048
    }
  ],
  "7562": [
    {
      "answer": "Goldman Sachs",
      "score": 0.994399905204773
    }
  ],
  "7563": [
    {
      "answer": "Raghuram Rajan",
      "score": 0.9935926198959351
    }
  ],
  "7564": [
    {
      "answer": "David Bevington",
      "score": 0.9953590631484985
    }
  ],
  "7565": [
    {
      "answer": "John Mearsheimer",
      "score": 0.976958155632019
    },
    {
      "answer": "Robert Pape",
      "score": 0.9484590888023376
    }
  ],
  "7566": [
    {
      "answer": "Neil Shubin",
      "score": 0.9828888177871704
    },
    {
      "answer": "Paul Sereno",
      "score": 0.9835091829299927
    }
  ],
  "7567": [
    {
      "answer": "Hank Paulson",
      "score": 0.8779401183128357
    }
  ],
  "7568": [],
  "7569": [
    {
      "answer": "Raghuram Rajan",
      "score": 0.9930926561355591
    }
  ],
  "7570": [
    {
      "answer": "Steven Levitt",
      "score": 0.9912355542182922
    }
  ],
  "7571": [
    {
      "answer": "Hank Paulson",
      "score": 0.9819386601448059
    }
  ],
  "7572": [
    {
      "answer": "\u5143\u671d",
      "score": 0.8953218460083008
    }
  ],
  "7573": [
    {
      "answer": "Great Yuan",
      "score": 0.9141978025436401
    }
  ],
  "7574": [
    {
      "answer": "Kublai Khan",
      "score": 0.9930769205093384
    },
    {
      "answer": "Kublai Khan",
      "score": 0.9228037595748901
    }
  ],
  "7575": [
    {
      "answer": "Kublai Khan",
      "score": 0.9929174184799194
    },
    {
      "answer": "Kublai Khan",
      "score": 0.9281041026115417
    }
  ],
  "7576": [
    {
      "answer": "1271",
      "score": 0.9923897385597229
    }
  ],
  "7577": [],
  "7578": [
    {
      "answer": "Great Yuan",
      "score": 0.5815935730934143
    }
  ],
  "7579": [
    {
      "answer": "1368",
      "score": 0.7528502941131592
    },
    {
      "answer": "Genghisid",
      "score": 0.9266173243522644
    }
  ],
  "7580": [
    {
      "answer": "Kublai Khan",
      "score": 0.6706607341766357
    }
  ],
  "7581": [
    {
      "answer": "1271",
      "score": 0.9912983775138855
    }
  ],
  "7582": [
    {
      "answer": "Mongol Empire",
      "score": 0.9830421805381775
    },
    {
      "answer": "Mongol Empire",
      "score": 0.9617959260940552
    }
  ],
  "7583": [
    {
      "answer": "Song dynasty",
      "score": 0.9864563345909119
    }
  ],
  "7584": [
    {
      "answer": "Song dynasty",
      "score": 0.7406996488571167
    },
    {
      "answer": "Ming dynasty",
      "score": 0.9652848243713379
    }
  ],
  "7585": [
    {
      "answer": "Genghis Khan",
      "score": 0.9926916360855103
    }
  ],
  "7586": [
    {
      "answer": "Mongol Empire",
      "score": 0.9840839505195618
    },
    {
      "answer": "Mongol Empire",
      "score": 0.9619303941726685
    }
  ],
  "7587": [
    {
      "answer": "Song dynasty",
      "score": 0.9935163855552673
    }
  ],
  "7588": [
    {
      "answer": "Song dynasty",
      "score": 0.7998179197311401
    },
    {
      "answer": "Ming dynasty",
      "score": 0.966069221496582
    }
  ],
  "7589": [
    {
      "answer": "Genghis Khan",
      "score": 0.8559240102767944
    }
  ],
  "7590": [
    {
      "answer": "1271",
      "score": 0.9627323150634766
    },
    {
      "answer": "1271",
      "score": 0.9574531316757202
    }
  ],
  "7591": [
    {
      "answer": "Commentaries on the Classic of Changes (I Ching)",
      "score": 0.9184619784355164
    }
  ],
  "7592": [
    {
      "answer": "Dai \u00d6n Ulus",
      "score": 0.9327327609062195
    }
  ],
  "7593": [
    {
      "answer": "Great Mongol State",
      "score": 0.657133936882019
    },
    {
      "answer": "Great Mongol State",
      "score": 0.8895946741104126
    }
  ],
  "7594": [
    {
      "answer": "Great Khan",
      "score": 0.929792046546936
    },
    {
      "answer": "Great Khan",
      "score": 0.9520716667175293
    },
    {
      "answer": "Great Khan",
      "score": 0.9812250137329102
    },
    {
      "answer": "Great Khans",
      "score": 0.6461396217346191
    }
  ],
  "7595": [
    {
      "answer": "1271",
      "score": 0.9387161731719971
    },
    {
      "answer": "1271",
      "score": 0.9440063834190369
    }
  ],
  "7596": [
    {
      "answer": "Commentaries on the Classic of Changes (I Ching)",
      "score": 0.8819775581359863
    }
  ],
  "7597": [],
  "7598": [],
  "7599": [
    {
      "answer": "Great Khan",
      "score": 0.8490512371063232
    },
    {
      "answer": "Great Khan",
      "score": 0.893983006477356
    },
    {
      "answer": "Great Khan",
      "score": 0.8933173418045044
    },
    {
      "answer": "Great Khans",
      "score": 0.6480365991592407
    }
  ],
  "7600": [
    {
      "answer": "Mongol",
      "score": 0.9838395714759827
    },
    {
      "answer": "Turkic",
      "score": 0.9837311506271362
    }
  ],
  "7601": [
    {
      "answer": "1206",
      "score": 0.9802783131599426
    }
  ],
  "7602": [
    {
      "answer": "\u00d6gedei Khan",
      "score": 0.9811550974845886
    }
  ],
  "7603": [
    {
      "answer": "1251",
      "score": 0.9820840954780579
    }
  ],
  "7604": [
    {
      "answer": "Kublai",
      "score": 0.8466311097145081
    }
  ],
  "7605": [
    {
      "answer": "Mongol",
      "score": 0.8599123954772949
    },
    {
      "answer": "Turkic",
      "score": 0.9361673593521118
    }
  ],
  "7606": [
    {
      "answer": "1206",
      "score": 0.9860575795173645
    }
  ],
  "7607": [
    {
      "answer": "\u00d6gedei Khan",
      "score": 0.7343336343765259
    }
  ],
  "7608": [
    {
      "answer": "1251",
      "score": 0.9885507225990295
    }
  ],
  "7609": [
    {
      "answer": "sought the counsel of Chinese Buddhist and Confucian advisers",
      "score": 0.855128824710846
    }
  ],
  "7610": [
    {
      "answer": "Jin",
      "score": 0.9935755133628845
    }
  ],
  "7611": [
    {
      "answer": "Xiao Zhala",
      "score": 0.9649628400802612
    }
  ],
  "7612": [
    {
      "answer": "Shi Tianze",
      "score": 0.8557129502296448
    },
    {
      "answer": "Liu Heima",
      "score": 0.7020363807678223
    },
    {
      "answer": "Liu Heima",
      "score": 0.6186516880989075
    },
    {
      "answer": "Shi Tianze",
      "score": 0.7067574858665466
    },
    {
      "answer": "Shi Tianze",
      "score": 0.7388178110122681
    }
  ],
  "7613": [
    {
      "answer": "10,000",
      "score": 0.995581328868866
    }
  ],
  "7614": [
    {
      "answer": "3",
      "score": 0.8125496506690979
    },
    {
      "answer": "3",
      "score": 0.9652500748634338
    },
    {
      "answer": "three",
      "score": 0.5522152781486511
    }
  ],
  "7615": [
    {
      "answer": "Jin",
      "score": 0.9940260648727417
    }
  ],
  "7616": [
    {
      "answer": "Xiao Zhala",
      "score": 0.9576945304870605
    }
  ],
  "7617": [
    {
      "answer": "Shi Tianze",
      "score": 0.8268335461616516
    },
    {
      "answer": "Liu Heima",
      "score": 0.6776151657104492
    },
    {
      "answer": "Liu Heima",
      "score": 0.6167105436325073
    },
    {
      "answer": "Shi Tianze",
      "score": 0.7600291967391968
    },
    {
      "answer": "Shi Tianze",
      "score": 0.7729513645172119
    }
  ],
  "7618": [
    {
      "answer": "10,000",
      "score": 0.9943072199821472
    }
  ],
  "7619": [
    {
      "answer": "3",
      "score": 0.7082349061965942
    },
    {
      "answer": "3",
      "score": 0.9687855839729309
    }
  ],
  "7620": [
    {
      "answer": "Han Chinese",
      "score": 0.9917922019958496
    },
    {
      "answer": "Han Chinese",
      "score": 0.8964752554893494
    },
    {
      "answer": "Han Chinese",
      "score": 0.9015644788742065
    },
    {
      "answer": "Han Chinese",
      "score": 0.8710607290267944
    }
  ],
  "7621": [
    {
      "answer": "Jin",
      "score": 0.9904881715774536
    },
    {
      "answer": "Jin dynasty",
      "score": 0.9254155158996582
    },
    {
      "answer": "Jin dynasty",
      "score": 0.905150830745697
    }
  ],
  "7622": [
    {
      "answer": "Interethnic marriage between Han and Jurchen",
      "score": 0.9931068420410156
    }
  ],
  "7623": [
    {
      "answer": "Shi Bingzhi",
      "score": 0.9974087476730347
    },
    {
      "answer": "Shi Bingzhi",
      "score": 0.9602527618408203
    }
  ],
  "7624": [
    {
      "answer": "Song",
      "score": 0.9953102469444275
    }
  ],
  "7625": [
    {
      "answer": "Han Chinese",
      "score": 0.9369416236877441
    },
    {
      "answer": "Han Chinese",
      "score": 0.736174464225769
    },
    {
      "answer": "Han Chinese",
      "score": 0.7206514477729797
    },
    {
      "answer": "Han Chinese",
      "score": 0.6387984752655029
    }
  ],
  "7626": [
    {
      "answer": "Jin",
      "score": 0.9430428147315979
    },
    {
      "answer": "Jin dynasty",
      "score": 0.8586562871932983
    },
    {
      "answer": "Jin dynasty",
      "score": 0.8302162885665894
    }
  ],
  "7627": [
    {
      "answer": "Interethnic marriage between Han and Jurchen",
      "score": 0.9701318740844727
    }
  ],
  "7628": [
    {
      "answer": "Shi Bingzhi",
      "score": 0.91862553358078
    },
    {
      "answer": "Shi Bingzhi",
      "score": 0.7461998462677002
    }
  ],
  "7629": [
    {
      "answer": "Jin dynasty",
      "score": 0.7441989183425903
    },
    {
      "answer": "Jin dynasty",
      "score": 0.8073980808258057
    },
    {
      "answer": "Jin dynasty",
      "score": 0.7423849105834961
    }
  ],
  "7630": [
    {
      "answer": "M\u00f6ngke Khan",
      "score": 0.9797157049179077
    }
  ],
  "7631": [
    {
      "answer": "southern China",
      "score": 0.9829418659210205
    },
    {
      "answer": "southern China",
      "score": 0.8780128359794617
    }
  ],
  "7632": [
    {
      "answer": "1259",
      "score": 0.9903982877731323
    }
  ],
  "7633": [
    {
      "answer": "Ariq B\u00f6ke",
      "score": 0.9953818917274475
    },
    {
      "answer": "Ariq B\u00f6ke",
      "score": 0.8650431036949158
    },
    {
      "answer": "Ariq B\u00f6ke",
      "score": 0.870088517665863
    }
  ],
  "7634": [
    {
      "answer": "Zhongtong",
      "score": 0.996866762638092
    }
  ],
  "7635": [
    {
      "answer": "M\u00f6ngke Khan",
      "score": 0.6334606409072876
    },
    {
      "answer": "Kublai",
      "score": 0.5304099917411804
    },
    {
      "answer": "Kublai",
      "score": 0.5711389183998108
    },
    {
      "answer": "Kublai",
      "score": 0.643595278263092
    },
    {
      "answer": "Kublai",
      "score": 0.6158300042152405
    }
  ],
  "7636": [
    {
      "answer": "southern China",
      "score": 0.9746876358985901
    },
    {
      "answer": "southern China",
      "score": 0.887737512588501
    }
  ],
  "7637": [
    {
      "answer": "1256",
      "score": 0.8656390905380249
    },
    {
      "answer": "1259",
      "score": 0.5662234425544739
    }
  ],
  "7638": [
    {
      "answer": "Kublai",
      "score": 0.6748087406158447
    },
    {
      "answer": "Kublai",
      "score": 0.709140419960022
    },
    {
      "answer": "Kublai",
      "score": 0.5980589389801025
    }
  ],
  "7639": [
    {
      "answer": "Zhongtong",
      "score": 0.9900623559951782
    }
  ],
  "7640": [
    {
      "answer": "Ogedei",
      "score": 0.9886849522590637
    }
  ],
  "7641": [
    {
      "answer": "south",
      "score": 0.9827393293380737
    }
  ],
  "7642": [
    {
      "answer": "Wonjong",
      "score": 0.9938218593597412
    }
  ],
  "7643": [
    {
      "answer": "northeast",
      "score": 0.9414079785346985
    }
  ],
  "7644": [
    {
      "answer": "1262",
      "score": 0.979873538017273
    }
  ],
  "7645": [
    {
      "answer": "Ogedei",
      "score": 0.9719154238700867
    }
  ],
  "7646": [
    {
      "answer": "south",
      "score": 0.963610827922821
    }
  ],
  "7647": [
    {
      "answer": "Wonjong",
      "score": 0.931156575679779
    }
  ],
  "7648": [],
  "7649": [
    {
      "answer": "1262",
      "score": 0.9875346422195435
    }
  ],
  "7650": [
    {
      "answer": "preserving Mongol interests in China",
      "score": 0.9885851144790649
    },
    {
      "answer": "satisfying the demands of his Chinese subjects",
      "score": 0.9787700176239014
    }
  ],
  "7651": [
    {
      "answer": "salt",
      "score": 0.9805381894111633
    },
    {
      "answer": "iron",
      "score": 0.9836915731430054
    }
  ],
  "7652": [
    {
      "answer": "local administrative structure",
      "score": 0.872016429901123
    }
  ],
  "7653": [
    {
      "answer": "three",
      "score": 0.9587501287460327
    },
    {
      "answer": "four",
      "score": 0.9037610292434692
    }
  ],
  "7654": [
    {
      "answer": "Han Chinese",
      "score": 0.9916999936103821
    }
  ],
  "7655": [
    {
      "answer": "preserving Mongol interests in China",
      "score": 0.9688276648521423
    },
    {
      "answer": "satisfying the demands of his Chinese subjects",
      "score": 0.9599217176437378
    }
  ],
  "7656": [
    {
      "answer": "salt",
      "score": 0.9300235509872437
    },
    {
      "answer": "iron",
      "score": 0.9434077143669128
    }
  ],
  "7657": [
    {
      "answer": "local administrative structure of past Chinese dynasties unchanged",
      "score": 0.7797867059707642
    }
  ],
  "7658": [
    {
      "answer": "three",
      "score": 0.9487431645393372
    },
    {
      "answer": "four",
      "score": 0.9324772357940674
    }
  ],
  "7659": [
    {
      "answer": "Han Chinese",
      "score": 0.9882725477218628
    }
  ],
  "7660": [
    {
      "answer": "Karakorum",
      "score": 0.9901566505432129
    }
  ],
  "7661": [
    {
      "answer": "Khanbaliq",
      "score": 0.9814221858978271
    },
    {
      "answer": "Khanbaliq",
      "score": 0.9552578330039978
    }
  ],
  "7662": [
    {
      "answer": "1264",
      "score": 0.9820733070373535
    }
  ],
  "7663": [
    {
      "answer": "Zhongdu",
      "score": 0.8896417021751404
    }
  ],
  "7664": [
    {
      "answer": "Confucian propriety",
      "score": 0.9863624572753906
    },
    {
      "answer": "ancestor veneration",
      "score": 0.98249351978302
    }
  ],
  "7665": [
    {
      "answer": "Karakorum",
      "score": 0.9862063527107239
    }
  ],
  "7666": [
    {
      "answer": "Khanbaliq",
      "score": 0.7933434247970581
    },
    {
      "answer": "Khanbaliq",
      "score": 0.8247466087341309
    }
  ],
  "7667": [
    {
      "answer": "1264",
      "score": 0.983407199382782
    }
  ],
  "7668": [
    {
      "answer": "Beijing",
      "score": 0.899700939655304
    }
  ],
  "7669": [
    {
      "answer": "Confucian propriety",
      "score": 0.9880133867263794
    },
    {
      "answer": "ancestor veneration",
      "score": 0.9867708086967468
    }
  ],
  "7670": [
    {
      "answer": "commercial",
      "score": 0.9700801372528076
    },
    {
      "answer": "scientific",
      "score": 0.9734398126602173
    },
    {
      "answer": "cultural",
      "score": 0.9659765362739563
    }
  ],
  "7671": [
    {
      "answer": "Mongol peace",
      "score": 0.9767798185348511
    },
    {
      "answer": "enabled the spread of technologies, commodities, and culture between China and the West",
      "score": 0.8052117824554443
    }
  ],
  "7672": [
    {
      "answer": "southern China",
      "score": 0.9850013256072998
    },
    {
      "answer": "Daidu",
      "score": 0.813133180141449
    }
  ],
  "7673": [
    {
      "answer": "Daidu",
      "score": 0.9931725859642029
    }
  ],
  "7674": [
    {
      "answer": "Marco Polo",
      "score": 0.9955397844314575
    },
    {
      "answer": "Marco Polo",
      "score": 0.9563567638397217
    }
  ],
  "7675": [
    {
      "answer": "commercial, scientific, and cultural",
      "score": 0.8093440532684326
    }
  ],
  "7676": [
    {
      "answer": "Pax Mongolica",
      "score": 0.675139307975769
    },
    {
      "answer": "Mongol peace",
      "score": 0.9716129899024963
    }
  ],
  "7677": [
    {
      "answer": "southern China",
      "score": 0.8799929022789001
    },
    {
      "answer": "Daidu",
      "score": 0.975786030292511
    }
  ],
  "7678": [
    {
      "answer": "Daidu",
      "score": 0.9953734278678894
    }
  ],
  "7679": [
    {
      "answer": "Marco Polo",
      "score": 0.9477200508117676
    },
    {
      "answer": "Marco Polo",
      "score": 0.8182514905929565
    }
  ],
  "7680": [
    {
      "answer": "Song Emperor",
      "score": 0.9883612394332886
    }
  ],
  "7681": [
    {
      "answer": "1115",
      "score": 0.9924827218055725
    }
  ],
  "7682": [
    {
      "answer": "1115",
      "score": 0.9615155458450317
    },
    {
      "answer": "1234",
      "score": 0.986425518989563
    }
  ],
  "7683": [
    {
      "answer": "Kong Duancao",
      "score": 0.9653187990188599
    }
  ],
  "7684": [
    {
      "answer": "30,000",
      "score": 0.9897019863128662
    }
  ],
  "7685": [
    {
      "answer": "Song Emperor",
      "score": 0.9822003245353699
    }
  ],
  "7686": [
    {
      "answer": "1115",
      "score": 0.9614598155021667
    }
  ],
  "7687": [
    {
      "answer": "1115",
      "score": 0.9678966999053955
    }
  ],
  "7688": [
    {
      "answer": "Kong Zhu",
      "score": 0.8873163461685181
    },
    {
      "answer": "Kong Zhu",
      "score": 0.851146936416626
    }
  ],
  "7689": [
    {
      "answer": "northern China",
      "score": 0.988021731376648
    }
  ],
  "7690": [
    {
      "answer": "1268",
      "score": 0.9667358994483948
    },
    {
      "answer": "1273",
      "score": 0.9380003213882446
    }
  ],
  "7691": [
    {
      "answer": "Yangzi River basin",
      "score": 0.9793604612350464
    }
  ],
  "7692": [
    {
      "answer": "Hangzhou",
      "score": 0.9834197759628296
    }
  ],
  "7693": [
    {
      "answer": "drowned",
      "score": 0.9930548071861267
    }
  ],
  "7694": [
    {
      "answer": "south",
      "score": 0.960851788520813
    },
    {
      "answer": "Xiangyang",
      "score": 0.7071405649185181
    }
  ],
  "7695": [
    {
      "answer": "1268",
      "score": 0.962213933467865
    },
    {
      "answer": "1273",
      "score": 0.9456765651702881
    }
  ],
  "7696": [
    {
      "answer": "Yangzi River basin",
      "score": 0.9808351993560791
    }
  ],
  "7697": [
    {
      "answer": "Hangzhou",
      "score": 0.9932159781455994
    }
  ],
  "7698": [
    {
      "answer": "drowned",
      "score": 0.714529275894165
    }
  ],
  "7699": [
    {
      "answer": "1279",
      "score": 0.9833937287330627
    }
  ],
  "7700": [
    {
      "answer": "inauspicious typhoon",
      "score": 0.9832288026809692
    }
  ],
  "7701": [
    {
      "answer": "Annam",
      "score": 0.7616416215896606
    },
    {
      "answer": "Champa",
      "score": 0.6227785348892212
    },
    {
      "answer": "Java",
      "score": 0.5999359488487244
    },
    {
      "answer": "Burma",
      "score": 0.6125112771987915
    },
    {
      "answer": "Annam",
      "score": 0.7037710547447205
    },
    {
      "answer": "Annam",
      "score": 0.5591374635696411
    }
  ],
  "7702": [
    {
      "answer": "Battle of B\u1ea1ch \u0110\u1eb1ng",
      "score": 0.9223432540893555
    }
  ],
  "7703": [
    {
      "answer": "1288",
      "score": 0.9805630445480347
    }
  ],
  "7704": [
    {
      "answer": "Wars and construction projects had drained the Mongol treasury",
      "score": 0.8425542116165161
    },
    {
      "answer": "corruption and political scandals",
      "score": 0.8944410085678101
    }
  ],
  "7705": [
    {
      "answer": "inauspicious typhoon",
      "score": 0.980243444442749
    }
  ],
  "7706": [
    {
      "answer": "crushed and defeated the Mongols at the Battle of B\u1ea1ch \u0110\u1eb1ng (1288)",
      "score": 0.784826397895813
    }
  ],
  "7707": [
    {
      "answer": "Battle of B\u1ea1ch \u0110\u1eb1ng",
      "score": 0.9456744194030762
    }
  ],
  "7708": [
    {
      "answer": "1253",
      "score": 0.9896934628486633
    }
  ],
  "7709": [
    {
      "answer": "Zhenjin",
      "score": 0.9869722723960876
    },
    {
      "answer": "Zhenjin",
      "score": 0.7174914479255676
    }
  ],
  "7710": [
    {
      "answer": "1285",
      "score": 0.9940959215164185
    }
  ],
  "7711": [
    {
      "answer": "Emperor Chengzong",
      "score": 0.9486659169197083
    }
  ],
  "7712": [
    {
      "answer": "1294",
      "score": 0.9910564422607422
    },
    {
      "answer": "1307",
      "score": 0.9774206280708313
    }
  ],
  "7713": [
    {
      "answer": "1253",
      "score": 0.9920296669006348
    }
  ],
  "7714": [
    {
      "answer": "Zhenjin",
      "score": 0.9853783845901489
    },
    {
      "answer": "Zhenjin",
      "score": 0.6564896702766418
    }
  ],
  "7715": [
    {
      "answer": "1253",
      "score": 0.5666975975036621
    },
    {
      "answer": "1285",
      "score": 0.7342187762260437
    },
    {
      "answer": "1294",
      "score": 0.7150343060493469
    }
  ],
  "7716": [
    {
      "answer": "Emperor Chengzong",
      "score": 0.9374771118164062
    }
  ],
  "7717": [
    {
      "answer": "1307",
      "score": 0.9747656583786011
    }
  ],
  "7718": [
    {
      "answer": "Buyantu Khan",
      "score": 0.9916218519210815
    }
  ],
  "7719": [
    {
      "answer": "actively support and adopt mainstream Chinese culture",
      "score": 0.8505145907402039
    },
    {
      "answer": "liquidation of the Department of State Affairs",
      "score": 0.7961546182632446
    }
  ],
  "7720": [
    {
      "answer": "Li Meng",
      "score": 0.9984354972839355
    }
  ],
  "7721": [
    {
      "answer": "Department of State Affairs",
      "score": 0.9796345829963684
    }
  ],
  "7722": [
    {
      "answer": "1313",
      "score": 0.9965399503707886
    }
  ],
  "7723": [
    {
      "answer": "Buyantu Khan",
      "score": 0.9530755281448364
    }
  ],
  "7724": [
    {
      "answer": "actively support and adopt mainstream Chinese culture",
      "score": 0.792959988117218
    },
    {
      "answer": "liquidation of the Department of State Affairs",
      "score": 0.6536827087402344
    }
  ],
  "7725": [
    {
      "answer": "Mongol elite",
      "score": 0.7228451371192932
    }
  ],
  "7726": [
    {
      "answer": "Department of State Affairs",
      "score": 0.9750593304634094
    }
  ],
  "7727": [
    {
      "answer": "1313",
      "score": 0.9966270923614502
    }
  ],
  "7728": [
    {
      "answer": "Gegeen Khan",
      "score": 0.9857120513916016
    }
  ],
  "7729": [
    {
      "answer": "1321",
      "score": 0.9894558787345886
    },
    {
      "answer": "1323",
      "score": 0.9651703238487244
    }
  ],
  "7730": [
    {
      "answer": "Baiju",
      "score": 0.993493378162384
    }
  ],
  "7731": [
    {
      "answer": "the comprehensive institutions of the Great Yuan",
      "score": 0.9885882139205933
    }
  ],
  "7732": [
    {
      "answer": "five",
      "score": 0.9931193590164185
    }
  ],
  "7733": [],
  "7734": [
    {
      "answer": "1321",
      "score": 0.9823821187019348
    },
    {
      "answer": "1323",
      "score": 0.9401772022247314
    }
  ],
  "7735": [
    {
      "answer": "Baiju",
      "score": 0.9921854138374329
    }
  ],
  "7736": [
    {
      "answer": "the comprehensive institutions of the Great Yuan",
      "score": 0.942823052406311
    }
  ],
  "7737": [
    {
      "answer": "five",
      "score": 0.99146568775177
    }
  ],
  "7738": [
    {
      "answer": "Shangdu",
      "score": 0.9952125549316406
    },
    {
      "answer": "Shangdu",
      "score": 0.9610892534255981
    }
  ],
  "7739": [
    {
      "answer": "War of the Two Capitals",
      "score": 0.984271228313446
    }
  ],
  "7740": [
    {
      "answer": "four days",
      "score": 0.9942142367362976
    }
  ],
  "7741": [
    {
      "answer": "El Tem\u00fcr",
      "score": 0.8380364179611206
    },
    {
      "answer": "El Tem\u00fcr",
      "score": 0.9637743234634399
    },
    {
      "answer": "El Tem\u00fcr",
      "score": 0.7794004678726196
    },
    {
      "answer": "El Tem\u00fcr",
      "score": 0.8390771150588989
    }
  ],
  "7742": [
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.8286224603652954
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.8336431980133057
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.7847306132316589
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.868370771408081
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.9313098192214966
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.8056159615516663
    }
  ],
  "7743": [
    {
      "answer": "killed with poison",
      "score": 0.8443950414657593
    }
  ],
  "7744": [
    {
      "answer": "War of the Two Capitals",
      "score": 0.9831814169883728
    }
  ],
  "7745": [
    {
      "answer": "four days",
      "score": 0.9904096126556396
    }
  ],
  "7746": [
    {
      "answer": "Dawlat Shah",
      "score": 0.717854380607605
    }
  ],
  "7747": [
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.8460445404052734
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.8399094343185425
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.7899976372718811
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.88254714012146
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.9240196943283081
    },
    {
      "answer": "Tugh Tem\u00fcr",
      "score": 0.820947527885437
    }
  ],
  "7748": [
    {
      "answer": "cultural contribution",
      "score": 0.9512592554092407
    }
  ],
  "7749": [
    {
      "answer": "Academy of the Pavilion of the Star of Literature",
      "score": 0.9841327667236328
    }
  ],
  "7750": [
    {
      "answer": "1329",
      "score": 0.9918015599250793
    }
  ],
  "7751": [
    {
      "answer": "Jingshi Dadian",
      "score": 0.9927346706390381
    }
  ],
  "7752": [
    {
      "answer": "Buddhism",
      "score": 0.9912571907043457
    }
  ],
  "7753": [
    {
      "answer": "cultural contribution",
      "score": 0.7472633123397827
    }
  ],
  "7754": [
    {
      "answer": "Academy of the Pavilion of the Star of Literature",
      "score": 0.9665406346321106
    }
  ],
  "7755": [
    {
      "answer": "1329",
      "score": 0.9674167633056641
    }
  ],
  "7756": [
    {
      "answer": "Jingshi Dadian",
      "score": 0.9827725887298584
    }
  ],
  "7757": [
    {
      "answer": "Buddhism",
      "score": 0.948062002658844
    }
  ],
  "7758": [
    {
      "answer": "1332",
      "score": 0.9932544827461243
    }
  ],
  "7759": [
    {
      "answer": "Emperor Ningzong",
      "score": 0.9592501521110535
    }
  ],
  "7760": [
    {
      "answer": "13-year-old",
      "score": 0.9868947267532349
    }
  ],
  "7761": [
    {
      "answer": "nine",
      "score": 0.9930845499038696
    }
  ],
  "7762": [
    {
      "answer": "Liao",
      "score": 0.9955138564109802
    },
    {
      "answer": "Jin",
      "score": 0.9925770163536072
    },
    {
      "answer": "Song",
      "score": 0.9911913275718689
    }
  ],
  "7763": [
    {
      "answer": "1332",
      "score": 0.7956715822219849
    },
    {
      "answer": "13-year-old",
      "score": 0.6851663589477539
    }
  ],
  "7764": [
    {
      "answer": "Ningzong",
      "score": 0.9890751838684082
    }
  ],
  "7765": [
    {
      "answer": "13-year-old",
      "score": 0.987929105758667
    }
  ],
  "7766": [
    {
      "answer": "nine",
      "score": 0.9919247031211853
    }
  ],
  "7767": [
    {
      "answer": "Liao",
      "score": 0.9946122169494629
    },
    {
      "answer": "Jin",
      "score": 0.9914544820785522
    },
    {
      "answer": "Song",
      "score": 0.9907641410827637
    }
  ],
  "7768": [
    {
      "answer": "struggle",
      "score": 0.8689260482788086
    },
    {
      "answer": "famine",
      "score": 0.9246858954429626
    },
    {
      "answer": "bitterness",
      "score": 0.9222043752670288
    }
  ],
  "7769": [
    {
      "answer": "struggle, famine, and bitterness",
      "score": 0.7816216349601746
    }
  ],
  "7770": [
    {
      "answer": "army",
      "score": 0.9379987120628357
    },
    {
      "answer": "populace",
      "score": 0.9151612520217896
    }
  ],
  "7771": [
    {
      "answer": "Outlaws",
      "score": 0.9664433002471924
    }
  ],
  "7772": [
    {
      "answer": "administration",
      "score": 0.981698751449585
    }
  ],
  "7773": [
    {
      "answer": "struggle",
      "score": 0.8699060678482056
    },
    {
      "answer": "famine",
      "score": 0.8904946446418762
    },
    {
      "answer": "bitterness",
      "score": 0.903441309928894
    }
  ],
  "7774": [
    {
      "answer": "struggle, famine, and bitterness",
      "score": 0.7325111627578735
    }
  ],
  "7775": [
    {
      "answer": "army",
      "score": 0.83115154504776
    },
    {
      "answer": "populace",
      "score": 0.8596222400665283
    }
  ],
  "7776": [
    {
      "answer": "Outlaws ravaged the country",
      "score": 0.6482552289962769
    }
  ],
  "7777": [
    {
      "answer": "intrigues and rivalries",
      "score": 0.9488279819488525
    },
    {
      "answer": "administration",
      "score": 0.6075484752655029
    }
  ],
  "7778": [
    {
      "answer": "1340s",
      "score": 0.983949601650238
    }
  ],
  "7779": [
    {
      "answer": "Red Turban Rebellion",
      "score": 0.9934975504875183
    }
  ],
  "7780": [
    {
      "answer": "fear of betrayal",
      "score": 0.9795150756835938
    }
  ],
  "7781": [
    {
      "answer": "Red Turban rebels",
      "score": 0.9748333692550659
    }
  ],
  "7782": [
    {
      "answer": "1340s",
      "score": 0.7505776286125183
    },
    {
      "answer": "1368",
      "score": 0.5839453339576721
    }
  ],
  "7783": [
    {
      "answer": "1340s",
      "score": 0.9839921593666077
    }
  ],
  "7784": [
    {
      "answer": "Red Turban Rebellion",
      "score": 0.9875957369804382
    }
  ],
  "7785": [
    {
      "answer": "fear of betrayal",
      "score": 0.8612338900566101
    }
  ],
  "7786": [
    {
      "answer": "Red Turban rebels",
      "score": 0.9627282619476318
    }
  ],
  "7787": [
    {
      "answer": "1340s",
      "score": 0.7078885436058044
    },
    {
      "answer": "1368",
      "score": 0.676543653011322
    },
    {
      "answer": "1368",
      "score": 0.6398684978485107
    }
  ],
  "7788": [
    {
      "answer": "political unity of China and much of central Asia",
      "score": 0.958350419998169
    }
  ],
  "7789": [
    {
      "answer": "political unity of China and much of central Asia promoted trade between East and West",
      "score": 0.9094683527946472
    }
  ],
  "7790": [
    {
      "answer": "Ilkhanate",
      "score": 0.9915074110031128
    }
  ],
  "7791": [
    {
      "answer": "carrots",
      "score": 0.9425034523010254
    },
    {
      "answer": "turnips",
      "score": 0.933451771736145
    },
    {
      "answer": "new varieties of lemons",
      "score": 0.9201950430870056
    },
    {
      "answer": "eggplants",
      "score": 0.9490625262260437
    },
    {
      "answer": "melons",
      "score": 0.937279999256134
    },
    {
      "answer": "high-quality granulated sugar",
      "score": 0.886542022228241
    },
    {
      "answer": "cotton",
      "score": 0.9407185316085815
    }
  ],
  "7792": [],
  "7793": [
    {
      "answer": "The political unity of China and much of central Asia",
      "score": 0.903700053691864
    }
  ],
  "7794": [
    {
      "answer": "Ilkhanate",
      "score": 0.9831328988075256
    }
  ],
  "7795": [
    {
      "answer": "Western",
      "score": 0.987041711807251
    }
  ],
  "7796": [
    {
      "answer": "Nestorianism",
      "score": 0.973000168800354
    },
    {
      "answer": "Roman Catholicism",
      "score": 0.9838994741439819
    }
  ],
  "7797": [
    {
      "answer": "Taoism",
      "score": 0.9904848337173462
    }
  ],
  "7798": [
    {
      "answer": "Confucian governmental practices and examinations",
      "score": 0.8946347236633301
    }
  ],
  "7799": [
    {
      "answer": "travel literature",
      "score": 0.9799723625183105
    },
    {
      "answer": "cartography",
      "score": 0.9801256060600281
    },
    {
      "answer": "geography",
      "score": 0.979103147983551
    },
    {
      "answer": "scientific education",
      "score": 0.9824780225753784
    }
  ],
  "7800": [
    {
      "answer": "Western",
      "score": 0.9622930884361267
    }
  ],
  "7801": [],
  "7802": [
    {
      "answer": "Taoism",
      "score": 0.6649335622787476
    }
  ],
  "7803": [
    {
      "answer": "Confucian",
      "score": 0.9695234894752502
    }
  ],
  "7804": [
    {
      "answer": "travel literature",
      "score": 0.9443833827972412
    },
    {
      "answer": "cartography",
      "score": 0.9563642144203186
    },
    {
      "answer": "geography",
      "score": 0.9566682577133179
    },
    {
      "answer": "scientific education",
      "score": 0.9745142459869385
    }
  ],
  "7805": [
    {
      "answer": "Marco Polo",
      "score": 0.9684282541275024
    },
    {
      "answer": "Marco Polo",
      "score": 0.884030818939209
    },
    {
      "answer": "Marco Polo",
      "score": 0.8204952478408813
    },
    {
      "answer": "Marco Polo",
      "score": 0.871921956539154
    }
  ],
  "7806": [
    {
      "answer": "Cambaluc",
      "score": 0.9864405989646912
    }
  ],
  "7807": [
    {
      "answer": "Travels of Marco Polo",
      "score": 0.9369498491287231
    }
  ],
  "7808": [
    {
      "answer": "Il milione",
      "score": 0.9769442081451416
    }
  ],
  "7809": [
    {
      "answer": "contact with Persian traders",
      "score": 0.9872479438781738
    }
  ],
  "7810": [
    {
      "answer": "Marco Polo",
      "score": 0.9576630592346191
    },
    {
      "answer": "Marco Polo",
      "score": 0.8516910076141357
    },
    {
      "answer": "Marco Polo",
      "score": 0.7985091805458069
    },
    {
      "answer": "Marco Polo",
      "score": 0.8500727415084839
    }
  ],
  "7811": [
    {
      "answer": "Cambaluc",
      "score": 0.9864078760147095
    }
  ],
  "7812": [
    {
      "answer": "Il milione",
      "score": 0.9569646120071411
    }
  ],
  "7813": [
    {
      "answer": "Il milione",
      "score": 0.9008054733276367
    }
  ],
  "7814": [
    {
      "answer": "Guo Shoujing",
      "score": 0.9935733079910278
    }
  ],
  "7815": [
    {
      "answer": "365.2425",
      "score": 0.9897485971450806
    }
  ],
  "7816": [
    {
      "answer": "granaries were ordered built throughout the empire",
      "score": 0.9349501729011536
    }
  ],
  "7817": [
    {
      "answer": "Beijing",
      "score": 0.6456129550933838
    },
    {
      "answer": "Beijing",
      "score": 0.7132139801979065
    }
  ],
  "7818": [
    {
      "answer": "sorghum",
      "score": 0.984468400478363
    }
  ],
  "7819": [
    {
      "answer": "Guo Shoujing",
      "score": 0.9926466941833496
    }
  ],
  "7820": [
    {
      "answer": "365.2425",
      "score": 0.9888598918914795
    }
  ],
  "7821": [
    {
      "answer": "granaries were ordered built throughout the empire",
      "score": 0.9311826229095459
    }
  ],
  "7822": [],
  "7823": [
    {
      "answer": "sorghum",
      "score": 0.9874524474143982
    }
  ],
  "7824": [
    {
      "answer": "non-native Chinese people",
      "score": 0.9731108546257019
    }
  ],
  "7825": [
    {
      "answer": "Eternal Heaven",
      "score": 0.993979811668396
    }
  ],
  "7826": [
    {
      "answer": "Song dynasty",
      "score": 0.9921389222145081
    }
  ],
  "7827": [
    {
      "answer": "Ming dynasty",
      "score": 0.961293637752533
    },
    {
      "answer": "Ming dynasty",
      "score": 0.9583005905151367
    }
  ],
  "7828": [
    {
      "answer": "a period of foreign domination",
      "score": 0.9634916186332703
    }
  ],
  "7829": [
    {
      "answer": "non-native Chinese people",
      "score": 0.911024272441864
    }
  ],
  "7830": [
    {
      "answer": "Eternal Heaven",
      "score": 0.8986908197402954
    }
  ],
  "7831": [
    {
      "answer": "Song dynasty",
      "score": 0.9811334013938904
    }
  ],
  "7832": [
    {
      "answer": "Ming dynasty",
      "score": 0.9428178668022156
    },
    {
      "answer": "Ming dynasty",
      "score": 0.9528849720954895
    }
  ],
  "7833": [
    {
      "answer": "Han Chinese",
      "score": 0.960346519947052
    },
    {
      "answer": "Khitans",
      "score": 0.9632641673088074
    },
    {
      "answer": "Jurchens",
      "score": 0.9665364027023315
    },
    {
      "answer": "Mongols",
      "score": 0.958370566368103
    },
    {
      "answer": "Tibetan Buddhists",
      "score": 0.9728454947471619
    }
  ],
  "7834": [
    {
      "answer": "Tang",
      "score": 0.9758780002593994
    },
    {
      "answer": "Song",
      "score": 0.9670084714889526
    },
    {
      "answer": "Khitan Liao",
      "score": 0.9595221281051636
    },
    {
      "answer": "Jurchen Jin",
      "score": 0.965192437171936
    }
  ],
  "7835": [
    {
      "answer": "Liu Bingzhong",
      "score": 0.9582604169845581
    },
    {
      "answer": "Yao Shu",
      "score": 0.9273356199264526
    }
  ],
  "7836": [
    {
      "answer": "traditional Chinese tripartite division of authority among civil, military, and censorial offices",
      "score": 0.8414919376373291
    }
  ],
  "7837": [],
  "7838": [
    {
      "answer": "Han Chinese",
      "score": 0.6589319109916687
    },
    {
      "answer": "Jurchens",
      "score": 0.7223007082939148
    },
    {
      "answer": "Tibetan Buddhists",
      "score": 0.8066344261169434
    }
  ],
  "7839": [
    {
      "answer": "Khitan Liao",
      "score": 0.7516726851463318
    },
    {
      "answer": "Jurchen Jin",
      "score": 0.7698476314544678
    }
  ],
  "7840": [
    {
      "answer": "Liu Bingzhong",
      "score": 0.9809361100196838
    },
    {
      "answer": "Yao Shu",
      "score": 0.8459144830703735
    }
  ],
  "7841": [
    {
      "answer": "traditional Chinese tripartite division of authority among civil, military, and censorial offices",
      "score": 0.8552698493003845
    }
  ],
  "7842": [
    {
      "answer": "Privy Council",
      "score": 0.9921186566352844
    }
  ],
  "7843": [
    {
      "answer": "Sui and Tang",
      "score": 0.9839032888412476
    }
  ],
  "7844": [
    {
      "answer": "Mongols",
      "score": 0.9807010889053345
    },
    {
      "answer": "Semuren",
      "score": 0.9708303213119507
    }
  ],
  "7845": [
    {
      "answer": "Privy Council",
      "score": 0.9882922172546387
    }
  ],
  "7846": [
    {
      "answer": "Privy Council",
      "score": 0.9921186566352844
    }
  ],
  "7847": [
    {
      "answer": "Sui and Tang",
      "score": 0.9721916913986206
    }
  ],
  "7848": [
    {
      "answer": "Mongols",
      "score": 0.978071928024292
    },
    {
      "answer": "Semuren",
      "score": 0.9746827483177185
    }
  ],
  "7849": [
    {
      "answer": "Privy Council",
      "score": 0.9906573295593262
    }
  ],
  "7850": [
    {
      "answer": "1269",
      "score": 0.9918901920318604
    }
  ],
  "7851": [
    {
      "answer": "Mongolian",
      "score": 0.9712391495704651
    },
    {
      "answer": "Tibetan",
      "score": 0.9625575542449951
    },
    {
      "answer": "Chinese",
      "score": 0.9624674916267395
    },
    {
      "answer": "Chinese",
      "score": 0.6499089598655701
    },
    {
      "answer": "Chinese",
      "score": 0.6896277070045471
    }
  ],
  "7852": [
    {
      "answer": "Most of the Emperors could not master written Chinese, but they could generally converse well in the language",
      "score": 0.8867098093032837
    }
  ],
  "7853": [
    {
      "answer": "Tugh Temur",
      "score": 0.9563579559326172
    },
    {
      "answer": "Tugh Temur",
      "score": 0.8325600624084473
    }
  ],
  "7854": [
    {
      "answer": "Emperor Wenzong",
      "score": 0.8893671631813049
    }
  ],
  "7855": [
    {
      "answer": "1269",
      "score": 0.9427216649055481
    }
  ],
  "7856": [
    {
      "answer": "Mongolian",
      "score": 0.670738697052002
    },
    {
      "answer": "Tibetan",
      "score": 0.6936960220336914
    },
    {
      "answer": "Chinese",
      "score": 0.8193418383598328
    },
    {
      "answer": "Chinese",
      "score": 0.762323260307312
    },
    {
      "answer": "Chinese",
      "score": 0.734595537185669
    }
  ],
  "7857": [
    {
      "answer": "Most of the Emperors could not master written Chinese, but they could generally converse well in the language.",
      "score": 0.8351652026176453
    }
  ],
  "7858": [
    {
      "answer": "Tugh Temur",
      "score": 0.8672483563423157
    },
    {
      "answer": "Tugh Temur",
      "score": 0.7847994565963745
    }
  ],
  "7859": [
    {
      "answer": "Emperor Wenzong",
      "score": 0.8381273746490479
    }
  ],
  "7860": [
    {
      "answer": "1290",
      "score": 0.9945456981658936
    }
  ],
  "7861": [
    {
      "answer": "1291",
      "score": 0.9934893846511841
    }
  ],
  "7862": [
    {
      "answer": "debt slavery",
      "score": 0.8625503778457642
    }
  ],
  "7863": [
    {
      "answer": "1290",
      "score": 0.9893634915351868
    }
  ],
  "7864": [
    {
      "answer": "1291",
      "score": 0.987648606300354
    }
  ],
  "7865": [
    {
      "answer": "income from the harvests of their Chinese tenants",
      "score": 0.8320980668067932
    },
    {
      "answer": "costs of equipping and dispatching men for their tours of duty",
      "score": 0.9060698747634888
    }
  ],
  "7866": [
    {
      "answer": "painting",
      "score": 0.933012068271637
    },
    {
      "answer": "mathematics",
      "score": 0.9213345050811768
    },
    {
      "answer": "calligraphy",
      "score": 0.9488250613212585
    },
    {
      "answer": "poetry",
      "score": 0.9296000599861145
    },
    {
      "answer": "theater",
      "score": 0.9459850788116455
    }
  ],
  "7867": [
    {
      "answer": "painting",
      "score": 0.6188720464706421
    },
    {
      "answer": "calligraphy",
      "score": 0.782821774482727
    }
  ],
  "7868": [
    {
      "answer": "Song",
      "score": 0.995895504951477
    },
    {
      "answer": "Song dynasty",
      "score": 0.8357957005500793
    }
  ],
  "7869": [
    {
      "answer": "qu",
      "score": 0.963080883026123
    },
    {
      "answer": "qu",
      "score": 0.7216565608978271
    },
    {
      "answer": "qu",
      "score": 0.8685067296028137
    }
  ],
  "7870": [
    {
      "answer": "zaju",
      "score": 0.9857674837112427
    },
    {
      "answer": "zaju",
      "score": 0.9542706608772278
    }
  ],
  "7871": [
    {
      "answer": "vernacular Chinese",
      "score": 0.8278137445449829
    }
  ],
  "7872": [
    {
      "answer": "mathematics",
      "score": 0.7802517414093018
    },
    {
      "answer": "calligraphy",
      "score": 0.5893155336380005
    }
  ],
  "7873": [
    {
      "answer": "Song dynasty",
      "score": 0.7517518997192383
    },
    {
      "answer": "Song dynasty",
      "score": 0.6133102178573608
    }
  ],
  "7874": [
    {
      "answer": "qu",
      "score": 0.9185455441474915
    },
    {
      "answer": "qu",
      "score": 0.7636942863464355
    },
    {
      "answer": "qu",
      "score": 0.8385792970657349
    }
  ],
  "7875": [
    {
      "answer": "western",
      "score": 0.9410709738731384
    }
  ],
  "7876": [
    {
      "answer": "Buddhism",
      "score": 0.8318695425987244
    },
    {
      "answer": "Buddhism",
      "score": 0.9850097298622131
    },
    {
      "answer": "Buddhism",
      "score": 0.7225022315979004
    },
    {
      "answer": "Buddhism",
      "score": 0.8510505557060242
    },
    {
      "answer": "Buddhism",
      "score": 0.6216645836830139
    }
  ],
  "7877": [
    {
      "answer": "Buddhism",
      "score": 0.9198222756385803
    },
    {
      "answer": "Tibetan Buddhism",
      "score": 0.7908199429512024
    }
  ],
  "7878": [
    {
      "answer": "Bureau of Buddhist and Tibetan Affairs",
      "score": 0.9903992414474487
    }
  ],
  "7879": [
    {
      "answer": "Sakya",
      "score": 0.9955629110336304
    }
  ],
  "7880": [
    {
      "answer": "western",
      "score": 0.9580426216125488
    }
  ],
  "7881": [
    {
      "answer": "Islam",
      "score": 0.8151558041572571
    },
    {
      "answer": "Islam",
      "score": 0.9672576785087585
    }
  ],
  "7882": [
    {
      "answer": "Tibetan Buddhism",
      "score": 0.9585089683532715
    },
    {
      "answer": "Tibetan Buddhism",
      "score": 0.844339907169342
    }
  ],
  "7883": [
    {
      "answer": "Sakya",
      "score": 0.9795535802841187
    }
  ],
  "7884": [
    {
      "answer": "1249",
      "score": 0.9952318072319031
    }
  ],
  "7885": [
    {
      "answer": "1314",
      "score": 0.9935444593429565
    }
  ],
  "7886": [
    {
      "answer": "matrices",
      "score": 0.9620594382286072
    }
  ],
  "7887": [
    {
      "answer": "polynomial algebra",
      "score": 0.9947704076766968
    }
  ],
  "7888": [
    {
      "answer": "1303",
      "score": 0.9958750605583191
    }
  ],
  "7889": [
    {
      "answer": "1249",
      "score": 0.9909650087356567
    },
    {
      "answer": "1314",
      "score": 0.8764657378196716
    }
  ],
  "7890": [
    {
      "answer": "Yuan era",
      "score": 0.5765664577484131
    },
    {
      "answer": "1303",
      "score": 0.6333299279212952
    }
  ],
  "7891": [
    {
      "answer": "matrices",
      "score": 0.7876197099685669
    },
    {
      "answer": "method of elimination",
      "score": 0.6675398349761963
    }
  ],
  "7892": [
    {
      "answer": "polynomial algebra",
      "score": 0.9662548303604126
    }
  ],
  "7893": [
    {
      "answer": "1303",
      "score": 0.9959419369697571
    }
  ],
  "7894": [
    {
      "answer": "derived a cubic interpolation formula",
      "score": 0.8665142059326172
    }
  ],
  "7895": [
    {
      "answer": "cubic interpolation formula",
      "score": 0.9718979597091675
    }
  ],
  "7896": [
    {
      "answer": "Shoushi Li",
      "score": 0.9181458950042725
    }
  ],
  "7897": [
    {
      "answer": "Shoushi Li",
      "score": 0.8712691068649292
    }
  ],
  "7898": [
    {
      "answer": "1281",
      "score": 0.9899910688400269
    }
  ],
  "7899": [],
  "7900": [
    {
      "answer": "mathematics",
      "score": 0.9384025931358337
    }
  ],
  "7901": [
    {
      "answer": "Shoushi Li",
      "score": 0.8910856246948242
    }
  ],
  "7902": [
    {
      "answer": "Shoushi Li",
      "score": 0.8180204629898071
    }
  ],
  "7903": [
    {
      "answer": "1281",
      "score": 0.9927042722702026
    }
  ],
  "7904": [
    {
      "answer": "non-Mongol physicians",
      "score": 0.9407260417938232
    }
  ],
  "7905": [
    {
      "answer": "herbal remedies",
      "score": 0.989111065864563
    }
  ],
  "7906": [
    {
      "answer": "herbal remedies",
      "score": 0.9923167824745178
    }
  ],
  "7907": [
    {
      "answer": "Imperial Academy of Medicine",
      "score": 0.9380914568901062
    }
  ],
  "7908": [
    {
      "answer": "it ensured a high income and medical ethics were compatible with Confucian virtues",
      "score": 0.9792383909225464
    }
  ],
  "7909": [
    {
      "answer": "non-Mongol physicians",
      "score": 0.9170714616775513
    }
  ],
  "7910": [
    {
      "answer": "spiritual cures",
      "score": 0.9676660299301147
    }
  ],
  "7911": [
    {
      "answer": "herbal remedies",
      "score": 0.9928685426712036
    }
  ],
  "7912": [
    {
      "answer": "Imperial Academy of Medicine",
      "score": 0.9835194945335388
    }
  ],
  "7913": [
    {
      "answer": "it ensured a high income and medical ethics were compatible with Confucian virtues",
      "score": 0.9450234770774841
    }
  ],
  "7914": [
    {
      "answer": "Four",
      "score": 0.9758837819099426
    },
    {
      "answer": "four",
      "score": 0.8581036925315857
    }
  ],
  "7915": [
    {
      "answer": "inherited from the Jin dynasty",
      "score": 0.9126304984092712
    }
  ],
  "7916": [
    {
      "answer": "Chinese physicians were brought along military campaigns by the Mongols as they expanded towards the west.",
      "score": 0.9019147753715515
    }
  ],
  "7917": [
    {
      "answer": "acupuncture",
      "score": 0.9699460864067078
    },
    {
      "answer": "moxibustion",
      "score": 0.9662630558013916
    },
    {
      "answer": "pulse diagnosis",
      "score": 0.9818018674850464
    },
    {
      "answer": "various herbal drugs and elixirs",
      "score": 0.8555672764778137
    }
  ],
  "7918": [
    {
      "answer": "1347",
      "score": 0.9926375150680542
    }
  ],
  "7919": [
    {
      "answer": "Four",
      "score": 0.8879138827323914
    },
    {
      "answer": "four",
      "score": 0.8206066489219666
    }
  ],
  "7920": [],
  "7921": [],
  "7922": [
    {
      "answer": "acupuncture",
      "score": 0.9329400658607483
    },
    {
      "answer": "moxibustion",
      "score": 0.8969347476959229
    },
    {
      "answer": "pulse diagnosis",
      "score": 0.9514917135238647
    }
  ],
  "7923": [
    {
      "answer": "Western medicine",
      "score": 0.8041841983795166
    },
    {
      "answer": "Muslim medicine",
      "score": 0.5706838369369507
    }
  ],
  "7924": [
    {
      "answer": "Jesus the Interpreter",
      "score": 0.9879783987998962
    }
  ],
  "7925": [
    {
      "answer": "1263",
      "score": 0.9780101180076599
    }
  ],
  "7926": [
    {
      "answer": "humoral system",
      "score": 0.9126318097114563
    }
  ],
  "7927": [
    {
      "answer": "yin-yang and wuxing",
      "score": 0.989046037197113
    }
  ],
  "7928": [],
  "7929": [
    {
      "answer": "Jesus the Interpreter",
      "score": 0.9887648820877075
    }
  ],
  "7930": [
    {
      "answer": "1263",
      "score": 0.9820260405540466
    }
  ],
  "7931": [
    {
      "answer": "humoral system",
      "score": 0.865146279335022
    }
  ],
  "7932": [
    {
      "answer": "yin-yang",
      "score": 0.9954915642738342
    }
  ],
  "7933": [
    {
      "answer": "Kingdom of Qocho and Tibetan intermediaries",
      "score": 0.9787420630455017
    }
  ],
  "7934": [
    {
      "answer": "Wang Zhen",
      "score": 0.9918689727783203
    }
  ],
  "7935": [
    {
      "answer": "12th century",
      "score": 0.9827150106430054
    }
  ],
  "7936": [
    {
      "answer": "T\u00f6regene Khatun",
      "score": 0.9907832145690918
    }
  ],
  "7937": [
    {
      "answer": "1273",
      "score": 0.9860799908638
    }
  ],
  "7938": [
    {
      "answer": "Kingdom of Qocho and Tibetan intermediaries",
      "score": 0.9644762873649597
    }
  ],
  "7939": [
    {
      "answer": "Wang Zhen",
      "score": 0.5904269218444824
    }
  ],
  "7940": [
    {
      "answer": "1273",
      "score": 0.9731274843215942
    }
  ],
  "7941": [
    {
      "answer": "T\u00f6regene Khatun",
      "score": 0.8785852193832397
    },
    {
      "answer": "\u00d6gedei",
      "score": 0.5620884299278259
    }
  ],
  "7942": [
    {
      "answer": "1273",
      "score": 0.9824135303497314
    }
  ],
  "7943": [
    {
      "answer": "chao",
      "score": 0.9661970734596252
    }
  ],
  "7944": [
    {
      "answer": "bark of mulberry trees",
      "score": 0.9838124513626099
    }
  ],
  "7945": [
    {
      "answer": "1275",
      "score": 0.995769739151001
    }
  ],
  "7946": [
    {
      "answer": "woodblocks",
      "score": 0.9955162405967712
    }
  ],
  "7947": [
    {
      "answer": "1294",
      "score": 0.9719365835189819
    }
  ],
  "7948": [
    {
      "answer": "chao",
      "score": 0.9385890960693359
    }
  ],
  "7949": [
    {
      "answer": "bark of mulberry trees",
      "score": 0.9829635620117188
    }
  ],
  "7950": [
    {
      "answer": "1275",
      "score": 0.995044469833374
    }
  ],
  "7951": [
    {
      "answer": "woodblocks",
      "score": 0.9934506416320801
    }
  ],
  "7952": [
    {
      "answer": "1275",
      "score": 0.9946882724761963
    }
  ],
  "7953": [
    {
      "answer": "Mongolian patrimonial feudalism",
      "score": 0.9145714640617371
    },
    {
      "answer": "traditional Chinese autocratic-bureaucratic system",
      "score": 0.9347973465919495
    }
  ],
  "7954": [
    {
      "answer": "Mongolian patrimonial feudalism",
      "score": 0.674846351146698
    },
    {
      "answer": "traditional Chinese autocratic-bureaucratic system",
      "score": 0.977627694606781
    }
  ],
  "7955": [
    {
      "answer": "various allied groups from Central Asia and the western end of the empire",
      "score": 0.9723683595657349
    }
  ],
  "7956": [
    {
      "answer": "a somewhat strong \"colonial\" coloration",
      "score": 0.8836363554000854
    }
  ],
  "7957": [
    {
      "answer": "Ilkhanate",
      "score": 0.9915434122085571
    }
  ],
  "7958": [
    {
      "answer": "Mongolian patrimonial feudalism",
      "score": 0.9254159927368164
    },
    {
      "answer": "traditional Chinese autocratic-bureaucratic system",
      "score": 0.609817385673523
    }
  ],
  "7959": [
    {
      "answer": "traditional Chinese autocratic-bureaucratic system",
      "score": 0.9698686599731445
    }
  ],
  "7960": [],
  "7961": [
    {
      "answer": "a somewhat strong \"colonial\" coloration",
      "score": 0.8886188268661499
    }
  ],
  "7962": [
    {
      "answer": "Central Asian Muslims",
      "score": 0.9331635236740112
    }
  ],
  "7963": [
    {
      "answer": "Han Chinese and Khitans",
      "score": 0.9673622250556946
    },
    {
      "answer": "Han Chinese",
      "score": 0.5311844348907471
    }
  ],
  "7964": [
    {
      "answer": "Besh Baliq",
      "score": 0.977826714515686
    },
    {
      "answer": "Almaliq",
      "score": 0.9707105755805969
    },
    {
      "answer": "Samarqand",
      "score": 0.9501985907554626
    },
    {
      "answer": "Samarqand",
      "score": 0.6272662281990051
    },
    {
      "answer": "Samarqand",
      "score": 0.6048937439918518
    }
  ],
  "7965": [
    {
      "answer": "artisans and farmers",
      "score": 0.9692221879959106
    }
  ],
  "7966": [
    {
      "answer": "a Qara-Khitay (Khitan)",
      "score": 0.9041496515274048
    }
  ],
  "7967": [
    {
      "answer": "Central Asian Muslims",
      "score": 0.8082633018493652
    }
  ],
  "7968": [
    {
      "answer": "Han Chinese",
      "score": 0.8947505950927734
    },
    {
      "answer": "Khitans",
      "score": 0.8704838156700134
    },
    {
      "answer": "Han Chinese",
      "score": 0.6311051845550537
    }
  ],
  "7969": [
    {
      "answer": "Besh Baliq",
      "score": 0.9420833587646484
    },
    {
      "answer": "Almaliq, and Samarqand",
      "score": 0.8848979473114014
    }
  ],
  "7970": [
    {
      "answer": "artisans and farmers",
      "score": 0.973353385925293
    }
  ],
  "7971": [
    {
      "answer": "restricting Halal slaughter and other Islamic practices like circumcision",
      "score": 0.9267226457595825
    },
    {
      "answer": "Kosher butchering for Jews",
      "score": 0.8332160711288452
    },
    {
      "answer": "forcing them to eat food the Mongol way",
      "score": 0.6668127179145813
    }
  ],
  "7972": [
    {
      "answer": "Kosher butchering",
      "score": 0.9651129245758057
    }
  ],
  "7973": [
    {
      "answer": "Zhu Yuanzhang",
      "score": 0.9930224418640137
    },
    {
      "answer": "Zhu Yuanzhang",
      "score": 0.95340895652771
    }
  ],
  "7974": [
    {
      "answer": "thanks",
      "score": 0.9882918000221252
    },
    {
      "answer": "thanks",
      "score": 0.5805103778839111
    }
  ],
  "7975": [
    {
      "answer": "Muslim generals",
      "score": 0.8030514717102051
    }
  ],
  "7976": [
    {
      "answer": "restricting Halal slaughter and other Islamic practices like circumcision",
      "score": 0.9211546778678894
    }
  ],
  "7977": [
    {
      "answer": "Kosher butchering",
      "score": 0.9738717079162598
    }
  ],
  "7978": [
    {
      "answer": "Zhu Yuanzhang",
      "score": 0.9542328119277954
    },
    {
      "answer": "Zhu Yuanzhang",
      "score": 0.9109368324279785
    }
  ],
  "7979": [
    {
      "answer": "thanks",
      "score": 0.98774254322052
    },
    {
      "answer": "thanks",
      "score": 0.622727632522583
    }
  ],
  "7980": [
    {
      "answer": "Chen Youding",
      "score": 0.9673928618431091
    }
  ],
  "7981": [
    {
      "answer": "Frederick W. Mote",
      "score": 0.9969717264175415
    }
  ],
  "7982": [
    {
      "answer": "degrees of privilege",
      "score": 0.9671168327331543
    }
  ],
  "7983": [],
  "7984": [],
  "7985": [
    {
      "answer": "Frederick W. Mote",
      "score": 0.9902845025062561
    }
  ],
  "7986": [
    {
      "answer": "not an indication of their actual social power and wealth",
      "score": 0.7624084949493408
    },
    {
      "answer": "degrees of privilege",
      "score": 0.7531813383102417
    }
  ],
  "7987": [],
  "7988": [],
  "7989": [
    {
      "answer": "Northern",
      "score": 0.9955328702926636
    }
  ],
  "7990": [
    {
      "answer": "Southern",
      "score": 0.9847983717918396
    }
  ],
  "7991": [
    {
      "answer": "southern China withstood and fought to the last before caving in",
      "score": 0.9816879034042358
    }
  ],
  "7992": [
    {
      "answer": "southern China withstood and fought to the last before caving in",
      "score": 0.9672142863273621
    }
  ],
  "7993": [
    {
      "answer": "southern Chinese manufacturers and merchants",
      "score": 0.9825213551521301
    }
  ],
  "7994": [
    {
      "answer": "Northern",
      "score": 0.994999885559082
    }
  ],
  "7995": [
    {
      "answer": "Southern",
      "score": 0.9702642560005188
    }
  ],
  "7996": [
    {
      "answer": "southern China withstood and fought to the last before caving in",
      "score": 0.9593167901039124
    }
  ],
  "7997": [
    {
      "answer": "southern China withstood and fought to the last before caving in",
      "score": 0.9429512023925781
    }
  ],
  "7998": [
    {
      "answer": "southern Chinese manufacturers and merchants",
      "score": 0.9785704016685486
    }
  ],
  "7999": [
    {
      "answer": "Uighur King of Qocho",
      "score": 0.6533873081207275
    },
    {
      "answer": "Karluk Kara-Khanid ruler",
      "score": 0.6513370871543884
    }
  ],
  "8000": [
    {
      "answer": "Karluk Kara-Khanid",
      "score": 0.9847029447555542
    }
  ],
  "8001": [
    {
      "answer": "Korean King",
      "score": 0.5912245512008667
    },
    {
      "answer": "Korean King",
      "score": 0.9876539707183838
    }
  ],
  "8002": [
    {
      "answer": "the Uighurs surrendered to the Mongols first",
      "score": 0.960578203201294
    }
  ],
  "8003": [
    {
      "answer": "Korean King",
      "score": 0.9544774293899536
    },
    {
      "answer": "Korean King",
      "score": 0.7444728016853333
    },
    {
      "answer": "Korean King",
      "score": 0.6951556205749512
    }
  ],
  "8004": [
    {
      "answer": "Karluk Kara-Khanid",
      "score": 0.96320641040802
    }
  ],
  "8005": [
    {
      "answer": "Korean King",
      "score": 0.6685290336608887
    },
    {
      "answer": "Korean King",
      "score": 0.6878794431686401
    },
    {
      "answer": "Korean King",
      "score": 0.9908612966537476
    }
  ],
  "8006": [
    {
      "answer": "the Uighurs surrendered to the Mongols first",
      "score": 0.9365088939666748
    }
  ],
  "8007": [
    {
      "answer": "Central Region",
      "score": 0.9656552076339722
    }
  ],
  "8008": [
    {
      "answer": "Central Secretariat",
      "score": 0.974979817867279
    }
  ],
  "8009": [
    {
      "answer": "Khanbaliq",
      "score": 0.94858717918396
    }
  ],
  "8010": [
    {
      "answer": "Beijing",
      "score": 0.9840267896652222
    }
  ],
  "8011": [
    {
      "answer": "Zhongshu Sheng",
      "score": 0.9856679439544678
    }
  ],
  "8012": [
    {
      "answer": "Central Region",
      "score": 0.9218494892120361
    }
  ],
  "8013": [
    {
      "answer": "Central Secretariat",
      "score": 0.9493290185928345
    }
  ],
  "8014": [
    {
      "answer": "Khanbaliq",
      "score": 0.9588936567306519
    }
  ],
  "8015": [
    {
      "answer": "Beijing",
      "score": 0.9926449060440063
    }
  ],
  "8016": [
    {
      "answer": "Zhongshu Sheng",
      "score": 0.9773176908493042
    }
  ],
  "8017": [
    {
      "answer": "disease",
      "score": 0.9837925434112549
    }
  ],
  "8018": [],
  "8019": [
    {
      "answer": "neuroimmune system",
      "score": 0.9713601469993591
    }
  ],
  "8020": [
    {
      "answer": "blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier, and similar fluid\u2013brain barriers",
      "score": 0.9390871524810791
    }
  ],
  "8021": [
    {
      "answer": "pathogens",
      "score": 0.911915123462677
    }
  ],
  "8022": [
    {
      "answer": "humoral immunity",
      "score": 0.9598487615585327
    },
    {
      "answer": "cell-mediated immunity",
      "score": 0.915318489074707
    }
  ],
  "8023": [
    {
      "answer": "innate immune system",
      "score": 0.9589020013809204
    },
    {
      "answer": "adaptive immune system",
      "score": 0.9468587636947632
    },
    {
      "answer": "humoral immunity versus cell-mediated immunity",
      "score": 0.6859211921691895
    }
  ],
  "8024": [
    {
      "answer": "neuroimmune system",
      "score": 0.8873593807220459
    }
  ],
  "8025": [
    {
      "answer": "immune system",
      "score": 0.9620187878608704
    },
    {
      "answer": "immune system",
      "score": 0.8056612014770508
    },
    {
      "answer": "immune system",
      "score": 0.8162316083908081
    },
    {
      "answer": "immune system",
      "score": 0.8187804222106934
    },
    {
      "answer": "immune system",
      "score": 0.6998723745346069
    },
    {
      "answer": "immune system",
      "score": 0.7518976330757141
    }
  ],
  "8026": [
    {
      "answer": "viruses",
      "score": 0.7703871130943298
    },
    {
      "answer": "parasitic worms",
      "score": 0.8832894563674927
    }
  ],
  "8027": [
    {
      "answer": "parasitic worms",
      "score": 0.6971075534820557
    }
  ],
  "8028": [],
  "8029": [
    {
      "answer": "blood\u2013brain barrier",
      "score": 0.9804307222366333
    },
    {
      "answer": "blood\u2013cerebrospinal fluid barrier",
      "score": 0.9334635138511658
    }
  ],
  "8030": [
    {
      "answer": "recurring and life-threatening infections",
      "score": 0.8830522298812866
    }
  ],
  "8031": [
    {
      "answer": "autoimmunity",
      "score": 0.9847304821014404
    }
  ],
  "8032": [
    {
      "answer": "Immunology",
      "score": 0.9843191504478455
    }
  ],
  "8033": [
    {
      "answer": "HIV/AIDS",
      "score": 0.992370069026947
    }
  ],
  "8034": [],
  "8035": [
    {
      "answer": "immunosuppressive",
      "score": 0.9956536293029785
    }
  ],
  "8036": [
    {
      "answer": "hyperactive",
      "score": 0.9563958048820496
    }
  ],
  "8037": [
    {
      "answer": "HIV/AIDS",
      "score": 0.7579599618911743
    },
    {
      "answer": "immunosuppressive medication",
      "score": 0.808810830116272
    }
  ],
  "8038": [],
  "8039": [
    {
      "answer": "Robert Koch",
      "score": 0.9954895973205566
    }
  ],
  "8040": [
    {
      "answer": "microorganisms",
      "score": 0.9662948846817017
    }
  ],
  "8041": [
    {
      "answer": "yellow fever",
      "score": 0.9757798910140991
    }
  ],
  "8042": [
    {
      "answer": "430 BC",
      "score": 0.9831855297088623
    }
  ],
  "8043": [
    {
      "answer": "Immunology",
      "score": 0.9685873985290527
    }
  ],
  "8044": [
    {
      "answer": "1891",
      "score": 0.8543530106544495
    }
  ],
  "8045": [
    {
      "answer": "Pierre-Louis Moreau de Maupertuis",
      "score": 0.9923216104507446
    }
  ],
  "8046": [
    {
      "answer": "Louis Pasteur",
      "score": 0.9808065891265869
    }
  ],
  "8047": [
    {
      "answer": "1891",
      "score": 0.9456769824028015
    },
    {
      "answer": "1901",
      "score": 0.6546393036842346
    }
  ],
  "8048": [
    {
      "answer": "Innate",
      "score": 0.96684730052948
    }
  ],
  "8049": [
    {
      "answer": "adaptive immune system",
      "score": 0.9851929545402527
    },
    {
      "answer": "adaptive immune system",
      "score": 0.8226560354232788
    }
  ],
  "8050": [
    {
      "answer": "immunological memory",
      "score": 0.9879026412963867
    }
  ],
  "8051": [
    {
      "answer": "physical barriers",
      "score": 0.9862430095672607
    }
  ],
  "8052": [
    {
      "answer": "physical barriers",
      "score": 0.8228597640991211
    }
  ],
  "8053": [
    {
      "answer": "bacteria and viruses",
      "score": 0.8677068948745728
    }
  ],
  "8054": [
    {
      "answer": "adaptive immune system",
      "score": 0.9866384267807007
    },
    {
      "answer": "adaptive immune system",
      "score": 0.9036130905151367
    }
  ],
  "8055": [
    {
      "answer": "immunological memory",
      "score": 0.9326850175857544
    }
  ],
  "8056": [
    {
      "answer": "physical barriers",
      "score": 0.9336233139038086
    }
  ],
  "8057": [
    {
      "answer": "self",
      "score": 0.980562686920166
    },
    {
      "answer": "non-self molecules",
      "score": 0.974705696105957
    }
  ],
  "8058": [
    {
      "answer": "self molecules",
      "score": 0.9541852474212646
    }
  ],
  "8059": [
    {
      "answer": "antigens",
      "score": 0.9098926782608032
    }
  ],
  "8060": [
    {
      "answer": "antigens",
      "score": 0.9766104221343994
    }
  ],
  "8061": [
    {
      "answer": "immune receptors",
      "score": 0.9920895099639893
    }
  ],
  "8062": [
    {
      "answer": "innate and adaptive immunity",
      "score": 0.9068952798843384
    }
  ],
  "8063": [
    {
      "answer": "antigens",
      "score": 0.9840306043624878
    }
  ],
  "8064": [
    {
      "answer": "self molecules",
      "score": 0.8839784860610962
    }
  ],
  "8065": [
    {
      "answer": "immune receptors",
      "score": 0.9860131740570068
    }
  ],
  "8066": [],
  "8067": [
    {
      "answer": "pattern recognition receptors",
      "score": 0.9720368385314941
    }
  ],
  "8068": [
    {
      "answer": "innate immune system",
      "score": 0.8927587270736694
    },
    {
      "answer": "innate immune system",
      "score": 0.9621738195419312
    }
  ],
  "8069": [
    {
      "answer": "microorganisms",
      "score": 0.9880040884017944
    }
  ],
  "8070": [
    {
      "answer": "non-specific",
      "score": 0.9926597476005554
    }
  ],
  "8071": [
    {
      "answer": "cells and mechanisms of the innate immune system",
      "score": 0.938326895236969
    }
  ],
  "8072": [
    {
      "answer": "pattern recognition receptors",
      "score": 0.7654611468315125
    },
    {
      "answer": "damaged, injured or stressed cells send out alarm signals",
      "score": 0.8414596915245056
    }
  ],
  "8073": [
    {
      "answer": "damaged, injured or stressed",
      "score": 0.9655608534812927
    }
  ],
  "8074": [
    {
      "answer": "Innate immune defenses are non-specific",
      "score": 0.8323107957839966
    }
  ],
  "8075": [
    {
      "answer": "innate immune system",
      "score": 0.8381603956222534
    },
    {
      "answer": "innate immune system",
      "score": 0.8539270162582397
    }
  ],
  "8076": [
    {
      "answer": "exoskeleton",
      "score": 0.9718067646026611
    }
  ],
  "8077": [
    {
      "answer": "waxy cuticle",
      "score": 0.9748207330703735
    }
  ],
  "8078": [
    {
      "answer": "coughing",
      "score": 0.982174277305603
    },
    {
      "answer": "sneezing",
      "score": 0.9788680076599121
    }
  ],
  "8079": [
    {
      "answer": "mucus",
      "score": 0.9819179773330688
    }
  ],
  "8080": [
    {
      "answer": "tears",
      "score": 0.8856567740440369
    },
    {
      "answer": "urine",
      "score": 0.9772015810012817
    }
  ],
  "8081": [
    {
      "answer": "mucus",
      "score": 0.7467390298843384
    }
  ],
  "8082": [],
  "8083": [
    {
      "answer": "other systems act to protect body openings such as the lungs, intestines, and the genitourinary tract",
      "score": 0.673918604850769
    }
  ],
  "8084": [
    {
      "answer": "coughing and sneezing",
      "score": 0.7921053767204285
    },
    {
      "answer": "urine",
      "score": 0.8091528415679932
    }
  ],
  "8085": [
    {
      "answer": "skin",
      "score": 0.8369924426078796
    }
  ],
  "8086": [
    {
      "answer": "\u03b2-defensins",
      "score": 0.9673136472702026
    }
  ],
  "8087": [
    {
      "answer": "lysozyme",
      "score": 0.9558295011520386
    },
    {
      "answer": "phospholipase A2",
      "score": 0.9366673231124878
    }
  ],
  "8088": [
    {
      "answer": "defensins",
      "score": 0.9750778079032898
    },
    {
      "answer": "zinc",
      "score": 0.9700148701667786
    }
  ],
  "8089": [
    {
      "answer": "gastric acid",
      "score": 0.9538412690162659
    },
    {
      "answer": "proteases",
      "score": 0.9714424014091492
    }
  ],
  "8090": [
    {
      "answer": "menarche",
      "score": 0.9939550757408142
    }
  ],
  "8091": [
    {
      "answer": "antimicrobial peptides",
      "score": 0.9165567755699158
    },
    {
      "answer": "\u03b2-defensins",
      "score": 0.6334273815155029
    }
  ],
  "8092": [
    {
      "answer": "lysozyme",
      "score": 0.8042324781417847
    },
    {
      "answer": "phospholipase A2",
      "score": 0.8158125877380371
    }
  ],
  "8093": [
    {
      "answer": "Vaginal secretions",
      "score": 0.9433652758598328
    }
  ],
  "8094": [
    {
      "answer": "menarche",
      "score": 0.99349445104599
    }
  ],
  "8095": [
    {
      "answer": "Vaginal secretions",
      "score": 0.6116006374359131
    },
    {
      "answer": "gastric acid",
      "score": 0.6492011547088623
    }
  ],
  "8096": [
    {
      "answer": "commensal flora",
      "score": 0.9916900396347046
    }
  ],
  "8097": [
    {
      "answer": "fungi",
      "score": 0.9035804867744446
    }
  ],
  "8098": [
    {
      "answer": "lactobacilli",
      "score": 0.9642925262451172
    }
  ],
  "8099": [
    {
      "answer": "pH",
      "score": 0.9931039214134216
    }
  ],
  "8100": [
    {
      "answer": "genitourinary",
      "score": 0.9705629944801331
    },
    {
      "answer": "gastrointestinal",
      "score": 0.9744263887405396
    }
  ],
  "8101": [
    {
      "answer": "pathogenic bacteria",
      "score": 0.9724316596984863
    }
  ],
  "8102": [
    {
      "answer": "antibiotics",
      "score": 0.9835721850395203
    }
  ],
  "8103": [
    {
      "answer": "unpasteurized yogurt",
      "score": 0.9760875105857849
    }
  ],
  "8104": [
    {
      "answer": "vaginal candidiasis",
      "score": 0.9346963763237
    }
  ],
  "8105": [
    {
      "answer": "Inflammation",
      "score": 0.8673892021179199
    },
    {
      "answer": "inflammation",
      "score": 0.698222815990448
    },
    {
      "answer": "Inflammation",
      "score": 0.6978220343589783
    },
    {
      "answer": "inflammation",
      "score": 0.7100598812103271
    }
  ],
  "8106": [
    {
      "answer": "increased blood flow into tissue",
      "score": 0.9594056010246277
    }
  ],
  "8107": [
    {
      "answer": "eicosanoids",
      "score": 0.9057207703590393
    }
  ],
  "8108": [
    {
      "answer": "prostaglandins",
      "score": 0.9868738055229187
    }
  ],
  "8109": [
    {
      "answer": "interleukins",
      "score": 0.9701167345046997
    }
  ],
  "8110": [
    {
      "answer": "Inflammation",
      "score": 0.6474687457084656
    }
  ],
  "8111": [],
  "8112": [],
  "8113": [],
  "8114": [],
  "8115": [
    {
      "answer": "phagocytes",
      "score": 0.9625747799873352
    }
  ],
  "8116": [
    {
      "answer": "cytokines",
      "score": 0.9917230010032654
    }
  ],
  "8117": [
    {
      "answer": "phagosome",
      "score": 0.975575864315033
    },
    {
      "answer": "phagolysosome",
      "score": 0.7214520573616028
    }
  ],
  "8118": [
    {
      "answer": "phagolysosome",
      "score": 0.9810051918029785
    },
    {
      "answer": "phagolysosome",
      "score": 0.7215898633003235
    }
  ],
  "8119": [
    {
      "answer": "acquiring nutrients",
      "score": 0.9837335348129272
    }
  ],
  "8120": [
    {
      "answer": "Phagocytes",
      "score": 0.8195233345031738
    }
  ],
  "8121": [
    {
      "answer": "cytokines",
      "score": 0.9909515380859375
    }
  ],
  "8122": [
    {
      "answer": "intracellular",
      "score": 0.9497376084327698
    }
  ],
  "8123": [
    {
      "answer": "activity of digestive enzymes",
      "score": 0.946366012096405
    }
  ],
  "8124": [],
  "8125": [
    {
      "answer": "Neutrophils",
      "score": 0.9316927194595337
    },
    {
      "answer": "macrophages",
      "score": 0.9351400136947632
    },
    {
      "answer": "Neutrophils",
      "score": 0.6867595911026001
    },
    {
      "answer": "Macrophages",
      "score": 0.6617342233657837
    },
    {
      "answer": "Macrophages",
      "score": 0.6799376606941223
    }
  ],
  "8126": [
    {
      "answer": "Neutrophils",
      "score": 0.5694209337234497
    },
    {
      "answer": "Neutrophils",
      "score": 0.9741809368133545
    }
  ],
  "8127": [
    {
      "answer": "50% to 60%",
      "score": 0.9855518341064453
    }
  ],
  "8128": [
    {
      "answer": "chemotaxis",
      "score": 0.9733704924583435
    }
  ],
  "8129": [
    {
      "answer": "interleukin 1",
      "score": 0.9553765058517456
    }
  ],
  "8130": [],
  "8131": [],
  "8132": [
    {
      "answer": "Neutrophils",
      "score": 0.9369983673095703
    }
  ],
  "8133": [],
  "8134": [],
  "8135": [],
  "8136": [],
  "8137": [
    {
      "answer": "adaptive",
      "score": 0.9903310537338257
    }
  ],
  "8138": [
    {
      "answer": "neutrophils",
      "score": 0.8376542329788208
    },
    {
      "answer": "dendritic cells",
      "score": 0.895552396774292
    }
  ],
  "8139": [],
  "8140": [
    {
      "answer": "innate immune system",
      "score": 0.9598673582077026
    }
  ],
  "8141": [],
  "8142": [],
  "8143": [
    {
      "answer": "Innate cells",
      "score": 0.9397835731506348
    }
  ],
  "8144": [],
  "8145": [
    {
      "answer": "neuronal dendrites",
      "score": 0.9941843748092651
    }
  ],
  "8146": [
    {
      "answer": "T cells",
      "score": 0.7662936449050903
    }
  ],
  "8147": [
    {
      "answer": "T cells",
      "score": 0.5744155645370483
    }
  ],
  "8148": [],
  "8149": [],
  "8150": [
    {
      "answer": "neuronal dendrites",
      "score": 0.7312799692153931
    }
  ],
  "8151": [],
  "8152": [
    {
      "answer": "Dendritic cells",
      "score": 0.8932238817214966
    }
  ],
  "8153": [
    {
      "answer": "Natural killer cells",
      "score": 0.9729971885681152
    }
  ],
  "8154": [
    {
      "answer": "missing self",
      "score": 0.9960101842880249
    },
    {
      "answer": "missing self",
      "score": 0.873015284538269
    },
    {
      "answer": "missing self",
      "score": 0.8703532218933105
    }
  ],
  "8155": [
    {
      "answer": "MHC I",
      "score": 0.9715722799301147
    }
  ],
  "8156": [
    {
      "answer": "killer cell immunoglobulin receptors",
      "score": 0.9722914695739746
    }
  ],
  "8157": [
    {
      "answer": "Natural killer cells",
      "score": 0.6139200925827026
    }
  ],
  "8158": [
    {
      "answer": "compromised host cells",
      "score": 0.8157626986503601
    }
  ],
  "8159": [],
  "8160": [
    {
      "answer": "many years",
      "score": 0.9491511583328247
    }
  ],
  "8161": [
    {
      "answer": "recognition of \"missing self\"",
      "score": 0.9244463443756104
    }
  ],
  "8162": [
    {
      "answer": "vertebrates",
      "score": 0.9910227060317993
    }
  ],
  "8163": [
    {
      "answer": "antigen presentation",
      "score": 0.9976193904876709
    }
  ],
  "8164": [
    {
      "answer": "pathogens",
      "score": 0.9810143113136292
    },
    {
      "answer": "pathogen-infected cells",
      "score": 0.9430269002914429
    }
  ],
  "8165": [
    {
      "answer": "adaptive immune system",
      "score": 0.9898749589920044
    }
  ],
  "8166": [
    {
      "answer": "adaptive immune response",
      "score": 0.7969111204147339
    }
  ],
  "8167": [
    {
      "answer": "antigen-specific",
      "score": 0.7314494252204895
    },
    {
      "answer": "recognition of specific \"non-self\" antigens",
      "score": 0.7191153764724731
    }
  ],
  "8168": [
    {
      "answer": "Antigen specificity",
      "score": 0.9701552391052246
    }
  ],
  "8169": [
    {
      "answer": "memory cells",
      "score": 0.9812841415405273
    }
  ],
  "8170": [
    {
      "answer": "killer T cell",
      "score": 0.9917506575584412
    }
  ],
  "8171": [
    {
      "answer": "regulatory T cells",
      "score": 0.9178365468978882
    }
  ],
  "8172": [
    {
      "answer": "Class I MHC molecules",
      "score": 0.9845149517059326
    }
  ],
  "8173": [
    {
      "answer": "Class II MHC molecules",
      "score": 0.9628899097442627
    }
  ],
  "8174": [
    {
      "answer": "\u03b3\u03b4",
      "score": 0.9901065230369568
    }
  ],
  "8175": [
    {
      "answer": "\u03b3\u03b4 T cells",
      "score": 0.7746299505233765
    }
  ],
  "8176": [
    {
      "answer": "pathogen",
      "score": 0.8952099680900574
    }
  ],
  "8177": [
    {
      "answer": "two",
      "score": 0.976242184638977
    },
    {
      "answer": "two",
      "score": 0.6302835941314697
    },
    {
      "answer": "two",
      "score": 0.7380505204200745
    }
  ],
  "8178": [
    {
      "answer": "two",
      "score": 0.69110107421875
    },
    {
      "answer": "two",
      "score": 0.6712690591812134
    },
    {
      "answer": "two",
      "score": 0.8947164416313171
    }
  ],
  "8179": [
    {
      "answer": "antigens",
      "score": 0.946748673915863
    }
  ],
  "8180": [
    {
      "answer": "Killer T cells",
      "score": 0.9597188234329224
    },
    {
      "answer": "Killer T cells",
      "score": 0.8194052577018738
    }
  ],
  "8181": [
    {
      "answer": "T cell receptor",
      "score": 0.8646368980407715
    }
  ],
  "8182": [
    {
      "answer": "CD8",
      "score": 0.9812340140342712
    }
  ],
  "8183": [
    {
      "answer": "perforin",
      "score": 0.9915741086006165
    }
  ],
  "8184": [
    {
      "answer": "granulysin",
      "score": 0.9771631956100464
    }
  ],
  "8185": [
    {
      "answer": "Killer T cells",
      "score": 0.7033323645591736
    }
  ],
  "8186": [
    {
      "answer": "cells that are infected with viruses",
      "score": 0.8469448089599609
    }
  ],
  "8187": [],
  "8188": [
    {
      "answer": "CD8",
      "score": 0.9874420762062073
    }
  ],
  "8189": [
    {
      "answer": "perforin",
      "score": 0.9327117204666138
    }
  ],
  "8190": [
    {
      "answer": "CD4",
      "score": 0.9701940417289734
    }
  ],
  "8191": [
    {
      "answer": "200\u2013300",
      "score": 0.9850921034812927
    }
  ],
  "8192": [
    {
      "answer": "200\u2013300",
      "score": 0.9827984571456909
    }
  ],
  "8193": [
    {
      "answer": "cytokines",
      "score": 0.9574865698814392
    }
  ],
  "8194": [
    {
      "answer": "CD40 ligand",
      "score": 0.9367392063140869
    }
  ],
  "8195": [],
  "8196": [
    {
      "answer": "Helper T cells",
      "score": 0.9168680906295776
    }
  ],
  "8197": [],
  "8198": [],
  "8199": [],
  "8200": [],
  "8201": [
    {
      "answer": "T cell receptor",
      "score": 0.921678900718689
    }
  ],
  "8202": [
    {
      "answer": "Gamma delta T cells",
      "score": 0.8787142038345337
    },
    {
      "answer": "\u03b3\u03b4 T cells",
      "score": 0.6599513292312622
    },
    {
      "answer": "\u03b3\u03b4 T cells",
      "score": 0.7331809997558594
    }
  ],
  "8203": [
    {
      "answer": "diversity",
      "score": 0.9960099458694458
    }
  ],
  "8204": [
    {
      "answer": "V\u03b39/V\u03b42 T cells",
      "score": 0.9268863797187805
    }
  ],
  "8205": [
    {
      "answer": "CD4+ and CD8+ (\u03b1\u03b2) T cells",
      "score": 0.8504892587661743
    }
  ],
  "8206": [],
  "8207": [],
  "8208": [
    {
      "answer": "human V\u03b39/V\u03b42 T cells",
      "score": 0.9451380968093872
    }
  ],
  "8209": [
    {
      "answer": "B cell",
      "score": 0.7714098691940308
    }
  ],
  "8210": [
    {
      "answer": "proteolysis",
      "score": 0.9707622528076172
    }
  ],
  "8211": [
    {
      "answer": "lymphokines",
      "score": 0.989006757736206
    }
  ],
  "8212": [
    {
      "answer": "antibodies on its surface bind to a specific foreign antigen",
      "score": 0.8340619206428528
    }
  ],
  "8213": [
    {
      "answer": "peptides",
      "score": 0.779177725315094
    }
  ],
  "8214": [
    {
      "answer": "This combination of MHC and antigen",
      "score": 0.8381413221359253
    }
  ],
  "8215": [
    {
      "answer": "blood plasma and lymph",
      "score": 0.9129080772399902
    }
  ],
  "8216": [
    {
      "answer": "bacterial toxins",
      "score": 0.8623521327972412
    }
  ],
  "8217": [
    {
      "answer": "long-lived memory cells",
      "score": 0.9948424696922302
    }
  ],
  "8218": [
    {
      "answer": "adaptive",
      "score": 0.9782720804214478
    }
  ],
  "8219": [
    {
      "answer": "passive short-term memory",
      "score": 0.990829348564148
    },
    {
      "answer": "active long-term memory",
      "score": 0.9888637065887451
    }
  ],
  "8220": [
    {
      "answer": "pathogen",
      "score": 0.9889300465583801
    }
  ],
  "8221": [
    {
      "answer": "some of their offspring become long-lived memory cells",
      "score": 0.8701118230819702
    }
  ],
  "8222": [],
  "8223": [
    {
      "answer": "passive short-term memory",
      "score": 0.8878223896026611
    },
    {
      "answer": "active long-term memory",
      "score": 0.8846632838249207
    }
  ],
  "8224": [
    {
      "answer": "it occurs during the lifetime of an individual as an adaptation to infection with that pathogen and prepares the immune system for future challenges",
      "score": 0.9085246920585632
    }
  ],
  "8225": [
    {
      "answer": "B cells",
      "score": 0.5771665573120117
    }
  ],
  "8226": [
    {
      "answer": "microbes",
      "score": 0.9935524463653564
    }
  ],
  "8227": [
    {
      "answer": "IgG",
      "score": 0.9400591850280762
    }
  ],
  "8228": [
    {
      "answer": "Breast milk",
      "score": 0.9857634902000427
    }
  ],
  "8229": [
    {
      "answer": "passive immunity",
      "score": 0.6483238339424133
    },
    {
      "answer": "passive immunity",
      "score": 0.8493309020996094
    }
  ],
  "8230": [
    {
      "answer": "Newborn infants",
      "score": 0.8434098958969116
    }
  ],
  "8231": [
    {
      "answer": "Several",
      "score": 0.8402817249298096
    }
  ],
  "8232": [
    {
      "answer": "IgG",
      "score": 0.9670183062553406
    }
  ],
  "8233": [
    {
      "answer": "antibodies",
      "score": 0.6899134516716003
    }
  ],
  "8234": [
    {
      "answer": "passive immunity",
      "score": 0.954533576965332
    }
  ],
  "8235": [
    {
      "answer": "immunomodulators",
      "score": 0.9888836741447449
    }
  ],
  "8236": [
    {
      "answer": "adaptive",
      "score": 0.9896414875984192
    }
  ],
  "8237": [
    {
      "answer": "lupus erythematosus",
      "score": 0.994600772857666
    }
  ],
  "8238": [
    {
      "answer": "immunosuppressive",
      "score": 0.9835013747215271
    }
  ],
  "8239": [],
  "8240": [
    {
      "answer": "puberty",
      "score": 0.9929919242858887
    }
  ],
  "8241": [
    {
      "answer": "testosterone",
      "score": 0.9250934720039368
    }
  ],
  "8242": [
    {
      "answer": "testosterone",
      "score": 0.975487232208252
    }
  ],
  "8243": [
    {
      "answer": "lupus erythematosus",
      "score": 0.9935387372970581
    }
  ],
  "8244": [
    {
      "answer": "NFIL3",
      "score": 0.9633589386940002
    }
  ],
  "8245": [
    {
      "answer": "heart disease",
      "score": 0.975263237953186
    },
    {
      "answer": "chronic pain",
      "score": 0.9744107723236084
    },
    {
      "answer": "asthma",
      "score": 0.9703744649887085
    }
  ],
  "8246": [
    {
      "answer": "sleep deprivation",
      "score": 0.6818421483039856
    },
    {
      "answer": "immunizations",
      "score": 0.9148766994476318
    }
  ],
  "8247": [
    {
      "answer": "immunizations",
      "score": 0.8282514214515686
    },
    {
      "answer": "antibody production",
      "score": 0.6904342174530029
    }
  ],
  "8248": [
    {
      "answer": "sleep deprivation",
      "score": 0.7371006608009338
    },
    {
      "answer": "active immunizations",
      "score": 0.7506512999534607
    }
  ],
  "8249": [
    {
      "answer": "NFIL3",
      "score": 0.8922657370567322
    }
  ],
  "8250": [
    {
      "answer": "heart disease",
      "score": 0.9679316878318787
    },
    {
      "answer": "chronic pain",
      "score": 0.9503453373908997
    },
    {
      "answer": "asthma",
      "score": 0.944556713104248
    }
  ],
  "8251": [],
  "8252": [
    {
      "answer": "hormone",
      "score": 0.9730015397071838
    }
  ],
  "8253": [
    {
      "answer": "vitamin D",
      "score": 0.6783556938171387
    },
    {
      "answer": "vitamin D",
      "score": 0.9833948612213135
    }
  ],
  "8254": [
    {
      "answer": "thyroid hormone",
      "score": 0.95658278465271
    }
  ],
  "8255": [
    {
      "answer": "cholecalciferol",
      "score": 0.9950462579727173
    }
  ],
  "8256": [],
  "8257": [
    {
      "answer": "weakened immune responses",
      "score": 0.951614260673523
    }
  ],
  "8258": [
    {
      "answer": "thyroid hormone",
      "score": 0.9664227962493896
    }
  ],
  "8259": [
    {
      "answer": "decreased activity levels",
      "score": 0.7947775721549988
    }
  ],
  "8260": [
    {
      "answer": "skin",
      "score": 0.9917762279510498
    }
  ],
  "8261": [
    {
      "answer": "killer T cells",
      "score": 0.9630370140075684
    },
    {
      "answer": "helper T cells",
      "score": 0.6577560901641846
    },
    {
      "answer": "killer T cells",
      "score": 0.7750083208084106
    }
  ],
  "8262": [
    {
      "answer": "MHC class I",
      "score": 0.9826091527938843
    }
  ],
  "8263": [
    {
      "answer": "viral antigens",
      "score": 0.989106297492981
    }
  ],
  "8264": [
    {
      "answer": "antibodies",
      "score": 0.958284854888916
    }
  ],
  "8265": [
    {
      "answer": "killer T cells",
      "score": 0.9565544128417969
    },
    {
      "answer": "helper T cells",
      "score": 0.694835901260376
    },
    {
      "answer": "killer T cells",
      "score": 0.8061984777450562
    }
  ],
  "8266": [
    {
      "answer": "killer T cells",
      "score": 0.9812412261962891
    },
    {
      "answer": "killer T cells",
      "score": 0.6393210291862488
    }
  ],
  "8267": [
    {
      "answer": "Tumor antigens",
      "score": 0.9572597742080688
    }
  ],
  "8268": [
    {
      "answer": "abnormal",
      "score": 0.9605866074562073
    }
  ],
  "8269": [
    {
      "answer": "tumor cells",
      "score": 0.9428055286407471
    }
  ],
  "8270": [
    {
      "answer": "phagocytic cells",
      "score": 0.9756709337234497
    }
  ],
  "8271": [
    {
      "answer": "Pathogen-associated molecular patterns",
      "score": 0.9941927790641785
    }
  ],
  "8272": [
    {
      "answer": "apoptosis",
      "score": 0.9848148822784424
    }
  ],
  "8273": [
    {
      "answer": "Systemic acquired resistance (SAR)",
      "score": 0.9760462641716003
    }
  ],
  "8274": [
    {
      "answer": "RNA silencing",
      "score": 0.9957180619239807
    }
  ],
  "8275": [
    {
      "answer": "plant cells",
      "score": 0.919792652130127
    }
  ],
  "8276": [
    {
      "answer": "the plant produces a localized hypersensitive response",
      "score": 0.8244667649269104
    }
  ],
  "8277": [
    {
      "answer": "apoptosis",
      "score": 0.9678135514259338
    }
  ],
  "8278": [
    {
      "answer": "plant cells",
      "score": 0.6125942468643188
    },
    {
      "answer": "cells at the site of infection",
      "score": 0.6309553384780884
    }
  ],
  "8279": [
    {
      "answer": "RNA silencing mechanisms",
      "score": 0.9440499544143677
    }
  ],
  "8280": [
    {
      "answer": "autoimmune disorders",
      "score": 0.9491527676582336
    }
  ],
  "8281": [
    {
      "answer": "self and non-self",
      "score": 0.9635075330734253
    }
  ],
  "8282": [
    {
      "answer": "thymus and bone marrow",
      "score": 0.9583596587181091
    }
  ],
  "8283": [
    {
      "answer": "self",
      "score": 0.9783087372779846
    }
  ],
  "8284": [
    {
      "answer": "autoimmune disorders",
      "score": 0.9769942760467529
    }
  ],
  "8285": [
    {
      "answer": "T cells",
      "score": 0.7975022792816162
    }
  ],
  "8286": [
    {
      "answer": "to eliminate those cells that recognize self-antigens, preventing autoimmunity",
      "score": 0.9421602487564087
    }
  ],
  "8287": [
    {
      "answer": "T cells",
      "score": 0.6905951499938965
    }
  ],
  "8288": [],
  "8289": [],
  "8290": [
    {
      "answer": "young",
      "score": 0.9552199840545654
    },
    {
      "answer": "elderly",
      "score": 0.9237388372421265
    }
  ],
  "8291": [
    {
      "answer": "50",
      "score": 0.983662486076355
    }
  ],
  "8292": [
    {
      "answer": "obesity",
      "score": 0.8045579195022583
    },
    {
      "answer": "alcoholism",
      "score": 0.862789511680603
    },
    {
      "answer": "drug use",
      "score": 0.9153832197189331
    }
  ],
  "8293": [
    {
      "answer": "malnutrition",
      "score": 0.9804927706718445
    }
  ],
  "8294": [],
  "8295": [],
  "8296": [
    {
      "answer": "malnutrition",
      "score": 0.8950921893119812
    }
  ],
  "8297": [
    {
      "answer": "impaired cell-mediated immunity",
      "score": 0.9423195719718933
    }
  ],
  "8298": [
    {
      "answer": "severe immunodeficiency and a high susceptibility to infection",
      "score": 0.7297261357307434
    }
  ],
  "8299": [
    {
      "answer": "vaccination",
      "score": 0.9752199649810791
    },
    {
      "answer": "vaccination",
      "score": 0.5840478539466858
    }
  ],
  "8300": [
    {
      "answer": "immunization",
      "score": 0.9840206503868103
    }
  ],
  "8301": [
    {
      "answer": "antigen",
      "score": 0.9811288118362427
    }
  ],
  "8302": [
    {
      "answer": "natural specificity",
      "score": 0.8975580930709839
    },
    {
      "answer": "inducibility",
      "score": 0.8029550313949585
    }
  ],
  "8303": [
    {
      "answer": "following infection",
      "score": 0.9731519222259521
    }
  ],
  "8304": [
    {
      "answer": "B and T cells",
      "score": 0.7854616641998291
    }
  ],
  "8305": [
    {
      "answer": "vaccination",
      "score": 0.8365662097930908
    },
    {
      "answer": "vaccination",
      "score": 0.5642615556716919
    },
    {
      "answer": "vaccination",
      "score": 0.6878665089607239
    }
  ],
  "8306": [
    {
      "answer": "natural specificity of the immune system",
      "score": 0.9135855436325073
    }
  ],
  "8307": [
    {
      "answer": "infectious disease",
      "score": 0.9634628891944885
    }
  ],
  "8308": [
    {
      "answer": "enzymes",
      "score": 0.9897924661636353
    }
  ],
  "8309": [
    {
      "answer": "type III secretion system",
      "score": 0.9462113380432129
    }
  ],
  "8310": [
    {
      "answer": "shut down host defenses",
      "score": 0.98795086145401
    }
  ],
  "8311": [
    {
      "answer": "elude host immune responses",
      "score": 0.9811497926712036
    }
  ],
  "8312": [
    {
      "answer": "ability to elude host immune responses",
      "score": 0.9679357409477234
    }
  ],
  "8313": [
    {
      "answer": "secreting enzymes that digest the barrier",
      "score": 0.9062835574150085
    }
  ],
  "8314": [
    {
      "answer": "type II secretion system",
      "score": 0.6950345039367676
    },
    {
      "answer": "type III secretion system",
      "score": 0.8858010768890381
    },
    {
      "answer": "insert a hollow tube",
      "score": 0.776506781578064
    }
  ],
  "8315": [],
  "8316": [
    {
      "answer": "These proteins",
      "score": 0.9018322229385376
    }
  ],
  "8317": [
    {
      "answer": "Frank Burnet",
      "score": 0.9966415166854858
    }
  ],
  "8318": [
    {
      "answer": "pathogens",
      "score": 0.9792055487632751
    },
    {
      "answer": "allograft",
      "score": 0.954475462436676
    }
  ],
  "8319": [
    {
      "answer": "histocompatibility",
      "score": 0.8431597352027893
    }
  ],
  "8320": [
    {
      "answer": "Niels Jerne",
      "score": 0.9966907501220703
    }
  ],
  "8321": [
    {
      "answer": "clonal selection theory",
      "score": 0.9794561862945557
    }
  ],
  "8322": [
    {
      "answer": "Niels Jerne",
      "score": 0.9966437220573425
    }
  ],
  "8323": [
    {
      "answer": "clonal selection theory",
      "score": 0.8602350950241089
    },
    {
      "answer": "self/nonself theory",
      "score": 0.8107157945632935
    }
  ],
  "8324": [
    {
      "answer": "clonal selection theory",
      "score": 0.7175358533859253
    },
    {
      "answer": "a theory of how an immune response is triggered according to the self/nonself distinction",
      "score": 0.7381973266601562
    }
  ],
  "8325": [
    {
      "answer": "clonal selection theory (CST)",
      "score": 0.9346766471862793
    }
  ],
  "8326": [
    {
      "answer": "Glucocorticoids",
      "score": 0.9910147786140442
    }
  ],
  "8327": [
    {
      "answer": "cytotoxic or immunosuppressive drugs",
      "score": 0.9684619903564453
    }
  ],
  "8328": [
    {
      "answer": "methotrexate",
      "score": 0.7010100483894348
    },
    {
      "answer": "azathioprine",
      "score": 0.7642611265182495
    },
    {
      "answer": "cyclosporin",
      "score": 0.6541805863380432
    }
  ],
  "8329": [
    {
      "answer": "cyclosporin",
      "score": 0.9874812960624695
    }
  ],
  "8330": [
    {
      "answer": "Anti-inflammatory drugs",
      "score": 0.9505095481872559
    },
    {
      "answer": "anti-inflammatory drugs",
      "score": 0.7147113084793091
    }
  ],
  "8331": [
    {
      "answer": "Glucocorticoids",
      "score": 0.9795427322387695
    }
  ],
  "8332": [],
  "8333": [
    {
      "answer": "cytotoxic or immunosuppressive drugs",
      "score": 0.9477957487106323
    }
  ],
  "8334": [
    {
      "answer": "methotrexate",
      "score": 0.8776640892028809
    },
    {
      "answer": "azathioprine",
      "score": 0.8660537004470825
    }
  ],
  "8335": [
    {
      "answer": "cytotoxic natural killer cells",
      "score": 0.9678031802177429
    },
    {
      "answer": "CTLs (cytotoxic T lymphocytes)",
      "score": 0.8382501006126404
    }
  ],
  "8336": [
    {
      "answer": "cortisol",
      "score": 0.9786967039108276
    },
    {
      "answer": "catecholamines",
      "score": 0.9772222638130188
    }
  ],
  "8337": [
    {
      "answer": "melatonin",
      "score": 0.9914351105690002
    },
    {
      "answer": "melatonin",
      "score": 0.6747033596038818
    }
  ],
  "8338": [
    {
      "answer": "free radical",
      "score": 0.9505638480186462
    }
  ],
  "8339": [
    {
      "answer": "cytotoxic natural killer cells",
      "score": 0.6927680969238281
    }
  ],
  "8340": [
    {
      "answer": "inflammation may occur during sleep times due to the presence of melatonin.",
      "score": 0.7922725081443787
    }
  ],
  "8341": [
    {
      "answer": "cortisol",
      "score": 0.849086582660675
    },
    {
      "answer": "catecholamines",
      "score": 0.8900747895240784
    }
  ],
  "8342": [],
  "8343": [
    {
      "answer": "melatonin",
      "score": 0.5857595801353455
    },
    {
      "answer": "melatonin",
      "score": 0.9666832089424133
    }
  ],
  "8344": [
    {
      "answer": "vitamin D receptor",
      "score": 0.9732669591903687
    },
    {
      "answer": "vitamin D receptor",
      "score": 0.811526894569397
    }
  ],
  "8345": [
    {
      "answer": "steroid hormone calcitriol",
      "score": 0.9137665033340454
    }
  ],
  "8346": [
    {
      "answer": "T-cells have a symbiotic relationship with vitamin D",
      "score": 0.767888069152832
    }
  ],
  "8347": [
    {
      "answer": "CYP27B1",
      "score": 0.9906132221221924
    }
  ],
  "8348": [
    {
      "answer": "dendritic cells",
      "score": 0.9601589441299438
    },
    {
      "answer": "keratinocytes",
      "score": 0.9404719471931458
    },
    {
      "answer": "macrophages",
      "score": 0.9461577534675598
    }
  ],
  "8349": [
    {
      "answer": "extends a vitamin D receptor",
      "score": 0.9772545695304871
    }
  ],
  "8350": [
    {
      "answer": "T-cell",
      "score": 0.7216468453407288
    }
  ],
  "8351": [
    {
      "answer": "vitamin D",
      "score": 0.8839110136032104
    },
    {
      "answer": "vitamin D",
      "score": 0.7136414647102356
    },
    {
      "answer": "vitamin D",
      "score": 0.9050345420837402
    },
    {
      "answer": "vitamin D",
      "score": 0.8801807165145874
    },
    {
      "answer": "vitamin D",
      "score": 0.772190511226654
    },
    {
      "answer": "vitamin D",
      "score": 0.7721526622772217
    },
    {
      "answer": "vitamin D",
      "score": 0.6290860772132874
    }
  ],
  "8352": [
    {
      "answer": "CYP27B1",
      "score": 0.9770041108131409
    }
  ],
  "8353": [
    {
      "answer": "CYP27B1",
      "score": 0.9887401461601257
    }
  ],
  "8354": [],
  "8355": [
    {
      "answer": "defensins",
      "score": 0.9434240460395813
    }
  ],
  "8356": [
    {
      "answer": "phagocytic",
      "score": 0.9766066670417786
    }
  ],
  "8357": [
    {
      "answer": "Ribonucleases",
      "score": 0.9345495104789734
    }
  ],
  "8358": [
    {
      "answer": "Antimicrobial peptides called defensins",
      "score": 0.5532439351081848
    }
  ],
  "8359": [
    {
      "answer": "defensins",
      "score": 0.8931750655174255
    }
  ],
  "8360": [],
  "8361": [
    {
      "answer": "Ribonucleases",
      "score": 0.9117693305015564
    }
  ],
  "8362": [
    {
      "answer": "eukaryotes",
      "score": 0.9005969762802124
    }
  ],
  "8363": [
    {
      "answer": "immunoglobulins and T cell receptors",
      "score": 0.8917536735534668
    }
  ],
  "8364": [
    {
      "answer": "lamprey",
      "score": 0.9654702544212341
    },
    {
      "answer": "hagfish",
      "score": 0.9588451385498047
    }
  ],
  "8365": [
    {
      "answer": "Variable lymphocyte receptors",
      "score": 0.9917730093002319
    }
  ],
  "8366": [
    {
      "answer": "adaptive",
      "score": 0.9879536628723145
    }
  ],
  "8367": [
    {
      "answer": "adaptive immune system",
      "score": 0.9625146389007568
    }
  ],
  "8368": [
    {
      "answer": "lamprey and hagfish",
      "score": 0.790219247341156
    }
  ],
  "8369": [
    {
      "answer": "lamprey",
      "score": 0.9351506233215332
    }
  ],
  "8370": [
    {
      "answer": "Variable lymphocyte receptors",
      "score": 0.9539541006088257
    },
    {
      "answer": "antigen receptors",
      "score": 0.7495548725128174
    }
  ],
  "8371": [
    {
      "answer": "Variable lymphocyte receptors",
      "score": 0.7008198499679565
    }
  ],
  "8372": [
    {
      "answer": "lymphocytes",
      "score": 0.9909924268722534
    }
  ],
  "8373": [
    {
      "answer": "restriction modification system",
      "score": 0.9893320798873901
    }
  ],
  "8374": [
    {
      "answer": "bacteriophages",
      "score": 0.9561999440193176
    }
  ],
  "8375": [
    {
      "answer": "CRISPR sequences",
      "score": 0.9708320498466492
    }
  ],
  "8376": [
    {
      "answer": "vertebrates",
      "score": 0.9316314458847046
    }
  ],
  "8377": [
    {
      "answer": "multicomponent, adaptive immune system",
      "score": 0.9792501330375671
    }
  ],
  "8378": [
    {
      "answer": "antibody-based humoral response",
      "score": 0.6992554664611816
    },
    {
      "answer": "restriction modification system",
      "score": 0.6950461268424988
    }
  ],
  "8379": [
    {
      "answer": "lymphocytes or an antibody-based humoral response",
      "score": 0.7146761417388916
    }
  ],
  "8380": [
    {
      "answer": "roles in defense",
      "score": 0.7260221838951111
    }
  ],
  "8381": [
    {
      "answer": "cellular",
      "score": 0.7056227922439575
    },
    {
      "answer": "cellular theory",
      "score": 0.8274372816085815
    },
    {
      "answer": "humoral theory",
      "score": 0.8785767555236816
    }
  ],
  "8382": [
    {
      "answer": "Elie Metchnikoff",
      "score": 0.994000256061554
    }
  ],
  "8383": [
    {
      "answer": "phagocytes",
      "score": 0.9901982545852661
    }
  ],
  "8384": [
    {
      "answer": "Robert Koch",
      "score": 0.949425220489502
    },
    {
      "answer": "Emil von Behring",
      "score": 0.9073247313499451
    }
  ],
  "8385": [
    {
      "answer": "soluble components (molecules)",
      "score": 0.9120551943778992
    }
  ],
  "8386": [
    {
      "answer": "Many theories",
      "score": 0.7566140294075012
    }
  ],
  "8387": [
    {
      "answer": "Robert Koch",
      "score": 0.9501989483833313
    },
    {
      "answer": "Emil von Behring",
      "score": 0.936407744884491
    }
  ],
  "8388": [
    {
      "answer": "Robert Koch",
      "score": 0.942140519618988
    },
    {
      "answer": "Emil von Behring",
      "score": 0.9164408445358276
    }
  ],
  "8389": [],
  "8390": [
    {
      "answer": "cancers",
      "score": 0.9637102484703064
    }
  ],
  "8391": [
    {
      "answer": "MHC class I",
      "score": 0.9648927450180054
    }
  ],
  "8392": [
    {
      "answer": "TGF-\u03b2",
      "score": 0.978435754776001
    }
  ],
  "8393": [
    {
      "answer": "macrophages",
      "score": 0.9872097969055176
    },
    {
      "answer": "lymphocytes",
      "score": 0.9832278490066528
    }
  ],
  "8394": [
    {
      "answer": "tumors",
      "score": 0.5641893148422241
    }
  ],
  "8395": [
    {
      "answer": "MHC class I molecules",
      "score": 0.9005815982818604
    }
  ],
  "8396": [
    {
      "answer": "cytokine TGF-\u03b2",
      "score": 0.9121077060699463
    }
  ],
  "8397": [
    {
      "answer": "macrophages and lymphocytes",
      "score": 0.9342103004455566
    }
  ],
  "8398": [
    {
      "answer": "immunological tolerance",
      "score": 0.7398453950881958
    }
  ],
  "8399": [],
  "8400": [
    {
      "answer": "four",
      "score": 0.9669119715690613
    }
  ],
  "8401": [
    {
      "answer": "Type I",
      "score": 0.9743767976760864
    }
  ],
  "8402": [
    {
      "answer": "IgE",
      "score": 0.8455920219421387
    }
  ],
  "8403": [
    {
      "answer": "Type II",
      "score": 0.9131326675415039
    }
  ],
  "8404": [],
  "8405": [],
  "8406": [],
  "8407": [
    {
      "answer": "Type IV hypersensitivity",
      "score": 0.9276515245437622
    }
  ],
  "8408": [
    {
      "answer": "Type II hypersensitivity",
      "score": 0.8603364825248718
    }
  ],
  "8409": [
    {
      "answer": "intracellular pathogenesis",
      "score": 0.9683506488800049
    }
  ],
  "8410": [
    {
      "answer": "Salmonella",
      "score": 0.975723922252655
    }
  ],
  "8411": [
    {
      "answer": "Plasmodium falciparum",
      "score": 0.8455881476402283
    }
  ],
  "8412": [
    {
      "answer": "Mycobacterium tuberculosis",
      "score": 0.9875110387802124
    }
  ],
  "8413": [
    {
      "answer": "protein A",
      "score": 0.934812068939209
    }
  ],
  "8414": [
    {
      "answer": "hide within the cells of their host",
      "score": 0.9216262698173523
    }
  ],
  "8415": [
    {
      "answer": "intracellular pathogenesis",
      "score": 0.909457802772522
    }
  ],
  "8416": [],
  "8417": [],
  "8418": [
    {
      "answer": "antibodies",
      "score": 0.9002915620803833
    }
  ],
  "8419": [
    {
      "answer": "antigenic variation",
      "score": 0.9841965436935425
    }
  ],
  "8420": [
    {
      "answer": "HIV",
      "score": 0.9657662510871887
    },
    {
      "answer": "HIV",
      "score": 0.5762717723846436
    }
  ],
  "8421": [
    {
      "answer": "Trypanosoma brucei",
      "score": 0.9827371835708618
    }
  ],
  "8422": [
    {
      "answer": "sugars",
      "score": 0.5566114783287048
    }
  ],
  "8423": [
    {
      "answer": "antigenic variation",
      "score": 0.7645220160484314
    },
    {
      "answer": "Masking antigens with host molecules",
      "score": 0.7251389026641846
    }
  ],
  "8424": [
    {
      "answer": "antigenic variation",
      "score": 0.9054560661315918
    }
  ],
  "8425": [
    {
      "answer": "HIV",
      "score": 0.7061038017272949
    },
    {
      "answer": "Trypanosoma brucei",
      "score": 0.6197259426116943
    }
  ],
  "8426": [
    {
      "answer": "frequent changes in antigens",
      "score": 0.877341628074646
    }
  ],
  "8427": [
    {
      "answer": "Trypanosoma brucei",
      "score": 0.9892346858978271
    }
  ],
  "8428": [
    {
      "answer": "immune surveillance",
      "score": 0.9894174933433533
    }
  ],
  "8429": [
    {
      "answer": "human papillomavirus",
      "score": 0.9949767589569092
    }
  ],
  "8430": [
    {
      "answer": "tyrosinase",
      "score": 0.9891743659973145
    }
  ],
  "8431": [
    {
      "answer": "melanomas",
      "score": 0.914720892906189
    }
  ],
  "8432": [
    {
      "answer": "melanocytes",
      "score": 0.9584651589393616
    }
  ],
  "8433": [
    {
      "answer": "identify and eliminate tumors",
      "score": 0.8904503583908081
    }
  ],
  "8434": [
    {
      "answer": "antigens",
      "score": 0.85582435131073
    }
  ],
  "8435": [
    {
      "answer": "human papillomavirus",
      "score": 0.863835871219635
    }
  ],
  "8436": [
    {
      "answer": "transforms certain skin cells (e.g. melanocytes) into tumors called melanomas",
      "score": 0.9425275921821594
    }
  ],
  "8437": [
    {
      "answer": "proteins normally important for regulating cell growth and survival",
      "score": 0.880936861038208
    }
  ],
  "8438": [
    {
      "answer": ">500 Da",
      "score": 0.934593915939331
    }
  ],
  "8439": [
    {
      "answer": "hydrophilic amino acids",
      "score": 0.9162005186080933
    }
  ],
  "8440": [
    {
      "answer": "immunoinformatics",
      "score": 0.6425825953483582
    },
    {
      "answer": "Immunoproteomics",
      "score": 0.7089229822158813
    }
  ],
  "8441": [
    {
      "answer": "B cells",
      "score": 0.9472114443778992
    }
  ],
  "8442": [
    {
      "answer": "immunoinformatics",
      "score": 0.982927143573761
    }
  ],
  "8443": [
    {
      "answer": "neutralizing",
      "score": 0.9767890572547913
    }
  ],
  "8444": [],
  "8445": [
    {
      "answer": "Computational methods",
      "score": 0.7223867177963257
    },
    {
      "answer": "machine learning techniques",
      "score": 0.6182056665420532
    }
  ],
  "8446": [
    {
      "answer": "amino acids",
      "score": 0.9775474667549133
    }
  ],
  "8447": [
    {
      "answer": "Immunoproteomics",
      "score": 0.9569854140281677
    }
  ],
  "8448": [
    {
      "answer": "leptin",
      "score": 0.9625340104103088
    },
    {
      "answer": "pituitary growth hormone",
      "score": 0.94395512342453
    },
    {
      "answer": "prolactin",
      "score": 0.8989591598510742
    }
  ],
  "8449": [],
  "8450": [
    {
      "answer": "Th1",
      "score": 0.8843880295753479
    }
  ],
  "8451": [
    {
      "answer": "Th1 immune responses",
      "score": 0.893133282661438
    }
  ],
  "8452": [],
  "8453": [
    {
      "answer": "leptin, pituitary growth hormone, and prolactin",
      "score": 0.8051748275756836
    }
  ],
  "8454": [
    {
      "answer": "cortisol",
      "score": 0.7673016786575317
    }
  ],
  "8455": [
    {
      "answer": "leptin",
      "score": 0.7025058269500732
    },
    {
      "answer": "pituitary growth hormone",
      "score": 0.7922264933586121
    },
    {
      "answer": "leptin",
      "score": 0.6960322856903076
    },
    {
      "answer": "pituitary growth hormone",
      "score": 0.8385187387466431
    }
  ],
  "8456": [],
  "8457": [
    {
      "answer": "bacteriophage",
      "score": 0.9883043766021729
    }
  ],
  "8458": [
    {
      "answer": "defensins",
      "score": 0.9815614819526672
    }
  ],
  "8459": [
    {
      "answer": "vaccination",
      "score": 0.9936390519142151
    }
  ],
  "8460": [],
  "8461": [],
  "8462": [
    {
      "answer": "enzymes",
      "score": 0.7403348088264465
    }
  ],
  "8463": [],
  "8464": [
    {
      "answer": "Adaptive (or acquired) immunity",
      "score": 0.9534404277801514
    }
  ],
  "8465": [
    {
      "answer": "vaccination",
      "score": 0.9635484218597412
    }
  ],
  "8466": [
    {
      "answer": "carbohydrates",
      "score": 0.9368263483047485
    }
  ],
  "8467": [
    {
      "answer": "signal amplification",
      "score": 0.979775071144104
    }
  ],
  "8468": [
    {
      "answer": "catalytic",
      "score": 0.9613028168678284
    }
  ],
  "8469": [
    {
      "answer": "disrupting their plasma membrane",
      "score": 0.9833444356918335
    }
  ],
  "8470": [
    {
      "answer": "killing",
      "score": 0.9327905774116516
    }
  ],
  "8471": [
    {
      "answer": "complement binding to antibodies",
      "score": 0.8711658120155334
    },
    {
      "answer": "binding of complement proteins to carbohydrates",
      "score": 0.8716521263122559
    }
  ],
  "8472": [
    {
      "answer": "signal amplification",
      "score": 0.918246865272522
    }
  ],
  "8473": [
    {
      "answer": "protease activity",
      "score": 0.8549669981002808
    }
  ],
  "8474": [
    {
      "answer": "complement binding to antibodies",
      "score": 0.5752899646759033
    }
  ],
  "8475": [
    {
      "answer": "United Nations",
      "score": 0.9333730936050415
    },
    {
      "answer": "United Nations",
      "score": 0.7093644142150879
    },
    {
      "answer": "United Nations",
      "score": 0.6376208066940308
    },
    {
      "answer": "United Nations",
      "score": 0.5527365803718567
    }
  ],
  "8476": [
    {
      "answer": "World Meteorological Organization (WMO)",
      "score": 0.9525051116943359
    },
    {
      "answer": "United Nations Environment Programme (UNEP)",
      "score": 0.9445696473121643
    }
  ],
  "8477": [
    {
      "answer": "greenhouse gas concentrations in the atmosphere",
      "score": 0.9821698665618896
    }
  ],
  "8478": [
    {
      "answer": "United Nations Framework Convention on Climate Change",
      "score": 0.9745806455612183
    }
  ],
  "8479": [
    {
      "answer": "43/53",
      "score": 0.9880485534667969
    }
  ],
  "8480": [
    {
      "answer": "Intergovernmental Panel on Climate Change",
      "score": 0.9345051050186157
    }
  ],
  "8481": [
    {
      "answer": "United Nations",
      "score": 0.5910975933074951
    },
    {
      "answer": "World Meteorological Organization",
      "score": 0.948075532913208
    },
    {
      "answer": "United Nations Environment Programme (UNEP)",
      "score": 0.7746241092681885
    },
    {
      "answer": "United Nations",
      "score": 0.6703101992607117
    },
    {
      "answer": "United Nations",
      "score": 0.5167658925056458
    }
  ],
  "8482": [
    {
      "answer": "United Nations General Assembly",
      "score": 0.7866135835647583
    }
  ],
  "8483": [
    {
      "answer": "United Nations",
      "score": 0.6085208058357239
    },
    {
      "answer": "United Nations",
      "score": 0.6040382385253906
    },
    {
      "answer": "United Nations",
      "score": 0.6088176965713501
    },
    {
      "answer": "Membership of the IPCC is open to all members of the WMO and UNEP",
      "score": 0.7213110327720642
    }
  ],
  "8484": [
    {
      "answer": "United Nations Framework Convention on Climate Change (UNFCCC)",
      "score": 0.7714705467224121
    }
  ],
  "8485": [
    {
      "answer": "Hoesung Lee",
      "score": 0.9886012077331543
    }
  ],
  "8486": [
    {
      "answer": "Korean",
      "score": 0.9848546981811523
    }
  ],
  "8487": [
    {
      "answer": "Ismail El Gizouli",
      "score": 0.9913389086723328
    }
  ],
  "8488": [],
  "8489": [
    {
      "answer": "February 2015",
      "score": 0.9865683913230896
    }
  ],
  "8490": [
    {
      "answer": "Hoesung Lee",
      "score": 0.9838770031929016
    }
  ],
  "8491": [
    {
      "answer": "2015",
      "score": 0.9730438590049744
    },
    {
      "answer": "2015",
      "score": 0.9202849268913269
    }
  ],
  "8492": [
    {
      "answer": "Ismail El Gizouli",
      "score": 0.7196545600891113
    },
    {
      "answer": "Robert Watson",
      "score": 0.8011684417724609
    },
    {
      "answer": "Bert Bolin",
      "score": 0.6644111275672913
    }
  ],
  "8493": [
    {
      "answer": "2015",
      "score": 0.9016757607460022
    },
    {
      "answer": "2015",
      "score": 0.9347394704818726
    }
  ],
  "8494": [],
  "8495": [
    {
      "answer": "representatives appointed by governments and organizations",
      "score": 0.937492847442627
    }
  ],
  "8496": [
    {
      "answer": "350",
      "score": 0.8791847825050354
    },
    {
      "answer": "322",
      "score": 0.7549805641174316
    }
  ],
  "8497": [
    {
      "answer": "government officials",
      "score": 0.9254049062728882
    }
  ],
  "8498": [
    {
      "answer": "seven-eighths",
      "score": 0.9927268028259277
    }
  ],
  "8499": [
    {
      "answer": "Non Governmental and Intergovernmental Organizations",
      "score": 0.9334186911582947
    }
  ],
  "8500": [
    {
      "answer": "Plenary sessions of the IPCC and IPCC Working groups",
      "score": 0.81831294298172
    }
  ],
  "8501": [
    {
      "answer": "2003",
      "score": 0.9941028952598572
    }
  ],
  "8502": [
    {
      "answer": "Sessions",
      "score": 0.6754043102264404
    }
  ],
  "8503": [],
  "8504": [
    {
      "answer": "1989",
      "score": 0.9686625599861145
    }
  ],
  "8505": [
    {
      "answer": "United Nations Environment Programme (UNEP)",
      "score": 0.9181067943572998
    },
    {
      "answer": "World Meteorological Organization (WMO)",
      "score": 0.7285950183868408
    }
  ],
  "8506": [
    {
      "answer": "United Nations Environment Programme (UNEP)",
      "score": 0.8397247791290283
    },
    {
      "answer": "World Meteorological Organization",
      "score": 0.9038548469543457
    }
  ],
  "8507": [
    {
      "answer": "UNEP",
      "score": 0.8090841770172119
    },
    {
      "answer": "World Meteorological Organization",
      "score": 0.6904716491699219
    },
    {
      "answer": "UNEP",
      "score": 0.8395581245422363
    }
  ],
  "8508": [
    {
      "answer": "Financial Regulations and Rules of the WMO",
      "score": 0.9879790544509888
    }
  ],
  "8509": [
    {
      "answer": "IPCC Trust Fund",
      "score": 0.9808712005615234
    }
  ],
  "8510": [
    {
      "answer": "UNEP",
      "score": 0.7657279372215271
    },
    {
      "answer": "UNEP",
      "score": 0.973897397518158
    }
  ],
  "8511": [
    {
      "answer": "1989",
      "score": 0.9899577498435974
    }
  ],
  "8512": [
    {
      "answer": "United Nations Environment Programme (UNEP)",
      "score": 0.6345077753067017
    },
    {
      "answer": "World Meteorological Organization",
      "score": 0.7614121437072754
    }
  ],
  "8513": [
    {
      "answer": "IPCC",
      "score": 0.5825966596603394
    },
    {
      "answer": "WMO",
      "score": 0.5315104126930237
    },
    {
      "answer": "WMO",
      "score": 0.6887134313583374
    }
  ],
  "8514": [
    {
      "answer": "carry out research",
      "score": 0.9744629263877869
    },
    {
      "answer": "monitor climate related data",
      "score": 0.9758001565933228
    }
  ],
  "8515": [
    {
      "answer": "published sources",
      "score": 0.9005627632141113
    }
  ],
  "8516": [
    {
      "answer": "non-peer-reviewed sources",
      "score": 0.930063009262085
    },
    {
      "answer": "Examples of non-peer-reviewed sources include model results, reports from government agencies and non-governmental organizations, and industry journals",
      "score": 0.7699691653251648
    }
  ],
  "8517": [
    {
      "answer": "model results",
      "score": 0.9697273969650269
    },
    {
      "answer": "reports from government agencies and non-governmental organizations",
      "score": 0.9710115194320679
    },
    {
      "answer": "industry journals",
      "score": 0.9709872007369995
    }
  ],
  "8518": [
    {
      "answer": "Lead authors",
      "score": 0.9533144235610962
    }
  ],
  "8519": [
    {
      "answer": "IPCC",
      "score": 0.6101690530776978
    },
    {
      "answer": "IPCC",
      "score": 0.5712685585021973
    },
    {
      "answer": "IPCC",
      "score": 0.51816725730896
    },
    {
      "answer": "IPCC",
      "score": 0.578343391418457
    }
  ],
  "8520": [
    {
      "answer": "authors should give priority to peer-reviewed sources",
      "score": 0.9444029927253723
    }
  ],
  "8521": [
    {
      "answer": "authors should give priority to peer-reviewed sources",
      "score": 0.9001634120941162
    }
  ],
  "8522": [
    {
      "answer": "model results",
      "score": 0.763076901435852
    },
    {
      "answer": "reports from government agencies and non-governmental organizations",
      "score": 0.8690860271453857
    },
    {
      "answer": "industry journals",
      "score": 0.819239616394043
    }
  ],
  "8523": [
    {
      "answer": "two",
      "score": 0.9921833872795105
    }
  ],
  "8524": [
    {
      "answer": "ten to fifteen",
      "score": 0.9870004057884216
    }
  ],
  "8525": [],
  "8526": [
    {
      "answer": "coordinating lead authors",
      "score": 0.9905937910079956
    }
  ],
  "8527": [
    {
      "answer": "Working Group chairs",
      "score": 0.9910790324211121
    }
  ],
  "8528": [
    {
      "answer": "writing sections of chapters",
      "score": 0.9831923842430115
    }
  ],
  "8529": [
    {
      "answer": "two",
      "score": 0.9881827235221863
    }
  ],
  "8530": [
    {
      "answer": "Working Group chairs",
      "score": 0.9835759997367859
    }
  ],
  "8531": [
    {
      "answer": "coordinating lead authors",
      "score": 0.5959764719009399
    }
  ],
  "8532": [
    {
      "answer": "Contributing authors",
      "score": 0.6132611036300659
    },
    {
      "answer": "lead authors",
      "score": 0.8690345287322998
    }
  ],
  "8533": [
    {
      "answer": "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases",
      "score": 0.795295000076294
    }
  ],
  "8534": [
    {
      "answer": "additional warming",
      "score": 0.79814612865448
    },
    {
      "answer": "enhanced greenhouse effect",
      "score": 0.6355990171432495
    },
    {
      "answer": "enhanced greenhouse effect",
      "score": 0.6024868488311768
    }
  ],
  "8535": [
    {
      "answer": "over half",
      "score": 0.9755464792251587
    }
  ],
  "8536": [
    {
      "answer": "business as usual",
      "score": 0.9767879247665405
    }
  ],
  "8537": [
    {
      "answer": "0.3 to 0.6 \u00b0C",
      "score": 0.9768087863922119
    }
  ],
  "8538": [
    {
      "answer": "WG I Summary for Policymakers report",
      "score": 0.9241161346435547
    }
  ],
  "8539": [
    {
      "answer": "0.3 \u00b0C",
      "score": 0.9790927767753601
    }
  ],
  "8540": [
    {
      "answer": "0.3 \u00b0C",
      "score": 0.9745704531669617
    }
  ],
  "8541": [
    {
      "answer": "global mean surface air temperature",
      "score": 0.7210055589675903
    }
  ],
  "8542": [
    {
      "answer": "a decade or more",
      "score": 0.9359842538833618
    }
  ],
  "8543": [
    {
      "answer": "2001",
      "score": 0.972076952457428
    }
  ],
  "8544": [
    {
      "answer": "16",
      "score": 0.9907602071762085
    }
  ],
  "8545": [
    {
      "answer": "Science",
      "score": 0.6758335828781128
    },
    {
      "answer": "Science",
      "score": 0.9836512207984924
    }
  ],
  "8546": [
    {
      "answer": "90% certain",
      "score": 0.9646272659301758
    }
  ],
  "8547": [
    {
      "answer": "1.4 and 5.8 \u00b0C",
      "score": 0.9856976270675659
    }
  ],
  "8548": [
    {
      "answer": "2001",
      "score": 0.9855278134346008
    }
  ],
  "8549": [
    {
      "answer": "Royal Society of Canada",
      "score": 0.783491313457489
    },
    {
      "answer": "Royal Society (UK)",
      "score": 0.8127215504646301
    }
  ],
  "8550": [
    {
      "answer": "Science",
      "score": 0.975043773651123
    }
  ],
  "8551": [],
  "8552": [
    {
      "answer": "2100",
      "score": 0.9840680956840515
    }
  ],
  "8553": [
    {
      "answer": "Richard Lindzen",
      "score": 0.9905150532722473
    }
  ],
  "8554": [
    {
      "answer": "does not faithfully summarize the full WGI report",
      "score": 0.7688077688217163
    },
    {
      "answer": "understates the uncertainty associated with climate models",
      "score": 0.887862503528595
    }
  ],
  "8555": [
    {
      "answer": "John Houghton",
      "score": 0.9948601126670837
    }
  ],
  "8556": [
    {
      "answer": "co-chair of TAR WGI",
      "score": 0.9762903451919556
    }
  ],
  "8557": [
    {
      "answer": "scientific evidence",
      "score": 0.9934374094009399
    }
  ],
  "8558": [
    {
      "answer": "IPCC",
      "score": 0.6915280222892761
    },
    {
      "answer": "WGI",
      "score": 0.6964302062988281
    }
  ],
  "8559": [
    {
      "answer": "John Houghton",
      "score": 0.9229007959365845
    }
  ],
  "8560": [
    {
      "answer": "Richard Lindzen",
      "score": 0.9781767725944519
    }
  ],
  "8561": [
    {
      "answer": "IPCC",
      "score": 0.5320196151733398
    },
    {
      "answer": "WGI",
      "score": 0.5274618864059448
    }
  ],
  "8562": [
    {
      "answer": "SPM",
      "score": 0.9154980778694153
    }
  ],
  "8563": [
    {
      "answer": "The preparation and approval process for all IPCC Special Reports follows the same procedures as for IPCC Assessment Reports",
      "score": 0.9797542095184326
    }
  ],
  "8564": [
    {
      "answer": "2011",
      "score": 0.9816762208938599
    }
  ],
  "8565": [
    {
      "answer": "2011",
      "score": 0.9860720038414001
    }
  ],
  "8566": [
    {
      "answer": "requested by governments",
      "score": 0.9806780815124512
    }
  ],
  "8567": [
    {
      "answer": "IPCC",
      "score": 0.5139068365097046
    },
    {
      "answer": "IPCC",
      "score": 0.6610366702079773
    },
    {
      "answer": "IPCC",
      "score": 0.8167328834533691
    },
    {
      "answer": "IPCC",
      "score": 0.6048207879066467
    }
  ],
  "8568": [
    {
      "answer": "Special Report on Renewable Energy Sources and Climate Change Mitigation (SRREN)",
      "score": 0.9411455392837524
    },
    {
      "answer": "Special Report on Managing Risks of Extreme Events and Disasters to Advance Climate Change Adaptation (SREX)",
      "score": 0.9231406450271606
    }
  ],
  "8569": [
    {
      "answer": "2011",
      "score": 0.9859209656715393
    }
  ],
  "8570": [
    {
      "answer": "Special Report on Renewable Energy Sources and Climate Change Mitigation",
      "score": 0.9263481497764587
    },
    {
      "answer": "Special Report on Managing Risks of Extreme Events and Disasters to Advance Climate Change Adaptation (SREX)",
      "score": 0.6791658401489258
    }
  ],
  "8571": [
    {
      "answer": "Special Report on Renewable Energy Sources and Climate Change Mitigation (SRREN)",
      "score": 0.7605674862861633
    },
    {
      "answer": "Special Report on Managing Risks of Extreme Events and Disasters to Advance Climate Change Adaptation",
      "score": 0.9644034504890442
    }
  ],
  "8572": [
    {
      "answer": "Data Distribution Centre",
      "score": 0.9425644874572754
    },
    {
      "answer": "National Greenhouse Gas Inventories Programme",
      "score": 0.9520609974861145
    }
  ],
  "8573": [
    {
      "answer": "default emission factors",
      "score": 0.9791207313537598
    }
  ],
  "8574": [
    {
      "answer": "fuel consumption",
      "score": 0.9951351881027222
    },
    {
      "answer": "industrial production",
      "score": 0.9820261001586914
    }
  ],
  "8575": [
    {
      "answer": "WMO Executive Council",
      "score": 0.9921833276748657
    },
    {
      "answer": "UNEP Governing Council",
      "score": 0.9811586141586304
    }
  ],
  "8576": [
    {
      "answer": "WMO Executive Council",
      "score": 0.6917297840118408
    },
    {
      "answer": "UNEP Governing Council",
      "score": 0.9080648422241211
    }
  ],
  "8577": [
    {
      "answer": "IPCC",
      "score": 0.8296773433685303
    },
    {
      "answer": "IPCC",
      "score": 0.5244081020355225
    }
  ],
  "8578": [
    {
      "answer": "Data Distribution Centre and the National Greenhouse Gas Inventories Programme",
      "score": 0.730487048625946
    }
  ],
  "8579": [
    {
      "answer": "IPCC",
      "score": 0.7332674860954285
    },
    {
      "answer": "IPCC",
      "score": 0.55873042345047
    },
    {
      "answer": "Data Distribution Centre",
      "score": 0.5434215068817139
    }
  ],
  "8580": [
    {
      "answer": "emission factors",
      "score": 0.9618141651153564
    }
  ],
  "8581": [
    {
      "answer": "the date",
      "score": 0.9009419679641724
    }
  ],
  "8582": [
    {
      "answer": "poor application of well-established IPCC procedures in this instance",
      "score": 0.9574034810066223
    }
  ],
  "8583": [
    {
      "answer": "ICSI report \"Variations of Snow and Ice in the past and at present on a Global and Regional Scale\"",
      "score": 0.6641473174095154
    }
  ],
  "8584": [
    {
      "answer": "2035",
      "score": 0.8681044578552246
    },
    {
      "answer": "Variations of Snow and Ice in the past and at present on a Global and Regional Scale",
      "score": 0.8902209401130676
    }
  ],
  "8585": [
    {
      "answer": "2035",
      "score": 0.9944977164268494
    }
  ],
  "8586": [
    {
      "answer": "summary",
      "score": 0.7584993243217468
    }
  ],
  "8587": [],
  "8588": [
    {
      "answer": "Variations of Snow and Ice in the past and at present on a Global and Regional Scale",
      "score": 0.9612634181976318
    }
  ],
  "8589": [
    {
      "answer": "chairman",
      "score": 0.985706090927124
    }
  ],
  "8590": [
    {
      "answer": "making it seem like climate change is more serious",
      "score": 0.9783927202224731
    }
  ],
  "8591": [
    {
      "answer": "co-chair of the IPCC working group II",
      "score": 0.9748241305351257
    }
  ],
  "8592": [
    {
      "answer": "Himalayan glaciers",
      "score": 0.9674752950668335
    }
  ],
  "8593": [
    {
      "answer": "generally unfounded",
      "score": 0.9566081762313843
    }
  ],
  "8594": [
    {
      "answer": "Robert Watson",
      "score": 0.9958198070526123
    }
  ],
  "8595": [
    {
      "answer": "Robert Watson",
      "score": 0.9184068441390991
    }
  ],
  "8596": [
    {
      "answer": "Martin Parry",
      "score": 0.9679369330406189
    }
  ],
  "8597": [
    {
      "answer": "Himalayan glaciers",
      "score": 0.9889005422592163
    }
  ],
  "8598": [
    {
      "answer": "Martin Parry",
      "score": 0.9701863527297974
    }
  ],
  "8599": [
    {
      "answer": "1999",
      "score": 0.986504316329956
    }
  ],
  "8600": [
    {
      "answer": "Michael E. Mann",
      "score": 0.9563819169998169
    }
  ],
  "8601": [
    {
      "answer": "hockey stick graph",
      "score": 0.7862691879272461
    }
  ],
  "8602": [
    {
      "answer": "Jones et al. 1998",
      "score": 0.9805334210395813
    },
    {
      "answer": "Briffa 2000",
      "score": 0.9792735576629639
    }
  ],
  "8603": [
    {
      "answer": "hockey stick graph",
      "score": 0.7250596880912781
    }
  ],
  "8604": [
    {
      "answer": "1999",
      "score": 0.9584696888923645
    }
  ],
  "8605": [
    {
      "answer": "temperature units",
      "score": 0.9152607917785645
    }
  ],
  "8606": [
    {
      "answer": "IPCC Second Assessment Report",
      "score": 0.7722463607788086
    }
  ],
  "8607": [
    {
      "answer": "central England",
      "score": 0.9484461545944214
    },
    {
      "answer": "central England",
      "score": 0.859866738319397
    }
  ],
  "8608": [
    {
      "answer": "between 1000 and 1900",
      "score": 0.9660570025444031
    }
  ],
  "8609": [
    {
      "answer": "Fred Singer",
      "score": 0.9971921443939209
    }
  ],
  "8610": [
    {
      "answer": "Capitol Hill, Washington, D.C",
      "score": 0.9608436822891235
    }
  ],
  "8611": [
    {
      "answer": "18 July 2000",
      "score": 0.9281185865402222
    }
  ],
  "8612": [
    {
      "answer": "United States Senate Committee on Commerce, Science and Transportation",
      "score": 0.9473435282707214
    }
  ],
  "8613": [
    {
      "answer": "2000",
      "score": 0.8176130056381226
    },
    {
      "answer": "2000",
      "score": 0.7195557355880737
    }
  ],
  "8614": [
    {
      "answer": "Wibj\u00f6rn Karl\u00e9n",
      "score": 0.9373582601547241
    }
  ],
  "8615": [],
  "8616": [
    {
      "answer": "18 July 2000",
      "score": 0.9099622964859009
    }
  ],
  "8617": [
    {
      "answer": "hockey stick",
      "score": 0.9788631200790405
    }
  ],
  "8618": [
    {
      "answer": "Joe Barton",
      "score": 0.9935976266860962
    }
  ],
  "8619": [
    {
      "answer": "Ed Whitfield",
      "score": 0.9968193173408508
    }
  ],
  "8620": [
    {
      "answer": "23 June 2005",
      "score": 0.9902693629264832
    }
  ],
  "8621": [
    {
      "answer": "Sherwood Boehlert",
      "score": 0.9915947318077087
    }
  ],
  "8622": [
    {
      "answer": "Sherwood Boehlert",
      "score": 0.9977656602859497
    }
  ],
  "8623": [
    {
      "answer": "Mann, Bradley and Hughes",
      "score": 0.86464923620224
    }
  ],
  "8624": [
    {
      "answer": "Mann, Bradley and Hughes",
      "score": 0.9120952486991882
    },
    {
      "answer": "Mann, Bradley, and Hughes",
      "score": 0.6311991214752197
    }
  ],
  "8625": [
    {
      "answer": "Sherwood Boehlert",
      "score": 0.9892507195472717
    }
  ],
  "8626": [
    {
      "answer": "Joe Barton",
      "score": 0.9332777261734009
    },
    {
      "answer": "Sherwood Boehlert",
      "score": 0.5693329572677612
    }
  ],
  "8627": [
    {
      "answer": "National Research Council",
      "score": 0.9360595941543579
    },
    {
      "answer": "National Research Council",
      "score": 0.9380990266799927
    }
  ],
  "8628": [
    {
      "answer": "2007",
      "score": 0.9805223345756531
    }
  ],
  "8629": [
    {
      "answer": "2001",
      "score": 0.9920367002487183
    }
  ],
  "8630": [
    {
      "answer": "14",
      "score": 0.8714317083358765
    }
  ],
  "8631": [
    {
      "answer": "Ten",
      "score": 0.9118857979774475
    },
    {
      "answer": "14",
      "score": 0.8001865148544312
    }
  ],
  "8632": [
    {
      "answer": "divergence",
      "score": 0.9918021559715271
    }
  ],
  "8633": [],
  "8634": [
    {
      "answer": "12",
      "score": 0.8447747230529785
    }
  ],
  "8635": [
    {
      "answer": "Briffa",
      "score": 0.9048888087272644
    }
  ],
  "8636": [
    {
      "answer": "Crowley & Lowery",
      "score": 0.9345054626464844
    },
    {
      "answer": "Osborn & Briffa",
      "score": 0.638439416885376
    }
  ],
  "8637": [
    {
      "answer": "Ten",
      "score": 0.911205530166626
    },
    {
      "answer": "14",
      "score": 0.8444277048110962
    }
  ],
  "8638": [
    {
      "answer": "1 February 2007",
      "score": 0.9825323820114136
    }
  ],
  "8639": [
    {
      "answer": "above the top of the range of the IPCC projection",
      "score": 0.9294036030769348
    }
  ],
  "8640": [
    {
      "answer": "above the top of the range of the IPCC projection",
      "score": 0.9289674758911133
    }
  ],
  "8641": [
    {
      "answer": "above the top of the range of the IPCC projection",
      "score": 0.9436575174331665
    }
  ],
  "8642": [
    {
      "answer": "temperatures and sea levels",
      "score": 0.8522064685821533
    }
  ],
  "8643": [
    {
      "answer": "six",
      "score": 0.9911127686500549
    }
  ],
  "8644": [
    {
      "answer": "IPCC",
      "score": 0.8115355968475342
    }
  ],
  "8645": [
    {
      "answer": "IPCC",
      "score": 0.6207453012466431
    }
  ],
  "8646": [],
  "8647": [
    {
      "answer": "rises in sea levels",
      "score": 0.919593334197998
    }
  ],
  "8648": [
    {
      "answer": "9\u201388 cm",
      "score": 0.9303096532821655
    }
  ],
  "8649": [
    {
      "answer": "0.5\u20131.4 m",
      "score": 0.9824033975601196
    }
  ],
  "8650": [
    {
      "answer": "2001",
      "score": 0.9940720200538635
    }
  ],
  "8651": [
    {
      "answer": "0.5\u20131.4 m",
      "score": 0.8882228136062622
    },
    {
      "answer": "9\u201388 cm",
      "score": 0.740117073059082
    }
  ],
  "8652": [
    {
      "answer": "9\u201388 cm",
      "score": 0.9268311858177185
    }
  ],
  "8653": [
    {
      "answer": "IPCC",
      "score": 0.9710637331008911
    }
  ],
  "8654": [
    {
      "answer": "a study on projected rises in sea levels",
      "score": 0.9636670351028442
    }
  ],
  "8655": [
    {
      "answer": "0.5\u20131.4 m",
      "score": 0.9697160720825195
    }
  ],
  "8656": [
    {
      "answer": "coordinating lead author",
      "score": 0.9658975601196289
    }
  ],
  "8657": [
    {
      "answer": "Michael Oppenheimer",
      "score": 0.8740681409835815
    },
    {
      "answer": "Science Magazine",
      "score": 0.5503087043762207
    }
  ],
  "8658": [
    {
      "answer": "concurring, smaller assessments of special problems",
      "score": 0.9613635540008545
    }
  ],
  "8659": [
    {
      "answer": "Michael Oppenheimer",
      "score": 0.9870124459266663
    }
  ],
  "8660": [
    {
      "answer": "2008-2009",
      "score": 0.9901819825172424
    }
  ],
  "8661": [
    {
      "answer": "concurring, smaller assessments of special problems",
      "score": 0.7881683707237244
    }
  ],
  "8662": [
    {
      "answer": "Science Magazine",
      "score": 0.9295051693916321
    }
  ],
  "8663": [
    {
      "answer": "Science",
      "score": 0.9859331250190735
    }
  ],
  "8664": [
    {
      "answer": "Montreal Protocol",
      "score": 0.9927658438682556
    }
  ],
  "8665": [
    {
      "answer": "climate change",
      "score": 0.6511791944503784
    },
    {
      "answer": "Climate Change",
      "score": 0.7118409872055054
    }
  ],
  "8666": [
    {
      "answer": "states and governments",
      "score": 0.9907094836235046
    }
  ],
  "8667": [
    {
      "answer": "Ozone",
      "score": 0.8680841326713562
    },
    {
      "answer": "Ozone",
      "score": 0.9008127450942993
    }
  ],
  "8668": [
    {
      "answer": "The lockstep situation of the IPCC is having built a broad science consensus",
      "score": 0.6089617013931274
    }
  ],
  "8669": [
    {
      "answer": "consensus",
      "score": 0.8290813565254211
    }
  ],
  "8670": [
    {
      "answer": "IPCC",
      "score": 0.773762583732605
    },
    {
      "answer": "IPCC",
      "score": 0.6753202676773071
    },
    {
      "answer": "IPCC",
      "score": 0.9489954113960266
    }
  ],
  "8671": [
    {
      "answer": "the better the political response will be is being doubted",
      "score": 0.6994966864585876
    }
  ],
  "8672": [
    {
      "answer": "Sheldon Ungar",
      "score": 0.997278094291687
    }
  ],
  "8673": [
    {
      "answer": "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions",
      "score": 0.9861639738082886
    }
  ],
  "8674": [
    {
      "answer": "regional burden sharing conflicts",
      "score": 0.9835888147354126
    }
  ],
  "8675": [
    {
      "answer": "UK government",
      "score": 0.9903316497802734
    }
  ],
  "8676": [
    {
      "answer": "Sheldon Ungar",
      "score": 0.9956477880477905
    }
  ],
  "8677": [
    {
      "answer": "popular culture",
      "score": 0.9906183481216431
    }
  ],
  "8678": [
    {
      "answer": "immediate risks",
      "score": 0.9059410095214844
    }
  ],
  "8679": [
    {
      "answer": "climate change",
      "score": 0.9216707944869995
    },
    {
      "answer": "climate change",
      "score": 0.8335423469543457
    },
    {
      "answer": "climate change",
      "score": 0.7075328826904297
    }
  ],
  "8680": [
    {
      "answer": "varying regional cost-benefit analysis and burden-sharing conflicts with regard to the distribution of emission reductions",
      "score": 0.8241987228393555
    }
  ],
  "8681": [
    {
      "answer": "scientific papers and independently documented results from other scientific bodies",
      "score": 0.9613960385322571
    }
  ],
  "8682": [
    {
      "answer": "significant new evidence or events that change our understanding of climate science",
      "score": 0.9678030014038086
    }
  ],
  "8683": [
    {
      "answer": "IPCC",
      "score": 0.9258027672767639
    },
    {
      "answer": "IPCC",
      "score": 0.5938008427619934
    }
  ],
  "8684": [
    {
      "answer": "IPCC",
      "score": 0.9657374620437622
    },
    {
      "answer": "IPCC",
      "score": 0.6046136617660522
    }
  ],
  "8685": [],
  "8686": [
    {
      "answer": "climate",
      "score": 0.9755724668502808
    }
  ],
  "8687": [],
  "8688": [
    {
      "answer": "five",
      "score": 0.9940395355224609
    }
  ],
  "8689": [
    {
      "answer": "Nature",
      "score": 0.9855060577392578
    }
  ],
  "8690": [
    {
      "answer": "tightening the selection of lead authors and contributors",
      "score": 0.8944313526153564
    },
    {
      "answer": "dumping it in favor of a small permanent body",
      "score": 0.8922045230865479
    }
  ],
  "8691": [
    {
      "answer": "tightening the selection of lead authors and contributors",
      "score": 0.7014005780220032
    },
    {
      "answer": "employ a full-time staff and remove government oversight from its processes",
      "score": 0.8863620162010193
    }
  ],
  "8692": [
    {
      "answer": "February 2010",
      "score": 0.9884227514266968
    }
  ],
  "8693": [
    {
      "answer": "Nature",
      "score": 0.9911706447601318
    }
  ],
  "8694": [
    {
      "answer": "five climate scientists",
      "score": 0.941470742225647
    }
  ],
  "8695": [
    {
      "answer": "political interference",
      "score": 0.954414963722229
    }
  ],
  "8696": [
    {
      "answer": "tightening the selection of lead authors and contributors",
      "score": 0.8472645282745361
    },
    {
      "answer": "dumping it in favor of a small permanent body",
      "score": 0.684167742729187
    }
  ],
  "8697": [
    {
      "answer": "1",
      "score": 0.6111355423927307
    },
    {
      "answer": "1",
      "score": 0.6431905627250671
    },
    {
      "answer": "1",
      "score": 0.5294522047042847
    }
  ],
  "8698": [
    {
      "answer": "prime number",
      "score": 0.7165813446044922
    },
    {
      "answer": "prime number",
      "score": 0.5973135232925415
    },
    {
      "answer": "composite number",
      "score": 0.607399582862854
    }
  ],
  "8699": [
    {
      "answer": "fundamental theorem of arithmetic",
      "score": 0.9926129579544067
    }
  ],
  "8700": [
    {
      "answer": "primes",
      "score": 0.9855440258979797
    }
  ],
  "8701": [
    {
      "answer": "one can include arbitrarily many instances of 1 in any factorization, e.g., 3, 1 \u00b7 3, 1 \u00b7 1 \u00b7 3, etc. are all valid factorizations of 3.",
      "score": 0.9336437582969666
    }
  ],
  "8702": [
    {
      "answer": "1",
      "score": 0.5454169511795044
    },
    {
      "answer": "1",
      "score": 0.6666073799133301
    }
  ],
  "8703": [
    {
      "answer": "prime number",
      "score": 0.7524427771568298
    },
    {
      "answer": "prime number",
      "score": 0.5663713812828064
    },
    {
      "answer": "composite number",
      "score": 0.5747026801109314
    }
  ],
  "8704": [
    {
      "answer": "product of primes",
      "score": 0.9780445098876953
    }
  ],
  "8705": [
    {
      "answer": "primes",
      "score": 0.9828373193740845
    }
  ],
  "8706": [
    {
      "answer": "one can include arbitrarily many instances of 1 in any factorization, e.g., 3, 1 \u00b7 3, 1 \u00b7 1 \u00b7 3, etc. are all valid factorizations of 3.",
      "score": 0.9337040781974792
    }
  ],
  "8707": [
    {
      "answer": "primality",
      "score": 0.9944621920585632
    },
    {
      "answer": "primality",
      "score": 0.9328048825263977
    },
    {
      "answer": "primality",
      "score": 0.9445525407791138
    },
    {
      "answer": "primality",
      "score": 0.9337100386619568
    },
    {
      "answer": "primality",
      "score": 0.9099697470664978
    }
  ],
  "8708": [
    {
      "answer": "trial division",
      "score": 0.9962855577468872
    },
    {
      "answer": "trial division",
      "score": 0.9735112190246582
    }
  ],
  "8709": [
    {
      "answer": "Miller\u2013Rabin primality test",
      "score": 0.9796959161758423
    }
  ],
  "8710": [
    {
      "answer": "Miller\u2013Rabin primality test",
      "score": 0.9891800284385681
    },
    {
      "answer": "AKS primality test",
      "score": 0.5790721774101257
    }
  ],
  "8711": [
    {
      "answer": "22",
      "score": 0.9927313923835754
    }
  ],
  "8712": [
    {
      "answer": "primality",
      "score": 0.9926813244819641
    },
    {
      "answer": "primality",
      "score": 0.9408707618713379
    },
    {
      "answer": "primality",
      "score": 0.9550341367721558
    },
    {
      "answer": "primality",
      "score": 0.9335795640945435
    },
    {
      "answer": "primality",
      "score": 0.9149798154830933
    }
  ],
  "8713": [
    {
      "answer": "trial division",
      "score": 0.9968898296356201
    },
    {
      "answer": "trial division",
      "score": 0.9754153490066528
    }
  ],
  "8714": [
    {
      "answer": "Miller\u2013Rabin primality test",
      "score": 0.9790138602256775
    }
  ],
  "8715": [
    {
      "answer": "Miller\u2013Rabin primality test",
      "score": 0.9895931482315063
    },
    {
      "answer": "AKS primality test",
      "score": 0.5827882885932922
    }
  ],
  "8716": [
    {
      "answer": "22,338,618",
      "score": 0.9513646960258484
    }
  ],
  "8717": [
    {
      "answer": "infinitely many",
      "score": 0.9528257846832275
    }
  ],
  "8718": [
    {
      "answer": "Euclid",
      "score": 0.9957257509231567
    }
  ],
  "8719": [
    {
      "answer": "distribution",
      "score": 0.9699677228927612
    }
  ],
  "8720": [
    {
      "answer": "prime number theorem",
      "score": 0.9951682090759277
    }
  ],
  "8721": [
    {
      "answer": "19th century",
      "score": 0.9788967370986938
    }
  ],
  "8722": [
    {
      "answer": "infinitely many",
      "score": 0.9318511486053467
    }
  ],
  "8723": [
    {
      "answer": "Euclid",
      "score": 0.99564528465271
    }
  ],
  "8724": [
    {
      "answer": "distribution",
      "score": 0.9462072849273682
    }
  ],
  "8725": [
    {
      "answer": "prime number theorem",
      "score": 0.9950281381607056
    }
  ],
  "8726": [
    {
      "answer": "19th century",
      "score": 0.9768661856651306
    }
  ],
  "8727": [
    {
      "answer": "Goldbach's conjecture",
      "score": 0.9482513070106506
    }
  ],
  "8728": [
    {
      "answer": "twin prime conjecture",
      "score": 0.9706830978393555
    }
  ],
  "8729": [
    {
      "answer": "algebraic",
      "score": 0.9739198088645935
    }
  ],
  "8730": [
    {
      "answer": "public-key cryptography",
      "score": 0.9977288246154785
    }
  ],
  "8731": [
    {
      "answer": "prime elements",
      "score": 0.7800332307815552
    },
    {
      "answer": "prime ideals",
      "score": 0.900945246219635
    }
  ],
  "8732": [
    {
      "answer": "Goldbach's conjecture",
      "score": 0.9417166709899902
    }
  ],
  "8733": [
    {
      "answer": "twin prime conjecture",
      "score": 0.9687086343765259
    }
  ],
  "8734": [
    {
      "answer": "algebraic",
      "score": 0.9452431797981262
    }
  ],
  "8735": [
    {
      "answer": "public-key cryptography",
      "score": 0.9971866011619568
    }
  ],
  "8736": [
    {
      "answer": "prime elements",
      "score": 0.767192006111145
    },
    {
      "answer": "prime ideals",
      "score": 0.9100698232650757
    }
  ],
  "8737": [
    {
      "answer": "2",
      "score": 0.964853048324585
    },
    {
      "answer": "2",
      "score": 0.6135459542274475
    },
    {
      "answer": "2",
      "score": 0.7941827774047852
    },
    {
      "answer": "2",
      "score": 0.5251758098602295
    }
  ],
  "8738": [
    {
      "answer": "2",
      "score": 0.5161153674125671
    },
    {
      "answer": "1, 2, and n",
      "score": 0.9738392233848572
    }
  ],
  "8739": [
    {
      "answer": "odd prime",
      "score": 0.9932352304458618
    }
  ],
  "8740": [
    {
      "answer": "9",
      "score": 0.9248740673065186
    }
  ],
  "8741": [
    {
      "answer": "even",
      "score": 0.567979633808136
    },
    {
      "answer": "even",
      "score": 0.9884572625160217
    }
  ],
  "8742": [
    {
      "answer": "2",
      "score": 0.9339098334312439
    },
    {
      "answer": "2",
      "score": 0.6209017038345337
    },
    {
      "answer": "2",
      "score": 0.7264288067817688
    }
  ],
  "8743": [
    {
      "answer": "1, 2, and n",
      "score": 0.9684362411499023
    }
  ],
  "8744": [
    {
      "answer": "odd prime",
      "score": 0.9935605525970459
    }
  ],
  "8745": [
    {
      "answer": "1, 3, 7, or 9",
      "score": 0.6015862226486206
    }
  ],
  "8746": [
    {
      "answer": "even",
      "score": 0.6754716634750366
    },
    {
      "answer": "even",
      "score": 0.9503546953201294
    }
  ],
  "8747": [
    {
      "answer": "1",
      "score": 0.982693612575531
    },
    {
      "answer": "1",
      "score": 0.8579407334327698
    },
    {
      "answer": "1",
      "score": 0.8630141615867615
    },
    {
      "answer": "1",
      "score": 0.9234828352928162
    },
    {
      "answer": "1",
      "score": 0.8720611929893494
    },
    {
      "answer": "1",
      "score": 0.8679631948471069
    },
    {
      "answer": "1",
      "score": 0.9327474236488342
    }
  ],
  "8748": [
    {
      "answer": "Christian Goldbach",
      "score": 0.9966622591018677
    }
  ],
  "8749": [
    {
      "answer": "Christian Goldbach",
      "score": 0.7502585053443909
    },
    {
      "answer": "Leonhard Euler",
      "score": 0.9732340574264526
    }
  ],
  "8750": [
    {
      "answer": "10",
      "score": 0.9772571325302124
    }
  ],
  "8751": [
    {
      "answer": "unit",
      "score": 0.9572431445121765
    }
  ],
  "8752": [
    {
      "answer": "1",
      "score": 0.7412631511688232
    },
    {
      "answer": "1",
      "score": 0.7718620300292969
    },
    {
      "answer": "1",
      "score": 0.7986935377120972
    },
    {
      "answer": "1",
      "score": 0.8292350172996521
    },
    {
      "answer": "1",
      "score": 0.7505308389663696
    },
    {
      "answer": "1",
      "score": 0.8112586140632629
    },
    {
      "answer": "1",
      "score": 0.9112180471420288
    }
  ],
  "8753": [
    {
      "answer": "Christian Goldbach",
      "score": 0.8866332769393921
    },
    {
      "answer": "Henri Lebesgue",
      "score": 0.5873174667358398
    }
  ],
  "8754": [
    {
      "answer": "Leonhard Euler",
      "score": 0.9660423994064331
    }
  ],
  "8755": [],
  "8756": [],
  "8757": [
    {
      "answer": "Euclid's fundamental theorem of arithmetic",
      "score": 0.9086298942565918
    },
    {
      "answer": "sieve of Eratosthenes",
      "score": 0.7278944253921509
    }
  ],
  "8758": [
    {
      "answer": "a prime",
      "score": 0.9308792352676392
    }
  ],
  "8759": [
    {
      "answer": "sum of divisors function",
      "score": 0.9444248676300049
    }
  ],
  "8760": [
    {
      "answer": "sum of divisors function",
      "score": 0.9722020626068115
    }
  ],
  "8761": [
    {
      "answer": "eliminate all multiples of 1",
      "score": 0.8019842505455017
    },
    {
      "answer": "only the single number 1",
      "score": 0.9473996162414551
    }
  ],
  "8762": [
    {
      "answer": "Euclid's fundamental theorem of arithmetic",
      "score": 0.9201240539550781
    },
    {
      "answer": "sieve of Eratosthenes",
      "score": 0.6964730024337769
    }
  ],
  "8763": [
    {
      "answer": "a prime",
      "score": 0.904218852519989
    }
  ],
  "8764": [
    {
      "answer": "sum of divisors function",
      "score": 0.949020266532898
    }
  ],
  "8765": [
    {
      "answer": "sum of divisors function",
      "score": 0.9730772972106934
    }
  ],
  "8766": [
    {
      "answer": "eliminate all multiples of 1",
      "score": 0.7914901375770569
    },
    {
      "answer": "only the single number 1",
      "score": 0.9408580660820007
    }
  ],
  "8767": [
    {
      "answer": "Rhind",
      "score": 0.9918146729469299
    }
  ],
  "8768": [
    {
      "answer": "Ancient Greeks",
      "score": 0.9787789583206177
    }
  ],
  "8769": [
    {
      "answer": "Euclid's Elements",
      "score": 0.9451335668563843
    }
  ],
  "8770": [
    {
      "answer": "Euclid",
      "score": 0.808352530002594
    },
    {
      "answer": "Euclid",
      "score": 0.9775616526603699
    }
  ],
  "8771": [
    {
      "answer": "a simple method to compute primes",
      "score": 0.9668633341789246
    }
  ],
  "8772": [
    {
      "answer": "Rhind",
      "score": 0.9917578101158142
    }
  ],
  "8773": [
    {
      "answer": "Ancient Greeks",
      "score": 0.9800151586532593
    }
  ],
  "8774": [
    {
      "answer": "Euclid's Elements",
      "score": 0.8801899552345276
    }
  ],
  "8775": [
    {
      "answer": "Euclid",
      "score": 0.8119606971740723
    },
    {
      "answer": "Euclid",
      "score": 0.9794231057167053
    }
  ],
  "8776": [
    {
      "answer": "a simple method to compute primes",
      "score": 0.9465762376785278
    }
  ],
  "8777": [
    {
      "answer": "1640",
      "score": 0.9942405223846436
    }
  ],
  "8778": [
    {
      "answer": "Euler",
      "score": 0.9931855201721191
    },
    {
      "answer": "Euler",
      "score": 0.9335598945617676
    }
  ],
  "8779": [
    {
      "answer": "22n + 1",
      "score": 0.9816738367080688
    }
  ],
  "8780": [
    {
      "answer": "all numbers of the form 22n + 1 are prime",
      "score": 0.7586132884025574
    },
    {
      "answer": "up to n = 4 (or 216 + 1)",
      "score": 0.8846462965011597
    }
  ],
  "8781": [
    {
      "answer": "2p \u2212 1",
      "score": 0.9867779612541199
    }
  ],
  "8782": [
    {
      "answer": "1640",
      "score": 0.9942730069160461
    }
  ],
  "8783": [
    {
      "answer": "Leibniz",
      "score": 0.9385385513305664
    }
  ],
  "8784": [],
  "8785": [
    {
      "answer": "up to n = 4 (or 216 + 1)",
      "score": 0.8470358848571777
    }
  ],
  "8786": [
    {
      "answer": "2p \u2212 1",
      "score": 0.8269671201705933
    }
  ],
  "8787": [
    {
      "answer": "trial division",
      "score": 0.9977205991744995
    }
  ],
  "8788": [
    {
      "answer": "a complete list of primes up to  is known",
      "score": 0.9644680023193359
    }
  ],
  "8789": [
    {
      "answer": "1",
      "score": 0.9285386204719543
    },
    {
      "answer": "square root of n",
      "score": 0.843650221824646
    }
  ],
  "8790": [
    {
      "answer": "square root of n",
      "score": 0.9695680141448975
    }
  ],
  "8791": [
    {
      "answer": "three",
      "score": 0.9924837946891785
    }
  ],
  "8792": [
    {
      "answer": "trial division",
      "score": 0.9951314926147461
    }
  ],
  "8793": [
    {
      "answer": "a complete list of primes up to  is known",
      "score": 0.9636073708534241
    }
  ],
  "8794": [
    {
      "answer": "square root of n",
      "score": 0.9305752515792847
    }
  ],
  "8795": [
    {
      "answer": "square root of n",
      "score": 0.9512563943862915
    }
  ],
  "8796": [
    {
      "answer": "three",
      "score": 0.9925373196601868
    }
  ],
  "8797": [],
  "8798": [
    {
      "answer": "Monte Carlo",
      "score": 0.9073354005813599
    }
  ],
  "8799": [
    {
      "answer": "Monte Carlo",
      "score": 0.8754956722259521
    }
  ],
  "8800": [
    {
      "answer": "deterministic",
      "score": 0.8248804211616516
    },
    {
      "answer": "deterministic",
      "score": 0.9908459782600403
    }
  ],
  "8801": [
    {
      "answer": "1/(1-p)n",
      "score": 0.8586439490318298
    }
  ],
  "8802": [],
  "8803": [
    {
      "answer": "Monte Carlo",
      "score": 0.7150505781173706
    },
    {
      "answer": "trial division",
      "score": 0.6789131164550781
    }
  ],
  "8804": [
    {
      "answer": "Monte Carlo",
      "score": 0.7154923677444458
    },
    {
      "answer": "trial division",
      "score": 0.6765638589859009
    }
  ],
  "8805": [
    {
      "answer": "deterministic",
      "score": 0.5555781126022339
    },
    {
      "answer": "deterministic",
      "score": 0.9849042892456055
    }
  ],
  "8806": [
    {
      "answer": "1/(1-p)n",
      "score": 0.8483341932296753
    }
  ],
  "8807": [
    {
      "answer": "Fermat primality test",
      "score": 0.9944796562194824
    },
    {
      "answer": "Fermat primality test",
      "score": 0.9060206413269043
    }
  ],
  "8808": [
    {
      "answer": "Fermat's little theorem) that np\u2261n (mod p) for any n if p is a prime number",
      "score": 0.899700939655304
    }
  ],
  "8809": [
    {
      "answer": "composite numbers",
      "score": 0.7648169994354248
    },
    {
      "answer": "Carmichael numbers",
      "score": 0.7548474073410034
    },
    {
      "answer": "Carmichael numbers",
      "score": 0.7128995656967163
    },
    {
      "answer": "Carmichael numbers",
      "score": 0.7990597486495972
    }
  ],
  "8810": [
    {
      "answer": "Baillie-PSW",
      "score": 0.9372880458831787
    },
    {
      "answer": "Miller-Rabin",
      "score": 0.7308682799339294
    }
  ],
  "8811": [
    {
      "answer": "Baillie-PSW",
      "score": 0.9466233849525452
    },
    {
      "answer": "Miller-Rabin",
      "score": 0.7530568242073059
    }
  ],
  "8812": [
    {
      "answer": "Fermat primality test",
      "score": 0.8182899355888367
    }
  ],
  "8813": [
    {
      "answer": "Fermat's little theorem",
      "score": 0.795251727104187
    }
  ],
  "8814": [
    {
      "answer": "composite numbers",
      "score": 0.9097914695739746
    }
  ],
  "8815": [
    {
      "answer": "Baillie-PSW",
      "score": 0.8729629516601562
    },
    {
      "answer": "Miller-Rabin",
      "score": 0.6093938946723938
    }
  ],
  "8816": [
    {
      "answer": "Fermat primality test",
      "score": 0.6603309512138367
    },
    {
      "answer": "Fermat primality test",
      "score": 0.680769145488739
    },
    {
      "answer": "Baillie-PSW",
      "score": 0.657524824142456
    }
  ],
  "8817": [
    {
      "answer": "2p + 1 with p prime",
      "score": 0.9333672523498535
    }
  ],
  "8818": [
    {
      "answer": "2p \u2212 1",
      "score": 0.9784440398216248
    }
  ],
  "8819": [
    {
      "answer": "Lucas\u2013Lehmer",
      "score": 0.997730016708374
    }
  ],
  "8820": [
    {
      "answer": "factorial primes",
      "score": 0.9303987622261047
    }
  ],
  "8821": [
    {
      "answer": "Sophie Germain primes",
      "score": 0.6730727553367615
    },
    {
      "answer": "Mersenne primes",
      "score": 0.7439868450164795
    }
  ],
  "8822": [
    {
      "answer": "2p + 1 with p prime",
      "score": 0.7694799304008484
    }
  ],
  "8823": [
    {
      "answer": "2p \u2212 1",
      "score": 0.957563042640686
    }
  ],
  "8824": [
    {
      "answer": "Lucas\u2013Lehmer",
      "score": 0.9976705312728882
    }
  ],
  "8825": [
    {
      "answer": "Lucas\u2013Lehmer",
      "score": 0.9938063025474548
    }
  ],
  "8826": [
    {
      "answer": "Lucas\u2013Lehmer test",
      "score": 0.9711546301841736
    }
  ],
  "8827": [
    {
      "answer": "distributed computing",
      "score": 0.9481624364852905
    }
  ],
  "8828": [
    {
      "answer": "2009",
      "score": 0.9967407584190369
    }
  ],
  "8829": [
    {
      "answer": "US$100,000",
      "score": 0.9686903357505798
    }
  ],
  "8830": [
    {
      "answer": "Electronic Frontier Foundation",
      "score": 0.9946677684783936
    }
  ],
  "8831": [
    {
      "answer": "256kn + 1, 256k(n + 1) \u2212 1",
      "score": 0.979538083076477
    }
  ],
  "8832": [
    {
      "answer": "distributed computing",
      "score": 0.8971579074859619
    }
  ],
  "8833": [
    {
      "answer": "2009",
      "score": 0.997136116027832
    }
  ],
  "8834": [
    {
      "answer": "$100,000",
      "score": 0.9744415283203125
    }
  ],
  "8835": [
    {
      "answer": "Electronic Frontier Foundation",
      "score": 0.9961084127426147
    }
  ],
  "8836": [
    {
      "answer": "256kn + 1, 256k(n + 1) \u2212 1",
      "score": 0.9791283011436462
    }
  ],
  "8837": [
    {
      "answer": "floor function",
      "score": 0.9858360290527344
    }
  ],
  "8838": [
    {
      "answer": "Chebyshev",
      "score": 0.9972688555717468
    }
  ],
  "8839": [
    {
      "answer": "> 3",
      "score": 0.9027450084686279
    }
  ],
  "8840": [
    {
      "answer": "floor function",
      "score": 0.9696942567825317
    }
  ],
  "8841": [
    {
      "answer": "Wilson's theorem",
      "score": 0.9305000901222229
    }
  ],
  "8842": [
    {
      "answer": "floor function",
      "score": 0.986777126789093
    }
  ],
  "8843": [
    {
      "answer": "Chebyshev",
      "score": 0.9974168539047241
    }
  ],
  "8844": [
    {
      "answer": "3",
      "score": 0.8902722597122192
    }
  ],
  "8845": [
    {
      "answer": "floor function",
      "score": 0.9693671464920044
    }
  ],
  "8846": [
    {
      "answer": "Wilson's theorem",
      "score": 0.8969884514808655
    }
  ],
  "8847": [
    {
      "answer": "their greatest common divisor is one",
      "score": 0.7567143440246582
    }
  ],
  "8848": [
    {
      "answer": "Dirichlet's theorem",
      "score": 0.9746469855308533
    }
  ],
  "8849": [
    {
      "answer": "1/6",
      "score": 0.9950783252716064
    }
  ],
  "8850": [
    {
      "answer": "infinitely many",
      "score": 0.618004560470581
    },
    {
      "answer": "infinitely many",
      "score": 0.7550508379936218
    },
    {
      "answer": "one",
      "score": 0.6304075121879578
    },
    {
      "answer": "infinitely many",
      "score": 0.6290174722671509
    }
  ],
  "8851": [
    {
      "answer": "infinitely many",
      "score": 0.7863490581512451
    },
    {
      "answer": "infinitely many",
      "score": 0.9020282626152039
    },
    {
      "answer": "infinitely many",
      "score": 0.8395880460739136
    }
  ],
  "8852": [
    {
      "answer": "greatest common divisor is one",
      "score": 0.7853747606277466
    }
  ],
  "8853": [
    {
      "answer": "Dirichlet's theorem",
      "score": 0.9326686859130859
    }
  ],
  "8854": [
    {
      "answer": "1/6",
      "score": 0.9949025511741638
    }
  ],
  "8855": [
    {
      "answer": "infinitely many",
      "score": 0.5873354077339172
    },
    {
      "answer": "infinitely many",
      "score": 0.736198902130127
    },
    {
      "answer": "infinitely many",
      "score": 0.596847653388977
    }
  ],
  "8856": [
    {
      "answer": "infinitely many",
      "score": 0.7234471440315247
    },
    {
      "answer": "infinitely many",
      "score": 0.8572440147399902
    },
    {
      "answer": "infinitely many",
      "score": 0.8070051074028015
    }
  ],
  "8857": [
    {
      "answer": "zeta function",
      "score": 0.9772664308547974
    },
    {
      "answer": "zeta function",
      "score": 0.9568277597427368
    },
    {
      "answer": "zeta function",
      "score": 0.9389485120773315
    }
  ],
  "8858": [
    {
      "answer": "finite",
      "score": 0.9639469981193542
    }
  ],
  "8859": [
    {
      "answer": "diverges",
      "score": 0.9927801489830017
    }
  ],
  "8860": [
    {
      "answer": "exceeds any given number",
      "score": 0.9419001340866089
    }
  ],
  "8861": [
    {
      "answer": "algebraic number theory",
      "score": 0.8416682481765747
    }
  ],
  "8862": [
    {
      "answer": "zeta function",
      "score": 0.9703313112258911
    },
    {
      "answer": "zeta function",
      "score": 0.9322550296783447
    },
    {
      "answer": "zeta function",
      "score": 0.9220754504203796
    }
  ],
  "8863": [
    {
      "answer": "finite",
      "score": 0.9582129120826721
    }
  ],
  "8864": [
    {
      "answer": "diverges",
      "score": 0.9924348592758179
    }
  ],
  "8865": [
    {
      "answer": "exceeds any given number",
      "score": 0.9457811117172241
    }
  ],
  "8866": [],
  "8867": [
    {
      "answer": "1859",
      "score": 0.9964577555656433
    }
  ],
  "8868": [
    {
      "answer": "\u22122, \u22124, ...",
      "score": 0.9097084403038025
    }
  ],
  "8869": [
    {
      "answer": "random noise",
      "score": 0.9977809190750122
    }
  ],
  "8870": [
    {
      "answer": "asymptotic",
      "score": 0.9903990626335144
    }
  ],
  "8871": [
    {
      "answer": "asymptotic",
      "score": 0.9918336868286133
    }
  ],
  "8872": [
    {
      "answer": "1859",
      "score": 0.9964392781257629
    }
  ],
  "8873": [
    {
      "answer": "\u22122, \u22124, ...",
      "score": 0.9131414890289307
    }
  ],
  "8874": [
    {
      "answer": "random noise",
      "score": 0.9967448711395264
    }
  ],
  "8875": [
    {
      "answer": "asymptotic",
      "score": 0.9900656938552856
    }
  ],
  "8876": [
    {
      "answer": "asymptotic",
      "score": 0.9918558597564697
    }
  ],
  "8877": [
    {
      "answer": "1912",
      "score": 0.9955885410308838
    }
  ],
  "8878": [
    {
      "answer": "Goldbach's conjecture",
      "score": 0.9648584127426147
    }
  ],
  "8879": [
    {
      "answer": "all numbers up to n = 2 \u00b7 1017",
      "score": 0.8841999173164368
    }
  ],
  "8880": [
    {
      "answer": "Vinogradov's theorem",
      "score": 0.8859055042266846
    }
  ],
  "8881": [
    {
      "answer": "Goldbach's conjecture",
      "score": 0.6102331876754761
    },
    {
      "answer": "Chen's theorem",
      "score": 0.7573437690734863
    }
  ],
  "8882": [
    {
      "answer": "1912",
      "score": 0.9959810972213745
    }
  ],
  "8883": [
    {
      "answer": "Goldbach's conjecture",
      "score": 0.9642740488052368
    }
  ],
  "8884": [
    {
      "answer": "all numbers up to n = 2 \u00b7 1017",
      "score": 0.8831428289413452
    }
  ],
  "8885": [
    {
      "answer": "Vinogradov's theorem",
      "score": 0.8319806456565857
    }
  ],
  "8886": [
    {
      "answer": "Goldbach's conjecture",
      "score": 0.6245415806770325
    },
    {
      "answer": "Chen's theorem",
      "score": 0.6763296127319336
    }
  ],
  "8887": [
    {
      "answer": "twin prime conjecture",
      "score": 0.9678702354431152
    }
  ],
  "8888": [
    {
      "answer": "pairs of primes with difference 2",
      "score": 0.9397662878036499
    }
  ],
  "8889": [
    {
      "answer": "Polignac's conjecture",
      "score": 0.9711264371871948
    }
  ],
  "8890": [
    {
      "answer": "n2 + 1",
      "score": 0.9764263033866882
    }
  ],
  "8891": [
    {
      "answer": "Brocard's conjecture",
      "score": 0.8859346508979797
    }
  ],
  "8892": [
    {
      "answer": "twin prime conjecture",
      "score": 0.9407434463500977
    }
  ],
  "8893": [
    {
      "answer": "twin primes",
      "score": 0.6957499980926514
    },
    {
      "answer": "pairs of primes with difference 2",
      "score": 0.7650792002677917
    }
  ],
  "8894": [
    {
      "answer": "Polignac's conjecture",
      "score": 0.9539616107940674
    }
  ],
  "8895": [
    {
      "answer": "n2 + 1",
      "score": 0.9760370254516602
    }
  ],
  "8896": [
    {
      "answer": "Brocard",
      "score": 0.9625545740127563
    }
  ],
  "8897": [
    {
      "answer": "number theory",
      "score": 0.8950119614601135
    }
  ],
  "8898": [
    {
      "answer": "G. H. Hardy",
      "score": 0.9960967302322388
    }
  ],
  "8899": [
    {
      "answer": "1970s",
      "score": 0.9956254959106445
    }
  ],
  "8900": [
    {
      "answer": "hash tables",
      "score": 0.9853634834289551
    },
    {
      "answer": "pseudorandom number generators",
      "score": 0.979061484336853
    }
  ],
  "8901": [
    {
      "answer": "hash tables",
      "score": 0.8837461471557617
    },
    {
      "answer": "pseudorandom",
      "score": 0.9923460483551025
    }
  ],
  "8902": [],
  "8903": [
    {
      "answer": "G. H. Hardy",
      "score": 0.9959688186645508
    }
  ],
  "8904": [
    {
      "answer": "1970s",
      "score": 0.9956236481666565
    }
  ],
  "8905": [
    {
      "answer": "hash tables",
      "score": 0.9056648015975952
    },
    {
      "answer": "pseudorandom number generators",
      "score": 0.8728647232055664
    }
  ],
  "8906": [
    {
      "answer": "pseudorandom",
      "score": 0.9855356216430664
    }
  ],
  "8907": [
    {
      "answer": "recurring",
      "score": 0.9871153831481934
    }
  ],
  "8908": [
    {
      "answer": "p \u2212 1",
      "score": 0.9883289337158203
    }
  ],
  "8909": [
    {
      "answer": "(p \u2212 1)! + 1",
      "score": 0.8656173348426819
    }
  ],
  "8910": [
    {
      "answer": "(p \u2212 1)!",
      "score": 0.7076959609985352
    },
    {
      "answer": "(n \u2212 1)!",
      "score": 0.9032413959503174
    }
  ],
  "8911": [
    {
      "answer": "not a prime factor of q",
      "score": 0.9327414035797119
    }
  ],
  "8912": [
    {
      "answer": "recurring",
      "score": 0.9881454706192017
    }
  ],
  "8913": [
    {
      "answer": "p \u2212 1",
      "score": 0.9894480109214783
    }
  ],
  "8914": [
    {
      "answer": "(p \u2212 1)! + 1",
      "score": 0.7243451476097107
    }
  ],
  "8915": [
    {
      "answer": "(n \u2212 1)!",
      "score": 0.8504209518432617
    }
  ],
  "8916": [
    {
      "answer": "not a prime factor of q",
      "score": 0.6462715268135071
    }
  ],
  "8917": [
    {
      "answer": "RSA",
      "score": 0.8278875350952148
    },
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.8091991543769836
    },
    {
      "answer": "RSA",
      "score": 0.5784279108047485
    },
    {
      "answer": "RSA",
      "score": 0.6148715019226074
    },
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.6072731018066406
    }
  ],
  "8918": [
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.9602872133255005
    },
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.8907290697097778
    }
  ],
  "8919": [
    {
      "answer": "512-bit",
      "score": 0.9888706803321838
    }
  ],
  "8920": [
    {
      "answer": "modular",
      "score": 0.9910878539085388
    }
  ],
  "8921": [
    {
      "answer": "1024-bit",
      "score": 0.9926987290382385
    }
  ],
  "8922": [
    {
      "answer": "RSA",
      "score": 0.8234346508979797
    },
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.8053641319274902
    },
    {
      "answer": "RSA",
      "score": 0.5625975728034973
    },
    {
      "answer": "RSA",
      "score": 0.5969191193580627
    },
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.6058189272880554
    }
  ],
  "8923": [
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.9570121765136719
    },
    {
      "answer": "Diffie\u2013Hellman key exchange",
      "score": 0.87690269947052
    }
  ],
  "8924": [
    {
      "answer": "512-bit",
      "score": 0.9876838326454163
    }
  ],
  "8925": [
    {
      "answer": "modular",
      "score": 0.9925854802131653
    }
  ],
  "8926": [
    {
      "answer": "1024-bit",
      "score": 0.9917541742324829
    }
  ],
  "8927": [
    {
      "answer": "cicadas",
      "score": 0.9159761071205139
    }
  ],
  "8928": [
    {
      "answer": "underground",
      "score": 0.9960532188415527
    }
  ],
  "8929": [
    {
      "answer": "17",
      "score": 0.8810557723045349
    }
  ],
  "8930": [
    {
      "answer": "the prime number intervals between emergences make it very difficult for predators to evolve that could specialize as predators on Magicicadas",
      "score": 0.9694271087646484
    }
  ],
  "8931": [
    {
      "answer": "2%",
      "score": 0.9634237289428711
    }
  ],
  "8932": [
    {
      "answer": "cicadas",
      "score": 0.9606531858444214
    }
  ],
  "8933": [
    {
      "answer": "underground",
      "score": 0.9955143332481384
    }
  ],
  "8934": [
    {
      "answer": "17 years",
      "score": 0.7175209522247314
    }
  ],
  "8935": [
    {
      "answer": "the prime number intervals between emergences make it very difficult for predators to evolve that could specialize as predators on Magicicadas",
      "score": 0.975773811340332
    }
  ],
  "8936": [
    {
      "answer": "2%",
      "score": 0.9631003141403198
    }
  ],
  "8937": [
    {
      "answer": "minimality",
      "score": 0.9956403970718384
    }
  ],
  "8938": [
    {
      "answer": "Q",
      "score": 0.7201821804046631
    }
  ],
  "8939": [],
  "8940": [],
  "8941": [
    {
      "answer": "any object can be, essentially uniquely, decomposed into its prime components",
      "score": 0.986318826675415
    }
  ],
  "8942": [
    {
      "answer": "minimality or indecomposability",
      "score": 0.6089927554130554
    },
    {
      "answer": "any object can be, essentially uniquely, decomposed into its prime components",
      "score": 0.7771939635276794
    }
  ],
  "8943": [
    {
      "answer": "Q",
      "score": 0.6368923187255859
    }
  ],
  "8944": [
    {
      "answer": "a knot that is indecomposable in the sense that it cannot be written as the knot sum of two nontrivial knots",
      "score": 0.8726627230644226
    }
  ],
  "8945": [
    {
      "answer": "Any knot can be uniquely expressed as a connected sum of prime knots",
      "score": 0.6749952435493469
    }
  ],
  "8946": [
    {
      "answer": "any object can be, essentially uniquely, decomposed into its prime components",
      "score": 0.9762221574783325
    }
  ],
  "8947": [
    {
      "answer": "commutative ring R",
      "score": 0.9564369916915894
    }
  ],
  "8948": [
    {
      "answer": "prime elements",
      "score": 0.7131762504577637
    },
    {
      "answer": "irreducible elements",
      "score": 0.6709403991699219
    },
    {
      "answer": "prime element",
      "score": 0.6088770627975464
    },
    {
      "answer": "prime elements",
      "score": 0.6139798164367676
    },
    {
      "answer": "irreducible elements",
      "score": 0.7540076971054077
    }
  ],
  "8949": [
    {
      "answer": "prime elements",
      "score": 0.9149792194366455
    },
    {
      "answer": "irreducible elements",
      "score": 0.9323170781135559
    },
    {
      "answer": "prime element",
      "score": 0.6134328842163086
    },
    {
      "answer": "prime elements",
      "score": 0.6030659675598145
    },
    {
      "answer": "irreducible elements",
      "score": 0.8627369403839111
    }
  ],
  "8950": [
    {
      "answer": "neither zero nor a unit",
      "score": 0.7859061360359192
    }
  ],
  "8951": [
    {
      "answer": "not a unit and cannot be written as a product of two ring elements that are not units",
      "score": 0.9853865504264832
    }
  ],
  "8952": [],
  "8953": [
    {
      "answer": "prime elements",
      "score": 0.6934120059013367
    },
    {
      "answer": "irreducible elements",
      "score": 0.6120516061782837
    },
    {
      "answer": "prime element",
      "score": 0.5917064547538757
    },
    {
      "answer": "prime elements",
      "score": 0.6171038150787354
    },
    {
      "answer": "irreducible elements",
      "score": 0.6779677867889404
    }
  ],
  "8954": [
    {
      "answer": "prime elements",
      "score": 0.8950191736221313
    },
    {
      "answer": "irreducible elements",
      "score": 0.9009013772010803
    },
    {
      "answer": "prime element",
      "score": 0.6294495463371277
    },
    {
      "answer": "prime elements",
      "score": 0.6288039684295654
    },
    {
      "answer": "irreducible elements",
      "score": 0.8435772657394409
    }
  ],
  "8955": [
    {
      "answer": "does not have a multiplicative inverse",
      "score": 0.7520760893821716
    }
  ],
  "8956": [
    {
      "answer": "neither zero nor a unit",
      "score": 0.9332348704338074
    },
    {
      "answer": "cannot be written as a product of two ring elements that are not units",
      "score": 0.690647542476654
    }
  ],
  "8957": [
    {
      "answer": "fundamental theorem of arithmetic",
      "score": 0.9928705096244812
    }
  ],
  "8958": [
    {
      "answer": "Gaussian integers Z[i]",
      "score": 0.9462467432022095
    }
  ],
  "8959": [
    {
      "answer": "a + bi",
      "score": 0.9729782342910767
    }
  ],
  "8960": [
    {
      "answer": "arbitrary integers",
      "score": 0.8789814114570618
    }
  ],
  "8961": [
    {
      "answer": "of the form 4k + 3",
      "score": 0.8602310419082642
    }
  ],
  "8962": [
    {
      "answer": "fundamental theorem of arithmetic",
      "score": 0.993086576461792
    }
  ],
  "8963": [
    {
      "answer": "4k + 3",
      "score": 0.9614664912223816
    }
  ],
  "8964": [
    {
      "answer": "4k + 3",
      "score": 0.9537193179130554
    }
  ],
  "8965": [
    {
      "answer": "arbitrary integers",
      "score": 0.8815468549728394
    }
  ],
  "8966": [
    {
      "answer": "of the form 4k + 3",
      "score": 0.8807839155197144
    }
  ],
  "8967": [
    {
      "answer": "ring theory",
      "score": 0.9776695966720581
    }
  ],
  "8968": [
    {
      "answer": "Prime ideals",
      "score": 0.9773999452590942
    },
    {
      "answer": "prime ideal",
      "score": 0.6933587789535522
    },
    {
      "answer": "prime ideals",
      "score": 0.8760377168655396
    }
  ],
  "8969": [
    {
      "answer": "commutative algebra",
      "score": 0.7601585388183594
    },
    {
      "answer": "algebraic",
      "score": 0.9718909859657288
    }
  ],
  "8970": [
    {
      "answer": "fundamental theorem of arithmetic",
      "score": 0.9884105920791626
    }
  ],
  "8971": [
    {
      "answer": "Noetherian",
      "score": 0.9943450689315796
    }
  ],
  "8972": [
    {
      "answer": "ring theory",
      "score": 0.9769675135612488
    }
  ],
  "8973": [
    {
      "answer": "Prime ideals",
      "score": 0.970991849899292
    },
    {
      "answer": "prime ideals",
      "score": 0.8801762461662292
    }
  ],
  "8974": [
    {
      "answer": "commutative algebra",
      "score": 0.569817066192627
    },
    {
      "answer": "algebraic",
      "score": 0.9712896347045898
    }
  ],
  "8975": [
    {
      "answer": "Lasker\u2013Noether theorem",
      "score": 0.9742105603218079
    }
  ],
  "8976": [
    {
      "answer": "Noetherian",
      "score": 0.9882044792175293
    }
  ],
  "8977": [
    {
      "answer": "Prime ideals",
      "score": 0.9950021505355835
    },
    {
      "answer": "prime ideals",
      "score": 0.78797847032547
    },
    {
      "answer": "prime ideals",
      "score": 0.8102292418479919
    }
  ],
  "8978": [
    {
      "answer": "ramification",
      "score": 0.9621837139129639
    }
  ],
  "8979": [
    {
      "answer": "ring of integers",
      "score": 0.944582462310791
    }
  ],
  "8980": [
    {
      "answer": "solvability of quadratic equations",
      "score": 0.9765559434890747
    }
  ],
  "8981": [
    {
      "answer": "Prime ideals",
      "score": 0.9868699312210083
    },
    {
      "answer": "prime ideals",
      "score": 0.8130143880844116
    },
    {
      "answer": "prime ideals",
      "score": 0.8915011882781982
    }
  ],
  "8982": [
    {
      "answer": "ramification",
      "score": 0.9674253463745117
    }
  ],
  "8983": [
    {
      "answer": "ring of integers",
      "score": 0.9071505069732666
    }
  ],
  "8984": [],
  "8985": [
    {
      "answer": "many concepts",
      "score": 0.8089077472686768
    }
  ],
  "8986": [
    {
      "answer": "gets smaller",
      "score": 0.9948979616165161
    }
  ],
  "8987": [
    {
      "answer": "completed (or local) fields",
      "score": 0.921991229057312
    }
  ],
  "8988": [
    {
      "answer": "absolute value",
      "score": 0.8036185503005981
    },
    {
      "answer": "absolute value",
      "score": 0.9809644222259521
    }
  ],
  "8989": [
    {
      "answer": "local-global principle",
      "score": 0.9771205186843872
    }
  ],
  "8990": [
    {
      "answer": "gets smaller",
      "score": 0.9945031404495239
    }
  ],
  "8991": [
    {
      "answer": "completed (or local) fields",
      "score": 0.9581211805343628
    }
  ],
  "8992": [
    {
      "answer": "absolute value",
      "score": 0.7524069547653198
    },
    {
      "answer": "absolute value",
      "score": 0.9664021730422974
    }
  ],
  "8993": [
    {
      "answer": "local-global principle",
      "score": 0.9754325151443481
    }
  ],
  "8994": [
    {
      "answer": "norm",
      "score": 0.9354699850082397
    },
    {
      "answer": "norm",
      "score": 0.71192866563797
    }
  ],
  "8995": [
    {
      "answer": "Olivier Messiaen",
      "score": 0.9952400922775269
    }
  ],
  "8996": [
    {
      "answer": "La Nativit\u00e9 du Seigneur",
      "score": 0.9849019646644592
    },
    {
      "answer": "Quatre \u00e9tudes de rythme",
      "score": 0.8740007877349854
    }
  ],
  "8997": [
    {
      "answer": "La Nativit\u00e9 du Seigneur",
      "score": 0.9604970216751099
    },
    {
      "answer": "Quatre \u00e9tudes de rythme",
      "score": 0.976607084274292
    }
  ],
  "8998": [
    {
      "answer": "third",
      "score": 0.988707423210144
    }
  ],
  "8999": [
    {
      "answer": "movements of nature",
      "score": 0.9886326789855957
    }
  ],
  "9000": [
    {
      "answer": "Olivier Messiaen",
      "score": 0.9952954053878784
    }
  ],
  "9001": [
    {
      "answer": "Neumes rythmiques",
      "score": 0.7357438802719116
    }
  ],
  "9002": [
    {
      "answer": "La Nativit\u00e9 du Seigneur",
      "score": 0.7473049163818359
    },
    {
      "answer": "Quatre \u00e9tudes de rythme",
      "score": 0.8570605516433716
    }
  ],
  "9003": [
    {
      "answer": "third",
      "score": 0.9274085760116577
    }
  ],
  "9004": [
    {
      "answer": "movements of nature",
      "score": 0.9888081550598145
    }
  ],
  "9005": [
    {
      "answer": "North Sea",
      "score": 0.9807800054550171
    }
  ],
  "9006": [
    {
      "answer": "Cologne",
      "score": 0.9863420128822327
    }
  ],
  "9007": [
    {
      "answer": "Danube",
      "score": 0.985366940498352
    }
  ],
  "9008": [
    {
      "answer": "1,230 km",
      "score": 0.9811291694641113
    }
  ],
  "9009": [
    {
      "answer": "Swiss canton of Graub\u00fcnden",
      "score": 0.8688198328018188
    },
    {
      "answer": "Swiss Alps",
      "score": 0.8491062521934509
    },
    {
      "answer": "Rhineland",
      "score": 0.5282350182533264
    },
    {
      "answer": "Netherlands",
      "score": 0.8559548854827881
    }
  ],
  "9010": [
    {
      "answer": "Netherlands",
      "score": 0.9949707388877869
    }
  ],
  "9011": [
    {
      "answer": "1,230 km",
      "score": 0.9811291694641113
    }
  ],
  "9012": [],
  "9013": [
    {
      "answer": "1,230 km",
      "score": 0.9630509614944458
    }
  ],
  "9014": [
    {
      "answer": "Netherlands",
      "score": 0.9957942962646484
    }
  ],
  "9015": [
    {
      "answer": "1,050,000",
      "score": 0.9515768885612488
    }
  ],
  "9016": [
    {
      "answer": "1,230 km",
      "score": 0.979994535446167
    }
  ],
  "9017": [
    {
      "answer": "Gaulish",
      "score": 0.9893760681152344
    }
  ],
  "9018": [
    {
      "answer": "Rhin",
      "score": 0.9726864099502563
    }
  ],
  "9019": [
    {
      "answer": "*R\u012bnaz",
      "score": 0.9540974497795105
    }
  ],
  "9020": [
    {
      "answer": "1st century BC",
      "score": 0.9902700185775757
    }
  ],
  "9021": [
    {
      "answer": "Gaulish name R\u0113nos",
      "score": 0.9664437770843506
    }
  ],
  "9022": [
    {
      "answer": "Rhin",
      "score": 0.9737871885299683
    }
  ],
  "9023": [
    {
      "answer": "*R\u012bnaz",
      "score": 0.9752521514892578
    }
  ],
  "9024": [
    {
      "answer": "Rijn",
      "score": 0.961114227771759
    }
  ],
  "9025": [
    {
      "answer": "Rhijn",
      "score": 0.9703009724617004
    }
  ],
  "9026": [
    {
      "answer": "Gaulish",
      "score": 0.9724519848823547
    }
  ],
  "9027": [
    {
      "answer": "early modern period",
      "score": 0.9521648287773132
    }
  ],
  "9028": [
    {
      "answer": "1st century BC",
      "score": 0.801875114440918
    }
  ],
  "9029": [
    {
      "answer": "early modern period",
      "score": 0.8821510076522827
    }
  ],
  "9030": [
    {
      "answer": "Rhine-kilometers",
      "score": 0.9642266631126404
    }
  ],
  "9031": [
    {
      "answer": "1939",
      "score": 0.9952178001403809
    }
  ],
  "9032": [
    {
      "answer": "Old Rhine Bridge at Constance",
      "score": 0.9492630362510681
    },
    {
      "answer": "Hoek van Holland",
      "score": 0.7325485944747925
    }
  ],
  "9033": [
    {
      "answer": "Hoek van Holland",
      "score": 0.9939996600151062
    }
  ],
  "9034": [
    {
      "answer": "canalisation projects",
      "score": 0.9777239561080933
    }
  ],
  "9035": [
    {
      "answer": "Rhine-kilometers",
      "score": 0.9788379669189453
    }
  ],
  "9036": [
    {
      "answer": "1939",
      "score": 0.9958261847496033
    }
  ],
  "9037": [
    {
      "answer": "Old Rhine Bridge at Constance",
      "score": 0.9109374284744263
    },
    {
      "answer": "Constance",
      "score": 0.5580136179924011
    }
  ],
  "9038": [
    {
      "answer": "Hoek van Holland",
      "score": 0.9964780807495117
    }
  ],
  "9039": [
    {
      "answer": "number of canalisation projects completed in the 19th and 20th century",
      "score": 0.9353291988372803
    }
  ],
  "9040": [
    {
      "answer": "0 km",
      "score": 0.9742244482040405
    }
  ],
  "9041": [
    {
      "answer": "1036.20 km",
      "score": 0.9824051856994629
    }
  ],
  "9042": [
    {
      "answer": "1939",
      "score": 0.9937699437141418
    }
  ],
  "9043": [
    {
      "answer": "1939",
      "score": 0.9427773952484131
    }
  ],
  "9044": [],
  "9045": [
    {
      "answer": "north",
      "score": 0.9935243129730225
    }
  ],
  "9046": [
    {
      "answer": "86 km",
      "score": 0.9809678792953491
    }
  ],
  "9047": [
    {
      "answer": "Rhine Valley",
      "score": 0.9686697721481323
    }
  ],
  "9048": [
    {
      "answer": "Sargans",
      "score": 0.9435621500015259
    }
  ],
  "9049": [
    {
      "answer": "Liechtenstein",
      "score": 0.9840166568756104
    },
    {
      "answer": "Austria",
      "score": 0.5567781925201416
    }
  ],
  "9050": [
    {
      "answer": "Chur",
      "score": 0.9857922196388245
    }
  ],
  "9051": [
    {
      "answer": "86 km",
      "score": 0.9847776889801025
    }
  ],
  "9052": [
    {
      "answer": "599 m",
      "score": 0.9505499601364136
    }
  ],
  "9053": [
    {
      "answer": "Rhine Valley",
      "score": 0.9595884680747986
    }
  ],
  "9054": [
    {
      "answer": "Liechtenstein",
      "score": 0.7756926417350769
    }
  ],
  "9055": [
    {
      "answer": "Chur",
      "score": 0.9763439893722534
    }
  ],
  "9056": [
    {
      "answer": "wide",
      "score": 0.9013871550559998
    }
  ],
  "9057": [
    {
      "answer": "Sargans",
      "score": 0.8803259134292603
    }
  ],
  "9058": [
    {
      "answer": "86 km",
      "score": 0.9450128078460693
    }
  ],
  "9059": [
    {
      "answer": "599 m",
      "score": 0.9550766944885254
    }
  ],
  "9060": [
    {
      "answer": "Lake Constance",
      "score": 0.9963279962539673
    }
  ],
  "9061": [
    {
      "answer": "Alter Rhein",
      "score": 0.9828898906707764
    }
  ],
  "9062": [
    {
      "answer": "modern canalized section",
      "score": 0.9840185046195984
    }
  ],
  "9063": [
    {
      "answer": "Isel",
      "score": 0.9654019474983215
    }
  ],
  "9064": [
    {
      "answer": "Esel",
      "score": 0.8931888341903687
    }
  ],
  "9065": [
    {
      "answer": "Lake Constance",
      "score": 0.994155764579773
    }
  ],
  "9066": [
    {
      "answer": "modern canalized section",
      "score": 0.991561770439148
    }
  ],
  "9067": [
    {
      "answer": "Alter Rhein",
      "score": 0.982528805732727
    }
  ],
  "9068": [
    {
      "answer": "inland delta",
      "score": 0.7640130519866943
    }
  ],
  "9069": [
    {
      "answer": "Isel",
      "score": 0.9514346122741699
    }
  ],
  "9070": [
    {
      "answer": "The mouth of the Rhine",
      "score": 0.9547005891799927
    }
  ],
  "9071": [
    {
      "answer": "Alter Rhein",
      "score": 0.899856448173523
    }
  ],
  "9072": [
    {
      "answer": "Alter Rhein",
      "score": 0.797308087348938
    }
  ],
  "9073": [
    {
      "answer": "Esel",
      "score": 0.8482146859169006
    }
  ],
  "9074": [
    {
      "answer": "Donkey",
      "score": 0.6377872824668884
    }
  ],
  "9075": [
    {
      "answer": "Diepoldsau",
      "score": 0.9923991560935974
    }
  ],
  "9076": [
    {
      "answer": "Fu\u00dfach",
      "score": 0.9833928942680359
    }
  ],
  "9077": [
    {
      "answer": "constant flooding and strong sedimentation in the western Rhine Delta",
      "score": 0.9359329342842102
    }
  ],
  "9078": [
    {
      "answer": "flows parallel to the canalized Rhine into the lake",
      "score": 0.7966451644897461
    }
  ],
  "9079": [
    {
      "answer": "silt up the lake",
      "score": 0.9651285409927368
    }
  ],
  "9080": [
    {
      "answer": "Fu\u00dfach",
      "score": 0.9786392450332642
    }
  ],
  "9081": [
    {
      "answer": "Diepoldsau",
      "score": 0.9898080229759216
    }
  ],
  "9082": [
    {
      "answer": "to counteract the constant flooding and strong sedimentation in the western Rhine Delta",
      "score": 0.9793693423271179
    }
  ],
  "9083": [
    {
      "answer": "Dornbirner Ach",
      "score": 0.980404257774353
    }
  ],
  "9084": [
    {
      "answer": "continuous input of sediment",
      "score": 0.9799066781997681
    }
  ],
  "9085": [
    {
      "answer": "Diepoldsau",
      "score": 0.9466152191162109
    },
    {
      "answer": "Fu\u00dfach",
      "score": 0.6948579549789429
    }
  ],
  "9086": [
    {
      "answer": "Diepoldsau",
      "score": 0.8972204327583313
    },
    {
      "answer": "Fu\u00dfach",
      "score": 0.9458023905754089
    }
  ],
  "9087": [
    {
      "answer": "Dornbirner Ach",
      "score": 0.9849236607551575
    }
  ],
  "9088": [
    {
      "answer": "to counteract the constant flooding and strong sedimentation in the western Rhine Delta",
      "score": 0.9799827337265015
    }
  ],
  "9089": [
    {
      "answer": "Lake Tuggenersee",
      "score": 0.9689891338348389
    }
  ],
  "9090": [
    {
      "answer": "three",
      "score": 0.9875505566596985
    }
  ],
  "9091": [
    {
      "answer": "Seerhein",
      "score": 0.9789940118789673
    }
  ],
  "9092": [
    {
      "answer": "upper lake",
      "score": 0.9886196851730347
    }
  ],
  "9093": [
    {
      "answer": "lower lake",
      "score": 0.9913440942764282
    }
  ],
  "9094": [
    {
      "answer": "Swiss-Austrian",
      "score": 0.9958173632621765
    }
  ],
  "9095": [
    {
      "answer": "three",
      "score": 0.9875505566596985
    }
  ],
  "9096": [
    {
      "answer": "Austria",
      "score": 0.9448641538619995
    }
  ],
  "9097": [
    {
      "answer": "Alps",
      "score": 0.9932693839073181
    }
  ],
  "9098": [
    {
      "answer": "Swiss-Austrian border",
      "score": 0.8938416242599487
    }
  ],
  "9099": [],
  "9100": [
    {
      "answer": "three",
      "score": 0.9897856712341309
    }
  ],
  "9101": [
    {
      "answer": "Swiss-Austrian border",
      "score": 0.8750908374786377
    }
  ],
  "9102": [
    {
      "answer": "Swiss-Austrian border",
      "score": 0.9050118923187256
    }
  ],
  "9103": [
    {
      "answer": "Swiss-Austrian",
      "score": 0.9936175346374512
    }
  ],
  "9104": [
    {
      "answer": "three",
      "score": 0.9918973445892334
    }
  ],
  "9105": [
    {
      "answer": "the greater density of cold water",
      "score": 0.982069194316864
    }
  ],
  "9106": [
    {
      "answer": "Rheinbrech",
      "score": 0.9329357147216797
    }
  ],
  "9107": [
    {
      "answer": "Lindau",
      "score": 0.9815143942832947
    }
  ],
  "9108": [
    {
      "answer": "Lake \u00dcberlingen",
      "score": 0.9514424800872803
    }
  ],
  "9109": [
    {
      "answer": "entire length of the lake",
      "score": 0.8348596692085266
    }
  ],
  "9110": [
    {
      "answer": "Rheinbrech",
      "score": 0.8682180047035217
    },
    {
      "answer": "northern (German) shore of the lake, off the island of Lindau",
      "score": 0.7657868266105652
    }
  ],
  "9111": [
    {
      "answer": "Lindau",
      "score": 0.9851780533790588
    }
  ],
  "9112": [
    {
      "answer": "Lake \u00dcberlingen",
      "score": 0.9860457181930542
    }
  ],
  "9113": [
    {
      "answer": "Rhine Gutter",
      "score": 0.9917293787002563
    }
  ],
  "9114": [
    {
      "answer": "water level",
      "score": 0.9946850538253784
    }
  ],
  "9115": [
    {
      "answer": "Rhine water",
      "score": 0.9416078329086304
    },
    {
      "answer": "Rhine water",
      "score": 0.7594109773635864
    }
  ],
  "9116": [
    {
      "answer": "Seerhein",
      "score": 0.6982027292251587
    }
  ],
  "9117": [
    {
      "answer": "Rhine water",
      "score": 0.7416877150535583
    },
    {
      "answer": "Rhine water",
      "score": 0.9602874517440796
    }
  ],
  "9118": [
    {
      "answer": "Lake \u00dcberlingen",
      "score": 0.9947869777679443
    }
  ],
  "9119": [
    {
      "answer": "Rhine",
      "score": 0.7961228489875793
    },
    {
      "answer": "Rhine",
      "score": 0.8158301711082458
    }
  ],
  "9120": [
    {
      "answer": "westward",
      "score": 0.9965509176254272
    }
  ],
  "9121": [
    {
      "answer": "Aare",
      "score": 0.9835367798805237
    }
  ],
  "9122": [
    {
      "answer": "1,000 m3/s",
      "score": 0.9849060773849487
    }
  ],
  "9123": [
    {
      "answer": "Finsteraarhorn",
      "score": 0.9918960928916931
    }
  ],
  "9124": [
    {
      "answer": "Basel",
      "score": 0.991196870803833
    }
  ],
  "9125": [
    {
      "answer": "westward",
      "score": 0.995235025882721
    }
  ],
  "9126": [
    {
      "answer": "Aare",
      "score": 0.9856833815574646
    }
  ],
  "9127": [
    {
      "answer": "1,000 m3/s",
      "score": 0.9864053726196289
    }
  ],
  "9128": [
    {
      "answer": "Finsteraarhorn",
      "score": 0.9817821979522705
    }
  ],
  "9129": [
    {
      "answer": "German-Swiss",
      "score": 0.9939903020858765
    }
  ],
  "9130": [
    {
      "answer": "Aare",
      "score": 0.9803121089935303
    }
  ],
  "9131": [
    {
      "answer": "1,000 m3/s",
      "score": 0.9853019714355469
    }
  ],
  "9132": [
    {
      "answer": "Lake Constance",
      "score": 0.9216291904449463
    },
    {
      "answer": "Lake Constance",
      "score": 0.9099900722503662
    }
  ],
  "9133": [
    {
      "answer": "Lake Constance",
      "score": 0.9788332581520081
    },
    {
      "answer": "Lake Constance",
      "score": 0.915333092212677
    }
  ],
  "9134": [
    {
      "answer": "Finsteraarhorn",
      "score": 0.5672104358673096
    }
  ],
  "9135": [
    {
      "answer": "Basel",
      "score": 0.9874978065490723
    }
  ],
  "9136": [
    {
      "answer": "Rhine knee",
      "score": 0.9849342703819275
    }
  ],
  "9137": [
    {
      "answer": "the Central Bridge",
      "score": 0.9687944650650024
    }
  ],
  "9138": [
    {
      "answer": "300 km",
      "score": 0.9890954494476318
    }
  ],
  "9139": [
    {
      "answer": "40 km",
      "score": 0.9838384985923767
    }
  ],
  "9140": [
    {
      "answer": "Basel",
      "score": 0.9877611398696899
    }
  ],
  "9141": [
    {
      "answer": "Rhine knee",
      "score": 0.9877474308013916
    }
  ],
  "9142": [
    {
      "answer": "North",
      "score": 0.9931129813194275
    },
    {
      "answer": "North",
      "score": 0.8078206777572632
    }
  ],
  "9143": [
    {
      "answer": "High Rhine",
      "score": 0.9938254356384277
    }
  ],
  "9144": [
    {
      "answer": "Central Bridge",
      "score": 0.9963775277137756
    }
  ],
  "9145": [
    {
      "answer": "Rhine knee",
      "score": 0.9792079329490662
    }
  ],
  "9146": [
    {
      "answer": "Rhine knee",
      "score": 0.985946536064148
    }
  ],
  "9147": [],
  "9148": [],
  "9149": [
    {
      "answer": "40 km",
      "score": 0.9687148928642273
    }
  ],
  "9150": [
    {
      "answer": "19th",
      "score": 0.9945681095123291
    }
  ],
  "9151": [
    {
      "answer": "The rate of flow was increased",
      "score": 0.864251971244812
    }
  ],
  "9152": [
    {
      "answer": "the ground water level fell",
      "score": 0.8778833746910095
    }
  ],
  "9153": [
    {
      "answer": "Grand Canal d'Alsace",
      "score": 0.980856716632843
    }
  ],
  "9154": [],
  "9155": [
    {
      "answer": "Upper Rhine",
      "score": 0.975285530090332
    }
  ],
  "9156": [
    {
      "answer": "19th Century",
      "score": 0.9804620742797852
    }
  ],
  "9157": [
    {
      "answer": "The rate of flow was increased",
      "score": 0.8623635172843933
    }
  ],
  "9158": [
    {
      "answer": "fell",
      "score": 0.9754716157913208
    }
  ],
  "9159": [
    {
      "answer": "Grand Canal d'Alsace",
      "score": 0.9846059679985046
    }
  ],
  "9160": [
    {
      "answer": "19th",
      "score": 0.9877298474311829
    }
  ],
  "9161": [
    {
      "answer": "Rhine straightening program",
      "score": 0.9914250373840332
    }
  ],
  "9162": [
    {
      "answer": "Rhine straightening program",
      "score": 0.9844526052474976
    }
  ],
  "9163": [
    {
      "answer": "19th",
      "score": 0.9952091574668884
    }
  ],
  "9164": [
    {
      "answer": "19th",
      "score": 0.9876759052276611
    }
  ],
  "9165": [
    {
      "answer": "Rhine",
      "score": 0.9737393856048584
    },
    {
      "answer": "Rhine",
      "score": 0.7630261778831482
    },
    {
      "answer": "Rhine",
      "score": 0.8157371878623962
    },
    {
      "answer": "Rhine",
      "score": 0.8121960759162903
    },
    {
      "answer": "Rhine",
      "score": 0.8213549852371216
    }
  ],
  "9166": [
    {
      "answer": "Germany",
      "score": 0.6909008622169495
    }
  ],
  "9167": [
    {
      "answer": "300 m3/s",
      "score": 0.9710007905960083
    }
  ],
  "9168": [
    {
      "answer": "Moselle",
      "score": 0.9396718144416809
    },
    {
      "answer": "Moselle",
      "score": 0.8956857919692993
    },
    {
      "answer": "Moselle",
      "score": 0.8633443117141724
    }
  ],
  "9169": [
    {
      "answer": "400 m",
      "score": 0.930022120475769
    }
  ],
  "9170": [
    {
      "answer": "Germany",
      "score": 0.9915875792503357
    }
  ],
  "9171": [
    {
      "answer": "Germany",
      "score": 0.9882057905197144
    }
  ],
  "9172": [
    {
      "answer": "Moselle",
      "score": 0.9904402494430542
    },
    {
      "answer": "Moselle",
      "score": 0.9092976450920105
    },
    {
      "answer": "Moselle",
      "score": 0.9282655119895935
    }
  ],
  "9173": [
    {
      "answer": "France",
      "score": 0.8540971279144287
    }
  ],
  "9174": [
    {
      "answer": "2,290 m3/s",
      "score": 0.9749730825424194
    }
  ],
  "9175": [
    {
      "answer": "Rhine",
      "score": 0.5375996232032776
    }
  ],
  "9176": [
    {
      "answer": "300 m3/s",
      "score": 0.9699146747589111
    }
  ],
  "9177": [
    {
      "answer": "400 m",
      "score": 0.8957871198654175
    }
  ],
  "9178": [
    {
      "answer": "2,290 m3/s",
      "score": 0.915148138999939
    }
  ],
  "9179": [
    {
      "answer": "400 m",
      "score": 0.9245685935020447
    }
  ],
  "9180": [
    {
      "answer": "Middle Rhine",
      "score": 0.987783670425415
    }
  ],
  "9181": [
    {
      "answer": "Rhine Gorge",
      "score": 0.9758341312408447
    }
  ],
  "9182": [
    {
      "answer": "erosion",
      "score": 0.9900464415550232
    }
  ],
  "9183": [
    {
      "answer": "the Romantic Rhine",
      "score": 0.9371594190597534
    }
  ],
  "9184": [
    {
      "answer": "Middle Rhine",
      "score": 0.9871208071708679
    }
  ],
  "9185": [
    {
      "answer": "Rhine Gorge",
      "score": 0.9855010509490967
    }
  ],
  "9186": [],
  "9187": [
    {
      "answer": "Romantic Rhine",
      "score": 0.9845067262649536
    }
  ],
  "9188": [
    {
      "answer": "2002",
      "score": 0.99357670545578
    }
  ],
  "9189": [],
  "9190": [
    {
      "answer": "Rhine Gorge",
      "score": 0.985609769821167
    }
  ],
  "9191": [],
  "9192": [
    {
      "answer": "Middle Rhine",
      "score": 0.9801058173179626
    }
  ],
  "9193": [
    {
      "answer": "industry",
      "score": 0.9713453054428101
    },
    {
      "answer": "industry",
      "score": 0.7776630520820618
    },
    {
      "answer": "industry",
      "score": 0.7348513007164001
    }
  ],
  "9194": [
    {
      "answer": "Lower Rhine",
      "score": 0.9815995693206787
    }
  ],
  "9195": [
    {
      "answer": "Duisburg",
      "score": 0.8270546197891235
    },
    {
      "answer": "Duisburg",
      "score": 0.9829217195510864
    },
    {
      "answer": "Duisburg",
      "score": 0.7934260964393616
    }
  ],
  "9196": [
    {
      "answer": "Ruhr",
      "score": 0.9825155735015869
    },
    {
      "answer": "Ruhr",
      "score": 0.8789103627204895
    },
    {
      "answer": "Ruhr",
      "score": 0.6389221549034119
    }
  ],
  "9197": [
    {
      "answer": "drinking water",
      "score": 0.9650893211364746
    }
  ],
  "9198": [
    {
      "answer": "water pollution",
      "score": 0.9774907827377319
    }
  ],
  "9199": [
    {
      "answer": "Lower Rhine",
      "score": 0.9916816353797913
    }
  ],
  "9200": [
    {
      "answer": "Switzerland",
      "score": 0.9922520518302917
    }
  ],
  "9201": [
    {
      "answer": "Duisburg",
      "score": 0.929174542427063
    },
    {
      "answer": "Duisburg",
      "score": 0.9755363464355469
    },
    {
      "answer": "Duisburg",
      "score": 0.8586574792861938
    }
  ],
  "9202": [
    {
      "answer": "Ruhr",
      "score": 0.9850226044654846
    },
    {
      "answer": "Ruhr",
      "score": 0.9053239822387695
    },
    {
      "answer": "Ruhr",
      "score": 0.7120860815048218
    }
  ],
  "9203": [
    {
      "answer": "industry",
      "score": 0.9708343744277954
    },
    {
      "answer": "industry",
      "score": 0.7239947319030762
    },
    {
      "answer": "industry",
      "score": 0.6178829073905945
    }
  ],
  "9204": [
    {
      "answer": "Lower Rhine",
      "score": 0.8982894420623779
    }
  ],
  "9205": [
    {
      "answer": "Duisburg",
      "score": 0.7836394309997559
    },
    {
      "answer": "Duisburg",
      "score": 0.9760001301765442
    },
    {
      "answer": "Duisburg",
      "score": 0.7657806873321533
    }
  ],
  "9206": [
    {
      "answer": "Lower Rhine",
      "score": 0.6027258634567261
    },
    {
      "answer": "Ruhr",
      "score": 0.6893466114997864
    }
  ],
  "9207": [
    {
      "answer": "Emscher",
      "score": 0.9625832438468933
    }
  ],
  "9208": [
    {
      "answer": "tourism",
      "score": 0.9864422082901001
    }
  ],
  "9209": [
    {
      "answer": "R\u00fcdesheim am Rhein",
      "score": 0.946556568145752
    }
  ],
  "9210": [
    {
      "answer": "Lorelei",
      "score": 0.9842473268508911
    }
  ],
  "9211": [
    {
      "answer": "Middle Rhine Valley",
      "score": 0.9912614822387695
    }
  ],
  "9212": [
    {
      "answer": "tourism",
      "score": 0.9907817244529724
    }
  ],
  "9213": [
    {
      "answer": "UNESCO World Heritage Site",
      "score": 0.9896343946456909
    }
  ],
  "9214": [
    {
      "answer": "R\u00fcdesheim am Rhein",
      "score": 0.9738285541534424
    }
  ],
  "9215": [
    {
      "answer": "Lorelei",
      "score": 0.9897816181182861
    }
  ],
  "9216": [
    {
      "answer": "Sankt Goarshausen",
      "score": 0.9803408980369568
    }
  ],
  "9217": [
    {
      "answer": "viniculture",
      "score": 0.9494970440864563
    },
    {
      "answer": "tourism",
      "score": 0.9714316725730896
    }
  ],
  "9218": [
    {
      "answer": "Rhine Gorge",
      "score": 0.8416990041732788
    }
  ],
  "9219": [
    {
      "answer": "Rhine Gorge",
      "score": 0.8809366226196289
    }
  ],
  "9220": [
    {
      "answer": "Lorelei",
      "score": 0.9629625082015991
    }
  ],
  "9221": [
    {
      "answer": "narrow river banks",
      "score": 0.8608909845352173
    },
    {
      "answer": "Middle Rhine Valley",
      "score": 0.7211639285087585
    }
  ],
  "9222": [
    {
      "answer": "Duisburg",
      "score": 0.9671438336372375
    },
    {
      "answer": "Duisburg",
      "score": 0.6572372317314148
    },
    {
      "answer": "Duisburg",
      "score": 0.6327304244041443
    }
  ],
  "9223": [
    {
      "answer": "Wesel-Datteln Canal",
      "score": 0.9198880195617676
    }
  ],
  "9224": [
    {
      "answer": "Lippe",
      "score": 0.9860922694206238
    }
  ],
  "9225": [
    {
      "answer": "Emmerich Rhine Bridge",
      "score": 0.9932876825332642
    }
  ],
  "9226": [
    {
      "answer": "400 m",
      "score": 0.9914155006408691
    }
  ],
  "9227": [
    {
      "answer": "Lower Rhine",
      "score": 0.9703745245933533
    }
  ],
  "9228": [
    {
      "answer": "Rhine-Ruhr",
      "score": 0.9905697107315063
    }
  ],
  "9229": [
    {
      "answer": "Duisport",
      "score": 0.9914947748184204
    }
  ],
  "9230": [
    {
      "answer": "Emmerich Rhine Bridge",
      "score": 0.989818274974823
    }
  ],
  "9231": [
    {
      "answer": "400 m",
      "score": 0.9954317808151245
    }
  ],
  "9232": [
    {
      "answer": "North Rhine-Westphalia",
      "score": 0.9193200469017029
    }
  ],
  "9233": [
    {
      "answer": "Cologne, D\u00fcsseldorf and Ruhr area",
      "score": 0.8257777094841003
    }
  ],
  "9234": [
    {
      "answer": "Duisburg",
      "score": 0.6784552335739136
    },
    {
      "answer": "Duisport",
      "score": 0.5343985557556152
    }
  ],
  "9235": [
    {
      "answer": "Emmerich Rhine Bridge",
      "score": 0.9742258787155151
    }
  ],
  "9236": [
    {
      "answer": "400 m",
      "score": 0.9950908422470093
    }
  ],
  "9237": [
    {
      "answer": "Rijn",
      "score": 0.9789536595344543
    }
  ],
  "9238": [
    {
      "answer": "Meuse",
      "score": 0.9914973378181458
    }
  ],
  "9239": [
    {
      "answer": "Two thirds",
      "score": 0.9864636659622192
    }
  ],
  "9240": [
    {
      "answer": "west",
      "score": 0.9950974583625793
    }
  ],
  "9241": [
    {
      "answer": "North Sea",
      "score": 0.9607691764831543
    },
    {
      "answer": "North Sea",
      "score": 0.8115425109863281
    }
  ],
  "9242": [
    {
      "answer": "Meuse",
      "score": 0.9916900396347046
    }
  ],
  "9243": [
    {
      "answer": "Oude Maas",
      "score": 0.7974650859832764
    }
  ],
  "9244": [
    {
      "answer": "Two thirds",
      "score": 0.9920186996459961
    }
  ],
  "9245": [
    {
      "answer": "Waal",
      "score": 0.8699417114257812
    },
    {
      "answer": "Merwede and Nieuwe Merwede",
      "score": 0.7639899849891663
    }
  ],
  "9246": [
    {
      "answer": "North Sea",
      "score": 0.9918416142463684
    },
    {
      "answer": "North Sea",
      "score": 0.9868471026420593
    }
  ],
  "9247": [
    {
      "answer": "Oude Maas",
      "score": 0.7596827745437622
    }
  ],
  "9248": [
    {
      "answer": "Pannerdens Kanaal",
      "score": 0.9749394655227661
    }
  ],
  "9249": [],
  "9250": [
    {
      "answer": "Lek",
      "score": 0.9901268482208252
    }
  ],
  "9251": [
    {
      "answer": "Wijk bij Duurstede",
      "score": 0.9283167123794556
    },
    {
      "answer": "Noord River",
      "score": 0.5478963851928711
    }
  ],
  "9252": [
    {
      "answer": "Pannerdens Kanaal",
      "score": 0.9838977456092834
    }
  ],
  "9253": [],
  "9254": [
    {
      "answer": "one ninth",
      "score": 0.9897018671035767
    }
  ],
  "9255": [
    {
      "answer": "Lek",
      "score": 0.9877408146858215
    }
  ],
  "9256": [
    {
      "answer": "Wijk bij Duurstede",
      "score": 0.9970362186431885
    }
  ],
  "9257": [
    {
      "answer": "The other third",
      "score": 0.7973846793174744
    }
  ],
  "9258": [
    {
      "answer": "Nieuwe Maas",
      "score": 0.843597948551178
    },
    {
      "answer": "North Sea",
      "score": 0.9145407676696777
    }
  ],
  "9259": [
    {
      "answer": "Wijk bij Duurstede",
      "score": 0.9923810958862305
    }
  ],
  "9260": [
    {
      "answer": "two ninths",
      "score": 0.6253108978271484
    }
  ],
  "9261": [
    {
      "answer": "Lek",
      "score": 0.9574012160301208
    }
  ],
  "9262": [
    {
      "answer": "Kromme Rijn",
      "score": 0.860575795173645
    },
    {
      "answer": "Leidse Rijn",
      "score": 0.5412713885307312
    }
  ],
  "9263": [
    {
      "answer": "draining the surrounding land and polders",
      "score": 0.9926756620407104
    }
  ],
  "9264": [
    {
      "answer": "Kromme Rijn",
      "score": 0.9614404439926147
    },
    {
      "answer": "Oude Rijn",
      "score": 0.6129579544067383
    }
  ],
  "9265": [
    {
      "answer": "Kromme Rijn",
      "score": 0.8023071885108948
    },
    {
      "answer": "Leidse Rijn",
      "score": 0.7478387355804443
    },
    {
      "answer": "Oude Rijn",
      "score": 0.8384803533554077
    }
  ],
  "9266": [
    {
      "answer": "Oude Rijn",
      "score": 0.9844943284988403
    }
  ],
  "9267": [
    {
      "answer": "Rijn",
      "score": 0.9018726348876953
    },
    {
      "answer": "Rijn",
      "score": 0.7988033890724182
    },
    {
      "answer": "Rhine",
      "score": 0.638389527797699
    },
    {
      "answer": "Rijn",
      "score": 0.8115547299385071
    },
    {
      "answer": "Rhine",
      "score": 0.5341130495071411
    },
    {
      "answer": "Rijn",
      "score": 0.7821372151374817
    },
    {
      "answer": "Rhine",
      "score": 0.6600531339645386
    }
  ],
  "9268": [
    {
      "answer": "Leidse Rijn",
      "score": 0.907199501991272
    },
    {
      "answer": "Oude Rijn",
      "score": 0.9283772706985474
    }
  ],
  "9269": [
    {
      "answer": "Oude Rijn",
      "score": 0.9075313806533813
    }
  ],
  "9270": [
    {
      "answer": "Channel River",
      "score": 0.9958444833755493
    }
  ],
  "9271": [
    {
      "answer": "ice ages",
      "score": 0.9733249545097351
    }
  ],
  "9272": [
    {
      "answer": "Rhine-Meuse Delta",
      "score": 0.6755135655403137
    },
    {
      "answer": "Rhine-Meuse delta",
      "score": 0.5751253962516785
    }
  ],
  "9273": [
    {
      "answer": "Millingen aan de Rijn",
      "score": 0.9955359697341919
    }
  ],
  "9274": [
    {
      "answer": "Rhine Delta",
      "score": 0.9503340721130371
    }
  ],
  "9275": [
    {
      "answer": "Rhine-Meuse Delta",
      "score": 0.8461785316467285
    },
    {
      "answer": "Rhine-Meuse delta",
      "score": 0.5315459966659546
    }
  ],
  "9276": [
    {
      "answer": "Scheldt",
      "score": 0.6008450388908386
    },
    {
      "answer": "Scheldt",
      "score": 0.748253583908081
    }
  ],
  "9277": [
    {
      "answer": "Rhine",
      "score": 0.645950198173523
    },
    {
      "answer": "Rhine",
      "score": 0.5850828886032104
    },
    {
      "answer": "Rhine",
      "score": 0.5807576775550842
    },
    {
      "answer": "Rhine",
      "score": 0.6583195328712463
    },
    {
      "answer": "Rhine",
      "score": 0.5425453782081604
    }
  ],
  "9278": [
    {
      "answer": "Rhine-Meuse delta",
      "score": 0.7159690856933594
    },
    {
      "answer": "Rhine\u2013Meuse\u2013Scheldt delta",
      "score": 0.9015012979507446
    }
  ],
  "9279": [
    {
      "answer": "Scheldt",
      "score": 0.6680047512054443
    },
    {
      "answer": "Scheldt",
      "score": 0.9716111421585083
    }
  ],
  "9280": [
    {
      "answer": "Waal and Pannerdens Kanaal",
      "score": 0.5562429428100586
    },
    {
      "answer": "Nederrijn",
      "score": 0.8835061192512512
    },
    {
      "answer": "Nederrijn",
      "score": 0.729889988899231
    },
    {
      "answer": "Nederrijn",
      "score": 0.6184031963348389
    }
  ],
  "9281": [
    {
      "answer": "three",
      "score": 0.9897217154502869
    },
    {
      "answer": "Three",
      "score": 0.7690249681472778
    }
  ],
  "9282": [
    {
      "answer": "Waal",
      "score": 0.744115948677063
    },
    {
      "answer": "Waal",
      "score": 0.8750342130661011
    }
  ],
  "9283": [
    {
      "answer": "the Rip",
      "score": 0.8965329527854919
    }
  ],
  "9284": [
    {
      "answer": "Old Meuse",
      "score": 0.9907643795013428
    }
  ],
  "9285": [
    {
      "answer": "Lake IJsselmeer",
      "score": 0.9943734407424927
    }
  ],
  "9286": [
    {
      "answer": "Noord",
      "score": 0.7814546823501587
    }
  ],
  "9287": [
    {
      "answer": "IJssel",
      "score": 0.5525845885276794
    },
    {
      "answer": "IJssel",
      "score": 0.8821146488189697
    },
    {
      "answer": "IJsselmeer",
      "score": 0.5677013993263245
    }
  ],
  "9288": [
    {
      "answer": "three",
      "score": 0.7718979716300964
    },
    {
      "answer": "Three",
      "score": 0.9770943522453308
    }
  ],
  "9289": [
    {
      "answer": "St. Elizabeth's flood",
      "score": 0.9521159529685974
    }
  ],
  "9290": [
    {
      "answer": "1421",
      "score": 0.9783610105514526
    },
    {
      "answer": "1421",
      "score": 0.8765262961387634
    }
  ],
  "9291": [
    {
      "answer": "North Sea",
      "score": 0.9888753890991211
    }
  ],
  "9292": [
    {
      "answer": "archipelago-like estuary",
      "score": 0.9898356199264526
    }
  ],
  "9293": [
    {
      "answer": "1904",
      "score": 0.9843612909317017
    }
  ],
  "9294": [
    {
      "answer": "1421",
      "score": 0.7087597846984863
    },
    {
      "answer": "1904",
      "score": 0.9664272665977478
    }
  ],
  "9295": [
    {
      "answer": "1421",
      "score": 0.9801589250564575
    },
    {
      "answer": "1421",
      "score": 0.9262540936470032
    }
  ],
  "9296": [
    {
      "answer": "1421",
      "score": 0.9785090088844299
    },
    {
      "answer": "1421",
      "score": 0.8851296901702881
    }
  ],
  "9297": [
    {
      "answer": "Amer",
      "score": 0.9667062759399414
    }
  ],
  "9298": [
    {
      "answer": "1421",
      "score": 0.8346863389015198
    },
    {
      "answer": "1421",
      "score": 0.935257613658905
    }
  ],
  "9299": [
    {
      "answer": "dammed",
      "score": 0.9894960522651672
    }
  ],
  "9300": [
    {
      "answer": "drainage channels for the numerous polders",
      "score": 0.9608994722366333
    }
  ],
  "9301": [
    {
      "answer": "The construction of Delta Works",
      "score": 0.9885810017585754
    }
  ],
  "9302": [
    {
      "answer": "second half of the 20th Century",
      "score": 0.9822012186050415
    }
  ],
  "9303": [
    {
      "answer": "smaller rivers and streams",
      "score": 0.7092934250831604
    }
  ],
  "9304": [
    {
      "answer": "The construction of Delta Works",
      "score": 0.9839739203453064
    }
  ],
  "9305": [
    {
      "answer": "20th",
      "score": 0.9880417585372925
    }
  ],
  "9306": [
    {
      "answer": "Rhine",
      "score": 0.9779948592185974
    }
  ],
  "9307": [
    {
      "answer": "tidal",
      "score": 0.9938929080963135
    }
  ],
  "9308": [
    {
      "answer": "tidal currents",
      "score": 0.9798998832702637
    },
    {
      "answer": "tidal currents",
      "score": 0.7318932414054871
    }
  ],
  "9309": [
    {
      "answer": "tear huge areas of land into the sea",
      "score": 0.9509044289588928
    }
  ],
  "9310": [
    {
      "answer": "Zaltbommel",
      "score": 0.9933413863182068
    }
  ],
  "9311": [
    {
      "answer": "Rhine-Meuse Delta",
      "score": 0.9373133182525635
    }
  ],
  "9312": [],
  "9313": [
    {
      "answer": "tear huge areas of land into the sea",
      "score": 0.9863008260726929
    }
  ],
  "9314": [],
  "9315": [
    {
      "answer": "Tethys Ocean",
      "score": 0.8368743658065796
    },
    {
      "answer": "Tethys sea",
      "score": 0.6392132043838501
    }
  ],
  "9316": [
    {
      "answer": "Triassic Period",
      "score": 0.963001012802124
    }
  ],
  "9317": [
    {
      "answer": "Jurassic Period",
      "score": 0.9705116152763367
    }
  ],
  "9318": [
    {
      "answer": "Mediterranean geography",
      "score": 0.8947052955627441
    }
  ],
  "9319": [
    {
      "answer": "Iberia",
      "score": 0.9792020916938782
    }
  ],
  "9320": [
    {
      "answer": "Jurassic Period",
      "score": 0.8869490027427673
    }
  ],
  "9321": [
    {
      "answer": "Triassic Period",
      "score": 0.9671379327774048
    }
  ],
  "9322": [
    {
      "answer": "Jurassic Period",
      "score": 0.6268666386604309
    }
  ],
  "9323": [
    {
      "answer": "Triassic Period",
      "score": 0.9703554511070251
    }
  ],
  "9324": [
    {
      "answer": "240 MBP",
      "score": 0.9642337560653687
    },
    {
      "answer": "220 MBP",
      "score": 0.9422515630722046
    }
  ],
  "9325": [
    {
      "answer": "Upper Rhine Graben",
      "score": 0.9596753120422363
    },
    {
      "answer": "Lower Rhine Embayment",
      "score": 0.763290524482727
    },
    {
      "answer": "Upper Rhine Graben",
      "score": 0.8294425010681152
    }
  ],
  "9326": [
    {
      "answer": "Upper Rhine Graben",
      "score": 0.9684062004089355
    },
    {
      "answer": "Lower Rhine Embayment",
      "score": 0.6832942366600037
    },
    {
      "answer": "Upper Rhine Graben",
      "score": 0.6949118971824646
    }
  ],
  "9327": [
    {
      "answer": "Miocene",
      "score": 0.9872883558273315
    }
  ],
  "9328": [
    {
      "answer": "Rhone",
      "score": 0.9524405598640442
    },
    {
      "answer": "Danube",
      "score": 0.9603614211082458
    }
  ],
  "9329": [
    {
      "answer": "the watersheds of the Rhone and Danube",
      "score": 0.9121700525283813
    }
  ],
  "9330": [
    {
      "answer": "Upper Rhine Graben",
      "score": 0.6504857540130615
    },
    {
      "answer": "Upper Rhine Graben",
      "score": 0.9737042188644409
    }
  ],
  "9331": [
    {
      "answer": "N\u2013S rift system",
      "score": 0.967573344707489
    }
  ],
  "9332": [
    {
      "answer": "Miocene",
      "score": 0.9308851361274719
    }
  ],
  "9333": [
    {
      "answer": "stream capture",
      "score": 0.9775022864341736
    }
  ],
  "9334": [
    {
      "answer": "Pliocene",
      "score": 0.9948542714118958
    }
  ],
  "9335": [
    {
      "answer": "Vosges Mountains",
      "score": 0.8497905135154724
    },
    {
      "answer": "Mosel",
      "score": 0.9002922177314758
    },
    {
      "answer": "Main",
      "score": 0.9128609895706177
    }
  ],
  "9336": [
    {
      "answer": "stream capture",
      "score": 0.9051294922828674
    }
  ],
  "9337": [
    {
      "answer": "Pliocene period",
      "score": 0.7492430210113525
    }
  ],
  "9338": [
    {
      "answer": "Rhone",
      "score": 0.9848600029945374
    }
  ],
  "9339": [
    {
      "answer": "Meuse",
      "score": 0.9848661422729492
    }
  ],
  "9340": [
    {
      "answer": "Vosges Mountains",
      "score": 0.9776285290718079
    },
    {
      "answer": "Vosges Mountains",
      "score": 0.9578921794891357
    }
  ],
  "9341": [
    {
      "answer": "the Ice Ages",
      "score": 0.8705775141716003
    }
  ],
  "9342": [
    {
      "answer": "six",
      "score": 0.9930253028869629
    }
  ],
  "9343": [
    {
      "answer": "120 m",
      "score": 0.988614559173584
    }
  ],
  "9344": [
    {
      "answer": "northwest",
      "score": 0.9949506521224976
    }
  ],
  "9345": [
    {
      "answer": "offshore of Brest, France",
      "score": 0.9685457348823547
    }
  ],
  "9346": [
    {
      "answer": "2.5 million years ago",
      "score": 0.8306158781051636
    },
    {
      "answer": "11,600 years ago",
      "score": 0.8817489743232727
    }
  ],
  "9347": [
    {
      "answer": "present level",
      "score": 0.7534473538398743
    }
  ],
  "9348": [
    {
      "answer": "~450,000 yr BP",
      "score": 0.5926640629768372
    }
  ],
  "9349": [
    {
      "answer": "France",
      "score": 0.8788447380065918
    }
  ],
  "9350": [
    {
      "answer": "74,000",
      "score": 0.9822815656661987
    }
  ],
  "9351": [
    {
      "answer": "11,600 BP",
      "score": 0.975496232509613
    }
  ],
  "9352": [
    {
      "answer": "west",
      "score": 0.990216851234436
    },
    {
      "answer": "southwest",
      "score": 0.5444414019584656
    }
  ],
  "9353": [
    {
      "answer": "120 m",
      "score": 0.984837532043457
    }
  ],
  "9354": [
    {
      "answer": "English Channel",
      "score": 0.6342909336090088
    }
  ],
  "9355": [
    {
      "answer": "74,000",
      "score": 0.9769765734672546
    }
  ],
  "9356": [
    {
      "answer": "70,000 BP",
      "score": 0.8434622287750244
    },
    {
      "answer": "29,000\u201324,000 BP",
      "score": 0.9409481287002563
    }
  ],
  "9357": [
    {
      "answer": "Atlantic Ocean",
      "score": 0.7249576449394226
    }
  ],
  "9358": [
    {
      "answer": "120 m (390 ft)",
      "score": 0.9439669847488403
    }
  ],
  "9359": [
    {
      "answer": "120 m (390 ft)",
      "score": 0.9452457427978516
    }
  ],
  "9360": [
    {
      "answer": "glacier",
      "score": 0.9770762324333191
    }
  ],
  "9361": [
    {
      "answer": "A tundra",
      "score": 0.9247303605079651
    }
  ],
  "9362": [
    {
      "answer": "22,000\u201314,000 yr BP",
      "score": 0.99051433801651
    }
  ],
  "9363": [
    {
      "answer": "ice-sheets",
      "score": 0.9854722619056702
    }
  ],
  "9364": [
    {
      "answer": "loess",
      "score": 0.9859848022460938
    }
  ],
  "9365": [
    {
      "answer": "glacier",
      "score": 0.9746301770210266
    }
  ],
  "9366": [
    {
      "answer": "Rhine",
      "score": 0.8075496554374695
    }
  ],
  "9367": [
    {
      "answer": "Last Glacial Maximum",
      "score": 0.9707038402557373
    },
    {
      "answer": "22,000\u201314,000 yr BP",
      "score": 0.8910473585128784
    }
  ],
  "9368": [
    {
      "answer": "22,000\u201314,000 yr BP",
      "score": 0.9254552125930786
    }
  ],
  "9369": [
    {
      "answer": "22,000 years ago",
      "score": 0.9903351068496704
    }
  ],
  "9370": [
    {
      "answer": "thaw",
      "score": 0.9652255177497864
    }
  ],
  "9371": [
    {
      "answer": "Rhine",
      "score": 0.9882546663284302
    }
  ],
  "9372": [
    {
      "answer": "13,000 BP",
      "score": 0.9948076009750366
    }
  ],
  "9373": [
    {
      "answer": "9000 BP",
      "score": 0.9892106652259827
    }
  ],
  "9374": [
    {
      "answer": "22,000",
      "score": 0.9692976474761963
    }
  ],
  "9375": [
    {
      "answer": "22,000",
      "score": 0.9424654841423035
    }
  ],
  "9376": [
    {
      "answer": "alpine glaciers",
      "score": 0.5638393759727478
    },
    {
      "answer": "forest",
      "score": 0.6366348266601562
    }
  ],
  "9377": [
    {
      "answer": "Meltwater",
      "score": 0.9858405590057373
    }
  ],
  "9378": [
    {
      "answer": "7500 yr ago",
      "score": 0.9889670610427856
    }
  ],
  "9379": [
    {
      "answer": "Rates of sea-level rise had dropped so far",
      "score": 0.9468472599983215
    }
  ],
  "9380": [
    {
      "answer": "7000 years",
      "score": 0.8140218257904053
    }
  ],
  "9381": [
    {
      "answer": "due to ongoing tectonic subsidence",
      "score": 0.8830999732017517
    }
  ],
  "9382": [
    {
      "answer": "about 1\u20133 cm (0.39\u20131.18 in) per century",
      "score": 0.9221828579902649
    }
  ],
  "9383": [
    {
      "answer": "7500 yr ago",
      "score": 0.9846927523612976
    }
  ],
  "9384": [
    {
      "answer": "about 1\u20133 cm (0.39\u20131.18 in) per century",
      "score": 0.9140187501907349
    }
  ],
  "9385": [
    {
      "answer": "7500",
      "score": 0.9908665418624878
    }
  ],
  "9386": [],
  "9387": [
    {
      "answer": "7500",
      "score": 0.9924429059028625
    }
  ],
  "9388": [
    {
      "answer": "11,700 years ago",
      "score": 0.9882364273071289
    }
  ],
  "9389": [
    {
      "answer": "Late-Glacial valley",
      "score": 0.9438353776931763
    }
  ],
  "9390": [
    {
      "answer": "Netherlands",
      "score": 0.9928983449935913
    }
  ],
  "9391": [
    {
      "answer": "8,000 years ago",
      "score": 0.9914795160293579
    }
  ],
  "9392": [
    {
      "answer": "11,700 years ago",
      "score": 0.8872736096382141
    }
  ],
  "9393": [
    {
      "answer": "8,000 years ago",
      "score": 0.9649818539619446
    }
  ],
  "9394": [
    {
      "answer": "11,700 years ago",
      "score": 0.9431442618370056
    }
  ],
  "9395": [
    {
      "answer": "11,700 years ago",
      "score": 0.9549509882926941
    }
  ],
  "9396": [
    {
      "answer": "~3000 yr BP",
      "score": 0.6018903255462646
    },
    {
      "answer": "Roman times",
      "score": 0.8103275299072266
    }
  ],
  "9397": [
    {
      "answer": "sediment load",
      "score": 0.976134181022644
    }
  ],
  "9398": [
    {
      "answer": "increased flooding and sedimentation",
      "score": 0.9401671290397644
    },
    {
      "answer": "ending peat formation",
      "score": 0.7786261439323425
    }
  ],
  "9399": [
    {
      "answer": "80",
      "score": 0.9874934554100037
    }
  ],
  "9400": [
    {
      "answer": "11\u201313th century AD",
      "score": 0.9825200438499451
    }
  ],
  "9401": [
    {
      "answer": "~3000 yr BP",
      "score": 0.9101214408874512
    }
  ],
  "9402": [],
  "9403": [
    {
      "answer": "80",
      "score": 0.5806786417961121
    }
  ],
  "9404": [],
  "9405": [
    {
      "answer": "11\u201313th century AD",
      "score": 0.7991816401481628
    }
  ],
  "9406": [
    {
      "answer": "North Sea",
      "score": 0.9937094449996948
    }
  ],
  "9407": [
    {
      "answer": "former Meuse estuary",
      "score": 0.9101576805114746
    }
  ],
  "9408": [
    {
      "answer": "north",
      "score": 0.9135756492614746
    },
    {
      "answer": "IJsselmeer",
      "score": 0.8562101125717163
    }
  ],
  "9409": [
    {
      "answer": "IJsselmeer",
      "score": 0.7518613338470459
    },
    {
      "answer": "freshwater lake",
      "score": 0.8208237886428833
    }
  ],
  "9410": [
    {
      "answer": "three",
      "score": 0.9884081482887268
    }
  ],
  "9411": [
    {
      "answer": "Meuse estuary",
      "score": 0.8049653768539429
    },
    {
      "answer": "Rotterdam",
      "score": 0.90021812915802
    }
  ],
  "9412": [
    {
      "answer": "1932",
      "score": 0.9946401715278625
    }
  ],
  "9413": [
    {
      "answer": "1709",
      "score": 0.995914876461029
    }
  ],
  "9414": [
    {
      "answer": "three",
      "score": 0.5938669443130493
    }
  ],
  "9415": [
    {
      "answer": "20th",
      "score": 0.9898389577865601
    }
  ],
  "9416": [
    {
      "answer": "1st century BC",
      "score": 0.9858614206314087
    },
    {
      "answer": "1st century BC",
      "score": 0.9361088275909424
    }
  ],
  "9417": [
    {
      "answer": "Germania",
      "score": 0.9895201921463013
    },
    {
      "answer": "Germania",
      "score": 0.7536499500274658
    }
  ],
  "9418": [
    {
      "answer": "6th century BC",
      "score": 0.9912933707237244
    }
  ],
  "9419": [
    {
      "answer": "Maurus Servius Honoratus",
      "score": 0.8078838586807251
    }
  ],
  "9420": [
    {
      "answer": "1st century BC",
      "score": 0.979670524597168
    },
    {
      "answer": "1st century BC",
      "score": 0.9226593375205994
    }
  ],
  "9421": [
    {
      "answer": "Gaul and Germania",
      "score": 0.953224778175354
    }
  ],
  "9422": [
    {
      "answer": "1st century BC",
      "score": 0.8024289608001709
    },
    {
      "answer": "6th century BC",
      "score": 0.7413641810417175
    },
    {
      "answer": "1st century BC",
      "score": 0.8066189289093018
    }
  ],
  "9423": [
    {
      "answer": "1st century BC",
      "score": 0.9264529943466187
    },
    {
      "answer": "1st century BC",
      "score": 0.8786457777023315
    }
  ],
  "9424": [
    {
      "answer": "AD 14",
      "score": 0.9976966381072998
    }
  ],
  "9425": [
    {
      "answer": "Danube",
      "score": 0.9614138603210449
    },
    {
      "answer": "Danube",
      "score": 0.7605282068252563
    }
  ],
  "9426": [
    {
      "answer": "AD 70",
      "score": 0.9837724566459656
    }
  ],
  "9427": [
    {
      "answer": "modern Baden and W\u00fcrttemberg",
      "score": 0.7533153295516968
    }
  ],
  "9428": [
    {
      "answer": "eastwards",
      "score": 0.9969667792320251
    }
  ],
  "9429": [
    {
      "answer": "AD 14",
      "score": 0.974479615688324
    },
    {
      "answer": "AD 70",
      "score": 0.5669788122177124
    }
  ],
  "9430": [
    {
      "answer": "Frankfurt",
      "score": 0.9903252124786377
    }
  ],
  "9431": [
    {
      "answer": "AD 14",
      "score": 0.7778316736221313
    },
    {
      "answer": "AD 70",
      "score": 0.624211311340332
    }
  ],
  "9432": [
    {
      "answer": "AD 70",
      "score": 0.9919596910476685
    }
  ],
  "9433": [
    {
      "answer": "Germanic",
      "score": 0.9765520095825195
    }
  ],
  "9434": [
    {
      "answer": "eight",
      "score": 0.991236686706543
    }
  ],
  "9435": [
    {
      "answer": "a state or threat of war existed",
      "score": 0.9783529043197632
    }
  ],
  "9436": [
    {
      "answer": "army of Germania Inferior",
      "score": 0.9737119078636169
    }
  ],
  "9437": [
    {
      "answer": "oppidum Ubiorum",
      "score": 0.9857653379440308
    }
  ],
  "9438": [
    {
      "answer": "oppidum Ubiorum",
      "score": 0.9638549089431763
    }
  ],
  "9439": [
    {
      "answer": "eight",
      "score": 0.9768481254577637
    }
  ],
  "9440": [
    {
      "answer": "AD 14",
      "score": 0.9741520285606384
    },
    {
      "answer": "180",
      "score": 0.8468210101127625
    }
  ],
  "9441": [
    {
      "answer": "eight",
      "score": 0.5312584638595581
    },
    {
      "answer": "two",
      "score": 0.7127256989479065
    }
  ],
  "9442": [
    {
      "answer": "XXI",
      "score": 0.981089174747467
    }
  ],
  "9443": [],
  "9444": [
    {
      "answer": "Migration period",
      "score": 0.9177254438400269
    },
    {
      "answer": "5th century",
      "score": 0.786759614944458
    }
  ],
  "9445": [
    {
      "answer": "kingdoms of Francia on the Lower Rhine",
      "score": 0.7475200891494751
    },
    {
      "answer": "Burgundy on the Upper Rhine",
      "score": 0.7997565269470215
    },
    {
      "answer": "Alemannia on the High Rhine",
      "score": 0.7266439199447632
    }
  ],
  "9446": [
    {
      "answer": "dragons rock",
      "score": 0.9172960519790649
    }
  ],
  "9447": [
    {
      "answer": "Siegfried",
      "score": 0.9907229542732239
    }
  ],
  "9448": [
    {
      "answer": "Hagen",
      "score": 0.9913073182106018
    }
  ],
  "9449": [
    {
      "answer": "5th century",
      "score": 0.9777612686157227
    }
  ],
  "9450": [
    {
      "answer": "golden treasure",
      "score": 0.9683276414871216
    }
  ],
  "9451": [
    {
      "answer": "Drachenfels",
      "score": 0.9742190837860107
    }
  ],
  "9452": [
    {
      "answer": "Bonn",
      "score": 0.9835221767425537
    }
  ],
  "9453": [
    {
      "answer": "Kriemhild",
      "score": 0.8896520137786865
    }
  ],
  "9454": [
    {
      "answer": "6th century",
      "score": 0.973859965801239
    }
  ],
  "9455": [
    {
      "answer": "10th",
      "score": 0.9923275113105774
    }
  ],
  "9456": [
    {
      "answer": "Lower Lorraine",
      "score": 0.9872127771377563
    }
  ],
  "9457": [
    {
      "answer": "Archduke Sigismund of Austria",
      "score": 0.9854987263679504
    }
  ],
  "9458": [
    {
      "answer": "1469",
      "score": 0.989931583404541
    }
  ],
  "9459": [
    {
      "answer": "6th century",
      "score": 0.9770557880401611
    }
  ],
  "9460": [
    {
      "answer": "9th",
      "score": 0.9731566309928894
    }
  ],
  "9461": [
    {
      "answer": "6th century",
      "score": 0.6285361051559448
    }
  ],
  "9462": [
    {
      "answer": "1469",
      "score": 0.994027853012085
    }
  ],
  "9463": [
    {
      "answer": "Thirty Years' War",
      "score": 0.9133312702178955
    }
  ],
  "9464": [
    {
      "answer": "Peace of Westphalia",
      "score": 0.9740790128707886
    }
  ],
  "9465": [
    {
      "answer": "Establishing \"natural borders\"",
      "score": 0.9731850624084473
    }
  ],
  "9466": [
    {
      "answer": "Napoleon",
      "score": 0.8240765929222107
    },
    {
      "answer": "Napoleon",
      "score": 0.9785847067832947
    }
  ],
  "9467": [
    {
      "answer": "1806",
      "score": 0.9795971512794495
    }
  ],
  "9468": [
    {
      "answer": "1840",
      "score": 0.9870284795761108
    }
  ],
  "9469": [
    {
      "answer": "Peace of Westphalia",
      "score": 0.970613420009613
    }
  ],
  "9470": [],
  "9471": [],
  "9472": [
    {
      "answer": "1814",
      "score": 0.9885949492454529
    }
  ],
  "9473": [
    {
      "answer": "1814",
      "score": 0.9035598635673523
    }
  ],
  "9474": [
    {
      "answer": "At the end of World War I",
      "score": 0.7778124213218689
    }
  ],
  "9475": [
    {
      "answer": "1930",
      "score": 0.9888625741004944
    }
  ],
  "9476": [
    {
      "answer": "German army",
      "score": 0.9792014360427856
    }
  ],
  "9477": [
    {
      "answer": "Adolf Hitler's rise to power",
      "score": 0.9704572558403015
    }
  ],
  "9478": [
    {
      "answer": "1936",
      "score": 0.9864028096199036
    }
  ],
  "9479": [
    {
      "answer": "1935",
      "score": 0.9719613790512085
    }
  ],
  "9480": [
    {
      "answer": "1936",
      "score": 0.9863755106925964
    }
  ],
  "9481": [
    {
      "answer": "1930",
      "score": 0.8092350363731384
    }
  ],
  "9482": [
    {
      "answer": "1936",
      "score": 0.9839380383491516
    }
  ],
  "9483": [
    {
      "answer": "Arnhem",
      "score": 0.9309250116348267
    },
    {
      "answer": "Arnhem",
      "score": 0.7193521857261658
    },
    {
      "answer": "Remagen",
      "score": 0.7569120526313782
    },
    {
      "answer": "Remagen",
      "score": 0.7946547865867615
    }
  ],
  "9484": [
    {
      "answer": "formidable natural obstacle to the invasion of Germany",
      "score": 0.9193875193595886
    }
  ],
  "9485": [
    {
      "answer": "September 1944",
      "score": 0.992310643196106
    }
  ],
  "9486": [
    {
      "answer": "Ludendorff Bridge",
      "score": 0.9817955493927002
    }
  ],
  "9487": [
    {
      "answer": "Seven Days to the River Rhine",
      "score": 0.9963728785514832
    }
  ],
  "9488": [
    {
      "answer": "World War II",
      "score": 0.983546257019043
    }
  ],
  "9489": [
    {
      "answer": "September 1944",
      "score": 0.9655784964561462
    }
  ],
  "9490": [
    {
      "answer": "September 1944",
      "score": 0.9791929721832275
    }
  ],
  "9491": [
    {
      "answer": "Seven Days",
      "score": 0.9668828248977661
    }
  ],
  "9492": [
    {
      "answer": "Seven Days",
      "score": 0.9650794267654419
    }
  ],
  "9493": [
    {
      "answer": "1,230 kilometres",
      "score": 0.9799657464027405
    }
  ],
  "9494": [
    {
      "answer": "Knaurs Lexikon",
      "score": 0.9855023622512817
    }
  ],
  "9495": [
    {
      "answer": "1,320 kilometres",
      "score": 0.9323943853378296
    }
  ],
  "9496": [
    {
      "answer": "a typographical error",
      "score": 0.9339478015899658
    }
  ],
  "9497": [
    {
      "answer": "2010",
      "score": 0.9932255148887634
    }
  ],
  "9498": [
    {
      "answer": "1932",
      "score": 0.9241785407066345
    },
    {
      "answer": "1932",
      "score": 0.9852964282035828
    }
  ],
  "9499": [
    {
      "answer": "2010",
      "score": 0.994130551815033
    }
  ],
  "9500": [
    {
      "answer": "2010",
      "score": 0.9947355389595032
    }
  ],
  "9501": [
    {
      "answer": "1932",
      "score": 0.9211759567260742
    },
    {
      "answer": "1932",
      "score": 0.9182060956954956
    }
  ],
  "9502": [
    {
      "answer": "1,232 kilometres (766 miles)",
      "score": 0.5916696786880493
    }
  ],
  "9503": [
    {
      "answer": "12 May 1999",
      "score": 0.9848539233207703
    }
  ],
  "9504": [
    {
      "answer": "Scotland Act 1998",
      "score": 0.9903992414474487
    }
  ],
  "9505": [
    {
      "answer": "the areas in which it can make laws",
      "score": 0.8683309555053711
    }
  ],
  "9506": [
    {
      "answer": "Parliament of the United Kingdom",
      "score": 0.9959806799888611
    }
  ],
  "9507": [
    {
      "answer": "Westminster",
      "score": 0.9809247851371765
    }
  ],
  "9508": [
    {
      "answer": "Scotland Act 1998",
      "score": 0.9738534688949585
    }
  ],
  "9509": [
    {
      "answer": "12 May 1999",
      "score": 0.9349303245544434
    }
  ],
  "9510": [
    {
      "answer": "British Parliament",
      "score": 0.6019372940063477
    }
  ],
  "9511": [
    {
      "answer": "British Parliament",
      "score": 0.9710946083068848
    }
  ],
  "9512": [
    {
      "answer": "The first meeting of the new Parliament",
      "score": 0.7931801676750183
    }
  ],
  "9513": [
    {
      "answer": "lack of a Parliament of Scotland",
      "score": 0.9850110411643982
    }
  ],
  "9514": [
    {
      "answer": "three",
      "score": 0.9927566647529602
    }
  ],
  "9515": [
    {
      "answer": "outbreak of the First World War",
      "score": 0.9916085004806519
    }
  ],
  "9516": [
    {
      "answer": "late 1960s",
      "score": 0.9758053421974182
    }
  ],
  "9517": [
    {
      "answer": "directly elected Scottish Assembly",
      "score": 0.9754437804222107
    }
  ],
  "9518": [
    {
      "answer": "lack of a Parliament of Scotland",
      "score": 0.8943610191345215
    }
  ],
  "9519": [
    {
      "answer": "First World War",
      "score": 0.8408941626548767
    }
  ],
  "9520": [
    {
      "answer": "demands for some form of home rule or complete independence",
      "score": 0.9852856993675232
    }
  ],
  "9521": [
    {
      "answer": "to examine ways of enabling more self-government for Scotland",
      "score": 0.9722311496734619
    }
  ],
  "9522": [
    {
      "answer": "1973",
      "score": 0.9909917116165161
    }
  ],
  "9523": [
    {
      "answer": "North Sea",
      "score": 0.9946418404579163
    }
  ],
  "9524": [
    {
      "answer": "It's Scotland's oil",
      "score": 0.9719953536987305
    }
  ],
  "9525": [
    {
      "answer": "the revenues from the oil were not benefitting Scotland as much as they should",
      "score": 0.953446090221405
    }
  ],
  "9526": [
    {
      "answer": "1974",
      "score": 0.9897626638412476
    }
  ],
  "9527": [
    {
      "answer": "1978",
      "score": 0.9900492429733276
    }
  ],
  "9528": [
    {
      "answer": "rising support for Scottish independence",
      "score": 0.9919628500938416
    }
  ],
  "9529": [
    {
      "answer": "some form of devolved legislature",
      "score": 0.9863411784172058
    }
  ],
  "9530": [
    {
      "answer": "1978",
      "score": 0.9942747950553894
    }
  ],
  "9531": [
    {
      "answer": "oil",
      "score": 0.627502977848053
    },
    {
      "answer": "oil",
      "score": 0.9661908149719238
    },
    {
      "answer": "oil",
      "score": 0.8744275569915771
    },
    {
      "answer": "oil",
      "score": 0.8076050281524658
    }
  ],
  "9532": [
    {
      "answer": "Edinburgh",
      "score": 0.9958444237709045
    }
  ],
  "9533": [
    {
      "answer": "40%",
      "score": 0.9602097272872925
    },
    {
      "answer": "40%",
      "score": 0.9572765827178955
    }
  ],
  "9534": [
    {
      "answer": "failed",
      "score": 0.9844153523445129
    }
  ],
  "9535": [
    {
      "answer": "51.6%",
      "score": 0.9943779706954956
    }
  ],
  "9536": [
    {
      "answer": "32.9%",
      "score": 0.9936058521270752
    }
  ],
  "9537": [
    {
      "answer": "Scottish Assembly",
      "score": 0.8872856497764587
    }
  ],
  "9538": [
    {
      "answer": "an elected assembly",
      "score": 0.9744992256164551
    }
  ],
  "9539": [
    {
      "answer": "1979",
      "score": 0.8832205533981323
    },
    {
      "answer": "1979",
      "score": 0.9186654686927795
    }
  ],
  "9540": [
    {
      "answer": "32.9%",
      "score": 0.9891594648361206
    }
  ],
  "9541": [
    {
      "answer": "Scottish Parliament",
      "score": 0.9914768934249878
    }
  ],
  "9542": [
    {
      "answer": "Conservative Party",
      "score": 0.989485502243042
    }
  ],
  "9543": [
    {
      "answer": "1989",
      "score": 0.9887856245040894
    }
  ],
  "9544": [
    {
      "answer": "Scottish Constitutional Convention",
      "score": 0.9572448134422302
    }
  ],
  "9545": [
    {
      "answer": "1979",
      "score": 0.9650422930717468
    }
  ],
  "9546": [
    {
      "answer": "Parliament",
      "score": 0.6670907139778137
    },
    {
      "answer": "Parliament",
      "score": 0.8433127403259277
    }
  ],
  "9547": [
    {
      "answer": "pressure",
      "score": 0.9946523904800415
    }
  ],
  "9548": [
    {
      "answer": "Convention",
      "score": 0.904622495174408
    }
  ],
  "9549": [
    {
      "answer": "Holyrood area of Edinburgh",
      "score": 0.7975032329559326
    }
  ],
  "9550": [
    {
      "answer": "Enric Miralles",
      "score": 0.9961256980895996
    }
  ],
  "9551": [
    {
      "answer": "Spanish",
      "score": 0.992723286151886
    }
  ],
  "9552": [
    {
      "answer": "leaf-shaped",
      "score": 0.9895106554031372
    }
  ],
  "9553": [
    {
      "answer": "Queen Elizabeth II",
      "score": 0.9903375506401062
    }
  ],
  "9554": [
    {
      "answer": "Holyrood area of Edinburgh",
      "score": 0.789795994758606
    }
  ],
  "9555": [
    {
      "answer": "leaf-shaped buildings",
      "score": 0.7242498397827148
    }
  ],
  "9556": [
    {
      "answer": "Garden",
      "score": 0.9933597445487976
    }
  ],
  "9557": [
    {
      "answer": "9 October 2004",
      "score": 0.9947709441184998
    }
  ],
  "9558": [
    {
      "answer": "Scottish Parliament Building",
      "score": 0.8814858198165894
    },
    {
      "answer": "Scottish Parliament building",
      "score": 0.7503470182418823
    }
  ],
  "9559": [
    {
      "answer": "General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh",
      "score": 0.9573274850845337
    }
  ],
  "9560": [
    {
      "answer": "courtyard adjoining the Assembly Hall",
      "score": 0.934051513671875
    }
  ],
  "9561": [
    {
      "answer": "meeting of the Church's General Assembly",
      "score": 0.9200924634933472
    }
  ],
  "9562": [
    {
      "answer": "former Strathclyde Regional Council debating chamber in Glasgow",
      "score": 0.9542871713638306
    }
  ],
  "9563": [
    {
      "answer": "University of Aberdeen",
      "score": 0.9812240600585938
    }
  ],
  "9564": [],
  "9565": [
    {
      "answer": "television interviews",
      "score": 0.9768962860107422
    }
  ],
  "9566": [
    {
      "answer": "General Assembly Hall",
      "score": 0.9154614210128784
    },
    {
      "answer": "Assembly Hall",
      "score": 0.5663589239120483
    }
  ],
  "9567": [
    {
      "answer": "General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh",
      "score": 0.745868980884552
    }
  ],
  "9568": [
    {
      "answer": "City of Edinburgh Council",
      "score": 0.992141842842102
    }
  ],
  "9569": [
    {
      "answer": "The former administrative building of Lothian Regional Council on George IV Bridge",
      "score": 0.886247992515564
    }
  ],
  "9570": [
    {
      "answer": "demolished",
      "score": 0.9767971634864807
    }
  ],
  "9571": [],
  "9572": [
    {
      "answer": "main hall",
      "score": 0.9727017879486084
    }
  ],
  "9573": [
    {
      "answer": "MSP's offices",
      "score": 0.9703402519226074
    }
  ],
  "9574": [
    {
      "answer": "former administrative building of Lothian Regional Council",
      "score": 0.9555562138557434
    }
  ],
  "9575": [
    {
      "answer": "Midlothian County Buildings",
      "score": 0.9734272956848145
    }
  ],
  "9576": [
    {
      "answer": "Holyrood",
      "score": 0.9450743794441223
    }
  ],
  "9577": [
    {
      "answer": "Tricia Marwick",
      "score": 0.9922782182693481
    }
  ],
  "9578": [
    {
      "answer": "Tricia Marwick",
      "score": 0.9969720840454102
    }
  ],
  "9579": [
    {
      "answer": "secret ballot",
      "score": 0.976740300655365
    }
  ],
  "9580": [
    {
      "answer": "129",
      "score": 0.9954527020454407
    }
  ],
  "9581": [
    {
      "answer": "vote clerk",
      "score": 0.988234281539917
    }
  ],
  "9582": [
    {
      "answer": "deputies",
      "score": 0.9756752252578735
    },
    {
      "answer": "deputies",
      "score": 0.7133933901786804
    },
    {
      "answer": "deputies",
      "score": 0.7499776482582092
    }
  ],
  "9583": [
    {
      "answer": "Presiding Officer",
      "score": 0.9331096410751343
    }
  ],
  "9584": [
    {
      "answer": "vote clerk",
      "score": 0.9787129759788513
    }
  ],
  "9585": [
    {
      "answer": "Tricia Marwick",
      "score": 0.9958782196044922
    }
  ],
  "9586": [
    {
      "answer": "Elaine Smith",
      "score": 0.9895898103713989
    },
    {
      "answer": "John Scott",
      "score": 0.981545090675354
    }
  ],
  "9587": [
    {
      "answer": "Presiding Officer",
      "score": 0.99103844165802
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8697327971458435
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8630800247192383
    },
    {
      "answer": "Presiding Officer",
      "score": 0.858080267906189
    }
  ],
  "9588": [
    {
      "answer": "Parliamentary Bureau",
      "score": 0.9933117628097534
    }
  ],
  "9589": [
    {
      "answer": "five or more seats in the Parliament",
      "score": 0.8110415935516357
    }
  ],
  "9590": [
    {
      "answer": "Presiding Officer",
      "score": 0.7457534074783325
    },
    {
      "answer": "Presiding Officer",
      "score": 0.7036843299865723
    },
    {
      "answer": "Presiding Officer",
      "score": 0.7329994440078735
    },
    {
      "answer": "Presiding Officer",
      "score": 0.969881534576416
    }
  ],
  "9591": [
    {
      "answer": "Parliamentary Bureau",
      "score": 0.9939204454421997
    }
  ],
  "9592": [
    {
      "answer": "Presiding Officer",
      "score": 0.9645172357559204
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8425973653793335
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8502488732337952
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8429803848266602
    }
  ],
  "9593": [
    {
      "answer": "Presiding Officer",
      "score": 0.6423182487487793
    }
  ],
  "9594": [
    {
      "answer": "Presiding Officer",
      "score": 0.8252986073493958
    },
    {
      "answer": "Presiding Officer",
      "score": 0.7965453863143921
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8281295299530029
    },
    {
      "answer": "Presiding Officer",
      "score": 0.9500629901885986
    }
  ],
  "9595": [
    {
      "answer": "a hemicycle",
      "score": 0.9654322862625122
    }
  ],
  "9596": [
    {
      "answer": "to encourage consensus amongst elected members",
      "score": 0.9519965052604675
    }
  ],
  "9597": [
    {
      "answer": "131",
      "score": 0.9854403138160706
    },
    {
      "answer": "131",
      "score": 0.8836564421653748
    }
  ],
  "9598": [
    {
      "answer": "2",
      "score": 0.9708385467529297
    }
  ],
  "9599": [
    {
      "answer": "vote",
      "score": 0.9836392402648926
    }
  ],
  "9600": [
    {
      "answer": "Scottish",
      "score": 0.9802491068840027
    }
  ],
  "9601": [
    {
      "answer": "Scottish Parliament",
      "score": 0.8793601393699646
    }
  ],
  "9602": [],
  "9603": [
    {
      "answer": "Law Officers",
      "score": 0.8040950298309326
    },
    {
      "answer": "Law Officers",
      "score": 0.6617212891578674
    },
    {
      "answer": "Law officers",
      "score": 0.9814055562019348
    }
  ],
  "9604": [
    {
      "answer": "semicircle",
      "score": 0.9894243478775024
    }
  ],
  "9605": [
    {
      "answer": "silver",
      "score": 0.990209698677063
    }
  ],
  "9606": [
    {
      "answer": "Scottish rivers",
      "score": 0.993405818939209
    }
  ],
  "9607": [
    {
      "answer": "Wisdom, Compassion, Justice",
      "score": 0.9730335474014282
    }
  ],
  "9608": [
    {
      "answer": "Queen",
      "score": 0.9944053888320923
    }
  ],
  "9609": [
    {
      "answer": "glass case",
      "score": 0.9881017208099365
    }
  ],
  "9610": [
    {
      "answer": "parliamentary mace",
      "score": 0.9373356103897095
    }
  ],
  "9611": [
    {
      "answer": "mace",
      "score": 0.7529085874557495
    },
    {
      "answer": "mace",
      "score": 0.7137259244918823
    }
  ],
  "9612": [
    {
      "answer": "parliamentary mace",
      "score": 0.6500824689865112
    }
  ],
  "9613": [
    {
      "answer": "the lid of the case is rotated so that the mace",
      "score": 0.7433218955993652
    }
  ],
  "9614": [
    {
      "answer": "parliamentary mace",
      "score": 0.9752804040908813
    }
  ],
  "9615": [
    {
      "answer": "April",
      "score": 0.9362944960594177
    },
    {
      "answer": "October",
      "score": 0.6487779021263123
    }
  ],
  "9616": [
    {
      "answer": "debating chamber",
      "score": 0.9670602083206177
    }
  ],
  "9617": [
    {
      "answer": "the public",
      "score": 0.9218801259994507
    }
  ],
  "9618": [
    {
      "answer": "free",
      "score": 0.982123076915741
    }
  ],
  "9619": [
    {
      "answer": "Official Report",
      "score": 0.9953503012657166
    }
  ],
  "9620": [
    {
      "answer": "Parliament",
      "score": 0.9686052799224854
    }
  ],
  "9621": [],
  "9622": [
    {
      "answer": "2 pm to 6 pm",
      "score": 0.9608207941055298
    }
  ],
  "9623": [
    {
      "answer": "Chamber debates and committee meetings",
      "score": 0.6613016128540039
    }
  ],
  "9624": [
    {
      "answer": "Chamber debates and committee meetings",
      "score": 0.8256962895393372
    }
  ],
  "9625": [
    {
      "answer": "Wednesdays",
      "score": 0.9948274493217468
    }
  ],
  "9626": [
    {
      "answer": "four minutes",
      "score": 0.9940032362937927
    }
  ],
  "9627": [
    {
      "answer": "religious beliefs",
      "score": 0.993331789970398
    }
  ],
  "9628": [
    {
      "answer": "Presiding Officer",
      "score": 0.988315224647522
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8018131256103516
    }
  ],
  "9629": [
    {
      "answer": "nominate speakers",
      "score": 0.9750593900680542
    }
  ],
  "9630": [
    {
      "answer": "Time for Reflection",
      "score": 0.9837302565574646
    }
  ],
  "9631": [
    {
      "answer": "Time for Reflection",
      "score": 0.9961718320846558
    }
  ],
  "9632": [
    {
      "answer": "Time for Reflection",
      "score": 0.9973556995391846
    }
  ],
  "9633": [
    {
      "answer": "Presiding Officer",
      "score": 0.990013062953949
    }
  ],
  "9634": [
    {
      "answer": "Presiding Officer",
      "score": 0.9825525283813477
    },
    {
      "answer": "Presiding Officer",
      "score": 0.6746745109558105
    },
    {
      "answer": "Presiding Officer",
      "score": 0.934112548828125
    },
    {
      "answer": "Presiding Officer",
      "score": 0.9447148442268372
    },
    {
      "answer": "Presiding Officer",
      "score": 0.9299570918083191
    }
  ],
  "9635": [
    {
      "answer": "who speaks in chamber debates",
      "score": 0.9624662399291992
    }
  ],
  "9636": [
    {
      "answer": "different viewpoints and political parties",
      "score": 0.9923890233039856
    }
  ],
  "9637": [
    {
      "answer": "ministers or party leaders",
      "score": 0.9947952032089233
    }
  ],
  "9638": [
    {
      "answer": "Gaelic",
      "score": 0.667757511138916
    },
    {
      "answer": "Gaelic",
      "score": 0.9941991567611694
    }
  ],
  "9639": [
    {
      "answer": "political parties",
      "score": 0.9964855313301086
    }
  ],
  "9640": [
    {
      "answer": "Presiding Officer",
      "score": 0.6148945093154907
    },
    {
      "answer": "Presiding Officer",
      "score": 0.5473617315292358
    },
    {
      "answer": "Presiding Officer",
      "score": 0.7770618200302124
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8126840591430664
    },
    {
      "answer": "Presiding Officer",
      "score": 0.7296534776687622
    }
  ],
  "9641": [],
  "9642": [
    {
      "answer": "less",
      "score": 0.9801384210586548
    }
  ],
  "9643": [
    {
      "answer": "a large number of members wish to participate in the debate",
      "score": 0.9811415672302246
    }
  ],
  "9644": [
    {
      "answer": "5 pm",
      "score": 0.9975128769874573
    }
  ],
  "9645": [
    {
      "answer": "Decision Time",
      "score": 0.9949074387550354
    },
    {
      "answer": "Decision Time",
      "score": 0.9237164258956909
    }
  ],
  "9646": [
    {
      "answer": "vote",
      "score": 0.9816983938217163
    }
  ],
  "9647": [
    {
      "answer": "members vote by means of electronic consoles on their desks",
      "score": 0.9392234683036804
    }
  ],
  "9648": [
    {
      "answer": "seconds",
      "score": 0.9873435497283936
    }
  ],
  "9649": [
    {
      "answer": "all the motions and amendments",
      "score": 0.9740496873855591
    }
  ],
  "9650": [
    {
      "answer": "Decision Time",
      "score": 0.9856417179107666
    },
    {
      "answer": "Decision Time",
      "score": 0.9247175455093384
    }
  ],
  "9651": [
    {
      "answer": "Decision Time",
      "score": 0.8414807319641113
    },
    {
      "answer": "Decision Time",
      "score": 0.9854637384414673
    }
  ],
  "9652": [
    {
      "answer": "There will be a division",
      "score": 0.9794864654541016
    }
  ],
  "9653": [
    {
      "answer": "division",
      "score": 0.9470589756965637
    }
  ],
  "9654": [
    {
      "answer": "The outcome of most votes",
      "score": 0.9571291208267212
    }
  ],
  "9655": [
    {
      "answer": "political parties",
      "score": 0.993317723274231
    }
  ],
  "9656": [
    {
      "answer": "MSPs",
      "score": 0.9571735858917236
    }
  ],
  "9657": [
    {
      "answer": "Errant members can be deselected as official party candidates during future elections",
      "score": 0.9446164965629578
    }
  ],
  "9658": [
    {
      "answer": "moral issues",
      "score": 0.9398693442344666
    }
  ],
  "9659": [
    {
      "answer": "The outcome of most votes",
      "score": 0.6284645199775696
    },
    {
      "answer": "free votes",
      "score": 0.6341434717178345
    }
  ],
  "9660": [
    {
      "answer": "MSPs",
      "score": 0.9335407614707947
    }
  ],
  "9661": [
    {
      "answer": "Scottish",
      "score": 0.9910247325897217
    }
  ],
  "9662": [
    {
      "answer": "backbench",
      "score": 0.9801161289215088
    }
  ],
  "9663": [
    {
      "answer": "Immediately after Decision Time",
      "score": 0.9927549958229065
    }
  ],
  "9664": [
    {
      "answer": "45 minutes",
      "score": 0.9951760768890381
    }
  ],
  "9665": [
    {
      "answer": "Such motions are on issues which may be of interest to a particular area such as a member's own constituency, an upcoming or past event or any other item which would otherwise not be accorded official parliamentary time",
      "score": 0.9038783311843872
    }
  ],
  "9666": [
    {
      "answer": "other members",
      "score": 0.9818413257598877
    }
  ],
  "9667": [
    {
      "answer": "winds up",
      "score": 0.9893302917480469
    }
  ],
  "9668": [
    {
      "answer": "Decision Time",
      "score": 0.9865779876708984
    }
  ],
  "9669": [
    {
      "answer": "debate",
      "score": 0.8531670570373535
    }
  ],
  "9670": [
    {
      "answer": "Members Debate",
      "score": 0.9826363325119019
    }
  ],
  "9671": [
    {
      "answer": "Members Business",
      "score": 0.9852935671806335
    }
  ],
  "9672": [
    {
      "answer": "committee",
      "score": 0.9736952781677246
    }
  ],
  "9673": [
    {
      "answer": "stronger in the Scottish Parliament than in other parliamentary systems",
      "score": 0.9272310137748718
    }
  ],
  "9674": [
    {
      "answer": "there is no revising chamber",
      "score": 0.9530438780784607
    }
  ],
  "9675": [
    {
      "answer": "principal role of committees",
      "score": 0.7619547843933105
    }
  ],
  "9676": [
    {
      "answer": "Scotland",
      "score": 0.9873813390731812
    }
  ],
  "9677": [
    {
      "answer": "committee",
      "score": 0.8942953944206238
    }
  ],
  "9678": [
    {
      "answer": "partly as a means of strengthening the role of backbenchers in their scrutiny of the government",
      "score": 0.9619206190109253
    }
  ],
  "9679": [
    {
      "answer": "backbenchers",
      "score": 0.995029628276825
    }
  ],
  "9680": [
    {
      "answer": "committees",
      "score": 0.5609808564186096
    },
    {
      "answer": "Committees",
      "score": 0.9094058871269226
    }
  ],
  "9681": [
    {
      "answer": "MSPs",
      "score": 0.9848604798316956
    }
  ],
  "9682": [
    {
      "answer": "the balance of parties",
      "score": 0.976824164390564
    }
  ],
  "9683": [
    {
      "answer": "functions",
      "score": 0.9749453067779541
    }
  ],
  "9684": [
    {
      "answer": "Mandatory Committees",
      "score": 0.9842493534088135
    },
    {
      "answer": "Mandatory Committees",
      "score": 0.8366858959197998
    }
  ],
  "9685": [
    {
      "answer": "fourth",
      "score": 0.9923388957977295
    }
  ],
  "9686": [
    {
      "answer": "Committees",
      "score": 0.8547577261924744
    },
    {
      "answer": "committees",
      "score": 0.6080273389816284
    },
    {
      "answer": "Committees",
      "score": 0.5880552530288696
    },
    {
      "answer": "committees",
      "score": 0.5899350047111511
    }
  ],
  "9687": [
    {
      "answer": "MSPs",
      "score": 0.808536946773529
    }
  ],
  "9688": [
    {
      "answer": "standing orders",
      "score": 0.9646795988082886
    }
  ],
  "9689": [
    {
      "answer": "Scottish Parliament",
      "score": 0.524047315120697
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.9525837302207947
    }
  ],
  "9690": [
    {
      "answer": "beginning of each parliamentary session",
      "score": 0.9918899536132812
    }
  ],
  "9691": [
    {
      "answer": "one (or more)",
      "score": 0.9305257797241211
    }
  ],
  "9692": [
    {
      "answer": "Subject Committees",
      "score": 0.8918830156326294
    }
  ],
  "9693": [
    {
      "answer": "Session",
      "score": 0.8695809841156006
    }
  ],
  "9694": [
    {
      "answer": "Subject Committees",
      "score": 0.9287726879119873
    }
  ],
  "9695": [
    {
      "answer": "Economy, Energy and Tourism",
      "score": 0.940129280090332
    },
    {
      "answer": "Education and Culture",
      "score": 0.9331068396568298
    },
    {
      "answer": "Health and Sport",
      "score": 0.9314450025558472
    },
    {
      "answer": "Justice",
      "score": 0.90089350938797
    },
    {
      "answer": "Local Government and Regeneration",
      "score": 0.9564046859741211
    },
    {
      "answer": "Rural Affairs, Climate Change and Environment",
      "score": 0.9627930521965027
    },
    {
      "answer": "Welfare Reform",
      "score": 0.9574527740478516
    },
    {
      "answer": "Infrastructure and Capital Investment",
      "score": 0.9666634798049927
    }
  ],
  "9696": [
    {
      "answer": "Subject Committees",
      "score": 0.5579896569252014
    },
    {
      "answer": "Local Government and Regeneration",
      "score": 0.8262115120887756
    },
    {
      "answer": "Rural Affairs, Climate Change and Environment; Welfare Reform; and Infrastructure and Capital Investment",
      "score": 0.7669022083282471
    }
  ],
  "9697": [
    {
      "answer": "Economy, Energy and Tourism",
      "score": 0.746335506439209
    },
    {
      "answer": "Local Government and Regeneration",
      "score": 0.6539967656135559
    }
  ],
  "9698": [
    {
      "answer": "A further type of committee",
      "score": 0.8027100563049316
    }
  ],
  "9699": [
    {
      "answer": "large-scale development projects",
      "score": 0.9407275915145874
    }
  ],
  "9700": [
    {
      "answer": "Scottish Parliament",
      "score": 0.9764750599861145
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.7185288667678833
    }
  ],
  "9701": [
    {
      "answer": "Private Bill Committees",
      "score": 0.9931552410125732
    }
  ],
  "9702": [
    {
      "answer": "Private Bill Committees",
      "score": 0.914505660533905
    }
  ],
  "9703": [
    {
      "answer": "development projects",
      "score": 0.9555090665817261
    },
    {
      "answer": "infrastructure projects that require the use of land or property",
      "score": 0.7180642485618591
    }
  ],
  "9704": [
    {
      "answer": "consider legislation on issues such as the development of the Edinburgh Tram Network, the Glasgow Airport Rail Link, the Airdrie-Bathgate Rail Link and extensions to the National Gallery of Scotland",
      "score": 0.9549762010574341
    }
  ],
  "9705": [
    {
      "answer": "Private Bill Committees",
      "score": 0.871118426322937
    }
  ],
  "9706": [
    {
      "answer": "Scotland Act 1998",
      "score": 0.987127423286438
    }
  ],
  "9707": [
    {
      "answer": "Queen Elizabeth II",
      "score": 0.9926127195358276
    }
  ],
  "9708": [
    {
      "answer": "devolved competencies",
      "score": 0.9798499345779419
    }
  ],
  "9709": [
    {
      "answer": "Parliament of the United Kingdom",
      "score": 0.7464367151260376
    },
    {
      "answer": "Parliament of the United Kingdom",
      "score": 0.9848524332046509
    }
  ],
  "9710": [
    {
      "answer": "Scottish Parliament",
      "score": 0.5870643854141235
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.6422830820083618
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.6955546736717224
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.7646738290786743
    }
  ],
  "9711": [
    {
      "answer": "devolved competencies",
      "score": 0.9327622056007385
    }
  ],
  "9712": [
    {
      "answer": "Parliament of the United Kingdom",
      "score": 0.972392737865448
    },
    {
      "answer": "Parliament of the United Kingdom",
      "score": 0.8576138615608215
    }
  ],
  "9713": [
    {
      "answer": "Queen Elizabeth II",
      "score": 0.991595447063446
    }
  ],
  "9714": [
    {
      "answer": "primary legislation",
      "score": 0.9858783483505249
    }
  ],
  "9715": [
    {
      "answer": "Scottish Parliament",
      "score": 0.7999157309532166
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.7513694763183594
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.7702707052230835
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.9350530505180359
    }
  ],
  "9716": [
    {
      "answer": "Schedule 5",
      "score": 0.9932727813720703
    }
  ],
  "9717": [
    {
      "answer": "Scottish Parliament",
      "score": 0.9935760498046875
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.8521758317947388
    }
  ],
  "9718": [],
  "9719": [
    {
      "answer": "3 pence",
      "score": 0.9865872859954834
    }
  ],
  "9720": [
    {
      "answer": "2012 Act",
      "score": 0.9827055931091309
    }
  ],
  "9721": [
    {
      "answer": "devolved matters",
      "score": 0.921356737613678
    }
  ],
  "9722": [
    {
      "answer": "Scottish Parliament",
      "score": 0.8509220480918884
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.9728633165359497
    }
  ],
  "9723": [
    {
      "answer": "Scottish Parliament",
      "score": 0.8851708173751831
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.9873573780059814
    }
  ],
  "9724": [
    {
      "answer": "borrowing powers",
      "score": 0.9412722587585449
    }
  ],
  "9725": [
    {
      "answer": "Reserved matters",
      "score": 0.7831990718841553
    }
  ],
  "9726": [],
  "9727": [
    {
      "answer": "Westminster",
      "score": 0.9884474873542786
    }
  ],
  "9728": [
    {
      "answer": "Westminster",
      "score": 0.9821189641952515
    }
  ],
  "9729": [
    {
      "answer": "Westminster",
      "score": 0.9606232643127441
    }
  ],
  "9730": [
    {
      "answer": "UK Government ministers",
      "score": 0.8374306559562683
    }
  ],
  "9731": [
    {
      "answer": "abortion, broadcasting policy, civil service",
      "score": 0.8030138611793518
    },
    {
      "answer": "common markets for UK goods and services, constitution, electricity, coal, oil, gas, nuclear energy, defence and national security, drug policy, employment, foreign policy and relations with Europe, most aspects of transport safety and regulation, National Lottery, protection of borders, social security and stability of UK's fiscal, economic and monetary system",
      "score": 0.8241402506828308
    }
  ],
  "9732": [
    {
      "answer": "Reserved matters",
      "score": 0.9169613718986511
    }
  ],
  "9733": [
    {
      "answer": "the Scottish Government can introduce new laws or amendments to existing laws as a bill",
      "score": 0.7258613705635071
    },
    {
      "answer": "a committee of the Parliament can present a bill in one of the areas under its remit",
      "score": 0.8264130353927612
    },
    {
      "answer": "a member of the Scottish Parliament can introduce a bill",
      "score": 0.8726299405097961
    }
  ],
  "9734": [
    {
      "answer": "Scottish Government",
      "score": 0.9962273836135864
    }
  ],
  "9735": [
    {
      "answer": "private member",
      "score": 0.990708589553833
    }
  ],
  "9736": [
    {
      "answer": "outside proposer",
      "score": 0.9416295289993286
    }
  ],
  "9737": [],
  "9738": [
    {
      "answer": "government bills",
      "score": 0.869133710861206
    }
  ],
  "9739": [
    {
      "answer": "bill",
      "score": 0.957514226436615
    }
  ],
  "9740": [
    {
      "answer": "Scottish",
      "score": 0.9862004518508911
    }
  ],
  "9741": [
    {
      "answer": "a member of the Scottish Parliament",
      "score": 0.9706382155418396
    }
  ],
  "9742": [
    {
      "answer": "the first, or introductory stage",
      "score": 0.8975762128829956
    }
  ],
  "9743": [
    {
      "answer": "Explanatory Notes",
      "score": 0.9823167324066162
    },
    {
      "answer": "Policy Memorandum",
      "score": 0.9705430865287781
    },
    {
      "answer": "a Financial Memorandum",
      "score": 0.8717039823532104
    }
  ],
  "9744": [
    {
      "answer": "whether the bill is within the legislative competence of the Parliament",
      "score": 0.9841794371604919
    }
  ],
  "9745": [
    {
      "answer": "relevant committee or committees",
      "score": 0.9735363721847534
    }
  ],
  "9746": [
    {
      "answer": "Stage 2",
      "score": 0.9955470561981201
    }
  ],
  "9747": [],
  "9748": [
    {
      "answer": "Stage 2",
      "score": 0.9542800188064575
    }
  ],
  "9749": [
    {
      "answer": "Stage 1",
      "score": 0.7092028856277466
    },
    {
      "answer": "Stage 1",
      "score": 0.9710596799850464
    }
  ],
  "9750": [
    {
      "answer": "Stage 1",
      "score": 0.9277591705322266
    }
  ],
  "9751": [
    {
      "answer": "Stage 3",
      "score": 0.9878851175308228
    }
  ],
  "9752": [
    {
      "answer": "two",
      "score": 0.9927560687065125
    }
  ],
  "9753": [
    {
      "answer": "final vote on the bill",
      "score": 0.8666015863418579
    }
  ],
  "9754": [
    {
      "answer": "wrecking amendments",
      "score": 0.9732479453086853
    }
  ],
  "9755": [
    {
      "answer": "Decision Time",
      "score": 0.9955039024353027
    }
  ],
  "9756": [
    {
      "answer": "bill",
      "score": 0.8859091401100159
    },
    {
      "answer": "bill",
      "score": 0.631411612033844
    },
    {
      "answer": "bill",
      "score": 0.5891964435577393
    },
    {
      "answer": "bill",
      "score": 0.6235557198524475
    },
    {
      "answer": "bill",
      "score": 0.6813761591911316
    },
    {
      "answer": "bill",
      "score": 0.6940710544586182
    },
    {
      "answer": "bill",
      "score": 0.6237106919288635
    }
  ],
  "9757": [
    {
      "answer": "Stage 3",
      "score": 0.9643792510032654
    }
  ],
  "9758": [
    {
      "answer": "Decision Time",
      "score": 0.9461016058921814
    }
  ],
  "9759": [
    {
      "answer": "thwart further progress",
      "score": 0.8866050243377686
    }
  ],
  "9760": [
    {
      "answer": "Monarch",
      "score": 0.9951968789100647
    }
  ],
  "9761": [],
  "9762": [
    {
      "answer": "4-week",
      "score": 0.9958219528198242
    }
  ],
  "9763": [
    {
      "answer": "Supreme Court of the United Kingdom",
      "score": 0.9918228983879089
    }
  ],
  "9764": [
    {
      "answer": "The Bill for this Act of the Scottish Parliament was passed by the Parliament on [Date] and received royal assent on [Date]",
      "score": 0.8632968068122864
    }
  ],
  "9765": [
    {
      "answer": "Scottish Parliament",
      "score": 0.9691472053527832
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.7240873575210571
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.8095678091049194
    }
  ],
  "9766": [
    {
      "answer": "Monarch",
      "score": 0.9924253225326538
    }
  ],
  "9767": [
    {
      "answer": "Scottish Parliament",
      "score": 0.899814784526825
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.8321514129638672
    },
    {
      "answer": "Scottish Parliament",
      "score": 0.8667780756950378
    }
  ],
  "9768": [
    {
      "answer": "The Bill for this Act of the Scottish Parliament was passed by the Parliament on [Date] and received royal assent on [Date]",
      "score": 0.9756655097007751
    }
  ],
  "9769": [
    {
      "answer": "Supreme Court of the United Kingdom",
      "score": 0.9878604412078857
    }
  ],
  "9770": [],
  "9771": [
    {
      "answer": "First Minister",
      "score": 0.972261905670166
    }
  ],
  "9772": [
    {
      "answer": "Any member",
      "score": 0.9670816659927368
    }
  ],
  "9773": [
    {
      "answer": "elected MSPs",
      "score": 0.9495385885238647
    }
  ],
  "9774": [
    {
      "answer": "Sovereign",
      "score": 0.9914149641990662
    }
  ],
  "9775": [
    {
      "answer": "Scottish Government",
      "score": 0.9363327026367188
    },
    {
      "answer": "Scottish Government",
      "score": 0.9167200326919556
    }
  ],
  "9776": [],
  "9777": [
    {
      "answer": "elected MSPs",
      "score": 0.9373944997787476
    }
  ],
  "9778": [],
  "9779": [
    {
      "answer": "first Thursday",
      "score": 0.9857614040374756
    },
    {
      "answer": "first Thursday in May",
      "score": 0.8753006458282471
    }
  ],
  "9780": [
    {
      "answer": "May",
      "score": 0.9783403277397156
    },
    {
      "answer": "May",
      "score": 0.895229160785675
    },
    {
      "answer": "May",
      "score": 0.7368970513343811
    },
    {
      "answer": "May",
      "score": 0.6844135522842407
    }
  ],
  "9781": [
    {
      "answer": "Monarch",
      "score": 0.9945089221000671
    }
  ],
  "9782": [
    {
      "answer": "28",
      "score": 0.9930495023727417
    }
  ],
  "9783": [
    {
      "answer": "supplant",
      "score": 0.9901397824287415
    }
  ],
  "9784": [
    {
      "answer": "first Thursday in May",
      "score": 0.9742957949638367
    }
  ],
  "9785": [
    {
      "answer": "ordinary general elections for the Scottish Parliament",
      "score": 0.5908226370811462
    },
    {
      "answer": "The date of the poll",
      "score": 0.8268222808837891
    }
  ],
  "9786": [
    {
      "answer": "the Monarch",
      "score": 0.6464775800704956
    },
    {
      "answer": "Presiding Officer",
      "score": 0.8060200214385986
    },
    {
      "answer": "Presiding Officer",
      "score": 0.6630053520202637
    }
  ],
  "9787": [
    {
      "answer": "the Monarch",
      "score": 0.8477081060409546
    },
    {
      "answer": "Presiding Officer",
      "score": 0.7515111565589905
    },
    {
      "answer": "Presiding Officer",
      "score": 0.6514697074890137
    }
  ],
  "9788": [
    {
      "answer": "Several procedures",
      "score": 0.8494681119918823
    }
  ],
  "9789": [
    {
      "answer": "MSPs",
      "score": 0.8356423377990723
    },
    {
      "answer": "MSPs",
      "score": 0.7419722676277161
    }
  ],
  "9790": [
    {
      "answer": "a statement to the chamber setting out the Government's legislative programme for the forthcoming year",
      "score": 0.9609598517417908
    }
  ],
  "9791": [
    {
      "answer": "issues related to the substance of the statement",
      "score": 0.9057364463806152
    }
  ],
  "9792": [
    {
      "answer": "The First Minister or members of the cabinet can deliver statements to Parliament upon which MSPs are invited to question.",
      "score": 0.8687053918838501
    }
  ],
  "9793": [
    {
      "answer": "statements",
      "score": 0.9366750717163086
    }
  ],
  "9794": [
    {
      "answer": "First Minister",
      "score": 0.6134496927261353
    },
    {
      "answer": "First Minister",
      "score": 0.731404721736908
    },
    {
      "answer": "First Minister",
      "score": 0.8536782264709473
    }
  ],
  "9795": [
    {
      "answer": "MSPs",
      "score": 0.6216743588447571
    }
  ],
  "9796": [
    {
      "answer": "Parliamentary time",
      "score": 0.9869804382324219
    }
  ],
  "9797": [
    {
      "answer": "Thursday",
      "score": 0.9930450320243835
    },
    {
      "answer": "Thursdays",
      "score": 0.5261085033416748
    }
  ],
  "9798": [
    {
      "answer": "any member of the Scottish Government",
      "score": 0.9765217304229736
    }
  ],
  "9799": [
    {
      "answer": "issues under their jurisdiction",
      "score": 0.9749175310134888
    }
  ],
  "9800": [
    {
      "answer": "four",
      "score": 0.9944828748703003
    }
  ],
  "9801": [
    {
      "answer": "2.30pm",
      "score": 0.7131189107894897
    }
  ],
  "9802": [
    {
      "answer": "2.30pm",
      "score": 0.8929774165153503
    }
  ],
  "9803": [
    {
      "answer": "12:30 p.m.",
      "score": 0.9713321328163147
    }
  ],
  "9804": [
    {
      "answer": "Opposition leaders",
      "score": 0.9945688843727112
    },
    {
      "answer": "opposition leaders",
      "score": 0.8050532341003418
    }
  ],
  "9805": [
    {
      "answer": "73",
      "score": 0.9844312071800232
    },
    {
      "answer": "73",
      "score": 0.9121493697166443
    }
  ],
  "9806": [
    {
      "answer": "one",
      "score": 0.9652858376502991
    }
  ],
  "9807": [
    {
      "answer": "2005",
      "score": 0.9915846586227417
    }
  ],
  "9808": [
    {
      "answer": "55,000",
      "score": 0.9745131731033325
    }
  ],
  "9809": [
    {
      "answer": "dispersed population and distance from the Scottish Parliament in Edinburgh",
      "score": 0.9832488894462585
    }
  ],
  "9810": [
    {
      "answer": "73",
      "score": 0.9902623295783997
    },
    {
      "answer": "73",
      "score": 0.9036126136779785
    }
  ],
  "9811": [
    {
      "answer": "first past the post",
      "score": 0.9802184700965881
    }
  ],
  "9812": [
    {
      "answer": "Orkney",
      "score": 0.6961606740951538
    },
    {
      "answer": "Orkney",
      "score": 0.9559035301208496
    },
    {
      "answer": "Shetland",
      "score": 0.9458499550819397
    },
    {
      "answer": "Western Isles",
      "score": 0.9368253946304321
    }
  ],
  "9813": [
    {
      "answer": "a by-election",
      "score": 0.9823499917984009
    }
  ],
  "9814": [
    {
      "answer": "proportionally to the number of votes received in the second vote of the ballot using the d'Hondt method",
      "score": 0.9228591322898865
    }
  ],
  "9815": [
    {
      "answer": "d'Hondt",
      "score": 0.9876399040222168
    }
  ],
  "9816": [
    {
      "answer": "quotient",
      "score": 0.9876975417137146
    }
  ],
  "9817": [
    {
      "answer": "constituency seats",
      "score": 0.9749547243118286
    }
  ],
  "9818": [
    {
      "answer": "iteratively",
      "score": 0.958705723285675
    }
  ],
  "9819": [
    {
      "answer": "seat",
      "score": 0.6343741416931152
    },
    {
      "answer": "seat",
      "score": 0.9509339928627014
    }
  ],
  "9820": [],
  "9821": [
    {
      "answer": "d'Hondt",
      "score": 0.9686678647994995
    }
  ],
  "9822": [
    {
      "answer": "d'Hondt",
      "score": 0.9402622580528259
    }
  ],
  "9823": [
    {
      "answer": "members must be over the age of 18 and must be a citizen of the United Kingdom, the Republic of Ireland, one of the countries in the Commonwealth of Nations, a citizen of a British overseas territory, or a European Union citizen resident in the UK",
      "score": 0.8228709101676941
    }
  ],
  "9824": [
    {
      "answer": "1981",
      "score": 0.9954097867012024
    }
  ],
  "9825": [
    {
      "answer": "18",
      "score": 0.9914082884788513
    }
  ],
  "9826": [
    {
      "answer": "police",
      "score": 0.9911778569221497
    }
  ],
  "9827": [
    {
      "answer": "Mental Health (Care and Treatment) (Scotland) Act 2003",
      "score": 0.990915060043335
    }
  ],
  "9828": [],
  "9829": [
    {
      "answer": "MSP",
      "score": 0.9360599517822266
    }
  ],
  "9830": [
    {
      "answer": "MSP",
      "score": 0.8319780826568604
    }
  ],
  "9831": [
    {
      "answer": "MSP",
      "score": 0.7281222939491272
    }
  ],
  "9832": [
    {
      "answer": "first time in the Scottish Parliament where a party has commanded a parliamentary majority",
      "score": 0.9219532608985901
    }
  ],
  "9833": [
    {
      "answer": "Labour",
      "score": 0.9948754906654358
    },
    {
      "answer": "Labour",
      "score": 0.8150985836982727
    }
  ],
  "9834": [
    {
      "answer": "151",
      "score": 0.9941520094871521
    }
  ],
  "9835": [
    {
      "answer": "eight",
      "score": 0.9801394939422607
    }
  ],
  "9836": [
    {
      "answer": "Scottish independence",
      "score": 0.9942920207977295
    }
  ],
  "9837": [
    {
      "answer": "16",
      "score": 0.9937547445297241
    }
  ],
  "9838": [
    {
      "answer": "Labour",
      "score": 0.9045660495758057
    },
    {
      "answer": "Labour",
      "score": 0.5427159070968628
    }
  ],
  "9839": [
    {
      "answer": "151",
      "score": 0.9944432377815247
    }
  ],
  "9840": [
    {
      "answer": "Liberal Democrats",
      "score": 0.9916936159133911
    }
  ],
  "9841": [
    {
      "answer": "Conservatives",
      "score": 0.9693726897239685
    }
  ],
  "9842": [
    {
      "answer": "Edinburgh Pentlands",
      "score": 0.9895025491714478
    }
  ],
  "9843": [
    {
      "answer": "five",
      "score": 0.9911608099937439
    }
  ],
  "9844": [
    {
      "answer": "Annabel Goldie",
      "score": 0.9948282837867737
    }
  ],
  "9845": [
    {
      "answer": "Cameron",
      "score": 0.98739093542099
    }
  ],
  "9846": [
    {
      "answer": "loss of Edinburgh Pentlands",
      "score": 0.9595699310302734
    }
  ],
  "9847": [
    {
      "answer": "Edinburgh Pentlands",
      "score": 0.9940510988235474
    }
  ],
  "9848": [
    {
      "answer": "David McLetchie",
      "score": 0.7908200025558472
    },
    {
      "answer": "McLetchie",
      "score": 0.8744869828224182
    }
  ],
  "9849": [
    {
      "answer": "Annabel Goldie",
      "score": 0.9520078897476196
    }
  ],
  "9850": [
    {
      "answer": "Cameron",
      "score": 0.9902898669242859
    }
  ],
  "9851": [
    {
      "answer": "able to vote on domestic legislation that applies only to England, Wales and Northern Ireland",
      "score": 0.9718755483627319
    }
  ],
  "9852": [
    {
      "answer": "domestic legislation of the Scottish Parliament",
      "score": 0.9304482340812683
    },
    {
      "answer": "West Lothian question",
      "score": 0.8925212621688843
    }
  ],
  "9853": [
    {
      "answer": "West Lothian question",
      "score": 0.9974362254142761
    }
  ],
  "9854": [
    {
      "answer": "Conservative",
      "score": 0.9962078332901001
    }
  ],
  "9855": [
    {
      "answer": "England",
      "score": 0.7717580795288086
    },
    {
      "answer": "England",
      "score": 0.9871383309364319
    }
  ],
  "9856": [
    {
      "answer": "West Lothian question",
      "score": 0.9680618047714233
    }
  ],
  "9857": [
    {
      "answer": "give MPs representing English constituencies a new \"veto\" over laws only affecting England",
      "score": 0.9675420522689819
    }
  ],
  "9858": [
    {
      "answer": "Conservative",
      "score": 0.9891674518585205
    }
  ],
  "9859": [
    {
      "answer": "West Lothian question",
      "score": 0.9420296549797058
    }
  ],
  "9860": [
    {
      "answer": "Islamism",
      "score": 0.6962539553642273
    },
    {
      "answer": "Islamism",
      "score": 0.5486826300621033
    }
  ],
  "9861": [
    {
      "answer": "Islamic values",
      "score": 0.9543887972831726
    }
  ],
  "9862": [
    {
      "answer": "reordering of government and society in accordance with the Shari'a",
      "score": 0.9726928472518921
    }
  ],
  "9863": [
    {
      "answer": "at one end is a strategy of Islamization of society through state power seized by revolution or invasion",
      "score": 0.8549612164497375
    }
  ],
  "9864": [
    {
      "answer": "revolution",
      "score": 0.9938535690307617
    },
    {
      "answer": "invasion",
      "score": 0.9909685254096985
    }
  ],
  "9865": [
    {
      "answer": "Islamism",
      "score": 0.5728551745414734
    }
  ],
  "9866": [
    {
      "answer": "Islamic values",
      "score": 0.8412337899208069
    }
  ],
  "9867": [
    {
      "answer": "the reordering of government and society in accordance with the Shari'a",
      "score": 0.8237817287445068
    }
  ],
  "9868": [
    {
      "answer": "from the bottom up",
      "score": 0.7722363471984863
    }
  ],
  "9869": [
    {
      "answer": "democratic",
      "score": 0.9960235357284546
    }
  ],
  "9870": [
    {
      "answer": "Palestine",
      "score": 0.9924248456954956
    }
  ],
  "9871": [
    {
      "answer": "abolish the state of Israel",
      "score": 0.9944496154785156
    }
  ],
  "9872": [
    {
      "answer": "democratic",
      "score": 0.8698132634162903
    },
    {
      "answer": "democracy",
      "score": 0.9816212058067322
    }
  ],
  "9873": [
    {
      "answer": "religious",
      "score": 0.9778265953063965
    }
  ],
  "9874": [
    {
      "answer": "democratic",
      "score": 0.8618084192276001
    },
    {
      "answer": "democracy",
      "score": 0.8137393593788147
    }
  ],
  "9875": [],
  "9876": [
    {
      "answer": "abolish the state of Israel",
      "score": 0.9937683343887329
    }
  ],
  "9877": [
    {
      "answer": "democratic",
      "score": 0.670883059501648
    },
    {
      "answer": "democracy",
      "score": 0.9788960814476013
    }
  ],
  "9878": [
    {
      "answer": "religious",
      "score": 0.9678344130516052
    }
  ],
  "9879": [
    {
      "answer": "vanguard of change and Islamic reform",
      "score": 0.8973588943481445
    }
  ],
  "9880": [
    {
      "answer": "Sunni pan-Islamism",
      "score": 0.9880523681640625
    }
  ],
  "9881": [
    {
      "answer": "sharia",
      "score": 0.9798636436462402
    }
  ],
  "9882": [
    {
      "answer": "democracy",
      "score": 0.9818537831306458
    }
  ],
  "9883": [
    {
      "answer": "to maintain their legitimacy",
      "score": 0.9852138757705688
    }
  ],
  "9884": [],
  "9885": [
    {
      "answer": "Sunni pan-Islamism",
      "score": 0.9869667887687683
    }
  ],
  "9886": [
    {
      "answer": "sharia rather than the building of Islamic institutions",
      "score": 0.8302323818206787
    },
    {
      "answer": "rejection of Shia Islam",
      "score": 0.6113879084587097
    }
  ],
  "9887": [
    {
      "answer": "democracy",
      "score": 0.9812962412834167
    }
  ],
  "9888": [],
  "9889": [
    {
      "answer": "political",
      "score": 0.9878203272819519
    }
  ],
  "9890": [
    {
      "answer": "Islam",
      "score": 0.7749712467193604
    },
    {
      "answer": "Islam",
      "score": 0.9696416258811951
    },
    {
      "answer": "Islam",
      "score": 0.7744578123092651
    },
    {
      "answer": "Islam",
      "score": 0.7495366930961609
    },
    {
      "answer": "Islam",
      "score": 0.8104334473609924
    },
    {
      "answer": "Islamic",
      "score": 0.6363311409950256
    }
  ],
  "9891": [
    {
      "answer": "Fred Halliday",
      "score": 0.904813289642334
    },
    {
      "answer": "John Esposito",
      "score": 0.8987833261489868
    },
    {
      "answer": "Muslim intellectuals like Javed Ahmad Ghamidi",
      "score": 0.8137642741203308
    }
  ],
  "9892": [
    {
      "answer": "illiberal Islamic regimes",
      "score": 0.996187150478363
    }
  ],
  "9893": [
    {
      "answer": "religion from politics",
      "score": 0.9897251129150391
    }
  ],
  "9894": [
    {
      "answer": "political",
      "score": 0.9737573266029358
    },
    {
      "answer": "political",
      "score": 0.5766999125480652
    }
  ],
  "9895": [
    {
      "answer": "Islam",
      "score": 0.7832599878311157
    },
    {
      "answer": "Islam",
      "score": 0.6347719430923462
    }
  ],
  "9896": [
    {
      "answer": "Fred Halliday",
      "score": 0.8814996480941772
    },
    {
      "answer": "John Esposito",
      "score": 0.8791975975036621
    },
    {
      "answer": "Javed Ahmad Ghamidi",
      "score": 0.8428182601928711
    }
  ],
  "9897": [
    {
      "answer": "illiberal Islamic regimes",
      "score": 0.9964354038238525
    }
  ],
  "9898": [
    {
      "answer": "religion from politics",
      "score": 0.9751200675964355
    }
  ],
  "9899": [
    {
      "answer": "Islamists",
      "score": 0.5252776741981506
    },
    {
      "answer": "Islamists",
      "score": 0.773461103439331
    },
    {
      "answer": "Islamism",
      "score": 0.8228273391723633
    },
    {
      "answer": "Islamism",
      "score": 0.6507654786109924
    }
  ],
  "9900": [
    {
      "answer": "Americans",
      "score": 0.9947113990783691
    }
  ],
  "9901": [
    {
      "answer": "a historical fluke of the \"short-lived era of the heyday of secular Arab nationalism between 1945 and 1970",
      "score": 0.947150707244873
    }
  ],
  "9902": [
    {
      "answer": "1945",
      "score": 0.9943674206733704
    }
  ],
  "9903": [
    {
      "answer": "quietist/non-political Islam",
      "score": 0.9930638074874878
    }
  ],
  "9904": [],
  "9905": [
    {
      "answer": "Americans",
      "score": 0.9799331426620483
    }
  ],
  "9906": [
    {
      "answer": "quietist/non-political Islam",
      "score": 0.9220834970474243
    }
  ],
  "9907": [
    {
      "answer": "1945",
      "score": 0.9945557117462158
    }
  ],
  "9908": [
    {
      "answer": "quietist/non-political Islam",
      "score": 0.98909592628479
    }
  ],
  "9909": [
    {
      "answer": "1970s",
      "score": 0.9891290068626404
    }
  ],
  "9910": [
    {
      "answer": "dangerous enemies",
      "score": 0.9931038022041321
    }
  ],
  "9911": [
    {
      "answer": "leftist/communist/nationalist insurgents",
      "score": 0.9895690679550171
    }
  ],
  "9912": [
    {
      "answer": "mujahideen",
      "score": 0.9852745532989502
    }
  ],
  "9913": [
    {
      "answer": "experience, ideology",
      "score": 0.9775875806808472
    }
  ],
  "9914": [
    {
      "answer": "1970s",
      "score": 0.9879043698310852
    }
  ],
  "9915": [
    {
      "answer": "dangerous enemies",
      "score": 0.9939590692520142
    }
  ],
  "9916": [
    {
      "answer": "leftist/communist/nationalist insurgents",
      "score": 0.9899815320968628
    }
  ],
  "9917": [
    {
      "answer": "mujahideen Muslim Afghanistan",
      "score": 0.8311939239501953
    }
  ],
  "9918": [
    {
      "answer": "experience, ideology, and weapons",
      "score": 0.8094071745872498
    }
  ],
  "9919": [
    {
      "answer": "Anwar Sadat",
      "score": 0.9926780462265015
    }
  ],
  "9920": [
    {
      "answer": "peace",
      "score": 0.9856513738632202
    }
  ],
  "9921": [
    {
      "answer": "political support in his struggle against leftists",
      "score": 0.9713135361671448
    }
  ],
  "9922": [
    {
      "answer": "1975",
      "score": 0.9909239411354065
    }
  ],
  "9923": [
    {
      "answer": "released Islamists from prison",
      "score": 0.9453942775726318
    }
  ],
  "9924": [
    {
      "answer": "Anwar Sadat",
      "score": 0.9105993509292603
    }
  ],
  "9925": [
    {
      "answer": "peace",
      "score": 0.9778187274932861
    }
  ],
  "9926": [
    {
      "answer": "political support in his struggle against leftists",
      "score": 0.9042700529098511
    }
  ],
  "9927": [
    {
      "answer": "1975",
      "score": 0.9869187474250793
    }
  ],
  "9928": [
    {
      "answer": "released Islamists from prison",
      "score": 0.9621343612670898
    }
  ],
  "9929": [
    {
      "answer": "strict, conservative Saudi-based Wahhabism",
      "score": 0.9623188376426697
    }
  ],
  "9930": [
    {
      "answer": "hate them for their religion",
      "score": 0.9532085657119751
    }
  ],
  "9931": [
    {
      "answer": "wars",
      "score": 0.9823248386383057
    }
  ],
  "9932": [
    {
      "answer": "infidels",
      "score": 0.6804171800613403
    },
    {
      "answer": "infidels",
      "score": 0.9728816747665405
    }
  ],
  "9933": [
    {
      "answer": "Saudi-interpretation",
      "score": 0.9870455265045166
    }
  ],
  "9934": [
    {
      "answer": "moderate local interpretations",
      "score": 0.8834452629089355
    }
  ],
  "9935": [
    {
      "answer": "hate them for their religion",
      "score": 0.9356145858764648
    }
  ],
  "9936": [
    {
      "answer": "wars",
      "score": 0.9823519587516785
    }
  ],
  "9937": [
    {
      "answer": "infidels",
      "score": 0.6377594470977783
    },
    {
      "answer": "infidels",
      "score": 0.9874274730682373
    }
  ],
  "9938": [
    {
      "answer": "Saudi-interpretation",
      "score": 0.9235567450523376
    }
  ],
  "9939": [
    {
      "answer": "Islamist",
      "score": 0.9820389151573181
    }
  ],
  "9940": [
    {
      "answer": "free or low cost medical clinics",
      "score": 0.7774757146835327
    },
    {
      "answer": "housing assistance",
      "score": 0.6166889667510986
    }
  ],
  "9941": [
    {
      "answer": "to avoid prohibitively costly dowry demands",
      "score": 0.988020122051239
    }
  ],
  "9942": [
    {
      "answer": "incompetent",
      "score": 0.9929425716400146
    },
    {
      "answer": "inefficient",
      "score": 0.9710902571678162
    }
  ],
  "9943": [
    {
      "answer": "rhetoric",
      "score": 0.9859809875488281
    }
  ],
  "9944": [
    {
      "answer": "Islamist",
      "score": 0.9623744487762451
    }
  ],
  "9945": [
    {
      "answer": "free or low cost medical clinics",
      "score": 0.8157453536987305
    },
    {
      "answer": "housing assistance",
      "score": 0.8106520175933838
    }
  ],
  "9946": [
    {
      "answer": "prohibitively costly dowry demands",
      "score": 0.9717425107955933
    }
  ],
  "9947": [
    {
      "answer": "incompetent",
      "score": 0.9877198338508606
    }
  ],
  "9948": [
    {
      "answer": "rhetoric",
      "score": 0.9588298797607422
    }
  ],
  "9949": [
    {
      "answer": "law and philosophy",
      "score": 0.983961820602417
    }
  ],
  "9950": [
    {
      "answer": "All India Muslim League",
      "score": 0.9293447136878967
    }
  ],
  "9951": [
    {
      "answer": "1908",
      "score": 0.967326283454895
    }
  ],
  "9952": [
    {
      "answer": "mainstream Indian nationalist and secularist Indian National Congress",
      "score": 0.9754313230514526
    }
  ],
  "9953": [
    {
      "answer": "The Reconstruction of Religious Thought in Islam",
      "score": 0.992918848991394
    }
  ],
  "9954": [
    {
      "answer": "law and philosophy",
      "score": 0.9363657832145691
    }
  ],
  "9955": [
    {
      "answer": "All India Muslim League",
      "score": 0.8813929557800293
    }
  ],
  "9956": [
    {
      "answer": "1908",
      "score": 0.9851328134536743
    }
  ],
  "9957": [
    {
      "answer": "Muslim League",
      "score": 0.9056757688522339
    }
  ],
  "9958": [
    {
      "answer": "The Reconstruction of Religious Thought in Islam",
      "score": 0.9938391447067261
    }
  ],
  "9959": [
    {
      "answer": "secularism and secular nationalism",
      "score": 0.9932731986045837
    }
  ],
  "9960": [
    {
      "answer": "crowd out",
      "score": 0.9958726167678833
    }
  ],
  "9961": [
    {
      "answer": "nationalist differences",
      "score": 0.9908592700958252
    }
  ],
  "9962": [
    {
      "answer": "1930",
      "score": 0.9822096824645996
    },
    {
      "answer": "1930",
      "score": 0.8421820402145386
    }
  ],
  "9963": [
    {
      "answer": "Pakistan movement",
      "score": 0.9944806098937988
    }
  ],
  "9964": [
    {
      "answer": "secularism and secular nationalism",
      "score": 0.9858721494674683
    }
  ],
  "9965": [
    {
      "answer": "crowd out",
      "score": 0.9709100723266602
    }
  ],
  "9966": [
    {
      "answer": "nationalist differences",
      "score": 0.9860895872116089
    }
  ],
  "9967": [
    {
      "answer": "1930",
      "score": 0.9805794358253479
    },
    {
      "answer": "1930",
      "score": 0.8540989756584167
    }
  ],
  "9968": [
    {
      "answer": "Pakistan movement",
      "score": 0.9851552844047546
    }
  ],
  "9969": [
    {
      "answer": "Sayyid Abul Ala Maududi",
      "score": 0.9868817329406738
    }
  ],
  "9970": [
    {
      "answer": "journalism",
      "score": 0.9946879148483276
    }
  ],
  "9971": [
    {
      "answer": "1941",
      "score": 0.9882721304893494
    }
  ],
  "9972": [
    {
      "answer": "Sayyid Abul Ala Maududi",
      "score": 0.9888800978660583
    }
  ],
  "9973": [
    {
      "answer": "journalism",
      "score": 0.9934514760971069
    }
  ],
  "9974": [
    {
      "answer": "India",
      "score": 0.903854250907898
    },
    {
      "answer": "Pakistan",
      "score": 0.9499616622924805
    }
  ],
  "9975": [
    {
      "answer": "modern context",
      "score": 0.9754897356033325
    }
  ],
  "9976": [
    {
      "answer": "Sayyid Abul Ala Maududi",
      "score": 0.9023351669311523
    }
  ],
  "9977": [
    {
      "answer": "Islamic",
      "score": 0.6654696464538574
    },
    {
      "answer": "Islam",
      "score": 0.6202470660209656
    },
    {
      "answer": "Islamic",
      "score": 0.7292569279670715
    },
    {
      "answer": "Islam",
      "score": 0.6841515302658081
    }
  ],
  "9978": [
    {
      "answer": "1972",
      "score": 0.9900428056716919
    }
  ],
  "9979": [
    {
      "answer": "India",
      "score": 0.6421946287155151
    },
    {
      "answer": "Pakistan",
      "score": 0.8371286988258362
    }
  ],
  "9980": [
    {
      "answer": "modern context",
      "score": 0.9010680913925171
    }
  ],
  "9981": [
    {
      "answer": "Sharia",
      "score": 0.9719436168670654
    }
  ],
  "9982": [
    {
      "answer": "Islamic state",
      "score": 0.9889482259750366
    }
  ],
  "9983": [
    {
      "answer": "unity of God",
      "score": 0.9519831538200378
    }
  ],
  "9984": [
    {
      "answer": "theo-democracy",
      "score": 0.5513796210289001
    }
  ],
  "9985": [
    {
      "answer": "educational process",
      "score": 0.9899196624755859
    }
  ],
  "9986": [
    {
      "answer": "Sharia",
      "score": 0.9378857612609863
    }
  ],
  "9987": [
    {
      "answer": "Islamic state",
      "score": 0.8879173994064331
    }
  ],
  "9988": [
    {
      "answer": "unity of God",
      "score": 0.8738702535629272
    }
  ],
  "9989": [
    {
      "answer": "Iranian Revolution",
      "score": 0.9637174606323242
    }
  ],
  "9990": [
    {
      "answer": "educational process",
      "score": 0.9765149354934692
    }
  ],
  "9991": [
    {
      "answer": "1928",
      "score": 0.9862792491912842
    }
  ],
  "9992": [
    {
      "answer": "Ismailiyah",
      "score": 0.9690650701522827
    }
  ],
  "9993": [
    {
      "answer": "Hassan al Banna",
      "score": 0.9929019808769226
    }
  ],
  "9994": [
    {
      "answer": "the Qur'an",
      "score": 0.9883506894111633
    }
  ],
  "9995": [
    {
      "answer": "imperialist",
      "score": 0.9909238219261169
    }
  ],
  "9996": [
    {
      "answer": "1928",
      "score": 0.9609620571136475
    }
  ],
  "9997": [
    {
      "answer": "Ismailiyah",
      "score": 0.8360735177993774
    }
  ],
  "9998": [
    {
      "answer": "violence",
      "score": 0.9785873293876648
    }
  ],
  "9999": [
    {
      "answer": "1949",
      "score": 0.9799355268478394
    }
  ],
  "10000": [
    {
      "answer": "Mahmud Fami Naqrashi",
      "score": 0.9709524512290955
    }
  ],
  "10001": [
    {
      "answer": "1948",
      "score": 0.9939045310020447
    }
  ],
  "10002": [
    {
      "answer": "Gamal Abdul Nasser",
      "score": 0.9944456815719604
    }
  ],
  "10003": [
    {
      "answer": "violence",
      "score": 0.9786365032196045
    }
  ],
  "10004": [
    {
      "answer": "1949",
      "score": 0.949963390827179
    }
  ],
  "10005": [
    {
      "answer": "Mahmud Fami Naqrashi",
      "score": 0.9827263355255127
    }
  ],
  "10006": [
    {
      "answer": "1949",
      "score": 0.7418444752693176
    },
    {
      "answer": "1948",
      "score": 0.5441958904266357
    }
  ],
  "10007": [
    {
      "answer": "Gamal Abdul Nasser",
      "score": 0.9954628944396973
    }
  ],
  "10008": [
    {
      "answer": "one of the most influential movements",
      "score": 0.9190747141838074
    }
  ],
  "10009": [
    {
      "answer": "semi-legal",
      "score": 0.9961769580841064
    }
  ],
  "10010": [
    {
      "answer": "field candidates",
      "score": 0.9936690330505371
    }
  ],
  "10011": [
    {
      "answer": "75%",
      "score": 0.9850956201553345
    }
  ],
  "10012": [
    {
      "answer": "Mohamed Morsi",
      "score": 0.9953572750091553
    }
  ],
  "10013": [
    {
      "answer": "one of the most influential movements",
      "score": 0.9208798408508301
    }
  ],
  "10014": [
    {
      "answer": "semi-legal",
      "score": 0.9963300824165344
    }
  ],
  "10015": [
    {
      "answer": "field candidates",
      "score": 0.9934853911399841
    }
  ],
  "10016": [
    {
      "answer": "75%",
      "score": 0.9851543307304382
    }
  ],
  "10017": [
    {
      "answer": "Mohamed Morsi",
      "score": 0.9942989349365234
    }
  ],
  "10018": [
    {
      "answer": "quick and decisive",
      "score": 0.9705303907394409
    }
  ],
  "10019": [
    {
      "answer": "pivotal event",
      "score": 0.9754247665405273
    }
  ],
  "10020": [
    {
      "answer": "economic stagnation in the defeated countries",
      "score": 0.6420197486877441
    }
  ],
  "10021": [
    {
      "answer": "A steep and steady decline",
      "score": 0.9635805487632751
    }
  ],
  "10022": [
    {
      "answer": "democratic and anti-democratic Islamist movements",
      "score": 0.9843965768814087
    }
  ],
  "10023": [
    {
      "answer": "quick and decisive",
      "score": 0.969761073589325
    }
  ],
  "10024": [
    {
      "answer": "pivotal event",
      "score": 0.9745426177978516
    }
  ],
  "10025": [
    {
      "answer": "economic stagnation in the defeated countries",
      "score": 0.656922459602356
    }
  ],
  "10026": [
    {
      "answer": "A steep and steady decline",
      "score": 0.9644986391067505
    }
  ],
  "10027": [
    {
      "answer": "secular, socialist and nationalist politics",
      "score": 0.9712206125259399
    }
  ],
  "10028": [
    {
      "answer": "Ali Shariati",
      "score": 0.9941176176071167
    }
  ],
  "10029": [
    {
      "answer": "ideological",
      "score": 0.99048912525177
    }
  ],
  "10030": [
    {
      "answer": "somewhere between",
      "score": 0.9582223892211914
    }
  ],
  "10031": [
    {
      "answer": "Prophet Mohammad",
      "score": 0.9824357032775879
    }
  ],
  "10032": [
    {
      "answer": "against Islam",
      "score": 0.9876002073287964
    }
  ],
  "10033": [
    {
      "answer": "Ali Shariati",
      "score": 0.8849489092826843
    }
  ],
  "10034": [
    {
      "answer": "ideological father",
      "score": 0.5777739882469177
    }
  ],
  "10035": [
    {
      "answer": "Prophet Mohammad",
      "score": 0.9018975496292114
    }
  ],
  "10036": [
    {
      "answer": "a long-term conspiracy against Islam",
      "score": 0.8456501364707947
    }
  ],
  "10037": [
    {
      "answer": "Islamic Republic",
      "score": 0.9850261211395264
    }
  ],
  "10038": [
    {
      "answer": "economic",
      "score": 0.9909449815750122
    }
  ],
  "10039": [
    {
      "answer": "Shia terrorist",
      "score": 0.9794359803199768
    }
  ],
  "10040": [
    {
      "answer": "2006 Israel-Lebanon conflict",
      "score": 0.956392765045166
    }
  ],
  "10041": [
    {
      "answer": "Mahmoud Ahmadinejad",
      "score": 0.9945163726806641
    }
  ],
  "10042": [
    {
      "answer": "Islamic Republic",
      "score": 0.9475289583206177
    }
  ],
  "10043": [
    {
      "answer": "economic",
      "score": 0.9503865838050842
    }
  ],
  "10044": [
    {
      "answer": "Shia terrorist",
      "score": 0.9802868366241455
    }
  ],
  "10045": [
    {
      "answer": "2006 Israel-Lebanon conflict",
      "score": 0.966417670249939
    }
  ],
  "10046": [
    {
      "answer": "Mahmoud Ahmadinejad",
      "score": 0.9930381178855896
    }
  ],
  "10047": [
    {
      "answer": "Soviet Union",
      "score": 0.9924440383911133
    }
  ],
  "10048": [
    {
      "answer": "Islamic rebellion",
      "score": 0.9791049957275391
    }
  ],
  "10049": [
    {
      "answer": "send aid",
      "score": 0.9737429618835449
    }
  ],
  "10050": [
    {
      "answer": "marginal",
      "score": 0.9893966317176819
    }
  ],
  "10051": [
    {
      "answer": "16,000",
      "score": 0.9925971031188965
    }
  ],
  "10052": [
    {
      "answer": "Soviet Union",
      "score": 0.9932814836502075
    }
  ],
  "10053": [
    {
      "answer": "suppress an Islamic rebellion",
      "score": 0.922692060470581
    }
  ],
  "10054": [
    {
      "answer": "send aid",
      "score": 0.962515115737915
    }
  ],
  "10055": [
    {
      "answer": "marginal",
      "score": 0.9864730834960938
    }
  ],
  "10056": [
    {
      "answer": "16,000",
      "score": 0.9896589517593384
    }
  ],
  "10057": [
    {
      "answer": "radicalize the Islamist movement",
      "score": 0.9616888761520386
    }
  ],
  "10058": [
    {
      "answer": "Saddam Hussein",
      "score": 0.991884708404541
    }
  ],
  "10059": [
    {
      "answer": "Islamist",
      "score": 0.9862042665481567
    }
  ],
  "10060": [
    {
      "answer": "Saudi",
      "score": 0.9281426668167114
    }
  ],
  "10061": [
    {
      "answer": "the west",
      "score": 0.9909961223602295
    }
  ],
  "10062": [
    {
      "answer": "brought several hundred thousand US and allied non-Muslim military personnel to Saudi Arabian soil to put an end to Saddam Hussein's occupation of Kuwait",
      "score": 0.8149207234382629
    }
  ],
  "10063": [
    {
      "answer": "Saddam Hussein",
      "score": 0.9932869672775269
    }
  ],
  "10064": [
    {
      "answer": "Islamist",
      "score": 0.9842277765274048
    }
  ],
  "10065": [
    {
      "answer": "Saudi",
      "score": 0.8945622444152832
    }
  ],
  "10066": [
    {
      "answer": "west",
      "score": 0.99607914686203
    }
  ],
  "10067": [
    {
      "answer": "conservative Muslims",
      "score": 0.9915758371353149
    }
  ],
  "10068": [
    {
      "answer": "kingdom",
      "score": 0.9664173722267151
    }
  ],
  "10069": [
    {
      "answer": "domestic Islamists",
      "score": 0.9900782704353333
    }
  ],
  "10070": [
    {
      "answer": "Algeria",
      "score": 0.987705647945404
    }
  ],
  "10071": [
    {
      "answer": "Osama bin Laden",
      "score": 0.9860429763793945
    }
  ],
  "10072": [
    {
      "answer": "conservative Muslims",
      "score": 0.9770094156265259
    }
  ],
  "10073": [
    {
      "answer": "kingdom",
      "score": 0.970069944858551
    }
  ],
  "10074": [
    {
      "answer": "aid to Islamic groups",
      "score": 0.7870213985443115
    }
  ],
  "10075": [
    {
      "answer": "Algeria",
      "score": 0.9678716063499451
    }
  ],
  "10076": [
    {
      "answer": "Osama bin Laden",
      "score": 0.7521342039108276
    }
  ],
  "10077": [
    {
      "answer": "Qutb",
      "score": 0.9789436459541321
    },
    {
      "answer": "Qutb",
      "score": 0.6263055205345154
    }
  ],
  "10078": [
    {
      "answer": "1966",
      "score": 0.9907637238502502
    }
  ],
  "10079": [
    {
      "answer": "Brotherhood",
      "score": 0.9815173745155334
    },
    {
      "answer": "Brotherhood",
      "score": 0.867902934551239
    }
  ],
  "10080": [
    {
      "answer": "Fringe or splinter movements",
      "score": 0.9777275323867798
    }
  ],
  "10081": [
    {
      "answer": "1970s",
      "score": 0.9920061230659485
    }
  ],
  "10082": [
    {
      "answer": "Hasan al-Hudaybi",
      "score": 0.8394672870635986
    }
  ],
  "10083": [
    {
      "answer": "1966",
      "score": 0.876062273979187
    }
  ],
  "10084": [
    {
      "answer": "Brotherhood",
      "score": 0.9167627096176147
    },
    {
      "answer": "Brotherhood",
      "score": 0.8519656658172607
    }
  ],
  "10085": [
    {
      "answer": "the Brotherhood",
      "score": 0.6217263340950012
    }
  ],
  "10086": [
    {
      "answer": "1970s",
      "score": 0.9843016862869263
    }
  ],
  "10087": [
    {
      "answer": "Egyptian Islamic Jihad organization",
      "score": 0.9690760374069214
    }
  ],
  "10088": [
    {
      "answer": "1981",
      "score": 0.9611937403678894
    }
  ],
  "10089": [
    {
      "answer": "Anwar Sadat",
      "score": 0.9391334056854248
    }
  ],
  "10090": [
    {
      "answer": "apostate",
      "score": 0.9796642065048218
    }
  ],
  "10091": [
    {
      "answer": "Muhammad Abd al-Salaam Farag",
      "score": 0.991825520992279
    }
  ],
  "10092": [
    {
      "answer": "Anwar Sadat",
      "score": 0.7896385192871094
    }
  ],
  "10093": [
    {
      "answer": "1981",
      "score": 0.9643751978874207
    }
  ],
  "10094": [
    {
      "answer": "Anwar Sadat",
      "score": 0.7295482158660889
    }
  ],
  "10095": [
    {
      "answer": "apostate",
      "score": 0.9819866418838501
    }
  ],
  "10096": [
    {
      "answer": "Muhammad Abd al-Salaam Farag",
      "score": 0.9905408620834351
    }
  ],
  "10097": [
    {
      "answer": "violence",
      "score": 0.9390681982040405
    },
    {
      "answer": "violence",
      "score": 0.7008719444274902
    }
  ],
  "10098": [
    {
      "answer": "al-Gama'a al-Islamiyya",
      "score": 0.8308084011077881
    },
    {
      "answer": "al-Gama'a al-Islamiyya",
      "score": 0.7082866430282593
    }
  ],
  "10099": [
    {
      "answer": "unsuccessful",
      "score": 0.9901987314224243
    }
  ],
  "10100": [
    {
      "answer": "2003",
      "score": 0.9865743517875671
    }
  ],
  "10101": [
    {
      "answer": "political figures",
      "score": 0.9356881380081177
    }
  ],
  "10102": [
    {
      "answer": "violence",
      "score": 0.8931123614311218
    },
    {
      "answer": "violence",
      "score": 0.6637385487556458
    }
  ],
  "10103": [
    {
      "answer": "al-Gama'a al-Islamiyya",
      "score": 0.8393208384513855
    },
    {
      "answer": "al-Gama'a al-Islamiyya",
      "score": 0.7290520668029785
    }
  ],
  "10104": [
    {
      "answer": "unsuccessful",
      "score": 0.9888561367988586
    }
  ],
  "10105": [
    {
      "answer": "2003",
      "score": 0.9889217615127563
    }
  ],
  "10106": [
    {
      "answer": "Major General Raouf Khayrat",
      "score": 0.6013689041137695
    },
    {
      "answer": "Rifaat al-Mahgoub",
      "score": 0.6208808422088623
    },
    {
      "answer": "political figures",
      "score": 0.5555152297019958
    }
  ],
  "10107": [
    {
      "answer": "quiescent",
      "score": 0.9824984073638916
    }
  ],
  "10108": [
    {
      "answer": "HAMAS",
      "score": 0.9773842096328735
    }
  ],
  "10109": [
    {
      "answer": "the destruction of Israel and the establishment of an Islamic state in Palestine",
      "score": 0.9291421175003052
    }
  ],
  "10110": [
    {
      "answer": "Palestine",
      "score": 0.8984887599945068
    },
    {
      "answer": "Palestine",
      "score": 0.8440353870391846
    },
    {
      "answer": "Palestine",
      "score": 0.975977897644043
    }
  ],
  "10111": [
    {
      "answer": "alcohol",
      "score": 0.9954921007156372
    }
  ],
  "10112": [
    {
      "answer": "quiescent",
      "score": 0.9834852814674377
    }
  ],
  "10113": [
    {
      "answer": "HAMAS",
      "score": 0.9849393367767334
    }
  ],
  "10114": [
    {
      "answer": "the destruction of Israel and the establishment of an Islamic state in Palestine",
      "score": 0.8710696697235107
    }
  ],
  "10115": [
    {
      "answer": "Israel",
      "score": 0.7646980881690979
    },
    {
      "answer": "Israel",
      "score": 0.6837269067764282
    },
    {
      "answer": "Israel",
      "score": 0.8583703637123108
    },
    {
      "answer": "Israel",
      "score": 0.9239134192466736
    }
  ],
  "10116": [
    {
      "answer": "drinking alcohol",
      "score": 0.9386997818946838
    }
  ],
  "10117": [
    {
      "answer": "Hamas",
      "score": 0.9724966287612915
    },
    {
      "answer": "Hamas",
      "score": 0.837361752986908
    }
  ],
  "10118": [
    {
      "answer": "542",
      "score": 0.9919428825378418
    }
  ],
  "10119": [
    {
      "answer": "majority of the seats",
      "score": 0.9685465693473816
    }
  ],
  "10120": [
    {
      "answer": "2007",
      "score": 0.8452132344245911
    },
    {
      "answer": "2007",
      "score": 0.9774739146232605
    }
  ],
  "10121": [
    {
      "answer": "driving Israel out of the Gaza Strip",
      "score": 0.9943248629570007
    }
  ],
  "10122": [
    {
      "answer": "Hamas",
      "score": 0.6540193557739258
    },
    {
      "answer": "Hamas",
      "score": 0.5574700832366943
    }
  ],
  "10123": [
    {
      "answer": "542",
      "score": 0.9826540350914001
    }
  ],
  "10124": [
    {
      "answer": "won the majority of the seats",
      "score": 0.8114702105522156
    }
  ],
  "10125": [
    {
      "answer": "2007",
      "score": 0.8578152656555176
    },
    {
      "answer": "2007",
      "score": 0.9544625282287598
    }
  ],
  "10126": [
    {
      "answer": "failure to achieve its demands in the 2008-9 and 2014 Gaza Wars",
      "score": 0.9719499349594116
    }
  ],
  "10127": [
    {
      "answer": "Islamist",
      "score": 0.995037853717804
    },
    {
      "answer": "Islamist",
      "score": 0.5424122214317322
    }
  ],
  "10128": [
    {
      "answer": "Hassan al-Turabi",
      "score": 0.9849684238433838
    }
  ],
  "10129": [
    {
      "answer": "National Islamic Front",
      "score": 0.9865825176239014
    }
  ],
  "10130": [
    {
      "answer": "money from foreign Islamist banking systems",
      "score": 0.9846581220626831
    }
  ],
  "10131": [
    {
      "answer": "university and military academy",
      "score": 0.9738067984580994
    }
  ],
  "10132": [
    {
      "answer": "Islamist",
      "score": 0.9947562217712402
    },
    {
      "answer": "Islamist",
      "score": 0.5508590936660767
    }
  ],
  "10133": [
    {
      "answer": "National Islamic Front",
      "score": 0.9872268438339233
    }
  ],
  "10134": [
    {
      "answer": "money from foreign Islamist banking systems",
      "score": 0.9798411726951599
    }
  ],
  "10135": [
    {
      "answer": "university and military academy",
      "score": 0.9712140560150146
    }
  ],
  "10136": [
    {
      "answer": "1985",
      "score": 0.9910891056060791
    }
  ],
  "10137": [
    {
      "answer": "help of the military",
      "score": 0.9746527671813965
    }
  ],
  "10138": [
    {
      "answer": "sharia law",
      "score": 0.986972451210022
    }
  ],
  "10139": [
    {
      "answer": "Osama bin Laden",
      "score": 0.993649959564209
    }
  ],
  "10140": [
    {
      "answer": "American attack on Iraq in the 1991 Gulf War",
      "score": 0.980815052986145
    }
  ],
  "10141": [
    {
      "answer": "1985",
      "score": 0.9390811324119568
    },
    {
      "answer": "1989",
      "score": 0.8787084817886353
    }
  ],
  "10142": [
    {
      "answer": "help of the military",
      "score": 0.931911051273346
    }
  ],
  "10143": [
    {
      "answer": "sharia law",
      "score": 0.9876382350921631
    }
  ],
  "10144": [
    {
      "answer": "Osama bin Laden",
      "score": 0.9797393679618835
    }
  ],
  "10145": [
    {
      "answer": "Islamic Salvation Front",
      "score": 0.8246268033981323
    }
  ],
  "10146": [
    {
      "answer": "Algeria",
      "score": 0.9895580410957336
    }
  ],
  "10147": [
    {
      "answer": "1989",
      "score": 0.9796899557113647
    }
  ],
  "10148": [
    {
      "answer": "gender segregation",
      "score": 0.9710868000984192
    }
  ],
  "10149": [
    {
      "answer": "military coup d'\u00e9tat",
      "score": 0.9160327315330505
    }
  ],
  "10150": [
    {
      "answer": "Islamic Salvation Front",
      "score": 0.7819492220878601
    }
  ],
  "10151": [
    {
      "answer": "Algeria",
      "score": 0.9913160800933838
    }
  ],
  "10152": [
    {
      "answer": "1989",
      "score": 0.988612711429596
    }
  ],
  "10153": [
    {
      "answer": "gender segregation",
      "score": 0.9878019094467163
    }
  ],
  "10154": [
    {
      "answer": "military coup d'\u00e9tat",
      "score": 0.917153000831604
    }
  ],
  "10155": [
    {
      "answer": "justice and prosperity",
      "score": 0.9199614524841309
    }
  ],
  "10156": [
    {
      "answer": "vicious and destructive",
      "score": 0.982587993144989
    }
  ],
  "10157": [
    {
      "answer": "one of the poorest countries on earth",
      "score": 0.9253010749816895
    }
  ],
  "10158": [
    {
      "answer": "1992",
      "score": 0.9880936741828918
    }
  ],
  "10159": [
    {
      "answer": "80%",
      "score": 0.9933415651321411
    }
  ],
  "10160": [
    {
      "answer": "one of the poorest countries on earth",
      "score": 0.8626863360404968
    }
  ],
  "10161": [
    {
      "answer": "vicious and destructive",
      "score": 0.957748293876648
    }
  ],
  "10162": [
    {
      "answer": "one of the poorest countries on earth",
      "score": 0.9187012910842896
    }
  ],
  "10163": [
    {
      "answer": "1992",
      "score": 0.9908389449119568
    }
  ],
  "10164": [
    {
      "answer": "80%",
      "score": 0.9892666339874268
    }
  ],
  "10165": [
    {
      "answer": "Taliban",
      "score": 0.9654695987701416
    },
    {
      "answer": "Taliban",
      "score": 0.7993957996368408
    }
  ],
  "10166": [
    {
      "answer": "Pakistan",
      "score": 0.9917245507240295
    }
  ],
  "10167": [
    {
      "answer": "Islamic fundamentalist",
      "score": 0.9949589967727661
    }
  ],
  "10168": [
    {
      "answer": "Sharia",
      "score": 0.9604213237762451
    }
  ],
  "10169": [
    {
      "answer": "Wahhabism",
      "score": 0.9770532846450806
    },
    {
      "answer": "Osama bin Laden",
      "score": 0.9458104968070984
    }
  ],
  "10170": [
    {
      "answer": "Taliban",
      "score": 0.9652246236801147
    },
    {
      "answer": "Taliban",
      "score": 0.8082787394523621
    }
  ],
  "10171": [
    {
      "answer": "Pakistan",
      "score": 0.9861970543861389
    }
  ],
  "10172": [
    {
      "answer": "Islamic fundamentalist",
      "score": 0.994152307510376
    },
    {
      "answer": "neofundamentalist",
      "score": 0.9819979071617126
    }
  ],
  "10173": [
    {
      "answer": "Sharia",
      "score": 0.9485691785812378
    }
  ],
  "10174": [
    {
      "answer": "Wahhabism",
      "score": 0.9641485214233398
    },
    {
      "answer": "Osama bin Laden",
      "score": 0.9374961853027344
    }
  ],
  "10175": [
    {
      "answer": "July 1977",
      "score": 0.9773051142692566
    }
  ],
  "10176": [
    {
      "answer": "alcohol and nightclubs",
      "score": 0.9171991348266602
    }
  ],
  "10177": [
    {
      "answer": "Islamism",
      "score": 0.8833429217338562
    },
    {
      "answer": "Islamization",
      "score": 0.564383327960968
    },
    {
      "answer": "Islamism",
      "score": 0.9548733234405518
    }
  ],
  "10178": [
    {
      "answer": "his means of seizing power",
      "score": 0.8366824388504028
    }
  ],
  "10179": [
    {
      "answer": "1988",
      "score": 0.9871342778205872
    }
  ],
  "10180": [
    {
      "answer": "July 1977",
      "score": 0.9686132669448853
    }
  ],
  "10181": [
    {
      "answer": "banning alcohol and nightclubs",
      "score": 0.9682459235191345
    }
  ],
  "10182": [],
  "10183": [
    {
      "answer": "symbols",
      "score": 0.838927686214447
    }
  ],
  "10184": [
    {
      "answer": "July 1977",
      "score": 0.9653850793838501
    }
  ],
  "10185": [
    {
      "answer": "Wahhabi/Salafi jihadist extremist militant",
      "score": 0.9846570491790771
    }
  ],
  "10186": [
    {
      "answer": "Sunni Arabs",
      "score": 0.9162298440933228
    }
  ],
  "10187": [
    {
      "answer": "caliphate",
      "score": 0.9845257997512817
    }
  ],
  "10188": [
    {
      "answer": "ten million",
      "score": 0.9865107536315918
    }
  ],
  "10189": [
    {
      "answer": "recognition",
      "score": 0.9874782562255859
    }
  ],
  "10190": [
    {
      "answer": "Wahhabi/Salafi jihadist extremist militant",
      "score": 0.9780373573303223
    }
  ],
  "10191": [],
  "10192": [
    {
      "answer": "caliphate",
      "score": 0.8570151329040527
    }
  ],
  "10193": [
    {
      "answer": "ten million",
      "score": 0.9862462282180786
    }
  ],
  "10194": [
    {
      "answer": "lacks international recognition",
      "score": 0.7949036955833435
    }
  ],
  "10195": [
    {
      "answer": "2004",
      "score": 0.9880950450897217
    }
  ],
  "10196": [
    {
      "answer": "March 2003",
      "score": 0.9943952560424805
    }
  ],
  "10197": [
    {
      "answer": "March 2011",
      "score": 0.9937974810600281
    }
  ],
  "10198": [
    {
      "answer": "failure to consult",
      "score": 0.9641852378845215
    }
  ],
  "10199": [
    {
      "answer": "terrorist organisation",
      "score": 0.9776486158370972
    }
  ],
  "10200": [
    {
      "answer": "2014",
      "score": 0.9643910527229309
    },
    {
      "answer": "2014",
      "score": 0.7960013747215271
    }
  ],
  "10201": [
    {
      "answer": "March 2003",
      "score": 0.9840859174728394
    }
  ],
  "10202": [
    {
      "answer": "March 2011",
      "score": 0.974428653717041
    }
  ],
  "10203": [],
  "10204": [],
  "10205": [
    {
      "answer": "7th century",
      "score": 0.9566172361373901
    }
  ],
  "10206": [
    {
      "answer": "1924",
      "score": 0.9959119558334351
    }
  ],
  "10207": [
    {
      "answer": "true Islamic",
      "score": 0.9769487380981445
    }
  ],
  "10208": [
    {
      "answer": "abolition of the Ottoman Caliphate",
      "score": 0.9917520880699158
    }
  ],
  "10209": [
    {
      "answer": "the abolition of the Ottoman Caliphate in 1924",
      "score": 0.8869805335998535
    }
  ],
  "10210": [
    {
      "answer": "1924",
      "score": 0.9557397365570068
    }
  ],
  "10211": [
    {
      "answer": "1924",
      "score": 0.9950090646743774
    }
  ],
  "10212": [
    {
      "answer": "true Islamic",
      "score": 0.9784719944000244
    }
  ],
  "10213": [
    {
      "answer": "abolition of the Ottoman Caliphate",
      "score": 0.9622840285301208
    }
  ],
  "10214": [
    {
      "answer": "armed",
      "score": 0.9874811768531799
    }
  ],
  "10215": [
    {
      "answer": "ideological struggle",
      "score": 0.9782196283340454
    }
  ],
  "10216": [
    {
      "answer": "elites",
      "score": 0.9924633502960205
    }
  ],
  "10217": [
    {
      "answer": "Egypt",
      "score": 0.9803066849708557
    }
  ],
  "10218": [
    {
      "answer": "terrorist groups",
      "score": 0.984546422958374
    }
  ],
  "10219": [
    {
      "answer": "ideological struggle",
      "score": 0.7966451644897461
    }
  ],
  "10220": [
    {
      "answer": "ideological struggle",
      "score": 0.8942372798919678
    }
  ],
  "10221": [
    {
      "answer": "elites",
      "score": 0.9910652041435242
    }
  ],
  "10222": [
    {
      "answer": "Egypt",
      "score": 0.9767506122589111
    }
  ],
  "10223": [
    {
      "answer": "coups",
      "score": 0.8081787824630737
    }
  ],
  "10224": [
    {
      "answer": "900,000",
      "score": 0.9728817343711853
    }
  ],
  "10225": [
    {
      "answer": "Islamist",
      "score": 0.9929563999176025
    }
  ],
  "10226": [
    {
      "answer": "2007",
      "score": 0.991727352142334
    }
  ],
  "10227": [
    {
      "answer": "Londonistan",
      "score": 0.988623857498169
    }
  ],
  "10228": [
    {
      "answer": "incitement to terrorism",
      "score": 0.9962471723556519
    }
  ],
  "10229": [
    {
      "answer": "900,000",
      "score": 0.7159347534179688
    }
  ],
  "10230": [
    {
      "answer": "Islamist",
      "score": 0.9903980493545532
    }
  ],
  "10231": [
    {
      "answer": "2007",
      "score": 0.9930960536003113
    }
  ],
  "10232": [
    {
      "answer": "Londonistan",
      "score": 0.9932899475097656
    }
  ],
  "10233": [
    {
      "answer": "incitement to terrorism",
      "score": 0.9965702295303345
    }
  ],
  "10234": [
    {
      "answer": "2001",
      "score": 0.9916356801986694
    }
  ],
  "10235": [
    {
      "answer": "State Department",
      "score": 0.9849450588226318
    }
  ],
  "10236": [
    {
      "answer": "Christian Whiton",
      "score": 0.99505615234375
    }
  ],
  "10237": [
    {
      "answer": "Defense Secretary",
      "score": 0.9625154733657837
    }
  ],
  "10238": [
    {
      "answer": "undermining the communist ideology",
      "score": 0.9874612092971802
    }
  ],
  "10239": [
    {
      "answer": "2001",
      "score": 0.9699305295944214
    }
  ],
  "10240": [
    {
      "answer": "State Department",
      "score": 0.985798716545105
    }
  ],
  "10241": [
    {
      "answer": "Christian Whiton",
      "score": 0.9727535247802734
    }
  ],
  "10242": [
    {
      "answer": "Defense Secretary",
      "score": 0.9720379114151001
    }
  ],
  "10243": [
    {
      "answer": "undermining the communist ideology",
      "score": 0.9912009835243225
    }
  ],
  "10244": [
    {
      "answer": "Latin",
      "score": 0.9917213320732117
    }
  ],
  "10245": [
    {
      "answer": "colonization",
      "score": 0.8264368176460266
    },
    {
      "answer": "military force",
      "score": 0.9701857566833496
    }
  ],
  "10246": [
    {
      "answer": "Japanese",
      "score": 0.8865129947662354
    }
  ],
  "10247": [
    {
      "answer": "technologies and ideas",
      "score": 0.9835020899772644
    }
  ],
  "10248": [
    {
      "answer": "Latin",
      "score": 0.984043538570404
    }
  ],
  "10249": [
    {
      "answer": "colonization",
      "score": 0.6338134407997131
    },
    {
      "answer": "military force",
      "score": 0.9079768657684326
    }
  ],
  "10250": [
    {
      "answer": "19th",
      "score": 0.9843969941139221
    },
    {
      "answer": "20th",
      "score": 0.8380205035209656
    }
  ],
  "10251": [
    {
      "answer": "Asia and Africa",
      "score": 0.7122628092765808
    }
  ],
  "10252": [
    {
      "answer": "technologies and ideas",
      "score": 0.9703758955001831
    }
  ],
  "10253": [
    {
      "answer": "influence",
      "score": 0.9718429446220398
    }
  ],
  "10254": [
    {
      "answer": "formal",
      "score": 0.5556629300117493
    },
    {
      "answer": "Formal imperialism",
      "score": 0.9007216691970825
    }
  ],
  "10255": [
    {
      "answer": "othering",
      "score": 0.9816129207611084
    }
  ],
  "10256": [
    {
      "answer": "less direct",
      "score": 0.8891723155975342
    }
  ],
  "10257": [],
  "10258": [
    {
      "answer": "Formal imperialism",
      "score": 0.8365244269371033
    }
  ],
  "10259": [
    {
      "answer": "another group of people",
      "score": 0.6224247217178345
    }
  ],
  "10260": [
    {
      "answer": "othering",
      "score": 0.9469069838523865
    }
  ],
  "10261": [
    {
      "answer": "dominance",
      "score": 0.8978152871131897
    }
  ],
  "10262": [],
  "10263": [
    {
      "answer": "formal",
      "score": 0.911189079284668
    },
    {
      "answer": "informal",
      "score": 0.8169007897377014
    }
  ],
  "10264": [
    {
      "answer": "general-purpose aggressiveness",
      "score": 0.8906166553497314
    }
  ],
  "10265": [
    {
      "answer": "Informal rule",
      "score": 0.981087863445282
    },
    {
      "answer": "informal rule",
      "score": 0.6601055264472961
    }
  ],
  "10266": [
    {
      "answer": "technological superiority",
      "score": 0.9778525829315186
    },
    {
      "answer": "enforcing land officials into large debts that cannot be repaid",
      "score": 0.6621858477592468
    }
  ],
  "10267": [],
  "10268": [
    {
      "answer": "formal",
      "score": 0.7675569653511047
    },
    {
      "answer": "informal",
      "score": 0.6809302568435669
    }
  ],
  "10269": [
    {
      "answer": "general-purpose aggressiveness",
      "score": 0.7831336259841919
    }
  ],
  "10270": [
    {
      "answer": "Informal rule",
      "score": 0.9769656658172607
    },
    {
      "answer": "informal rule",
      "score": 0.7429660558700562
    }
  ],
  "10271": [
    {
      "answer": "technological superiority",
      "score": 0.9702406525611877
    },
    {
      "answer": "enforcing land officials into large debts that cannot be repaid",
      "score": 0.6250633597373962
    },
    {
      "answer": "ownership of private industries",
      "score": 0.6716235876083374
    }
  ],
  "10272": [],
  "10273": [
    {
      "answer": "world systems theory",
      "score": 0.9953603744506836
    }
  ],
  "10274": [
    {
      "answer": "Lenin",
      "score": 0.9868727922439575
    },
    {
      "answer": "Lenin",
      "score": 0.6076204776763916
    }
  ],
  "10275": [],
  "10276": [
    {
      "answer": "sea",
      "score": 0.6830218434333801
    },
    {
      "answer": "overland",
      "score": 0.6386257410049438
    },
    {
      "answer": "sea",
      "score": 0.5201796889305115
    }
  ],
  "10277": [],
  "10278": [],
  "10279": [
    {
      "answer": "Lenin",
      "score": 0.982451856136322
    },
    {
      "answer": "Lenin",
      "score": 0.5860592126846313
    }
  ],
  "10280": [],
  "10281": [
    {
      "answer": "sea",
      "score": 0.6669037342071533
    },
    {
      "answer": "sea",
      "score": 0.5573750138282776
    }
  ],
  "10282": [
    {
      "answer": "colonialism",
      "score": 0.9761837720870972
    },
    {
      "answer": "colonialism",
      "score": 0.8450548648834229
    },
    {
      "answer": "colonialism",
      "score": 0.8761920928955078
    },
    {
      "answer": "Colonialism",
      "score": 0.6794777512550354
    },
    {
      "answer": "colonialism",
      "score": 0.8121169805526733
    },
    {
      "answer": "colonialism",
      "score": 0.8414404988288879
    },
    {
      "answer": "colonialism",
      "score": 0.8798217177391052
    },
    {
      "answer": "colonialism",
      "score": 0.8925530314445496
    },
    {
      "answer": "colonialism",
      "score": 0.8589665293693542
    }
  ],
  "10283": [
    {
      "answer": "political focus",
      "score": 0.9891518354415894
    }
  ],
  "10284": [
    {
      "answer": "ideological",
      "score": 0.9515052437782288
    }
  ],
  "10285": [
    {
      "answer": "Ottoman",
      "score": 0.9740150570869446
    }
  ],
  "10286": [],
  "10287": [
    {
      "answer": "colonialism",
      "score": 0.9622950553894043
    },
    {
      "answer": "colonialism",
      "score": 0.8414021134376526
    },
    {
      "answer": "colonialism",
      "score": 0.8756192326545715
    },
    {
      "answer": "Colonialism",
      "score": 0.6442671418190002
    },
    {
      "answer": "colonialism",
      "score": 0.811219334602356
    },
    {
      "answer": "colonialism",
      "score": 0.8207149505615234
    },
    {
      "answer": "colonialism",
      "score": 0.8668364882469177
    },
    {
      "answer": "colonialism",
      "score": 0.9064502716064453
    },
    {
      "answer": "colonialism",
      "score": 0.841853678226471
    }
  ],
  "10288": [],
  "10289": [
    {
      "answer": "ideological",
      "score": 0.8791260123252869
    }
  ],
  "10290": [
    {
      "answer": "Ottoman",
      "score": 0.9518845081329346
    }
  ],
  "10291": [
    {
      "answer": "political focus",
      "score": 0.8592253923416138
    }
  ],
  "10292": [
    {
      "answer": "Imperialism",
      "score": 0.888898491859436
    },
    {
      "answer": "colonialism",
      "score": 0.8536935448646545
    }
  ],
  "10293": [],
  "10294": [
    {
      "answer": "conquering the other state's lands and therefore increasing its own dominance",
      "score": 0.9382814764976501
    }
  ],
  "10295": [
    {
      "answer": "characteristics",
      "score": 0.9602009057998657
    }
  ],
  "10296": [
    {
      "answer": "the exploitation of the valuable assets and supplies of the nation that was conquered and the conquering nation then gaining the benefits from the spoils of the war",
      "score": 0.9644978642463684
    }
  ],
  "10297": [
    {
      "answer": "Imperialism",
      "score": 0.8942602276802063
    },
    {
      "answer": "colonialism",
      "score": 0.8549937605857849
    }
  ],
  "10298": [],
  "10299": [],
  "10300": [],
  "10301": [
    {
      "answer": "Imperialism",
      "score": 0.6202792525291443
    },
    {
      "answer": "imperialism",
      "score": 0.6802679896354675
    },
    {
      "answer": "imperialism",
      "score": 0.7611722350120544
    },
    {
      "answer": "imperialism",
      "score": 0.6829714775085449
    },
    {
      "answer": "imperialism",
      "score": 0.7954595685005188
    }
  ],
  "10302": [
    {
      "answer": "the defense and justification of empire-building based on seemingly rational grounds",
      "score": 0.9602946043014526
    }
  ],
  "10303": [
    {
      "answer": "the races which can do this work best",
      "score": 0.9540375471115112
    }
  ],
  "10304": [
    {
      "answer": "imperialism",
      "score": 0.7697394490242004
    },
    {
      "answer": "imperialism",
      "score": 0.7959758639335632
    },
    {
      "answer": "imperialism",
      "score": 0.9790576696395874
    },
    {
      "answer": "imperialism",
      "score": 0.7012959718704224
    },
    {
      "answer": "imperialism",
      "score": 0.7671828269958496
    }
  ],
  "10305": [
    {
      "answer": "Social Darwinism",
      "score": 0.9848333597183228
    }
  ],
  "10306": [
    {
      "answer": "whiteness",
      "score": 0.9947372078895569
    }
  ],
  "10307": [],
  "10308": [
    {
      "answer": "the races which can do this work best",
      "score": 0.9542427062988281
    }
  ],
  "10309": [
    {
      "answer": "imperialism",
      "score": 0.6929706931114197
    },
    {
      "answer": "imperialism",
      "score": 0.7413183450698853
    },
    {
      "answer": "imperialism",
      "score": 0.9509554505348206
    },
    {
      "answer": "imperialism",
      "score": 0.7164615392684937
    },
    {
      "answer": "imperialism",
      "score": 0.7620499730110168
    }
  ],
  "10310": [
    {
      "answer": "Social Darwinism",
      "score": 0.9672872424125671
    }
  ],
  "10311": [
    {
      "answer": "whiteness",
      "score": 0.9941198825836182
    }
  ],
  "10312": [
    {
      "answer": "Germany",
      "score": 0.9904054999351501
    }
  ],
  "10313": [
    {
      "answer": "Britain",
      "score": 0.9742940068244934
    },
    {
      "answer": "Britain",
      "score": 0.8148916363716125
    }
  ],
  "10314": [
    {
      "answer": "Political geographers",
      "score": 0.9139114618301392
    }
  ],
  "10315": [
    {
      "answer": "survival",
      "score": 0.949601948261261
    }
  ],
  "10316": [
    {
      "answer": "fund travelers who would come back with tales of their discoveries",
      "score": 0.8860600590705872
    }
  ],
  "10317": [
    {
      "answer": "Germany",
      "score": 0.9890073537826538
    }
  ],
  "10318": [
    {
      "answer": "Britain",
      "score": 0.9825244545936584
    },
    {
      "answer": "Britain",
      "score": 0.8532793521881104
    }
  ],
  "10319": [
    {
      "answer": "Political geographers",
      "score": 0.9814571142196655
    }
  ],
  "10320": [
    {
      "answer": "expansion was necessary for a state\u2019s survival",
      "score": 0.7149806618690491
    }
  ],
  "10321": [],
  "10322": [
    {
      "answer": "environmental determinism",
      "score": 0.9940049052238464
    }
  ],
  "10323": [
    {
      "answer": "temperate",
      "score": 0.9970752000808716
    }
  ],
  "10324": [
    {
      "answer": "Orientalism",
      "score": 0.9957791566848755
    },
    {
      "answer": "orientalism",
      "score": 0.7982047200202942
    }
  ],
  "10325": [
    {
      "answer": "uncivilized people",
      "score": 0.9388606548309326
    }
  ],
  "10326": [
    {
      "answer": "superior",
      "score": 0.9907241463661194
    }
  ],
  "10327": [
    {
      "answer": "environmental determinism",
      "score": 0.968814492225647
    }
  ],
  "10328": [
    {
      "answer": "temperate",
      "score": 0.997081458568573
    }
  ],
  "10329": [
    {
      "answer": "Orientalism",
      "score": 0.995525062084198
    },
    {
      "answer": "orientalism",
      "score": 0.8067083954811096
    }
  ],
  "10330": [],
  "10331": [
    {
      "answer": "other",
      "score": 0.8903158903121948
    }
  ],
  "10332": [
    {
      "answer": "British",
      "score": 0.7397690415382385
    },
    {
      "answer": "British",
      "score": 0.5743535161018372
    }
  ],
  "10333": [
    {
      "answer": "Terra nullius",
      "score": 0.9934359192848206
    },
    {
      "answer": "terra nullius",
      "score": 0.9071892499923706
    }
  ],
  "10334": [
    {
      "answer": "Aboriginal",
      "score": 0.9928985834121704
    }
  ],
  "10335": [
    {
      "answer": "eighteenth century",
      "score": 0.9606568813323975
    }
  ],
  "10336": [
    {
      "answer": "empty land",
      "score": 0.9918702244758606
    }
  ],
  "10337": [],
  "10338": [
    {
      "answer": "Terra nullius",
      "score": 0.9090776443481445
    },
    {
      "answer": "terra nullius",
      "score": 0.9005600214004517
    }
  ],
  "10339": [],
  "10340": [
    {
      "answer": "eighteenth century",
      "score": 0.9575112462043762
    }
  ],
  "10341": [
    {
      "answer": "empty land",
      "score": 0.9823769330978394
    }
  ],
  "10342": [
    {
      "answer": "imaginative geography",
      "score": 0.9927772879600525
    },
    {
      "answer": "imaginative geography",
      "score": 0.5561044216156006
    }
  ],
  "10343": [
    {
      "answer": "irrational and backward",
      "score": 0.9858580827713013
    }
  ],
  "10344": [
    {
      "answer": "irrational and backward",
      "score": 0.9888884425163269
    }
  ],
  "10345": [
    {
      "answer": "Orientalism",
      "score": 0.9583374857902527
    }
  ],
  "10346": [
    {
      "answer": "irrational and backward",
      "score": 0.9019057154655457
    },
    {
      "answer": "inferior",
      "score": 0.5756086707115173
    }
  ],
  "10347": [
    {
      "answer": "imaginative geography",
      "score": 0.9757864475250244
    }
  ],
  "10348": [
    {
      "answer": "irrational and backward",
      "score": 0.9825476408004761
    }
  ],
  "10349": [
    {
      "answer": "irrational and backward",
      "score": 0.8991881608963013
    }
  ],
  "10350": [
    {
      "answer": "Orientalism",
      "score": 0.9659862518310547
    }
  ],
  "10351": [
    {
      "answer": "irrational and backward",
      "score": 0.8851757049560547
    },
    {
      "answer": "inferior",
      "score": 0.5943341255187988
    }
  ],
  "10352": [
    {
      "answer": "role of nineteenth-century maps during the \"scramble for Africa\"",
      "score": 0.924619197845459
    }
  ],
  "10353": [
    {
      "answer": "blank space",
      "score": 0.9866805076599121
    }
  ],
  "10354": [
    {
      "answer": "to denote unknown or unexplored territory",
      "score": 0.9313609004020691
    }
  ],
  "10355": [
    {
      "answer": "the role of nineteenth-century maps during the \"scramble for Africa\"",
      "score": 0.7067455053329468
    }
  ],
  "10356": [
    {
      "answer": "French",
      "score": 0.9883528351783752
    }
  ],
  "10357": [],
  "10358": [
    {
      "answer": "blank space",
      "score": 0.9873475432395935
    }
  ],
  "10359": [
    {
      "answer": "the role of nineteenth-century maps during the \"scramble for Africa\"",
      "score": 0.6813836097717285
    }
  ],
  "10360": [
    {
      "answer": "French",
      "score": 0.9650747179985046
    },
    {
      "answer": "British",
      "score": 0.6040443181991577
    }
  ],
  "10361": [
    {
      "answer": "Genghis Khan",
      "score": 0.9913569092750549
    }
  ],
  "10362": [
    {
      "answer": "pre-Columbian",
      "score": 0.9961293935775757
    }
  ],
  "10363": [
    {
      "answer": "Sub-Saharan Africa",
      "score": 0.9877983927726746
    }
  ],
  "10364": [
    {
      "answer": "dozens",
      "score": 0.9694088697433472
    }
  ],
  "10365": [],
  "10366": [
    {
      "answer": "Genghis Khan",
      "score": 0.9748338460922241
    }
  ],
  "10367": [
    {
      "answer": "pre-Columbian",
      "score": 0.9921371340751648
    }
  ],
  "10368": [
    {
      "answer": "Sub-Saharan Africa",
      "score": 0.9822800159454346
    }
  ],
  "10369": [
    {
      "answer": "dozens",
      "score": 0.6745124459266663
    }
  ],
  "10370": [],
  "10371": [
    {
      "answer": "Cultural imperialism",
      "score": 0.9268280267715454
    }
  ],
  "10372": [
    {
      "answer": "soft power",
      "score": 0.7929937839508057
    }
  ],
  "10373": [
    {
      "answer": "Dallas",
      "score": 0.9948124885559082
    }
  ],
  "10374": [
    {
      "answer": "Roman",
      "score": 0.9908487796783447
    },
    {
      "answer": "Roman",
      "score": 0.5769358277320862
    }
  ],
  "10375": [
    {
      "answer": "bans on foreign popular culture",
      "score": 0.9917417764663696
    },
    {
      "answer": "control of the internet and unauthorised satellite dishes",
      "score": 0.9886677861213684
    }
  ],
  "10376": [
    {
      "answer": "Cultural imperialism",
      "score": 0.5870053768157959
    }
  ],
  "10377": [
    {
      "answer": "Roman imperialism",
      "score": 0.8252205848693848
    }
  ],
  "10378": [
    {
      "answer": "Dallas",
      "score": 0.944922685623169
    }
  ],
  "10379": [
    {
      "answer": "Roman",
      "score": 0.9915620684623718
    }
  ],
  "10380": [
    {
      "answer": "bans on foreign popular culture",
      "score": 0.9457190632820129
    }
  ],
  "10381": [
    {
      "answer": "1700",
      "score": 0.9941678047180176
    }
  ],
  "10382": [
    {
      "answer": "engaging in the process of colonizing, influencing, and annexing other parts of the world",
      "score": 0.7954984903335571
    }
  ],
  "10383": [
    {
      "answer": "thousands of years",
      "score": 0.9717669486999512
    }
  ],
  "10384": [
    {
      "answer": "middle of the 20th century",
      "score": 0.9368225336074829
    }
  ],
  "10385": [
    {
      "answer": "Open Door Policy",
      "score": 0.9224822521209717
    }
  ],
  "10386": [
    {
      "answer": "middle of the 20th century",
      "score": 0.9495989680290222
    }
  ],
  "10387": [],
  "10388": [
    {
      "answer": "thousands of years",
      "score": 0.9120907783508301
    }
  ],
  "10389": [
    {
      "answer": "1700",
      "score": 0.9941567182540894
    }
  ],
  "10390": [
    {
      "answer": "Open Door Policy",
      "score": 0.9137886762619019
    }
  ],
  "10391": [
    {
      "answer": "1919",
      "score": 0.9961196184158325
    }
  ],
  "10392": [
    {
      "answer": "1920",
      "score": 0.8815121650695801
    },
    {
      "answer": "1999",
      "score": 0.9865614771842957
    }
  ],
  "10393": [
    {
      "answer": "historians",
      "score": 0.9721271991729736
    },
    {
      "answer": "historians",
      "score": 0.8179550766944885
    }
  ],
  "10394": [
    {
      "answer": "the world's economy",
      "score": 0.8428316116333008
    }
  ],
  "10395": [],
  "10396": [
    {
      "answer": "John Gallagher",
      "score": 0.7831050157546997
    },
    {
      "answer": "Ronald Robinson",
      "score": 0.734809160232544
    }
  ],
  "10397": [
    {
      "answer": "historians",
      "score": 0.8737117648124695
    },
    {
      "answer": "historians",
      "score": 0.5294123888015747
    }
  ],
  "10398": [
    {
      "answer": "economy",
      "score": 0.9489640593528748
    }
  ],
  "10399": [
    {
      "answer": "imperial powers",
      "score": 0.9860315322875977
    }
  ],
  "10400": [
    {
      "answer": "economic growth",
      "score": 0.9938238263130188
    }
  ],
  "10401": [
    {
      "answer": "economic growth",
      "score": 0.9679845571517944
    }
  ],
  "10402": [
    {
      "answer": "mid-18th century",
      "score": 0.9708850383758545
    }
  ],
  "10403": [
    {
      "answer": "Mughal state",
      "score": 0.9738193154335022
    }
  ],
  "10404": [
    {
      "answer": "economic growth",
      "score": 0.9673112630844116
    }
  ],
  "10405": [
    {
      "answer": "colonies",
      "score": 0.8073066473007202
    }
  ],
  "10406": [
    {
      "answer": "mid-18th century",
      "score": 0.9632583856582642
    }
  ],
  "10407": [
    {
      "answer": "Mughal state",
      "score": 0.9720343351364136
    }
  ],
  "10408": [
    {
      "answer": "this idea is not necessarily valid:",
      "score": 0.792999804019928
    }
  ],
  "10409": [
    {
      "answer": "communication",
      "score": 0.7906618118286133
    }
  ],
  "10410": [
    {
      "answer": "deadly explosives",
      "score": 0.9675557017326355
    }
  ],
  "10411": [
    {
      "answer": "machine gun",
      "score": 0.9919022917747498
    }
  ],
  "10412": [
    {
      "answer": "arrows",
      "score": 0.7431821823120117
    },
    {
      "answer": "swords",
      "score": 0.7301352024078369
    },
    {
      "answer": "leather shields",
      "score": 0.6689326763153076
    }
  ],
  "10413": [
    {
      "answer": "Europe",
      "score": 0.9832245111465454
    }
  ],
  "10414": [
    {
      "answer": "communication",
      "score": 0.7973430752754211
    }
  ],
  "10415": [
    {
      "answer": "deadly explosives",
      "score": 0.8356416821479797
    }
  ],
  "10416": [
    {
      "answer": "machine gun",
      "score": 0.9618024826049805
    }
  ],
  "10417": [],
  "10418": [
    {
      "answer": "Europe",
      "score": 0.5643980503082275
    },
    {
      "answer": "Southern Africa",
      "score": 0.5879805684089661
    }
  ],
  "10419": [
    {
      "answer": "British",
      "score": 0.9930166006088257
    },
    {
      "answer": "British",
      "score": 0.8956491947174072
    }
  ],
  "10420": [
    {
      "answer": "1870s",
      "score": 0.9913711547851562
    }
  ],
  "10421": [
    {
      "answer": "idealism and philanthropy",
      "score": 0.9714127779006958
    }
  ],
  "10422": [
    {
      "answer": "need for capitalist economies to constantly expand investment, material resources and manpower",
      "score": 0.9511239528656006
    }
  ],
  "10423": [
    {
      "answer": "British",
      "score": 0.968193769454956
    },
    {
      "answer": "British",
      "score": 0.6373750567436218
    }
  ],
  "10424": [
    {
      "answer": "1870s",
      "score": 0.9884495735168457
    }
  ],
  "10425": [
    {
      "answer": "idealism and philanthropy",
      "score": 0.9548441767692566
    }
  ],
  "10426": [
    {
      "answer": "need for capitalist economies to constantly expand investment, material resources and manpower",
      "score": 0.9532853960990906
    }
  ],
  "10427": [],
  "10428": [
    {
      "answer": "aristocracy",
      "score": 0.928503155708313
    }
  ],
  "10429": [
    {
      "answer": "before World War I",
      "score": 0.9843411445617676
    }
  ],
  "10430": [
    {
      "answer": "1950s",
      "score": 0.9932112097740173
    }
  ],
  "10431": [],
  "10432": [
    {
      "answer": "domestic social reforms could cure the international disease of imperialism by removing its economic foundation",
      "score": 0.9089503288269043
    },
    {
      "answer": "state intervention through taxation",
      "score": 0.7317360639572144
    }
  ],
  "10433": [
    {
      "answer": "aristocracy",
      "score": 0.8765213489532471
    }
  ],
  "10434": [
    {
      "answer": "before World War I",
      "score": 0.9715336561203003
    }
  ],
  "10435": [
    {
      "answer": "1950s",
      "score": 0.9930123686790466
    }
  ],
  "10436": [
    {
      "answer": "domestic social reforms could cure the international disease of imperialism by removing its economic foundation",
      "score": 0.7352777123451233
    }
  ],
  "10437": [
    {
      "answer": "state intervention through taxation",
      "score": 0.841558575630188
    }
  ],
  "10438": [
    {
      "answer": "environmental determinism",
      "score": 0.9962583184242249
    },
    {
      "answer": "environmental determinism",
      "score": 0.9685689210891724
    }
  ],
  "10439": [
    {
      "answer": "environment in which they lived",
      "score": 0.9217318892478943
    }
  ],
  "10440": [
    {
      "answer": "less civilized",
      "score": 0.9962242841720581
    }
  ],
  "10441": [
    {
      "answer": "Africa",
      "score": 0.9779407978057861
    }
  ],
  "10442": [
    {
      "answer": "orientalism",
      "score": 0.9949519634246826
    },
    {
      "answer": "tropicality",
      "score": 0.9938881993293762
    }
  ],
  "10443": [
    {
      "answer": "environmental determinism",
      "score": 0.9735633730888367
    },
    {
      "answer": "environmental determinism",
      "score": 0.8953991532325745
    }
  ],
  "10444": [
    {
      "answer": "environment in which they lived",
      "score": 0.7869526147842407
    }
  ],
  "10445": [
    {
      "answer": "less civilized",
      "score": 0.9933637976646423
    }
  ],
  "10446": [
    {
      "answer": "Africa",
      "score": 0.9739733934402466
    }
  ],
  "10447": [
    {
      "answer": "orientalism",
      "score": 0.9814090728759766
    },
    {
      "answer": "tropicality",
      "score": 0.9841667413711548
    }
  ],
  "10448": [
    {
      "answer": "geographic scholars",
      "score": 0.9872807860374451
    }
  ],
  "10449": [
    {
      "answer": "Northern Europe",
      "score": 0.9949101209640503
    },
    {
      "answer": "Mid-Atlantic",
      "score": 0.9686229825019836
    }
  ],
  "10450": [
    {
      "answer": "guidance and intervention",
      "score": 0.989599883556366
    }
  ],
  "10451": [
    {
      "answer": "orientalism",
      "score": 0.9952397346496582
    }
  ],
  "10452": [
    {
      "answer": "colonizing empires",
      "score": 0.9817442893981934
    }
  ],
  "10453": [
    {
      "answer": "geographic scholars",
      "score": 0.9621274471282959
    }
  ],
  "10454": [
    {
      "answer": "tropical",
      "score": 0.9609118700027466
    }
  ],
  "10455": [
    {
      "answer": "guidance",
      "score": 0.9357860684394836
    }
  ],
  "10456": [
    {
      "answer": "orientalism",
      "score": 0.9935476183891296
    }
  ],
  "10457": [
    {
      "answer": "colonizing empires",
      "score": 0.896801769733429
    }
  ],
  "10458": [
    {
      "answer": "sixteenth century",
      "score": 0.9774633049964905
    }
  ],
  "10459": [
    {
      "answer": "1599",
      "score": 0.9940043091773987
    }
  ],
  "10460": [
    {
      "answer": "Queen Elizabeth",
      "score": 0.9950313568115234
    }
  ],
  "10461": [
    {
      "answer": "almost bringing the company into bankruptcy",
      "score": 0.891305148601532
    }
  ],
  "10462": [
    {
      "answer": "Portuguese",
      "score": 0.9929206967353821
    }
  ],
  "10463": [
    {
      "answer": "sixteenth century",
      "score": 0.5835491418838501
    },
    {
      "answer": "1599",
      "score": 0.7491564750671387
    }
  ],
  "10464": [
    {
      "answer": "1599",
      "score": 0.9910129904747009
    }
  ],
  "10465": [
    {
      "answer": "Queen Elizabeth",
      "score": 0.9562114477157593
    }
  ],
  "10466": [
    {
      "answer": "almost bringing the company into bankruptcy",
      "score": 0.8127774000167847
    }
  ],
  "10467": [
    {
      "answer": "Portuguese",
      "score": 0.9823338985443115
    }
  ],
  "10468": [
    {
      "answer": "1830",
      "score": 0.9878585338592529
    }
  ],
  "10469": [
    {
      "answer": "1850",
      "score": 0.9940086603164673
    }
  ],
  "10470": [
    {
      "answer": "North and West Africa",
      "score": 0.9879052639007568
    },
    {
      "answer": "South-East Asia",
      "score": 0.9610856771469116
    },
    {
      "answer": "Central and East Africa",
      "score": 0.7920624017715454
    },
    {
      "answer": "South Pacific",
      "score": 0.6852871179580688
    }
  ],
  "10471": [
    {
      "answer": "1850",
      "score": 0.9828485250473022
    }
  ],
  "10472": [
    {
      "answer": "Catholicism",
      "score": 0.9962002635002136
    }
  ],
  "10473": [
    {
      "answer": "1830",
      "score": 0.6012710928916931
    },
    {
      "answer": "1850",
      "score": 0.9317932724952698
    }
  ],
  "10474": [
    {
      "answer": "1850",
      "score": 0.9943135976791382
    }
  ],
  "10475": [
    {
      "answer": "North and West Africa",
      "score": 0.9894249439239502
    },
    {
      "answer": "South-East Asia",
      "score": 0.9571033716201782
    },
    {
      "answer": "Central and East Africa",
      "score": 0.6555774211883545
    }
  ],
  "10476": [
    {
      "answer": "1850",
      "score": 0.961534321308136
    }
  ],
  "10477": [
    {
      "answer": "Catholicism",
      "score": 0.9964391589164734
    }
  ],
  "10478": [
    {
      "answer": "civilize the inferior",
      "score": 0.9691116809844971
    }
  ],
  "10479": [
    {
      "answer": "Christianity and French culture",
      "score": 0.8732032775878906
    }
  ],
  "10480": [
    {
      "answer": "France sent small numbers of settlers to its colonies",
      "score": 0.9736355543136597
    }
  ],
  "10481": [
    {
      "answer": "Christianity and French culture",
      "score": 0.967075765132904
    }
  ],
  "10482": [
    {
      "answer": "Algeria",
      "score": 0.9806748032569885
    }
  ],
  "10483": [
    {
      "answer": "civilize the inferior",
      "score": 0.9419153928756714
    }
  ],
  "10484": [
    {
      "answer": "Christianity and French culture",
      "score": 0.7540868520736694
    }
  ],
  "10485": [
    {
      "answer": "France sent small numbers of settlers to its colonies",
      "score": 0.9435138702392578
    }
  ],
  "10486": [
    {
      "answer": "Christianity and French culture",
      "score": 0.9324625730514526
    }
  ],
  "10487": [
    {
      "answer": "overseas colonies",
      "score": 0.8559228181838989
    }
  ],
  "10488": [
    {
      "answer": "anti-colonial movements",
      "score": 0.995872974395752
    }
  ],
  "10489": [
    {
      "answer": "Vietnam",
      "score": 0.9906355738639832
    }
  ],
  "10490": [],
  "10491": [
    {
      "answer": "1960",
      "score": 0.9872074723243713
    }
  ],
  "10492": [
    {
      "answer": "overseas colonies",
      "score": 0.8402261734008789
    }
  ],
  "10493": [
    {
      "answer": "anti-colonial movements",
      "score": 0.9958634376525879
    }
  ],
  "10494": [
    {
      "answer": "Vietnam",
      "score": 0.9902400970458984
    }
  ],
  "10495": [
    {
      "answer": "Vietnam",
      "score": 0.9901671409606934
    }
  ],
  "10496": [
    {
      "answer": "Algeria",
      "score": 0.747973620891571
    }
  ],
  "10497": [
    {
      "answer": "Scandinavia",
      "score": 0.9834842085838318
    },
    {
      "answer": "northern Europe",
      "score": 0.9672220349311829
    }
  ],
  "10498": [
    {
      "answer": "middle period of classical antiquity",
      "score": 0.9674236178398132
    }
  ],
  "10499": [
    {
      "answer": "800 CE",
      "score": 0.8178653120994568
    },
    {
      "answer": "1000 CE",
      "score": 0.7814819812774658
    }
  ],
  "10500": [
    {
      "answer": "Muslim Iberia",
      "score": 0.992914617061615
    }
  ],
  "10501": [
    {
      "answer": "central Europe",
      "score": 0.9898707866668701
    }
  ],
  "10502": [
    {
      "answer": "Scandinavia",
      "score": 0.7459309101104736
    },
    {
      "answer": "northern Europe",
      "score": 0.7929583787918091
    }
  ],
  "10503": [
    {
      "answer": "middle period of classical antiquity",
      "score": 0.9301013946533203
    }
  ],
  "10504": [
    {
      "answer": "1000 CE",
      "score": 0.9568641185760498
    }
  ],
  "10505": [
    {
      "answer": "Muslim Iberia",
      "score": 0.9862595796585083
    }
  ],
  "10506": [
    {
      "answer": "late 19th century",
      "score": 0.9839316606521606
    }
  ],
  "10507": [
    {
      "answer": "1862",
      "score": 0.9944340586662292
    }
  ],
  "10508": [
    {
      "answer": "1862",
      "score": 0.6904952526092529
    }
  ],
  "10509": [
    {
      "answer": "Europe itself",
      "score": 0.9899256229400635
    }
  ],
  "10510": [
    {
      "answer": "Napoleon",
      "score": 0.9939921498298645
    }
  ],
  "10511": [
    {
      "answer": "late 19th century",
      "score": 0.9760206937789917
    }
  ],
  "10512": [
    {
      "answer": "1862",
      "score": 0.7568038702011108
    },
    {
      "answer": "90",
      "score": 0.9851008057594299
    }
  ],
  "10513": [
    {
      "answer": "late 19th century",
      "score": 0.6759732961654663
    }
  ],
  "10514": [
    {
      "answer": "Europe itself",
      "score": 0.9931014776229858
    }
  ],
  "10515": [
    {
      "answer": "Napoleon",
      "score": 0.9755433797836304
    }
  ],
  "10516": [
    {
      "answer": "South Pacific",
      "score": 0.9768975973129272
    }
  ],
  "10517": [
    {
      "answer": "German prestige",
      "score": 0.97358238697052
    }
  ],
  "10518": [
    {
      "answer": "Friedrichsruh",
      "score": 0.9834585189819336
    }
  ],
  "10519": [
    {
      "answer": "1883",
      "score": 0.6382161974906921
    },
    {
      "answer": "1884",
      "score": 0.8619199991226196
    }
  ],
  "10520": [
    {
      "answer": "Hamburg merchants and traders",
      "score": 0.995868980884552
    }
  ],
  "10521": [
    {
      "answer": "South Pacific",
      "score": 0.9559148550033569
    }
  ],
  "10522": [
    {
      "answer": "German prestige",
      "score": 0.9657847881317139
    }
  ],
  "10523": [
    {
      "answer": "Friedrichsruh",
      "score": 0.9807372093200684
    }
  ],
  "10524": [
    {
      "answer": "Hamburg merchants and traders",
      "score": 0.9925054907798767
    }
  ],
  "10525": [
    {
      "answer": "1894",
      "score": 0.9785349369049072
    }
  ],
  "10526": [
    {
      "answer": "Japan took part of Sakhalin Island from Russia",
      "score": 0.9766846895217896
    }
  ],
  "10527": [
    {
      "answer": "Manchuria",
      "score": 0.949603259563446
    }
  ],
  "10528": [
    {
      "answer": "Thailand",
      "score": 0.9874802231788635
    },
    {
      "answer": "Thai",
      "score": 0.8842368125915527
    }
  ],
  "10529": [
    {
      "answer": "1937",
      "score": 0.9746979475021362
    }
  ],
  "10530": [
    {
      "answer": "took part of Sakhalin Island from Russia",
      "score": 0.8806906342506409
    }
  ],
  "10531": [],
  "10532": [
    {
      "answer": "Thailand",
      "score": 0.97762531042099
    }
  ],
  "10533": [
    {
      "answer": "People\u2019s Republic of China",
      "score": 0.9176203012466431
    }
  ],
  "10534": [
    {
      "answer": "1932",
      "score": 0.9918034076690674
    }
  ],
  "10535": [
    {
      "answer": "Lenin",
      "score": 0.9916908740997314
    }
  ],
  "10536": [
    {
      "answer": "Eastern Europe",
      "score": 0.959925651550293
    }
  ],
  "10537": [
    {
      "answer": "Bolshevik leaders",
      "score": 0.9588662385940552
    }
  ],
  "10538": [
    {
      "answer": "Soviet Union",
      "score": 0.727957010269165
    },
    {
      "answer": "People\u2019s Republic of China",
      "score": 0.9186310768127441
    }
  ],
  "10539": [
    {
      "answer": "1923",
      "score": 0.9901309013366699
    }
  ],
  "10540": [
    {
      "answer": "Lenin",
      "score": 0.9472509622573853
    }
  ],
  "10541": [],
  "10542": [
    {
      "answer": "Lenin",
      "score": 0.9797081351280212
    }
  ],
  "10543": [
    {
      "answer": "socialism in one country",
      "score": 0.9885743856430054
    }
  ],
  "10544": [
    {
      "answer": "Nikita Khrushchev",
      "score": 0.9910564422607422
    }
  ],
  "10545": [
    {
      "answer": "Mao Zedong",
      "score": 0.9939795136451721
    }
  ],
  "10546": [],
  "10547": [
    {
      "answer": "Lenin",
      "score": 0.917614221572876
    },
    {
      "answer": "Lenin",
      "score": 0.5714914202690125
    }
  ],
  "10548": [
    {
      "answer": "socialism in one country",
      "score": 0.9846973419189453
    }
  ],
  "10549": [
    {
      "answer": "mercantilism",
      "score": 0.9951879978179932
    }
  ],
  "10550": [
    {
      "answer": "1776",
      "score": 0.9904571175575256
    }
  ],
  "10551": [
    {
      "answer": "1820",
      "score": 0.9907035827636719
    }
  ],
  "10552": [
    {
      "answer": "free trade",
      "score": 0.9922087788581848
    }
  ],
  "10553": [
    {
      "answer": "1815",
      "score": 0.9889646768569946
    }
  ],
  "10554": [
    {
      "answer": "mercantilism",
      "score": 0.9859747290611267
    }
  ],
  "10555": [
    {
      "answer": "1820",
      "score": 0.785233736038208
    }
  ],
  "10556": [
    {
      "answer": "1820",
      "score": 0.9875262379646301
    }
  ],
  "10557": [
    {
      "answer": "free trade",
      "score": 0.9892071485519409
    }
  ],
  "10558": [
    {
      "answer": "British",
      "score": 0.9674922823905945
    }
  ],
  "10559": [
    {
      "answer": "pseudo-sciences",
      "score": 0.9870823621749878
    }
  ],
  "10560": [
    {
      "answer": "Africa",
      "score": 0.7989281415939331
    },
    {
      "answer": "Africa",
      "score": 0.5981312394142151
    }
  ],
  "10561": [
    {
      "answer": "British spirit of imperialism",
      "score": 0.8458794951438904
    }
  ],
  "10562": [
    {
      "answer": "British",
      "score": 0.5883978605270386
    },
    {
      "answer": "British",
      "score": 0.744740903377533
    }
  ],
  "10563": [
    {
      "answer": "pseudo-sciences",
      "score": 0.9826524257659912
    }
  ],
  "10564": [
    {
      "answer": "Africa",
      "score": 0.9029853940010071
    },
    {
      "answer": "Africa",
      "score": 0.807828962802887
    }
  ],
  "10565": [
    {
      "answer": "Monroe Doctrine",
      "score": 0.867665708065033
    }
  ],
  "10566": [
    {
      "answer": "interventionism in Central America",
      "score": 0.9162455201148987
    }
  ],
  "10567": [
    {
      "answer": "Philippines",
      "score": 0.9611542224884033
    },
    {
      "answer": "Philippines",
      "score": 0.8348932266235352
    },
    {
      "answer": "Philippines",
      "score": 0.8240260481834412
    }
  ],
  "10568": [
    {
      "answer": "a war erupted in the Philippines",
      "score": 0.8903409838676453
    }
  ],
  "10569": [
    {
      "answer": "racket",
      "score": 0.9797871112823486
    }
  ],
  "10570": [
    {
      "answer": "military force",
      "score": 0.9255456924438477
    }
  ],
  "10571": [
    {
      "answer": "interventionism in Central America",
      "score": 0.6990593671798706
    }
  ],
  "10572": [
    {
      "answer": "Philippines",
      "score": 0.9323768019676208
    },
    {
      "answer": "Philippines",
      "score": 0.8149685859680176
    },
    {
      "answer": "Philippines",
      "score": 0.7863281965255737
    }
  ],
  "10573": [
    {
      "answer": "a war erupted in the Philippines",
      "score": 0.8732041120529175
    }
  ],
  "10574": [
    {
      "answer": "Isiah Bowman",
      "score": 0.9916806221008301
    },
    {
      "answer": "Isiah Bowman",
      "score": 0.9125086665153503
    }
  ],
  "10575": [
    {
      "answer": "1917",
      "score": 0.9365333914756775
    },
    {
      "answer": "1917",
      "score": 0.8943065404891968
    }
  ],
  "10576": [
    {
      "answer": "Isiah Bowman",
      "score": 0.6608977317810059
    },
    {
      "answer": "President Wilson and the American delegation from the Paris Peace Conference",
      "score": 0.6640265583992004
    },
    {
      "answer": "Isiah Bowman",
      "score": 0.5214312076568604
    }
  ],
  "10577": [
    {
      "answer": "to build a premise that would allow for U.S authorship of a 'new world' which was to be characterized by geographical order",
      "score": 0.9413703680038452
    }
  ],
  "10578": [
    {
      "answer": "Wilson's geographer",
      "score": 0.8349117636680603
    }
  ],
  "10579": [
    {
      "answer": "Isiah Bowman",
      "score": 0.9873635768890381
    },
    {
      "answer": "Isiah Bowman",
      "score": 0.9176273345947266
    }
  ],
  "10580": [
    {
      "answer": "1917",
      "score": 0.856356680393219
    },
    {
      "answer": "1917",
      "score": 0.8411679267883301
    }
  ],
  "10581": [],
  "10582": [
    {
      "answer": "internal strife",
      "score": 0.9881975054740906
    }
  ],
  "10583": [
    {
      "answer": "internal colonialism",
      "score": 0.93074631690979
    },
    {
      "answer": "internal colonialism",
      "score": 0.8161829710006714
    },
    {
      "answer": "internal colonialism",
      "score": 0.7784059047698975
    }
  ],
  "10584": [
    {
      "answer": "12 to 15 million",
      "score": 0.9914387464523315
    }
  ],
  "10585": [
    {
      "answer": "the contemporary Orient",
      "score": 0.9297053217887878
    }
  ],
  "10586": [
    {
      "answer": "internal strife",
      "score": 0.8600271940231323
    }
  ],
  "10587": [
    {
      "answer": "internal colonialism",
      "score": 0.921992301940918
    },
    {
      "answer": "internal colonialism",
      "score": 0.7835168838500977
    },
    {
      "answer": "internal colonialism",
      "score": 0.766776442527771
    }
  ],
  "10588": [
    {
      "answer": "12 to 15 million",
      "score": 0.9889106154441833
    }
  ],
  "10589": [
    {
      "answer": "internal colonialism",
      "score": 0.5953938961029053
    },
    {
      "answer": "internal colonialism",
      "score": 0.6585680246353149
    }
  ],
  "10590": [
    {
      "answer": "1299",
      "score": 0.8737413287162781
    },
    {
      "answer": "1923",
      "score": 0.9927088022232056
    }
  ],
  "10591": [
    {
      "answer": "Suleiman the Magnificent",
      "score": 0.9595147967338562
    }
  ],
  "10592": [
    {
      "answer": "32",
      "score": 0.9901230931282043
    }
  ],
  "10593": [
    {
      "answer": "Southeast Europe",
      "score": 0.7462605237960815
    },
    {
      "answer": "Western Asia",
      "score": 0.8902099132537842
    },
    {
      "answer": "North Africa",
      "score": 0.9122821092605591
    },
    {
      "answer": "Horn of Africa",
      "score": 0.8608790636062622
    }
  ],
  "10594": [
    {
      "answer": "16th",
      "score": 0.9810494184494019
    },
    {
      "answer": "17th",
      "score": 0.9663600325584412
    },
    {
      "answer": "17th century",
      "score": 0.6738848686218262
    }
  ],
  "10595": [
    {
      "answer": "1299",
      "score": 0.9929797053337097
    }
  ],
  "10596": [
    {
      "answer": "Suleiman the Magnificent",
      "score": 0.9600607752799988
    }
  ],
  "10597": [
    {
      "answer": "32",
      "score": 0.9685803651809692
    }
  ],
  "10598": [
    {
      "answer": "Southeast Europe",
      "score": 0.8136618733406067
    },
    {
      "answer": "Western Asia",
      "score": 0.9145683646202087
    },
    {
      "answer": "North Africa",
      "score": 0.9395430088043213
    },
    {
      "answer": "Horn of Africa",
      "score": 0.9017804861068726
    }
  ],
  "10599": [
    {
      "answer": "Istanbul",
      "score": 0.9477256536483765
    }
  ],
  "10600": [
    {
      "answer": "Germany",
      "score": 0.9912595152854919
    }
  ],
  "10601": [
    {
      "answer": "Turkey",
      "score": 0.9812977313995361
    }
  ],
  "10602": [
    {
      "answer": "World War I",
      "score": 0.9749540686607361
    }
  ],
  "10603": [
    {
      "answer": "Istanbul",
      "score": 0.7537693381309509
    }
  ],
  "10604": [
    {
      "answer": "Istanbul",
      "score": 0.9322305917739868
    }
  ],
  "10605": [
    {
      "answer": "Germany",
      "score": 0.9917935729026794
    }
  ],
  "10606": [
    {
      "answer": "Turkey",
      "score": 0.9915628433227539
    }
  ],
  "10607": [
    {
      "answer": "World War I",
      "score": 0.8895366191864014
    },
    {
      "answer": "the emergence of the new state of Turkey in the Ottoman Anatolian heartland",
      "score": 0.7822167873382568
    }
  ],
  "10608": [
    {
      "answer": "Warsaw",
      "score": 0.9525279402732849
    },
    {
      "answer": "Warsaw",
      "score": 0.8439174890518188
    }
  ],
  "10609": [
    {
      "answer": "Vistula",
      "score": 0.9952263832092285
    }
  ],
  "10610": [
    {
      "answer": "260 kilometres",
      "score": 0.9920205473899841
    }
  ],
  "10611": [
    {
      "answer": "2.666",
      "score": 0.9828714728355408
    }
  ],
  "10612": [
    {
      "answer": "9th",
      "score": 0.9903990626335144
    }
  ],
  "10613": [],
  "10614": [
    {
      "answer": "Warsaw",
      "score": 0.8721079230308533
    },
    {
      "answer": "Warsaw",
      "score": 0.7420632243156433
    }
  ],
  "10615": [
    {
      "answer": "Vistula",
      "score": 0.9881203174591064
    }
  ],
  "10616": [
    {
      "answer": "1.740 million",
      "score": 0.9608708024024963
    }
  ],
  "10617": [
    {
      "answer": "9th",
      "score": 0.9895114302635193
    }
  ],
  "10618": [
    {
      "answer": "Economist Intelligence Unit",
      "score": 0.986868143081665
    }
  ],
  "10619": [
    {
      "answer": "2012",
      "score": 0.9413498640060425
    }
  ],
  "10620": [
    {
      "answer": "steel and electronic manufacturing",
      "score": 0.9912842512130737
    }
  ],
  "10621": [
    {
      "answer": "Warsaw Stock Exchange",
      "score": 0.9938269853591919
    }
  ],
  "10622": [
    {
      "answer": "Frontex",
      "score": 0.9371156096458435
    }
  ],
  "10623": [
    {
      "answer": "Economist Intelligence Unit",
      "score": 0.9858266115188599
    }
  ],
  "10624": [
    {
      "answer": "FMCG manufacturing",
      "score": 0.8220816254615784
    },
    {
      "answer": "metal processing, steel and electronic manufacturing",
      "score": 0.9612876772880554
    }
  ],
  "10625": [
    {
      "answer": "Warsaw Stock Exchange",
      "score": 0.9924477934837341
    }
  ],
  "10626": [
    {
      "answer": "2012",
      "score": 0.9627960324287415
    }
  ],
  "10627": [
    {
      "answer": "Frontex",
      "score": 0.9793537855148315
    }
  ],
  "10628": [
    {
      "answer": "1313",
      "score": 0.993897020816803
    }
  ],
  "10629": [
    {
      "answer": "Krak\u00f3w",
      "score": 0.9774353504180908
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.772587239742279
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.7416078448295593
    }
  ],
  "10630": [
    {
      "answer": "1596",
      "score": 0.9910483956336975
    }
  ],
  "10631": [
    {
      "answer": "Sigismund III Vasa",
      "score": 0.9933104515075684
    }
  ],
  "10632": [
    {
      "answer": "it has survived many wars, conflicts and invasions throughout its long history",
      "score": 0.9760372042655945
    }
  ],
  "10633": [
    {
      "answer": "1313",
      "score": 0.9921495914459229
    }
  ],
  "10634": [
    {
      "answer": "Krak\u00f3w",
      "score": 0.562889575958252
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.5899455547332764
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.5532581210136414
    }
  ],
  "10635": [
    {
      "answer": "1596",
      "score": 0.9064551591873169
    },
    {
      "answer": "1795",
      "score": 0.8375301361083984
    }
  ],
  "10636": [
    {
      "answer": "Sigismund III Vasa",
      "score": 0.9940080642700195
    }
  ],
  "10637": [
    {
      "answer": "it has survived many wars, conflicts and invasions throughout its long history",
      "score": 0.9678152799606323
    }
  ],
  "10638": [
    {
      "answer": "Roman Catholic",
      "score": 0.9829623699188232
    }
  ],
  "10639": [
    {
      "answer": "Polish Academy of Sciences",
      "score": 0.9852372407913208
    }
  ],
  "10640": [
    {
      "answer": "UNESCO World Heritage Site",
      "score": 0.9849450588226318
    }
  ],
  "10641": [
    {
      "answer": "architectural",
      "score": 0.9147013425827026
    }
  ],
  "10642": [
    {
      "answer": "luxurious parks and royal gardens",
      "score": 0.9859925508499146
    }
  ],
  "10643": [
    {
      "answer": "Roman Catholic",
      "score": 0.9662612676620483
    }
  ],
  "10644": [
    {
      "answer": "UNESCO World Heritage Site",
      "score": 0.9360424280166626
    }
  ],
  "10645": [
    {
      "answer": "luxurious parks and royal gardens",
      "score": 0.9891321063041687
    }
  ],
  "10646": [
    {
      "answer": "Polish Academy of Sciences",
      "score": 0.9809141159057617
    }
  ],
  "10647": [
    {
      "answer": "World Heritage Site",
      "score": 0.9668242931365967
    }
  ],
  "10648": [
    {
      "answer": "Warszawa",
      "score": 0.9710554480552673
    },
    {
      "answer": "Warszawa",
      "score": 0.7342661023139954
    }
  ],
  "10649": [
    {
      "answer": "belonging to Warsz",
      "score": 0.9873733520507812
    }
  ],
  "10650": [
    {
      "answer": "a 12th/13th-century nobleman",
      "score": 0.8865726590156555
    }
  ],
  "10651": [
    {
      "answer": "village",
      "score": 0.9895562529563904
    }
  ],
  "10652": [
    {
      "answer": "miasto sto\u0142eczne Warszawa",
      "score": 0.9904567003250122
    }
  ],
  "10653": [],
  "10654": [],
  "10655": [
    {
      "answer": "Vr\u0161ovci family which had escaped to Poland",
      "score": 0.7555958032608032
    }
  ],
  "10656": [
    {
      "answer": "village",
      "score": 0.9324654936790466
    }
  ],
  "10657": [
    {
      "answer": "miasto sto\u0142eczne Warszawa",
      "score": 0.9885863065719604
    }
  ],
  "10658": [
    {
      "answer": "Jazd\u00f3w",
      "score": 0.7288128733634949
    },
    {
      "answer": "Jazd\u00f3w",
      "score": 0.7942409515380859
    }
  ],
  "10659": [
    {
      "answer": "Prince of P\u0142ock",
      "score": 0.9824909567832947
    }
  ],
  "10660": [
    {
      "answer": "1300",
      "score": 0.9894953370094299
    }
  ],
  "10661": [
    {
      "answer": "1413",
      "score": 0.9904380440711975
    }
  ],
  "10662": [
    {
      "answer": "1526",
      "score": 0.9914980530738831
    }
  ],
  "10663": [
    {
      "answer": "The Prince of P\u0142ock",
      "score": 0.9019092321395874
    }
  ],
  "10664": [
    {
      "answer": "1300",
      "score": 0.9904877543449402
    }
  ],
  "10665": [
    {
      "answer": "Br\u00f3dno",
      "score": 0.5821799039840698
    },
    {
      "answer": "Jazd\u00f3w",
      "score": 0.8607993125915527
    },
    {
      "answer": "Jazd\u00f3w",
      "score": 0.7960104942321777
    }
  ],
  "10666": [
    {
      "answer": "1413",
      "score": 0.9924869537353516
    }
  ],
  "10667": [
    {
      "answer": "1526",
      "score": 0.9931725859642029
    }
  ],
  "10668": [
    {
      "answer": "General Sejm",
      "score": 0.9783725142478943
    }
  ],
  "10669": [
    {
      "answer": "1569",
      "score": 0.9723487496376038
    }
  ],
  "10670": [
    {
      "answer": "religious freedom in the Polish\u2013Lithuanian Commonwealth",
      "score": 0.8906716108322144
    }
  ],
  "10671": [
    {
      "answer": "central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius",
      "score": 0.9419589042663574
    }
  ],
  "10672": [
    {
      "answer": "1596",
      "score": 0.9844086766242981
    }
  ],
  "10673": [
    {
      "answer": "1569",
      "score": 0.9865713715553284
    }
  ],
  "10674": [
    {
      "answer": "religious freedom",
      "score": 0.9500333070755005
    }
  ],
  "10675": [
    {
      "answer": "central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius",
      "score": 0.9380102157592773
    }
  ],
  "10676": [
    {
      "answer": "1596",
      "score": 0.9938610792160034
    }
  ],
  "10677": [
    {
      "answer": "1796",
      "score": 0.9924458861351013
    }
  ],
  "10678": [
    {
      "answer": "Kingdom of Prussia",
      "score": 0.9914084672927856
    }
  ],
  "10679": [
    {
      "answer": "Napoleon",
      "score": 0.9935292601585388
    }
  ],
  "10680": [
    {
      "answer": "1815",
      "score": 0.9800241589546204
    }
  ],
  "10681": [
    {
      "answer": "1816",
      "score": 0.9868739247322083
    }
  ],
  "10682": [
    {
      "answer": "Kingdom of Prussia",
      "score": 0.9944174289703369
    }
  ],
  "10683": [
    {
      "answer": "Napoleon",
      "score": 0.9941685199737549
    }
  ],
  "10684": [
    {
      "answer": "1815",
      "score": 0.9849588871002197
    }
  ],
  "10685": [
    {
      "answer": "1816",
      "score": 0.9889644384384155
    }
  ],
  "10686": [
    {
      "answer": "1796",
      "score": 0.9907599687576294
    }
  ],
  "10687": [
    {
      "answer": "4 August 1915",
      "score": 0.9834644198417664
    }
  ],
  "10688": [
    {
      "answer": "areas controlled by Russia in 1914",
      "score": 0.9786472320556641
    }
  ],
  "10689": [
    {
      "answer": "Pi\u0142sudski",
      "score": 0.9916400909423828
    }
  ],
  "10690": [
    {
      "answer": "1920",
      "score": 0.9894489049911499
    }
  ],
  "10691": [
    {
      "answer": "Red Army",
      "score": 0.9934790730476379
    },
    {
      "answer": "Red Army",
      "score": 0.9695937633514404
    }
  ],
  "10692": [
    {
      "answer": "4 August 1915",
      "score": 0.9690415263175964
    }
  ],
  "10693": [
    {
      "answer": "areas controlled by Russia in 1914",
      "score": 0.9754940867424011
    }
  ],
  "10694": [
    {
      "answer": "Pi\u0142sudski",
      "score": 0.9911519885063171
    }
  ],
  "10695": [
    {
      "answer": "4 August 1915",
      "score": 0.563781201839447
    },
    {
      "answer": "November 1918",
      "score": 0.8289827108383179
    }
  ],
  "10696": [
    {
      "answer": "Red Army",
      "score": 0.9937240481376648
    },
    {
      "answer": "Red Army",
      "score": 0.9513281583786011
    }
  ],
  "10697": [
    {
      "answer": "1 September 1939",
      "score": 0.9900963306427002
    }
  ],
  "10698": [
    {
      "answer": "German Nazi",
      "score": 0.9235777854919434
    }
  ],
  "10699": [
    {
      "answer": "30%",
      "score": 0.9845166206359863
    }
  ],
  "10700": [
    {
      "answer": "19 April 1943",
      "score": 0.9641635417938232
    }
  ],
  "10701": [
    {
      "answer": "almost a month",
      "score": 0.9823609590530396
    }
  ],
  "10702": [
    {
      "answer": "General Government",
      "score": 0.9498903751373291
    }
  ],
  "10703": [
    {
      "answer": "30%",
      "score": 0.9689582586288452
    }
  ],
  "10704": [
    {
      "answer": "19 April 1943",
      "score": 0.9704877138137817
    }
  ],
  "10705": [
    {
      "answer": "1 September 1939",
      "score": 0.9902321696281433
    }
  ],
  "10706": [
    {
      "answer": "almost a month",
      "score": 0.9828845858573914
    }
  ],
  "10707": [
    {
      "answer": "Red Army",
      "score": 0.9885338544845581
    },
    {
      "answer": "Red Army",
      "score": 0.9204257726669312
    },
    {
      "answer": "Red Army",
      "score": 0.9049314260482788
    }
  ],
  "10708": [
    {
      "answer": "Stalin was hostile to the idea of an independent Poland",
      "score": 0.9903451800346375
    }
  ],
  "10709": [
    {
      "answer": "1 August 1944",
      "score": 0.9954182505607605
    }
  ],
  "10710": [
    {
      "answer": "63",
      "score": 0.9940432906150818
    }
  ],
  "10711": [
    {
      "answer": "150,000 and 200,000",
      "score": 0.979448139667511
    }
  ],
  "10712": [
    {
      "answer": "Red Army",
      "score": 0.9913452863693237
    },
    {
      "answer": "Red Army",
      "score": 0.9476052522659302
    },
    {
      "answer": "Red Army",
      "score": 0.9431200623512268
    }
  ],
  "10713": [
    {
      "answer": "Stalin was hostile to the idea of an independent Poland",
      "score": 0.988895058631897
    }
  ],
  "10714": [
    {
      "answer": "1 August 1944",
      "score": 0.9949259757995605
    }
  ],
  "10715": [
    {
      "answer": "63",
      "score": 0.9938437938690186
    }
  ],
  "10716": [
    {
      "answer": "150,000 and 200,000",
      "score": 0.9641237854957581
    }
  ],
  "10717": [],
  "10718": [
    {
      "answer": "prefabricated housing projects",
      "score": 0.9097188711166382
    }
  ],
  "10719": [
    {
      "answer": "Eastern Bloc city",
      "score": 0.908913791179657
    }
  ],
  "10720": [
    {
      "answer": "Palace of Culture and Science",
      "score": 0.9481920599937439
    }
  ],
  "10721": [
    {
      "answer": "World Heritage list",
      "score": 0.945036768913269
    }
  ],
  "10722": [],
  "10723": [
    {
      "answer": "prefabricated",
      "score": 0.9896859526634216
    }
  ],
  "10724": [
    {
      "answer": "Eastern Bloc city",
      "score": 0.7913459539413452
    }
  ],
  "10725": [
    {
      "answer": "Palace of Culture and Science",
      "score": 0.9626642465591431
    }
  ],
  "10726": [
    {
      "answer": "World Heritage list",
      "score": 0.9519059062004089
    }
  ],
  "10727": [
    {
      "answer": "John Paul II",
      "score": 0.9939882159233093
    }
  ],
  "10728": [
    {
      "answer": "support to the budding solidarity movement",
      "score": 0.7715341448783875
    },
    {
      "answer": "anti-communist fervor",
      "score": 0.972472608089447
    }
  ],
  "10729": [
    {
      "answer": "less than a year",
      "score": 0.9603859186172485
    }
  ],
  "10730": [
    {
      "answer": "Victory Square",
      "score": 0.9947226047515869
    }
  ],
  "10731": [
    {
      "answer": "democratic changes",
      "score": 0.9864853024482727
    }
  ],
  "10732": [
    {
      "answer": "John Paul II",
      "score": 0.8596357107162476
    }
  ],
  "10733": [
    {
      "answer": "support to the budding solidarity movement",
      "score": 0.7222137451171875
    },
    {
      "answer": "anti-communist fervor",
      "score": 0.9682148694992065
    }
  ],
  "10734": [
    {
      "answer": "less than a year",
      "score": 0.939307451248169
    }
  ],
  "10735": [
    {
      "answer": "Victory Square",
      "score": 0.9843225479125977
    }
  ],
  "10736": [
    {
      "answer": "democratic changes",
      "score": 0.9795743227005005
    }
  ],
  "10737": [
    {
      "answer": "300",
      "score": 0.9859283566474915
    }
  ],
  "10738": [
    {
      "answer": "523",
      "score": 0.9809619784355164
    }
  ],
  "10739": [
    {
      "answer": "Vistula",
      "score": 0.9861170649528503
    }
  ],
  "10740": [
    {
      "answer": "115.7 metres",
      "score": 0.9771084189414978
    }
  ],
  "10741": [
    {
      "answer": "at the right bank of the Vistula, by the eastern border of Warsaw",
      "score": 0.9518841505050659
    }
  ],
  "10742": [
    {
      "answer": "300",
      "score": 0.9897518157958984
    }
  ],
  "10743": [
    {
      "answer": "523",
      "score": 0.9740906953811646
    }
  ],
  "10744": [
    {
      "answer": "Vistula",
      "score": 0.9881795644760132
    }
  ],
  "10745": [
    {
      "answer": "122.1 metres (400.6 ft)",
      "score": 0.7871605753898621
    }
  ],
  "10746": [
    {
      "answer": "at the right bank of the Vistula, by the eastern border of Warsaw",
      "score": 0.9335938096046448
    }
  ],
  "10747": [
    {
      "answer": "two",
      "score": 0.9870802760124207
    },
    {
      "answer": "two",
      "score": 0.7854682207107544
    }
  ],
  "10748": [
    {
      "answer": "Vistula Valley",
      "score": 0.9720371961593628
    }
  ],
  "10749": [
    {
      "answer": "Vistula River",
      "score": 0.9854247570037842
    }
  ],
  "10750": [
    {
      "answer": "moraine plateau",
      "score": 0.783595085144043
    },
    {
      "answer": "moraine plateau",
      "score": 0.9747965931892395
    },
    {
      "answer": "moraine plateau",
      "score": 0.6779084205627441
    }
  ],
  "10751": [
    {
      "answer": "Warsaw Escarpment",
      "score": 0.9900493621826172
    }
  ],
  "10752": [
    {
      "answer": "Vistula Valley",
      "score": 0.9780527353286743
    }
  ],
  "10753": [
    {
      "answer": "two",
      "score": 0.987129271030426
    },
    {
      "answer": "two",
      "score": 0.8076896071434021
    }
  ],
  "10754": [
    {
      "answer": "Vistula River",
      "score": 0.9507316946983337
    }
  ],
  "10755": [
    {
      "answer": "Warsaw Escarpment",
      "score": 0.9917700290679932
    }
  ],
  "10756": [
    {
      "answer": "moraine plateau",
      "score": 0.7146072387695312
    },
    {
      "answer": "moraine plateau",
      "score": 0.9660292863845825
    },
    {
      "answer": "moraine plateau",
      "score": 0.5525487661361694
    }
  ],
  "10757": [
    {
      "answer": "plain moraine",
      "score": 0.9127781391143799
    }
  ],
  "10758": [
    {
      "answer": "former flooded terraces",
      "score": 0.9849149584770203
    }
  ],
  "10759": [
    {
      "answer": "valleys and ground depressions",
      "score": 0.9656349420547485
    }
  ],
  "10760": [
    {
      "answer": "highest terrace",
      "score": 0.9670566320419312
    }
  ],
  "10761": [
    {
      "answer": "pine forest",
      "score": 0.9830572009086609
    }
  ],
  "10762": [
    {
      "answer": "pine forest",
      "score": 0.9848439693450928
    }
  ],
  "10763": [
    {
      "answer": "valleys and ground depressions",
      "score": 0.948745846748352
    }
  ],
  "10764": [
    {
      "answer": "the highest terrace",
      "score": 0.8443934917449951
    }
  ],
  "10765": [
    {
      "answer": "The plain moraine",
      "score": 0.6929399371147156
    }
  ],
  "10766": [
    {
      "answer": "former flooded terraces",
      "score": 0.9886437654495239
    }
  ],
  "10767": [
    {
      "answer": "turbulent history of the city and country",
      "score": 0.7916852831840515
    }
  ],
  "10768": [
    {
      "answer": "Second World War",
      "score": 0.9762508273124695
    }
  ],
  "10769": [
    {
      "answer": "After liberation",
      "score": 0.9210167527198792
    }
  ],
  "10770": [
    {
      "answer": "Leopold Kronenberg Palace",
      "score": 0.9667109847068787
    }
  ],
  "10771": [
    {
      "answer": "Eastern bloc countries",
      "score": 0.9829148650169373
    }
  ],
  "10772": [
    {
      "answer": "1950s",
      "score": 0.8758569955825806
    },
    {
      "answer": "1960s",
      "score": 0.6364333629608154
    }
  ],
  "10773": [
    {
      "answer": "turbulent history of the city and country",
      "score": 0.8047465085983276
    }
  ],
  "10774": [
    {
      "answer": "Leopold Kronenberg Palace",
      "score": 0.9693402647972107
    }
  ],
  "10775": [
    {
      "answer": "Second World War",
      "score": 0.5728806853294373
    },
    {
      "answer": "1950s",
      "score": 0.8075552582740784
    }
  ],
  "10776": [
    {
      "answer": "Eastern bloc countries",
      "score": 0.9842760562896729
    }
  ],
  "10777": [
    {
      "answer": "Gothic",
      "score": 0.9888917803764343
    }
  ],
  "10778": [
    {
      "answer": "14th century",
      "score": 0.9798977375030518
    },
    {
      "answer": "14th century",
      "score": 0.8933572173118591
    }
  ],
  "10779": [
    {
      "answer": "Masovian gothic",
      "score": 0.9756380319595337
    }
  ],
  "10780": [
    {
      "answer": "Renaissance",
      "score": 0.9919946193695068
    }
  ],
  "10781": [
    {
      "answer": "mannerist architecture",
      "score": 0.9599064588546753
    }
  ],
  "10782": [
    {
      "answer": "14th century",
      "score": 0.9046527147293091
    },
    {
      "answer": "14th century",
      "score": 0.8549966812133789
    }
  ],
  "10783": [
    {
      "answer": "Masovian gothic",
      "score": 0.9659427404403687
    }
  ],
  "10784": [
    {
      "answer": "Renaissance",
      "score": 0.9898645281791687
    }
  ],
  "10785": [
    {
      "answer": "Gothic",
      "score": 0.8776248097419739
    }
  ],
  "10786": [
    {
      "answer": "mannerist architecture",
      "score": 0.9516327977180481
    }
  ],
  "10787": [
    {
      "answer": "17th century",
      "score": 0.9680702686309814
    }
  ],
  "10788": [
    {
      "answer": "1688",
      "score": 0.9598908424377441
    }
  ],
  "10789": [
    {
      "answer": "rococo",
      "score": 0.9919565916061401
    }
  ],
  "10790": [
    {
      "answer": "neoclassical architecture",
      "score": 0.9692980051040649
    }
  ],
  "10791": [
    {
      "answer": "1775",
      "score": 0.9923966526985168
    }
  ],
  "10792": [
    {
      "answer": "17th century",
      "score": 0.933341383934021
    }
  ],
  "10793": [
    {
      "answer": "1775",
      "score": 0.9881653785705566
    }
  ],
  "10794": [
    {
      "answer": "17th century",
      "score": 0.9708124399185181
    }
  ],
  "10795": [
    {
      "answer": "Neoclassical",
      "score": 0.9778497219085693
    }
  ],
  "10796": [
    {
      "answer": "neoclassical architecture",
      "score": 0.958111047744751
    }
  ],
  "10797": [
    {
      "answer": "bourgeois",
      "score": 0.9917337894439697
    }
  ],
  "10798": [
    {
      "answer": "Exceptional examples of the bourgeois architecture of the later periods were not restored by the communist authorities after the war",
      "score": 0.7502583861351013
    }
  ],
  "10799": [
    {
      "answer": "socialist realism",
      "score": 0.9974934458732605
    }
  ],
  "10800": [
    {
      "answer": "Warsaw University of Technology building",
      "score": 0.9906550645828247
    }
  ],
  "10801": [
    {
      "answer": "most distinctive buildings",
      "score": 0.9190422892570496
    }
  ],
  "10802": [
    {
      "answer": "socialist realism",
      "score": 0.9974623918533325
    }
  ],
  "10803": [],
  "10804": [
    {
      "answer": "bourgeois",
      "score": 0.976478099822998
    }
  ],
  "10805": [
    {
      "answer": "Exceptional examples of the bourgeois architecture of the later periods were not restored by the communist authorities after the war",
      "score": 0.7797470092773438
    }
  ],
  "10806": [
    {
      "answer": "Warsaw University of Technology building",
      "score": 0.9900843501091003
    }
  ],
  "10807": [
    {
      "answer": "Mausoleum of Memory of Martyrdom",
      "score": 0.5621922612190247
    },
    {
      "answer": "Warsaw Citadel",
      "score": 0.5868552923202515
    },
    {
      "answer": "statue of Little Insurgent",
      "score": 0.8469734787940979
    },
    {
      "answer": "Warsaw Uprising Monument",
      "score": 0.7327021360397339
    }
  ],
  "10808": [
    {
      "answer": "Pawiak",
      "score": 0.9656323194503784
    }
  ],
  "10809": [
    {
      "answer": "Warsaw Citadel",
      "score": 0.9358570575714111
    }
  ],
  "10810": [
    {
      "answer": "children who served as messengers and frontline troops in the Warsaw Uprising",
      "score": 0.968629777431488
    }
  ],
  "10811": [
    {
      "answer": "Warsaw Uprising Monument",
      "score": 0.9897969961166382
    }
  ],
  "10812": [
    {
      "answer": "statue of Little Insurgent",
      "score": 0.9756304621696472
    }
  ],
  "10813": [
    {
      "answer": "Pawiak",
      "score": 0.9688483476638794
    }
  ],
  "10814": [
    {
      "answer": "children who served as messengers and frontline troops in the Warsaw Uprising",
      "score": 0.9725848436355591
    }
  ],
  "10815": [
    {
      "answer": "Warsaw Citadel",
      "score": 0.9557523727416992
    }
  ],
  "10816": [
    {
      "answer": "Warsaw Uprising Monument",
      "score": 0.9911762475967407
    }
  ],
  "10817": [
    {
      "answer": "Saxon Garden",
      "score": 0.9923173189163208
    }
  ],
  "10818": [
    {
      "answer": "100",
      "score": 0.9909489750862122
    }
  ],
  "10819": [
    {
      "answer": "east",
      "score": 0.9921201467514038
    }
  ],
  "10820": [
    {
      "answer": "Krasi\u0144ski Palace Garden",
      "score": 0.791644811630249
    },
    {
      "answer": "Krasi\u0144ski Palace Garden",
      "score": 0.9649266004562378
    }
  ],
  "10821": [
    {
      "answer": "\u0141azienki Park",
      "score": 0.95679771900177
    }
  ],
  "10822": [
    {
      "answer": "Saxon Garden",
      "score": 0.9808269739151001
    }
  ],
  "10823": [
    {
      "answer": "Krasi\u0144ski Palace Garden",
      "score": 0.727165699005127
    },
    {
      "answer": "Krasi\u0144ski Palace Garden",
      "score": 0.9419591426849365
    }
  ],
  "10824": [
    {
      "answer": "\u0141azienki Park",
      "score": 0.9459412693977356
    }
  ],
  "10825": [
    {
      "answer": "100",
      "score": 0.9892904162406921
    }
  ],
  "10826": [
    {
      "answer": "east",
      "score": 0.991543173789978
    }
  ],
  "10827": [
    {
      "answer": "green spaces",
      "score": 0.9433879852294922
    }
  ],
  "10828": [
    {
      "answer": "New Orangery",
      "score": 0.9819791316986084
    }
  ],
  "10829": [
    {
      "answer": "Pole Mokotowskie",
      "score": 0.9828197360038757
    }
  ],
  "10830": [
    {
      "answer": "Park Ujazdowski",
      "score": 0.9822190999984741
    }
  ],
  "10831": [
    {
      "answer": "1927",
      "score": 0.9906497597694397
    }
  ],
  "10832": [
    {
      "answer": "Praga",
      "score": 0.5538358688354492
    },
    {
      "answer": "Praga",
      "score": 0.9204930663108826
    }
  ],
  "10833": [
    {
      "answer": "Park Skaryszewski",
      "score": 0.9729976654052734
    }
  ],
  "10834": [
    {
      "answer": "1927",
      "score": 0.9910440444946289
    }
  ],
  "10835": [
    {
      "answer": "green",
      "score": 0.9734749794006348
    }
  ],
  "10836": [
    {
      "answer": "New Orangery",
      "score": 0.9829462766647339
    }
  ],
  "10837": [
    {
      "answer": "location of Warsaw within the border region of several big floral regions comprising substantial proportions of close-to-wilderness areas (natural forests, wetlands along the Vistula) as well as arable land, meadows and forests",
      "score": 0.8841420412063599
    }
  ],
  "10838": [
    {
      "answer": "within the borders of Warsaw",
      "score": 0.883592426776886
    },
    {
      "answer": "Warsaw",
      "score": 0.5929611325263977
    }
  ],
  "10839": [
    {
      "answer": "Masovian Primeval Forest",
      "score": 0.9931244254112244
    }
  ],
  "10840": [
    {
      "answer": "Kabaty Forest",
      "score": 0.9690061807632446
    }
  ],
  "10841": [
    {
      "answer": "two",
      "score": 0.9927876591682434
    }
  ],
  "10842": [
    {
      "answer": "two",
      "score": 0.9838327765464783
    }
  ],
  "10843": [
    {
      "answer": "Warsaw",
      "score": 0.7029809355735779
    },
    {
      "answer": "Warsaw",
      "score": 0.7054409384727478
    },
    {
      "answer": "Warsaw",
      "score": 0.7608495354652405
    },
    {
      "answer": "Warsaw",
      "score": 0.7225778102874756
    }
  ],
  "10844": [
    {
      "answer": "location of Warsaw within the border region of several big floral regions comprising substantial proportions of close-to-wilderness areas (natural forests, wetlands along the Vistula) as well as arable land, meadows and forests",
      "score": 0.8765808939933777
    }
  ],
  "10845": [
    {
      "answer": "Masovian Primeval Forest",
      "score": 0.9641777276992798
    }
  ],
  "10846": [
    {
      "answer": "Kabaty Forest",
      "score": 0.9720776081085205
    }
  ],
  "10847": [
    {
      "answer": "13",
      "score": 0.993524432182312
    }
  ],
  "10848": [
    {
      "answer": "15 kilometres",
      "score": 0.9787620306015015
    }
  ],
  "10849": [],
  "10850": [
    {
      "answer": "13",
      "score": 0.7974315285682678
    }
  ],
  "10851": [
    {
      "answer": "to clean them of plants and sediments",
      "score": 0.9965695142745972
    }
  ],
  "10852": [
    {
      "answer": "13",
      "score": 0.9883684515953064
    }
  ],
  "10853": [
    {
      "answer": "15 kilometres",
      "score": 0.9768005609512329
    }
  ],
  "10854": [],
  "10855": [
    {
      "answer": "13",
      "score": 0.6784530282020569
    }
  ],
  "10856": [
    {
      "answer": "to clean them of plants and sediments",
      "score": 0.9958993792533875
    }
  ],
  "10857": [
    {
      "answer": "foreign-born inhabitants",
      "score": 0.8516042232513428
    }
  ],
  "10858": [
    {
      "answer": "Jewish",
      "score": 0.9661983847618103
    }
  ],
  "10859": [
    {
      "answer": "34%",
      "score": 0.9748557806015015
    }
  ],
  "10860": [
    {
      "answer": "833,500",
      "score": 0.9782442450523376
    }
  ],
  "10861": [
    {
      "answer": "internal migration and urbanisation",
      "score": 0.9961165189743042
    }
  ],
  "10862": [
    {
      "answer": "Jewish",
      "score": 0.9733498096466064
    }
  ],
  "10863": [],
  "10864": [],
  "10865": [
    {
      "answer": "internal migration and urbanisation",
      "score": 0.9958224892616272
    }
  ],
  "10866": [
    {
      "answer": "34%",
      "score": 0.978829562664032
    }
  ],
  "10867": [
    {
      "answer": "1,300,000",
      "score": 0.9879052042961121
    }
  ],
  "10868": [
    {
      "answer": "420,000",
      "score": 0.9507116079330444
    }
  ],
  "10869": [
    {
      "answer": "1951",
      "score": 0.9914020895957947
    }
  ],
  "10870": [
    {
      "answer": "better only because they lived in the capital",
      "score": 0.9414875507354736
    }
  ],
  "10871": [
    {
      "answer": "residency registration",
      "score": 0.7355000376701355
    },
    {
      "answer": "residency registration",
      "score": 0.98654705286026
    }
  ],
  "10872": [
    {
      "answer": "1,300,000",
      "score": 0.9825393557548523
    }
  ],
  "10873": [
    {
      "answer": "420,000",
      "score": 0.9559761881828308
    }
  ],
  "10874": [
    {
      "answer": "1951",
      "score": 0.991641640663147
    }
  ],
  "10875": [
    {
      "answer": "Varsovians thought of themselves as better only because they lived in the capital",
      "score": 0.8943455219268799
    }
  ],
  "10876": [
    {
      "answer": "residency registration",
      "score": 0.7521777749061584
    },
    {
      "answer": "residency registration",
      "score": 0.9886022210121155
    }
  ],
  "10877": [
    {
      "answer": "multi-cultural",
      "score": 0.9952665567398071
    }
  ],
  "10878": [
    {
      "answer": "711",
      "score": 0.9547072649002075
    },
    {
      "answer": "988",
      "score": 0.9184466004371643
    }
  ],
  "10879": [
    {
      "answer": "56.2%",
      "score": 0.9938904047012329
    }
  ],
  "10880": [
    {
      "answer": "2.8%",
      "score": 0.9845752120018005
    }
  ],
  "10881": [
    {
      "answer": "1944",
      "score": 0.9713042378425598
    }
  ],
  "10882": [
    {
      "answer": "multi-cultural",
      "score": 0.9951861500740051
    }
  ],
  "10883": [
    {
      "answer": "711",
      "score": 0.9452359676361084
    }
  ],
  "10884": [
    {
      "answer": "56.2%",
      "score": 0.9946553707122803
    }
  ],
  "10885": [
    {
      "answer": "2.8%",
      "score": 0.9881440997123718
    }
  ],
  "10886": [
    {
      "answer": "1944",
      "score": 0.9723808169364929
    }
  ],
  "10887": [
    {
      "answer": "commune",
      "score": 0.9832852482795715
    },
    {
      "answer": "commune",
      "score": 0.5645502209663391
    }
  ],
  "10888": [
    {
      "answer": "counties or powiats",
      "score": 0.9425182342529297
    }
  ],
  "10889": [
    {
      "answer": "Krak\u00f3w",
      "score": 0.8090039491653442
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.7005506753921509
    }
  ],
  "10890": [
    {
      "answer": "commune",
      "score": 0.9738842248916626
    },
    {
      "answer": "commune",
      "score": 0.6396505236625671
    }
  ],
  "10891": [
    {
      "answer": "counties",
      "score": 0.9542062282562256
    }
  ],
  "10892": [
    {
      "answer": "Krak\u00f3w",
      "score": 0.8242969512939453
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.726706862449646
    }
  ],
  "10893": [],
  "10894": [
    {
      "answer": "Krak\u00f3w",
      "score": 0.7637328505516052
    },
    {
      "answer": "Krak\u00f3w",
      "score": 0.9088307619094849
    }
  ],
  "10895": [
    {
      "answer": "Warsaw City Council",
      "score": 0.9337801933288574
    }
  ],
  "10896": [
    {
      "answer": "60",
      "score": 0.995122492313385
    }
  ],
  "10897": [
    {
      "answer": "every four years",
      "score": 0.9889529943466187
    }
  ],
  "10898": [
    {
      "answer": "committees",
      "score": 0.9840333461761475
    }
  ],
  "10899": [
    {
      "answer": "30",
      "score": 0.9955457448959351
    }
  ],
  "10900": [
    {
      "answer": "Warsaw City Council",
      "score": 0.9698216915130615
    }
  ],
  "10901": [
    {
      "answer": "60",
      "score": 0.9949203133583069
    }
  ],
  "10902": [
    {
      "answer": "every four years",
      "score": 0.9796175360679626
    }
  ],
  "10903": [
    {
      "answer": "committees",
      "score": 0.9832012057304382
    }
  ],
  "10904": [
    {
      "answer": "30",
      "score": 0.9957941770553589
    }
  ],
  "10905": [
    {
      "answer": "President",
      "score": 0.9723898768424988
    },
    {
      "answer": "president",
      "score": 0.5882338881492615
    },
    {
      "answer": "President",
      "score": 0.8598886728286743
    },
    {
      "answer": "President",
      "score": 0.9023715853691101
    },
    {
      "answer": "President",
      "score": 0.892541766166687
    },
    {
      "answer": "President",
      "score": 0.8803956508636475
    }
  ],
  "10906": [
    {
      "answer": "Jan Andrzej Menich",
      "score": 0.9970622062683105
    }
  ],
  "10907": [
    {
      "answer": "1695",
      "score": 0.9899242520332336
    }
  ],
  "10908": [
    {
      "answer": "City council",
      "score": 0.98906409740448
    }
  ],
  "10909": [
    {
      "answer": "Centrum",
      "score": 0.9885748028755188
    },
    {
      "answer": "Centrum",
      "score": 0.845973551273346
    },
    {
      "answer": "Centrum",
      "score": 0.8569049835205078
    },
    {
      "answer": "Centrum",
      "score": 0.8842813968658447
    }
  ],
  "10910": [
    {
      "answer": "President",
      "score": 0.7879234552383423
    },
    {
      "answer": "president",
      "score": 0.5559009313583374
    },
    {
      "answer": "President",
      "score": 0.8573951125144958
    },
    {
      "answer": "President",
      "score": 0.8480969071388245
    },
    {
      "answer": "President",
      "score": 0.8462367653846741
    },
    {
      "answer": "President",
      "score": 0.825498640537262
    }
  ],
  "10911": [
    {
      "answer": "Jan Andrzej Menich",
      "score": 0.994186282157898
    }
  ],
  "10912": [
    {
      "answer": "1994",
      "score": 0.9919739365577698
    },
    {
      "answer": "1999",
      "score": 0.9879376292228699
    }
  ],
  "10913": [
    {
      "answer": "City council",
      "score": 0.9749346971511841
    }
  ],
  "10914": [
    {
      "answer": "Centrum",
      "score": 0.9777870178222656
    },
    {
      "answer": "Centrum",
      "score": 0.8393111824989319
    },
    {
      "answer": "Centrum",
      "score": 0.8664650917053223
    },
    {
      "answer": "Centrum",
      "score": 0.8801225423812866
    }
  ],
  "10915": [
    {
      "answer": "\u015ar\u00f3dmie\u015bcie",
      "score": 0.9654598236083984
    }
  ],
  "10916": [
    {
      "answer": "304,016",
      "score": 0.9846501350402832
    }
  ],
  "10917": [
    {
      "answer": "emerging market",
      "score": 0.9730796217918396
    }
  ],
  "10918": [
    {
      "answer": "12%",
      "score": 0.9895291328430176
    }
  ],
  "10919": [
    {
      "answer": "191.766 billion PLN",
      "score": 0.9791187644004822
    }
  ],
  "10920": [
    {
      "answer": "\u015ar\u00f3dmie\u015bcie",
      "score": 0.9701554179191589
    }
  ],
  "10921": [
    {
      "answer": "304,016",
      "score": 0.9866544008255005
    }
  ],
  "10922": [
    {
      "answer": "emerging market",
      "score": 0.9926289319992065
    }
  ],
  "10923": [
    {
      "answer": "12%",
      "score": 0.9884047508239746
    }
  ],
  "10924": [
    {
      "answer": "191.766 billion PLN",
      "score": 0.9805000424385071
    }
  ],
  "10925": [
    {
      "answer": "1817",
      "score": 0.9781357049942017
    }
  ],
  "10926": [
    {
      "answer": "World War II",
      "score": 0.9972397685050964
    }
  ],
  "10927": [
    {
      "answer": "April 1991",
      "score": 0.9907702207565308
    }
  ],
  "10928": [
    {
      "answer": "374",
      "score": 0.9902466535568237
    }
  ],
  "10929": [
    {
      "answer": "Polish United Workers' Party (PZPR)",
      "score": 0.9148637056350708
    }
  ],
  "10930": [
    {
      "answer": "1817",
      "score": 0.9836863875389099
    }
  ],
  "10931": [
    {
      "answer": "end of the post-war communist control of the country",
      "score": 0.92434161901474
    },
    {
      "answer": "reintroduction of a free-market economy",
      "score": 0.9377653002738953
    }
  ],
  "10932": [
    {
      "answer": "World War II",
      "score": 0.8544853925704956
    }
  ],
  "10933": [
    {
      "answer": "374",
      "score": 0.9904815554618835
    }
  ],
  "10934": [
    {
      "answer": "Polish United Workers' Party (PZPR)",
      "score": 0.9140545129776001
    }
  ],
  "10935": [
    {
      "answer": "1951",
      "score": 0.9770355224609375
    }
  ],
  "10936": [
    {
      "answer": "Fiat 125p",
      "score": 0.7345028519630432
    }
  ],
  "10937": [
    {
      "answer": "Daewoo",
      "score": 0.9577475190162659
    }
  ],
  "10938": [
    {
      "answer": "AvtoZAZ",
      "score": 0.9855102300643921
    }
  ],
  "10939": [
    {
      "answer": "Aveo",
      "score": 0.8450896739959717
    }
  ],
  "10940": [
    {
      "answer": "1951",
      "score": 0.97407466173172
    }
  ],
  "10941": [],
  "10942": [
    {
      "answer": "Daewoo",
      "score": 0.6853135824203491
    },
    {
      "answer": "AvtoZAZ",
      "score": 0.7718172669410706
    }
  ],
  "10943": [
    {
      "answer": "Fiat 125p",
      "score": 0.5876529812812805
    }
  ],
  "10944": [],
  "10945": [
    {
      "answer": "1816",
      "score": 0.9734982252120972
    }
  ],
  "10946": [
    {
      "answer": "Warsaw University of Technology",
      "score": 0.9875651001930237
    }
  ],
  "10947": [
    {
      "answer": "2,000",
      "score": 0.9884786605834961
    }
  ],
  "10948": [
    {
      "answer": "Medical University of Warsaw",
      "score": 0.9908702373504639
    }
  ],
  "10949": [
    {
      "answer": "Fryderyk Chopin University of Music",
      "score": 0.9623659253120422
    }
  ],
  "10950": [
    {
      "answer": "1816",
      "score": 0.9640839099884033
    }
  ],
  "10951": [
    {
      "answer": "Warsaw University of Technology",
      "score": 0.9881466627120972
    }
  ],
  "10952": [
    {
      "answer": "2,000",
      "score": 0.9856299757957458
    }
  ],
  "10953": [
    {
      "answer": "Medical University of Warsaw",
      "score": 0.991104006767273
    }
  ],
  "10954": [
    {
      "answer": "Fryderyk Chopin University of Music",
      "score": 0.9430665969848633
    }
  ],
  "10955": [
    {
      "answer": "1816",
      "score": 0.9875437021255493
    }
  ],
  "10956": [
    {
      "answer": "two million",
      "score": 0.9825423955917358
    }
  ],
  "10957": [
    {
      "answer": "architects",
      "score": 0.9802952408790588
    }
  ],
  "10958": [
    {
      "answer": "Irena Bajerska",
      "score": 0.9938004612922668
    }
  ],
  "10959": [
    {
      "answer": "more than 10,000 m2",
      "score": 0.9189074039459229
    },
    {
      "answer": "5,111 m2",
      "score": 0.698991060256958
    }
  ],
  "10960": [
    {
      "answer": "15 December 1999",
      "score": 0.9925283789634705
    }
  ],
  "10961": [
    {
      "answer": "two million",
      "score": 0.9799855947494507
    }
  ],
  "10962": [
    {
      "answer": "architects",
      "score": 0.9785413146018982
    }
  ],
  "10963": [
    {
      "answer": "Irena Bajerska",
      "score": 0.9944413304328918
    }
  ],
  "10964": [
    {
      "answer": "10,000 m2",
      "score": 0.9771920442581177
    }
  ],
  "10965": [
    {
      "answer": "infrastructure",
      "score": 0.9674404263496399
    }
  ],
  "10966": [
    {
      "answer": "the initial Three-Year Plan",
      "score": 0.9684343934059143
    }
  ],
  "10967": [
    {
      "answer": "solid economic growth",
      "score": 0.9847535490989685
    },
    {
      "answer": "an increase in foreign investment",
      "score": 0.9625831842422485
    },
    {
      "answer": "funding from the European Union",
      "score": 0.9443336725234985
    }
  ],
  "10968": [
    {
      "answer": "improved",
      "score": 0.9818575382232666
    }
  ],
  "10969": [
    {
      "answer": "infrastructure",
      "score": 0.9847320318222046
    }
  ],
  "10970": [
    {
      "answer": "the initial Three-Year Plan",
      "score": 0.7070384621620178
    }
  ],
  "10971": [
    {
      "answer": "solid economic growth",
      "score": 0.9842871427536011
    },
    {
      "answer": "an increase in foreign investment",
      "score": 0.9643263220787048
    },
    {
      "answer": "funding from the European Union",
      "score": 0.9259616732597351
    }
  ],
  "10972": [
    {
      "answer": "improved markedly",
      "score": 0.9580403566360474
    }
  ],
  "10973": [
    {
      "answer": "the past decade",
      "score": 0.9821361899375916
    }
  ],
  "10974": [
    {
      "answer": "Warsaw",
      "score": 0.9139537215232849
    }
  ],
  "10975": [
    {
      "answer": "Children's Memorial Health Institute (CMHI)",
      "score": 0.9234312772750854
    }
  ],
  "10976": [
    {
      "answer": "Maria Sk\u0142odowska-Curie Institute of Oncology",
      "score": 0.9383916258811951
    }
  ],
  "10977": [
    {
      "answer": "700",
      "score": 0.988071084022522
    }
  ],
  "10978": [
    {
      "answer": "infrastructure",
      "score": 0.8838850259780884
    },
    {
      "answer": "developed",
      "score": 0.785714328289032
    }
  ],
  "10979": [
    {
      "answer": "Warsaw",
      "score": 0.95600825548172
    }
  ],
  "10980": [
    {
      "answer": "Children's Memorial Health Institute",
      "score": 0.9430866241455078
    }
  ],
  "10981": [
    {
      "answer": "Maria Sk\u0142odowska-Curie Institute of Oncology",
      "score": 0.9623767733573914
    }
  ],
  "10982": [
    {
      "answer": "700",
      "score": 0.9911155700683594
    }
  ],
  "10983": [
    {
      "answer": "infrastructure",
      "score": 0.7736623883247375
    },
    {
      "answer": "developed",
      "score": 0.8621416687965393
    }
  ],
  "10984": [
    {
      "answer": "musical",
      "score": 0.8786181807518005
    }
  ],
  "10985": [
    {
      "answer": "events and festivals",
      "score": 0.9735144376754761
    }
  ],
  "10986": [
    {
      "answer": "Palace of Culture and Science",
      "score": 0.85923832654953
    }
  ],
  "10987": [
    {
      "answer": "Warsaw",
      "score": 0.9509149193763733
    },
    {
      "answer": "Warsaw",
      "score": 0.823695957660675
    },
    {
      "answer": "Warsaw",
      "score": 0.8446738719940186
    }
  ],
  "10988": [
    {
      "answer": "International Fr\u00e9d\u00e9ric Chopin Piano Competition",
      "score": 0.6582989692687988
    },
    {
      "answer": "International Contemporary Music Festival Warsaw Autumn",
      "score": 0.6629151701927185
    },
    {
      "answer": "Jazz Jamboree",
      "score": 0.7852853536605835
    }
  ],
  "10989": [
    {
      "answer": "International Contemporary Music Festival",
      "score": 0.9419609308242798
    }
  ],
  "10990": [
    {
      "answer": "events and festivals",
      "score": 0.888849139213562
    },
    {
      "answer": "International Contemporary Music Festival",
      "score": 0.7417519092559814
    }
  ],
  "10991": [
    {
      "answer": "Warsaw",
      "score": 0.7274121046066284
    },
    {
      "answer": "Warsaw",
      "score": 0.7437971234321594
    },
    {
      "answer": "Warsaw",
      "score": 0.5853272676467896
    }
  ],
  "10992": [
    {
      "answer": "Warsaw",
      "score": 0.822147786617279
    },
    {
      "answer": "Warsaw",
      "score": 0.8061253428459167
    },
    {
      "answer": "Warsaw",
      "score": 0.6971660256385803
    }
  ],
  "10993": [
    {
      "answer": "International Contemporary Music Festival Warsaw Autumn",
      "score": 0.6073144674301147
    },
    {
      "answer": "Jazz Jamboree",
      "score": 0.6443823575973511
    }
  ],
  "10994": [
    {
      "answer": "Ogr\u00f3d Saski",
      "score": 0.9615155458450317
    }
  ],
  "10995": [
    {
      "answer": "Ogr\u00f3d Saski",
      "score": 0.9423943758010864
    }
  ],
  "10996": [
    {
      "answer": "1870 to 1939",
      "score": 0.983256995677948
    }
  ],
  "10997": [
    {
      "answer": "Momus",
      "score": 0.9795388579368591
    }
  ],
  "10998": [
    {
      "answer": "Wojciech Bogus\u0142awski Theatre",
      "score": 0.9846329689025879
    }
  ],
  "10999": [],
  "11000": [],
  "11001": [
    {
      "answer": "1870 to 1939",
      "score": 0.8026971817016602
    }
  ],
  "11002": [
    {
      "answer": "Momus",
      "score": 0.9656810760498047
    }
  ],
  "11003": [
    {
      "answer": "Wojciech Bogus\u0142awski Theatre",
      "score": 0.9847192764282227
    }
  ],
  "11004": [
    {
      "answer": "Wianki",
      "score": 0.9671084880828857
    }
  ],
  "11005": [
    {
      "answer": "thousands",
      "score": 0.9851580262184143
    }
  ],
  "11006": [
    {
      "answer": "Midsummer\u2019s Night",
      "score": 0.9091620445251465
    },
    {
      "answer": "Midsummer\u2019s Eve",
      "score": 0.572333812713623
    }
  ],
  "11007": [
    {
      "answer": "when they would be married",
      "score": 0.9778475165367126
    }
  ],
  "11008": [
    {
      "answer": "fern",
      "score": 0.9919881820678711
    }
  ],
  "11009": [
    {
      "answer": "Wianki",
      "score": 0.8485783934593201
    }
  ],
  "11010": [
    {
      "answer": "thousands",
      "score": 0.9837279319763184
    }
  ],
  "11011": [
    {
      "answer": "Midsummer\u2019s Night",
      "score": 0.8397809863090515
    },
    {
      "answer": "Midsummer\u2019s Eve",
      "score": 0.6411187052726746
    }
  ],
  "11012": [],
  "11013": [
    {
      "answer": "fern",
      "score": 0.9915158748626709
    }
  ],
  "11014": [
    {
      "answer": "art posters",
      "score": 0.9637986421585083
    }
  ],
  "11015": [
    {
      "answer": "60",
      "score": 0.9954186677932739
    }
  ],
  "11016": [
    {
      "answer": "most prestigious",
      "score": 0.8447625637054443
    }
  ],
  "11017": [
    {
      "answer": "some paintings",
      "score": 0.8433480262756348
    }
  ],
  "11018": [
    {
      "answer": "arms",
      "score": 0.9744551777839661
    }
  ],
  "11019": [
    {
      "answer": "60",
      "score": 0.9172735810279846
    }
  ],
  "11020": [
    {
      "answer": "posters",
      "score": 0.9662192463874817
    }
  ],
  "11021": [
    {
      "answer": "Museum of Posters",
      "score": 0.9356052279472351
    }
  ],
  "11022": [
    {
      "answer": "paintings",
      "score": 0.9245486855506897
    }
  ],
  "11023": [
    {
      "answer": "arms",
      "score": 0.9779331684112549
    }
  ],
  "11024": [
    {
      "answer": "Warsaw Uprising Museum",
      "score": 0.9841870069503784
    },
    {
      "answer": "Katy\u0144 Museum",
      "score": 0.9386072158813477
    },
    {
      "answer": "Warsaw Uprising Museum",
      "score": 0.8374428749084473
    }
  ],
  "11025": [
    {
      "answer": "Katy\u0144 Museum",
      "score": 0.9912893176078796
    }
  ],
  "11026": [
    {
      "answer": "stereoscopic",
      "score": 0.9889265298843384
    }
  ],
  "11027": [
    {
      "answer": "Museum of Independence",
      "score": 0.9821180105209351
    }
  ],
  "11028": [
    {
      "answer": "60",
      "score": 0.9954975843429565
    }
  ],
  "11029": [
    {
      "answer": "Warsaw Uprising Museum",
      "score": 0.968192458152771
    },
    {
      "answer": "Katy\u0144 Museum",
      "score": 0.8696110248565674
    },
    {
      "answer": "Warsaw Uprising Museum",
      "score": 0.7633273601531982
    }
  ],
  "11030": [
    {
      "answer": "Museum of Independence",
      "score": 0.9862496256828308
    }
  ],
  "11031": [
    {
      "answer": "stereoscopic",
      "score": 0.9879986047744751
    }
  ],
  "11032": [
    {
      "answer": "Museum of Independence",
      "score": 0.9821224212646484
    }
  ],
  "11033": [
    {
      "answer": "60",
      "score": 0.9931647181510925
    }
  ],
  "11034": [
    {
      "answer": "Royal Ujazd\u00f3w",
      "score": 0.969488799571991
    }
  ],
  "11035": [
    {
      "answer": "500",
      "score": 0.9833620190620422
    }
  ],
  "11036": [
    {
      "answer": "Zach\u0119ta National Gallery of Art",
      "score": 0.9850853085517883
    }
  ],
  "11037": [
    {
      "answer": "modern art",
      "score": 0.938575029373169
    }
  ],
  "11038": [
    {
      "answer": "last weekend of September",
      "score": 0.9518076181411743
    }
  ],
  "11039": [
    {
      "answer": "Royal Ujazd\u00f3w Castle",
      "score": 0.9566049575805664
    }
  ],
  "11040": [
    {
      "answer": "500",
      "score": 0.9747118353843689
    }
  ],
  "11041": [
    {
      "answer": "Royal Ujazd\u00f3w Castle",
      "score": 0.7882260084152222
    },
    {
      "answer": "Zach\u0119ta National Gallery of Art",
      "score": 0.8509537577629089
    }
  ],
  "11042": [
    {
      "answer": "modern art",
      "score": 0.8384900093078613
    }
  ],
  "11043": [
    {
      "answer": "last weekend of September",
      "score": 0.9305293560028076
    }
  ],
  "11044": [
    {
      "answer": "Polonia Warsaw",
      "score": 0.988844633102417
    }
  ],
  "11045": [
    {
      "answer": "1946",
      "score": 0.9006292819976807
    }
  ],
  "11046": [
    {
      "answer": "twice",
      "score": 0.9850916266441345
    }
  ],
  "11047": [
    {
      "answer": "Konwiktorska Street",
      "score": 0.9776160717010498
    }
  ],
  "11048": [
    {
      "answer": "disastrous financial situation",
      "score": 0.9879655838012695
    }
  ],
  "11049": [
    {
      "answer": "Polonia Warsaw",
      "score": 0.9842779636383057
    }
  ],
  "11050": [
    {
      "answer": "1946",
      "score": 0.8920189738273621
    }
  ],
  "11051": [
    {
      "answer": "twice",
      "score": 0.9842212200164795
    }
  ],
  "11052": [
    {
      "answer": "Konwiktorska Street",
      "score": 0.9799164533615112
    }
  ],
  "11053": [
    {
      "answer": "disastrous financial situation",
      "score": 0.9878484606742859
    }
  ],
  "11054": [
    {
      "answer": "syrenka",
      "score": 0.9658587574958801
    }
  ],
  "11055": [
    {
      "answer": "mermaid",
      "score": 0.9904404878616333
    }
  ],
  "11056": [
    {
      "answer": "mid-14th century",
      "score": 0.968169629573822
    }
  ],
  "11057": [
    {
      "answer": "1390",
      "score": 0.9961097836494446
    }
  ],
  "11058": [
    {
      "answer": "sword",
      "score": 0.9902245402336121
    }
  ],
  "11059": [
    {
      "answer": "syrenka",
      "score": 0.898520290851593
    }
  ],
  "11060": [
    {
      "answer": "mermaid",
      "score": 0.9867197871208191
    }
  ],
  "11061": [
    {
      "answer": "mid-14th century",
      "score": 0.96866375207901
    }
  ],
  "11062": [
    {
      "answer": "1390",
      "score": 0.9958706498146057
    }
  ],
  "11063": [
    {
      "answer": "sword",
      "score": 0.9760082960128784
    }
  ],
  "11064": [],
  "11065": [
    {
      "answer": "Denmark",
      "score": 0.6556017994880676
    },
    {
      "answer": "Vistula River",
      "score": 0.8510987758636475
    }
  ],
  "11066": [
    {
      "answer": "coast of Denmark",
      "score": 0.9084968566894531
    }
  ],
  "11067": [
    {
      "answer": "Warszowa",
      "score": 0.9974285960197449
    }
  ],
  "11068": [
    {
      "answer": "captured",
      "score": 0.9908258318901062
    }
  ],
  "11069": [],
  "11070": [
    {
      "answer": "Denmark",
      "score": 0.6635204553604126
    },
    {
      "answer": "Vistula River",
      "score": 0.845994234085083
    }
  ],
  "11071": [
    {
      "answer": "coast of Denmark",
      "score": 0.9112192988395691
    }
  ],
  "11072": [
    {
      "answer": "Warszowa",
      "score": 0.7596401572227478
    }
  ],
  "11073": [
    {
      "answer": "captured the mermaid",
      "score": 0.9825603365898132
    }
  ],
  "11074": [
    {
      "answer": "Maria Sk\u0142odowska-Curie",
      "score": 0.9908161759376526
    }
  ],
  "11075": [
    {
      "answer": "Nobel Prize",
      "score": 0.9911478757858276
    }
  ],
  "11076": [],
  "11077": [
    {
      "answer": "seven months",
      "score": 0.9929181337356567
    }
  ],
  "11078": [
    {
      "answer": "1745",
      "score": 0.99210125207901
    }
  ],
  "11079": [
    {
      "answer": "Maria Sk\u0142odowska-Curie",
      "score": 0.9853384494781494
    }
  ],
  "11080": [
    {
      "answer": "Nobel Prize",
      "score": 0.9919366836547852
    }
  ],
  "11081": [
    {
      "answer": "Fr\u00e9d\u00e9ric Chopin",
      "score": 0.7439759969711304
    },
    {
      "answer": "Chopin",
      "score": 0.581360936164856
    }
  ],
  "11082": [
    {
      "answer": "seven months",
      "score": 0.992458701133728
    }
  ],
  "11083": [
    {
      "answer": "1745",
      "score": 0.9944251775741577
    }
  ],
  "11084": [
    {
      "answer": "Warsaw",
      "score": 0.9580023884773254
    },
    {
      "answer": "Warsaw",
      "score": 0.9196868538856506
    },
    {
      "answer": "Warsaw",
      "score": 0.9310601353645325
    },
    {
      "answer": "Warsaw",
      "score": 0.906592607498169
    },
    {
      "answer": "Warsaw",
      "score": 0.90043044090271
    },
    {
      "answer": "Warsaw",
      "score": 0.9243559837341309
    },
    {
      "answer": "Warsaw",
      "score": 0.9271041750907898
    },
    {
      "answer": "Warsaw",
      "score": 0.903328001499176
    }
  ],
  "11085": [
    {
      "answer": "1916",
      "score": 0.995384156703949
    }
  ],
  "11086": [
    {
      "answer": "Art Deco style",
      "score": 0.9917157888412476
    }
  ],
  "11087": [
    {
      "answer": "poet",
      "score": 0.989266037940979
    }
  ],
  "11088": [
    {
      "answer": "Isaac Bashevis Singer",
      "score": 0.995945394039154
    }
  ],
  "11089": [
    {
      "answer": "Warsaw",
      "score": 0.9594749808311462
    },
    {
      "answer": "Warsaw",
      "score": 0.9220046997070312
    },
    {
      "answer": "Warsaw",
      "score": 0.9338672161102295
    },
    {
      "answer": "Warsaw",
      "score": 0.9079717993736267
    },
    {
      "answer": "Warsaw",
      "score": 0.9068939089775085
    },
    {
      "answer": "Warsaw",
      "score": 0.9277986288070679
    },
    {
      "answer": "Warsaw",
      "score": 0.9291083216667175
    },
    {
      "answer": "Warsaw",
      "score": 0.9049904346466064
    }
  ],
  "11090": [
    {
      "answer": "1916",
      "score": 0.9951274394989014
    }
  ],
  "11091": [
    {
      "answer": "Art Deco style",
      "score": 0.9886409640312195
    }
  ],
  "11092": [
    {
      "answer": "poet",
      "score": 0.989532470703125
    }
  ],
  "11093": [
    {
      "answer": "Isaac Bashevis Singer",
      "score": 0.9765404462814331
    }
  ],
  "11094": [
    {
      "answer": "1754",
      "score": 0.9736550450325012
    }
  ],
  "11095": [
    {
      "answer": "British America",
      "score": 0.936721920967102
    },
    {
      "answer": "New France",
      "score": 0.9176275730133057
    }
  ],
  "11096": [
    {
      "answer": "60,000",
      "score": 0.9869556427001953
    }
  ],
  "11097": [
    {
      "answer": "2 million",
      "score": 0.9906567335128784
    }
  ],
  "11098": [
    {
      "answer": "1754",
      "score": 0.9227142333984375
    },
    {
      "answer": "1763",
      "score": 0.9003794193267822
    }
  ],
  "11099": [
    {
      "answer": "1754",
      "score": 0.8565221428871155
    },
    {
      "answer": "1763",
      "score": 0.5912706851959229
    }
  ],
  "11100": [
    {
      "answer": "Great Britain",
      "score": 0.8438275456428528
    },
    {
      "answer": "Native American",
      "score": 0.9332088828086853
    }
  ],
  "11101": [
    {
      "answer": "60,000",
      "score": 0.955767035484314
    }
  ],
  "11102": [
    {
      "answer": "2 million",
      "score": 0.9888187050819397
    }
  ],
  "11103": [
    {
      "answer": "along the frontiers between New France and the British colonies",
      "score": 0.8731744885444641
    },
    {
      "answer": "Nova Scotia",
      "score": 0.8569458723068237
    }
  ],
  "11104": [
    {
      "answer": "a dispute over control of the confluence of the Allegheny and Monongahela rivers, called the Forks of the Ohio, and the site of the French Fort Duquesne and present-day Pittsburgh, Pennsylvania",
      "score": 0.9579344391822815
    }
  ],
  "11105": [
    {
      "answer": "May 1754",
      "score": 0.9949188232421875
    }
  ],
  "11106": [
    {
      "answer": "Nova Scotia",
      "score": 0.8838067650794983
    }
  ],
  "11107": [
    {
      "answer": "a dispute over control of the confluence of the Allegheny and Monongahela rivers",
      "score": 0.9755121469497681
    }
  ],
  "11108": [
    {
      "answer": "a dispute over control of the confluence of the Allegheny and Monongahela rivers",
      "score": 0.9811771512031555
    }
  ],
  "11109": [
    {
      "answer": "May 1754",
      "score": 0.9868072867393494
    }
  ],
  "11110": [
    {
      "answer": "May 1754",
      "score": 0.9906244874000549
    }
  ],
  "11111": [
    {
      "answer": "1755",
      "score": 0.9065812230110168
    },
    {
      "answer": "1755",
      "score": 0.7304213643074036
    },
    {
      "answer": "1755",
      "score": 0.5988735556602478
    },
    {
      "answer": "1755",
      "score": 0.6439895629882812
    }
  ],
  "11112": [
    {
      "answer": "a disaster",
      "score": 0.8533337116241455
    }
  ],
  "11113": [
    {
      "answer": "poor management",
      "score": 0.9845759868621826
    },
    {
      "answer": "effective Canadian scouts, French regular forces, and Indian warrior allies",
      "score": 0.9599089026451111
    }
  ],
  "11114": [
    {
      "answer": "Fort Beaus\u00e9jour",
      "score": 0.9401487112045288
    }
  ],
  "11115": [
    {
      "answer": "expulsion",
      "score": 0.9742053151130676
    }
  ],
  "11116": [
    {
      "answer": "1755",
      "score": 0.9122113585472107
    },
    {
      "answer": "1755",
      "score": 0.7339401245117188
    },
    {
      "answer": "1755",
      "score": 0.6545343399047852
    },
    {
      "answer": "1755",
      "score": 0.7080052495002747
    }
  ],
  "11117": [
    {
      "answer": "a disaster",
      "score": 0.8607330918312073
    }
  ],
  "11118": [
    {
      "answer": "poor management, internal divisions",
      "score": 0.9722661972045898
    },
    {
      "answer": "effective Canadian scouts, French regular forces, and Indian warrior allies",
      "score": 0.9566823840141296
    }
  ],
  "11119": [
    {
      "answer": "Fort Beaus\u00e9jour",
      "score": 0.9671926498413086
    }
  ],
  "11120": [
    {
      "answer": "expulsion of the Acadians",
      "score": 0.907874584197998
    }
  ],
  "11121": [
    {
      "answer": "William Pitt",
      "score": 0.9972424507141113
    }
  ],
  "11122": [],
  "11123": [
    {
      "answer": "European theatre",
      "score": 0.9677397012710571
    }
  ],
  "11124": [
    {
      "answer": "Sainte Foy",
      "score": 0.9885794520378113
    }
  ],
  "11125": [
    {
      "answer": "William Pitt",
      "score": 0.8948453664779663
    },
    {
      "answer": "France",
      "score": 0.5853851437568665
    },
    {
      "answer": "France",
      "score": 0.5466476082801819
    }
  ],
  "11126": [
    {
      "answer": "France was unwilling to risk large convoys to aid the limited forces it had in New France",
      "score": 0.6963760852813721
    }
  ],
  "11127": [],
  "11128": [
    {
      "answer": "European theatre",
      "score": 0.9610953330993652
    }
  ],
  "11129": [
    {
      "answer": "Sainte Foy",
      "score": 0.9887219667434692
    }
  ],
  "11130": [
    {
      "answer": "east of the Mississippi",
      "score": 0.988514244556427
    }
  ],
  "11131": [
    {
      "answer": "French Louisiana",
      "score": 0.9512168169021606
    }
  ],
  "11132": [
    {
      "answer": "France ceded its territory east of the Mississippi to Great Britain",
      "score": 0.8634498119354248
    },
    {
      "answer": "France's colonial presence north of the Caribbean was reduced to the islands of Saint Pierre and Miquelon, confirming Britain's position as the dominant colonial power in eastern North America",
      "score": 0.7396811246871948
    }
  ],
  "11133": [
    {
      "answer": "east of the Mississippi",
      "score": 0.7705584764480591
    },
    {
      "answer": "French Louisiana west of the Mississippi River",
      "score": 0.5607386827468872
    }
  ],
  "11134": [
    {
      "answer": "east of the Mississippi",
      "score": 0.9682297706604004
    }
  ],
  "11135": [
    {
      "answer": "New Orleans",
      "score": 0.9160714745521545
    }
  ],
  "11136": [],
  "11137": [
    {
      "answer": "France's colonial presence north of the Caribbean was reduced to the islands of Saint Pierre and Miquelon, confirming Britain's position as the dominant colonial power in eastern North America",
      "score": 0.8520965576171875
    }
  ],
  "11138": [
    {
      "answer": "1740s",
      "score": 0.9915760159492493
    }
  ],
  "11139": [
    {
      "answer": "Fourth Intercolonial War",
      "score": 0.7187730073928833
    },
    {
      "answer": "Great War for the Empire",
      "score": 0.7998366355895996
    }
  ],
  "11140": [
    {
      "answer": "a much larger conflict between France and Great Britain",
      "score": 0.7865484952926636
    }
  ],
  "11141": [
    {
      "answer": "Fourth Intercolonial War",
      "score": 0.9866921901702881
    },
    {
      "answer": "Great War for the Empire",
      "score": 0.9864208102226257
    }
  ],
  "11142": [
    {
      "answer": "1740s",
      "score": 0.993083119392395
    }
  ],
  "11143": [
    {
      "answer": "1740s",
      "score": 0.9913203120231628
    }
  ],
  "11144": [
    {
      "answer": "Fourth Intercolonial War",
      "score": 0.6071242690086365
    },
    {
      "answer": "Great War for the Empire",
      "score": 0.7021327614784241
    }
  ],
  "11145": [],
  "11146": [
    {
      "answer": "Fourth Intercolonial War",
      "score": 0.958953320980072
    },
    {
      "answer": "Great War for the Empire",
      "score": 0.9677799344062805
    }
  ],
  "11147": [
    {
      "answer": "from the official declaration of war in 1756 to the signing of the peace treaty in 1763",
      "score": 0.9251156449317932
    }
  ],
  "11148": [
    {
      "answer": "six years",
      "score": 0.9834063053131104
    }
  ],
  "11149": [
    {
      "answer": "1760",
      "score": 0.990278422832489
    }
  ],
  "11150": [
    {
      "answer": "Battle of Jumonville Glen",
      "score": 0.9358285665512085
    }
  ],
  "11151": [],
  "11152": [
    {
      "answer": "from the Battle of Jumonville Glen in 1754 to the capture of Montreal in 1760",
      "score": 0.9235681295394897
    }
  ],
  "11153": [
    {
      "answer": "1760",
      "score": 0.9876683354377747
    }
  ],
  "11154": [
    {
      "answer": "six years",
      "score": 0.9852332472801208
    }
  ],
  "11155": [
    {
      "answer": "Battle of Jumonville Glen",
      "score": 0.9441280364990234
    }
  ],
  "11156": [
    {
      "answer": "75,000",
      "score": 0.9822153449058533
    }
  ],
  "11157": [
    {
      "answer": "St. Lawrence River valley",
      "score": 0.9673881530761719
    },
    {
      "answer": "Acadia",
      "score": 0.6681424975395203
    },
    {
      "answer": "Biloxi, Mississippi",
      "score": 0.6184251308441162
    },
    {
      "answer": "Illinois Country",
      "score": 0.731956422328949
    }
  ],
  "11158": [
    {
      "answer": "St. Lawrence and Mississippi watersheds",
      "score": 0.976571798324585
    }
  ],
  "11159": [
    {
      "answer": "about 75,000",
      "score": 0.9255000948905945
    }
  ],
  "11160": [
    {
      "answer": "75,000",
      "score": 0.9567675590515137
    }
  ],
  "11161": [
    {
      "answer": "St. Lawrence River valley",
      "score": 0.7327750325202942
    },
    {
      "answer": "New Orleans",
      "score": 0.8879194259643555
    },
    {
      "answer": "Biloxi, Mississippi",
      "score": 0.8803884983062744
    },
    {
      "answer": "Mobile, Alabama",
      "score": 0.8675025701522827
    },
    {
      "answer": "Illinois Country",
      "score": 0.9154963493347168
    }
  ],
  "11162": [
    {
      "answer": "St. Lawrence River valley",
      "score": 0.9562191963195801
    },
    {
      "answer": "Acadia",
      "score": 0.5885805487632751
    },
    {
      "answer": "Illinois Country",
      "score": 0.7055119276046753
    }
  ],
  "11163": [
    {
      "answer": "New Orleans",
      "score": 0.9091883301734924
    },
    {
      "answer": "Biloxi, Mississippi",
      "score": 0.8745050430297852
    },
    {
      "answer": "Illinois Country",
      "score": 0.7961773872375488
    }
  ],
  "11164": [
    {
      "answer": "20 to 1",
      "score": 0.9918205142021179
    }
  ],
  "11165": [
    {
      "answer": "eastern coast of the continent",
      "score": 0.8466649055480957
    },
    {
      "answer": "Nova Scotia and Newfoundland",
      "score": 0.9039989709854126
    },
    {
      "answer": "Georgia",
      "score": 0.8406882882118225
    }
  ],
  "11166": [
    {
      "answer": "eastern coast of the continent",
      "score": 0.617326557636261
    }
  ],
  "11167": [
    {
      "answer": "20 to 1",
      "score": 0.984836220741272
    }
  ],
  "11168": [
    {
      "answer": "20 to 1",
      "score": 0.9887851476669312
    }
  ],
  "11169": [
    {
      "answer": "Nova Scotia and Newfoundland",
      "score": 0.8085581064224243
    },
    {
      "answer": "Georgia",
      "score": 0.7811005711555481
    },
    {
      "answer": "Nova Scotia",
      "score": 0.5987216830253601
    }
  ],
  "11170": [
    {
      "answer": "eastern coast of the continent",
      "score": 0.775550901889801
    },
    {
      "answer": "Nova Scotia",
      "score": 0.8546838760375977
    },
    {
      "answer": "Nova Scotia",
      "score": 0.5902267694473267
    }
  ],
  "11171": [],
  "11172": [
    {
      "answer": "native tribes",
      "score": 0.994306206703186
    }
  ],
  "11173": [
    {
      "answer": "Mi'kmaq and the Abenaki",
      "score": 0.9279309511184692
    }
  ],
  "11174": [
    {
      "answer": "present-day Upstate New York",
      "score": 0.9537007808685303
    }
  ],
  "11175": [
    {
      "answer": "Iroquois",
      "score": 0.9585616588592529
    }
  ],
  "11176": [
    {
      "answer": "native tribes",
      "score": 0.9852026700973511
    }
  ],
  "11177": [
    {
      "answer": "native tribes",
      "score": 0.9930803775787354
    }
  ],
  "11178": [
    {
      "answer": "Mi'kmaq and the Abenaki",
      "score": 0.8434844017028809
    }
  ],
  "11179": [
    {
      "answer": "Ohio Country",
      "score": 0.834708571434021
    }
  ],
  "11180": [
    {
      "answer": "Iroquois rule",
      "score": 0.8895703554153442
    }
  ],
  "11181": [
    {
      "answer": "Catawba",
      "score": 0.9255174398422241
    }
  ],
  "11182": [
    {
      "answer": "western portions of the Great Lakes region",
      "score": 0.9401159286499023
    }
  ],
  "11183": [
    {
      "answer": "Cherokee",
      "score": 0.5244027376174927
    },
    {
      "answer": "Iroquois Six Nations",
      "score": 0.7549626231193542
    },
    {
      "answer": "Cherokee",
      "score": 0.8844749331474304
    },
    {
      "answer": "Cherokee",
      "score": 0.574617862701416
    }
  ],
  "11184": [
    {
      "answer": "Catawba, Muskogee-speaking Creek and Choctaw",
      "score": 0.683774471282959
    }
  ],
  "11185": [],
  "11186": [
    {
      "answer": "western portions of the Great Lakes region",
      "score": 0.919452965259552
    }
  ],
  "11187": [
    {
      "answer": "western portions of the Great Lakes region",
      "score": 0.9417001605033875
    }
  ],
  "11188": [],
  "11189": [
    {
      "answer": "no",
      "score": 0.9787778854370117
    }
  ],
  "11190": [
    {
      "answer": "few",
      "score": 0.9220514297485352
    }
  ],
  "11191": [],
  "11192": [
    {
      "answer": "no",
      "score": 0.8798869252204895
    }
  ],
  "11193": [
    {
      "answer": "no",
      "score": 0.9758392572402954
    }
  ],
  "11194": [
    {
      "answer": "few",
      "score": 0.8484617471694946
    }
  ],
  "11195": [
    {
      "answer": "few",
      "score": 0.8290085196495056
    }
  ],
  "11196": [
    {
      "answer": "New France was defended by about 3,000 troupes de la marine",
      "score": 0.7744373679161072
    }
  ],
  "11197": [
    {
      "answer": "up the St. Lawrence",
      "score": 0.7710190415382385
    },
    {
      "answer": "continued along the northern shore of Lake Ontario",
      "score": 0.8833914995193481
    },
    {
      "answer": "crossed the portage at Niagara",
      "score": 0.8443560004234314
    },
    {
      "answer": "followed the southern shore of Lake Erie",
      "score": 0.8638153076171875
    }
  ],
  "11198": [
    {
      "answer": "Troupes de la marine",
      "score": 0.9373879432678223
    },
    {
      "answer": "Indians",
      "score": 0.907889723777771
    }
  ],
  "11199": [
    {
      "answer": "informed them of the French claims on the territory and told them to leave",
      "score": 0.9714056849479675
    }
  ],
  "11200": [
    {
      "answer": "buried lead plates engraved with the French claim to the Ohio Country",
      "score": 0.8939586877822876
    }
  ],
  "11201": [],
  "11202": [],
  "11203": [
    {
      "answer": "Troupes de la marine",
      "score": 0.9542720913887024
    },
    {
      "answer": "Indians",
      "score": 0.9275025725364685
    }
  ],
  "11204": [
    {
      "answer": "informed them of the French claims on the territory and told them to leave",
      "score": 0.9405379295349121
    }
  ],
  "11205": [],
  "11206": [
    {
      "answer": "Pickawillany",
      "score": 0.9961287975311279
    }
  ],
  "11207": [
    {
      "answer": "threatened \"Old Briton\" with severe consequences if he continued to trade with the British.",
      "score": 0.8810647130012512
    }
  ],
  "11208": [
    {
      "answer": "ignored the warning",
      "score": 0.9581305980682373
    }
  ],
  "11209": [
    {
      "answer": "they owned the Ohio Country and that they would trade with the British regardless of the French",
      "score": 0.8486294150352478
    }
  ],
  "11210": [
    {
      "answer": "Pickawillany",
      "score": 0.9739718437194824
    }
  ],
  "11211": [
    {
      "answer": "Pickawillany",
      "score": 0.9933037161827087
    }
  ],
  "11212": [
    {
      "answer": "threatened \"Old Briton\" with severe consequences if he continued to trade with the British.",
      "score": 0.8568328619003296
    }
  ],
  "11213": [
    {
      "answer": "ignored the warning",
      "score": 0.9326252937316895
    }
  ],
  "11214": [
    {
      "answer": "very badly disposed towards the French",
      "score": 0.9501757621765137
    }
  ],
  "11215": [],
  "11216": [
    {
      "answer": "British colonists would not be safe as long as the French were present",
      "score": 0.8776810765266418
    }
  ],
  "11217": [
    {
      "answer": "very badly disposed towards the French",
      "score": 0.9565640687942505
    }
  ],
  "11218": [
    {
      "answer": "very badly disposed towards the French",
      "score": 0.864729642868042
    }
  ],
  "11219": [],
  "11220": [
    {
      "answer": "very badly disposed towards the French",
      "score": 0.8464841842651367
    }
  ],
  "11221": [
    {
      "answer": "British colonists would not be safe as long as the French were present",
      "score": 0.8095154762268066
    }
  ],
  "11222": [
    {
      "answer": "1749",
      "score": 0.9819905161857605
    }
  ],
  "11223": [
    {
      "answer": "Ohio Company of Virginia",
      "score": 0.9716442823410034
    }
  ],
  "11224": [
    {
      "answer": "Christopher Gist",
      "score": 0.993483304977417
    }
  ],
  "11225": [
    {
      "answer": "Treaty of Logstown",
      "score": 0.9845002889633179
    }
  ],
  "11226": [
    {
      "answer": "the mouth of the Monongahela River",
      "score": 0.9795341491699219
    }
  ],
  "11227": [
    {
      "answer": "1749",
      "score": 0.9874208569526672
    }
  ],
  "11228": [
    {
      "answer": "Ohio Company of Virginia",
      "score": 0.8988755941390991
    }
  ],
  "11229": [
    {
      "answer": "Christopher Gist",
      "score": 0.9936892986297607
    }
  ],
  "11230": [
    {
      "answer": "the territory was also claimed by Pennsylvania",
      "score": 0.8899593949317932
    }
  ],
  "11231": [
    {
      "answer": "the mouth of the Monongahela River",
      "score": 0.9769551157951355
    }
  ],
  "11232": [
    {
      "answer": "King George's War",
      "score": 0.5967958569526672
    },
    {
      "answer": "no decision",
      "score": 0.6806265711784363
    }
  ],
  "11233": [
    {
      "answer": "1748 with the signing of the Treaty of Aix-la-Chapelle",
      "score": 0.8460119962692261
    }
  ],
  "11234": [
    {
      "answer": "conflicting territorial claims between British and French colonies in North America",
      "score": 0.978984534740448
    }
  ],
  "11235": [
    {
      "answer": "no decision",
      "score": 0.9034922122955322
    }
  ],
  "11236": [
    {
      "answer": "Ohio Country",
      "score": 0.8708266019821167
    }
  ],
  "11237": [
    {
      "answer": "no decision",
      "score": 0.762330174446106
    }
  ],
  "11238": [
    {
      "answer": "1748 with the signing of the Treaty of Aix-la-Chapelle",
      "score": 0.8314058780670166
    }
  ],
  "11239": [
    {
      "answer": "resolving issues in Europe",
      "score": 0.8901839852333069
    },
    {
      "answer": "conflicting territorial claims between British and French colonies in North America",
      "score": 0.8683747053146362
    }
  ],
  "11240": [
    {
      "answer": "no decision",
      "score": 0.9424326419830322
    }
  ],
  "11241": [
    {
      "answer": "Marquis de la Jonqui\u00e8re",
      "score": 0.9803876280784607
    }
  ],
  "11242": [
    {
      "answer": "300",
      "score": 0.9935702085494995
    }
  ],
  "11243": [
    {
      "answer": "to punish the Miami people of Pickawillany for not following C\u00e9loron's orders to cease trading with the British",
      "score": 0.9830524325370789
    }
  ],
  "11244": [
    {
      "answer": "capturing three traders",
      "score": 0.9699931144714355
    },
    {
      "answer": "killing 14 people of the Miami nation",
      "score": 0.870970606803894
    }
  ],
  "11245": [
    {
      "answer": "Marquis de la Jonqui\u00e8re",
      "score": 0.9673659801483154
    }
  ],
  "11246": [
    {
      "answer": "Marquis de la Jonqui\u00e8re",
      "score": 0.8700097799301147
    }
  ],
  "11247": [
    {
      "answer": "300",
      "score": 0.9391679763793945
    }
  ],
  "11248": [
    {
      "answer": "to punish the Miami people of Pickawillany for not following C\u00e9loron's orders to cease trading with the British",
      "score": 0.9736990928649902
    }
  ],
  "11249": [
    {
      "answer": "capturing three traders",
      "score": 0.9546273946762085
    },
    {
      "answer": "killing 14 people of the Miami nation",
      "score": 0.895392119884491
    }
  ],
  "11250": [
    {
      "answer": "Paul Marin de la Malgue",
      "score": 0.9845787286758423
    }
  ],
  "11251": [
    {
      "answer": "Fort Presque Isle",
      "score": 0.9354031085968018
    }
  ],
  "11252": [
    {
      "answer": "Fort Le Boeuf (present-day Waterford, Pennsylvania",
      "score": 0.7825005650520325
    }
  ],
  "11253": [
    {
      "answer": "to protect the King's land in the Ohio Valley from the British",
      "score": 0.980906069278717
    }
  ],
  "11254": [
    {
      "answer": "Tanaghrisson",
      "score": 0.9812002778053284
    }
  ],
  "11255": [
    {
      "answer": "Paul Marin de la Malgue",
      "score": 0.9656298756599426
    }
  ],
  "11256": [
    {
      "answer": "Fort Le Boeuf",
      "score": 0.6782779693603516
    },
    {
      "answer": "Fort Le Boeuf",
      "score": 0.7046560645103455
    }
  ],
  "11257": [
    {
      "answer": "Fort Presque Isle",
      "score": 0.9308937788009644
    }
  ],
  "11258": [
    {
      "answer": "to protect the King's land in the Ohio Valley from the British",
      "score": 0.9682784080505371
    }
  ],
  "11259": [
    {
      "answer": "Tanaghrisson",
      "score": 0.9879062175750732
    }
  ],
  "11260": [
    {
      "answer": "British Superintendent for Indian Affairs",
      "score": 0.6520875096321106
    },
    {
      "answer": "colonel",
      "score": 0.8189228177070618
    }
  ],
  "11261": [
    {
      "answer": "Warraghiggey",
      "score": 0.9848932027816772
    }
  ],
  "11262": [
    {
      "answer": "colonel",
      "score": 0.9520589709281921
    },
    {
      "answer": "colonel",
      "score": 0.8191400766372681
    }
  ],
  "11263": [
    {
      "answer": "Mohawk Chief Hendrick",
      "score": 0.9663085341453552
    }
  ],
  "11264": [
    {
      "answer": "British Superintendent for Indian Affairs",
      "score": 0.7757368683815002
    },
    {
      "answer": "colonel",
      "score": 0.6639797687530518
    }
  ],
  "11265": [
    {
      "answer": "colonel",
      "score": 0.8432934284210205
    }
  ],
  "11266": [
    {
      "answer": "Warraghiggey",
      "score": 0.979127824306488
    }
  ],
  "11267": [
    {
      "answer": "Warraghiggey",
      "score": 0.9692205786705017
    }
  ],
  "11268": [
    {
      "answer": "Mohawk Chief Hendrick",
      "score": 0.8439041376113892
    }
  ],
  "11269": [
    {
      "answer": "Ohio Company",
      "score": 0.9931473135948181
    },
    {
      "answer": "Ohio Company",
      "score": 0.9647297859191895
    }
  ],
  "11270": [
    {
      "answer": "Major George Washington",
      "score": 0.9645768404006958
    }
  ],
  "11271": [
    {
      "answer": "Jacob Van Braam",
      "score": 0.9932565689086914
    },
    {
      "answer": "Christopher Gist",
      "score": 0.5561691522598267
    }
  ],
  "11272": [
    {
      "answer": "December 12",
      "score": 0.9972070455551147
    }
  ],
  "11273": [
    {
      "answer": "Ohio Company",
      "score": 0.9918316602706909
    },
    {
      "answer": "Ohio Company",
      "score": 0.9629287719726562
    }
  ],
  "11274": [
    {
      "answer": "Ohio Company",
      "score": 0.9899251461029053
    },
    {
      "answer": "Ohio Company",
      "score": 0.958105206489563
    }
  ],
  "11275": [
    {
      "answer": "George Washington",
      "score": 0.9842715859413147
    }
  ],
  "11276": [
    {
      "answer": "Jacob Van Braam",
      "score": 0.9184467196464539
    },
    {
      "answer": "Christopher Gist",
      "score": 0.9021075963973999
    }
  ],
  "11277": [
    {
      "answer": "December 12",
      "score": 0.9900312423706055
    }
  ],
  "11278": [
    {
      "answer": "Jacques Legardeur de Saint-Pierre",
      "score": 0.981209933757782
    }
  ],
  "11279": [
    {
      "answer": "letter from Dinwiddie",
      "score": 0.9531698226928711
    }
  ],
  "11280": [
    {
      "answer": "As to the Summons you send me to retire, I do not think myself obliged to obey it",
      "score": 0.9662983417510986
    }
  ],
  "11281": [
    {
      "answer": "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier",
      "score": 0.9830212593078613
    }
  ],
  "11282": [
    {
      "answer": "Jacques Legardeur de Saint-Pierre",
      "score": 0.9841245412826538
    }
  ],
  "11283": [
    {
      "answer": "Jacques Legardeur de Saint-Pierre",
      "score": 0.982459306716919
    }
  ],
  "11284": [
    {
      "answer": "letter from Dinwiddie",
      "score": 0.9583334922790527
    }
  ],
  "11285": [
    {
      "answer": "As to the Summons you send me to retire, I do not think myself obliged to obey it",
      "score": 0.9589105248451233
    }
  ],
  "11286": [
    {
      "answer": "Ren\u00e9-Robert Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier",
      "score": 0.9716296195983887
    }
  ],
  "11287": [
    {
      "answer": "500",
      "score": 0.7439054846763611
    }
  ],
  "11288": [
    {
      "answer": "early months of 1754",
      "score": 0.9395374059677124
    }
  ],
  "11289": [
    {
      "answer": "Fort Duquesne",
      "score": 0.9776058197021484
    }
  ],
  "11290": [
    {
      "answer": "additional French forces",
      "score": 0.8768050074577332
    }
  ],
  "11291": [
    {
      "answer": "500",
      "score": 0.5785595774650574
    }
  ],
  "11292": [
    {
      "answer": "early months of 1754",
      "score": 0.9293665885925293
    }
  ],
  "11293": [
    {
      "answer": "Fort Duquesne",
      "score": 0.8925807476043701
    }
  ],
  "11294": [
    {
      "answer": "Fort Duquesne",
      "score": 0.9588286876678467
    }
  ],
  "11295": [
    {
      "answer": "surprised the Canadians on May 28 in what became known as the Battle of Jumonville Glen",
      "score": 0.794396162033081
    }
  ],
  "11296": [
    {
      "answer": "killed many of the Canadians",
      "score": 0.8991075754165649
    }
  ],
  "11297": [
    {
      "answer": "to gain the support of the British and regain authority over his own people",
      "score": 0.9575015306472778
    }
  ],
  "11298": [
    {
      "answer": "May 28",
      "score": 0.9353643655776978
    }
  ],
  "11299": [
    {
      "answer": "May 28",
      "score": 0.9832138419151306
    }
  ],
  "11300": [],
  "11301": [
    {
      "answer": "They killed many of the Canadians",
      "score": 0.803555965423584
    }
  ],
  "11302": [
    {
      "answer": "to gain the support of the British and regain authority over his own people",
      "score": 0.9601694345474243
    }
  ],
  "11303": [
    {
      "answer": "to dislodge the French",
      "score": 0.9628486633300781
    }
  ],
  "11304": [],
  "11305": [
    {
      "answer": "dispatched six regiments to New France under the command of Baron Dieskau in 1755",
      "score": 0.971947968006134
    }
  ],
  "11306": [
    {
      "answer": "send an army expedition the following year to dislodge the French",
      "score": 0.8103669285774231
    },
    {
      "answer": "to blockade French ports",
      "score": 0.6399081945419312
    }
  ],
  "11307": [
    {
      "answer": "to dislodge the French",
      "score": 0.856084942817688
    },
    {
      "answer": "to blockade French ports",
      "score": 0.670993447303772
    }
  ],
  "11308": [
    {
      "answer": "to dislodge the French",
      "score": 0.7539516687393188
    },
    {
      "answer": "to blockade French ports",
      "score": 0.6750172972679138
    }
  ],
  "11309": [],
  "11310": [
    {
      "answer": "King Louis XV dispatched six regiments to New France under the command of Baron Dieskau in 1755",
      "score": 0.9559388160705566
    }
  ],
  "11311": [
    {
      "answer": "to blockade French ports",
      "score": 0.7978214025497437
    }
  ],
  "11312": [
    {
      "answer": "Albany Congress",
      "score": 0.9941225647926331
    }
  ],
  "11313": [
    {
      "answer": "to formalize a unified front in trade and negotiations with various Indians",
      "score": 0.9876089096069336
    }
  ],
  "11314": [
    {
      "answer": "never ratified by the colonial legislatures nor approved of by the crown",
      "score": 0.9225670099258423
    }
  ],
  "11315": [
    {
      "answer": "to formalize a unified front in trade and negotiations with various Indians",
      "score": 0.9769949913024902
    }
  ],
  "11316": [
    {
      "answer": "Albany Congress",
      "score": 0.990601122379303
    }
  ],
  "11317": [
    {
      "answer": "Albany Congress",
      "score": 0.9857138991355896
    }
  ],
  "11318": [
    {
      "answer": "to formalize a unified front in trade and negotiations with various Indians",
      "score": 0.9666547775268555
    }
  ],
  "11319": [
    {
      "answer": "never ratified by the colonial legislatures nor approved of by the crown",
      "score": 0.9106838703155518
    }
  ],
  "11320": [
    {
      "answer": "never ratified by the colonial legislatures nor approved of by the crown",
      "score": 0.8937990069389343
    }
  ],
  "11321": [
    {
      "answer": "Braddock",
      "score": 0.9296915531158447
    },
    {
      "answer": "George Washington",
      "score": 0.6149908304214478
    },
    {
      "answer": "Braddock",
      "score": 0.6721155643463135
    },
    {
      "answer": "George Washington",
      "score": 0.8447221517562866
    }
  ],
  "11322": [
    {
      "answer": "a disaster",
      "score": 0.8621665239334106
    }
  ],
  "11323": [
    {
      "answer": "1,000",
      "score": 0.9900627136230469
    }
  ],
  "11324": [
    {
      "answer": "George Washington",
      "score": 0.6319119930267334
    },
    {
      "answer": "George Washington",
      "score": 0.7275477647781372
    },
    {
      "answer": "Thomas Gage",
      "score": 0.9470240473747253
    }
  ],
  "11325": [
    {
      "answer": "Braddock",
      "score": 0.7372501492500305
    },
    {
      "answer": "Braddock",
      "score": 0.560091495513916
    },
    {
      "answer": "George Washington",
      "score": 0.6867221593856812
    }
  ],
  "11326": [
    {
      "answer": "Braddock",
      "score": 0.8828422427177429
    },
    {
      "answer": "George Washington",
      "score": 0.566382110118866
    },
    {
      "answer": "Braddock",
      "score": 0.6609876751899719
    },
    {
      "answer": "George Washington",
      "score": 0.8037108182907104
    }
  ],
  "11327": [
    {
      "answer": "a disaster",
      "score": 0.8155534267425537
    }
  ],
  "11328": [
    {
      "answer": "1,000",
      "score": 0.9828038215637207
    }
  ],
  "11329": [
    {
      "answer": "George Washington",
      "score": 0.5957318544387817
    },
    {
      "answer": "George Washington",
      "score": 0.7450497150421143
    },
    {
      "answer": "Thomas Gage",
      "score": 0.8691889047622681
    }
  ],
  "11330": [
    {
      "answer": "Shirley and Johnson",
      "score": 0.9800083041191101
    }
  ],
  "11331": [
    {
      "answer": "logistical difficulties",
      "score": 0.9568315744400024
    }
  ],
  "11332": [
    {
      "answer": "Fort Niagara",
      "score": 0.9798098802566528
    }
  ],
  "11333": [
    {
      "answer": "Fort Williams",
      "score": 0.814773440361023
    }
  ],
  "11334": [
    {
      "answer": "Shirley",
      "score": 0.9792492985725403
    }
  ],
  "11335": [
    {
      "answer": "Shirley",
      "score": 0.8751887679100037
    },
    {
      "answer": "Johnson",
      "score": 0.9044919013977051
    }
  ],
  "11336": [
    {
      "answer": "logistical difficulties",
      "score": 0.9053733348846436
    }
  ],
  "11337": [
    {
      "answer": "Fort Niagara",
      "score": 0.9763089418411255
    }
  ],
  "11338": [
    {
      "answer": "Fort Williams",
      "score": 0.8303706645965576
    }
  ],
  "11339": [
    {
      "answer": "Marquis de Vaudreuil",
      "score": 0.9947537183761597
    }
  ],
  "11340": [
    {
      "answer": "Vaudreuil sent Dieskau to Fort St. Fr\u00e9d\u00e9ric to meet that threat",
      "score": 0.9712726473808289
    }
  ],
  "11341": [
    {
      "answer": "inconclusively",
      "score": 0.6976048946380615
    }
  ],
  "11342": [
    {
      "answer": "Fort William Henry",
      "score": 0.9083271026611328
    },
    {
      "answer": "Fort William Henry",
      "score": 0.9920949935913086
    }
  ],
  "11343": [
    {
      "answer": "Ticonderoga Point",
      "score": 0.9914042949676514
    }
  ],
  "11344": [
    {
      "answer": "Marquis de Vaudreuil",
      "score": 0.9940786361694336
    }
  ],
  "11345": [
    {
      "answer": "Vaudreuil sent Dieskau to Fort St. Fr\u00e9d\u00e9ric to meet that threat",
      "score": 0.970218300819397
    }
  ],
  "11346": [],
  "11347": [
    {
      "answer": "Fort St. Fr\u00e9d\u00e9ric",
      "score": 0.582667350769043
    },
    {
      "answer": "Fort William Henry",
      "score": 0.6241390109062195
    },
    {
      "answer": "Fort William Henry",
      "score": 0.8352920413017273
    }
  ],
  "11348": [
    {
      "answer": "Ticonderoga Point",
      "score": 0.9630686044692993
    }
  ],
  "11349": [
    {
      "answer": "Colonel Monckton",
      "score": 0.972642183303833
    }
  ],
  "11350": [
    {
      "answer": "Nova Scotia's Governor Charles Lawrence ordered the deportation of the French-speaking Acadian population from the area",
      "score": 0.8808742165565491
    }
  ],
  "11351": [
    {
      "answer": "Petitcodiac in 1755",
      "score": 0.9380898475646973
    }
  ],
  "11352": [
    {
      "answer": "Colonel Monckton",
      "score": 0.9075613617897034
    }
  ],
  "11353": [
    {
      "answer": "Colonel Monckton",
      "score": 0.9730319976806641
    }
  ],
  "11354": [],
  "11355": [
    {
      "answer": "Nova Scotia's Governor Charles Lawrence ordered the deportation of the French-speaking Acadian population from the area",
      "score": 0.8169257044792175
    }
  ],
  "11356": [
    {
      "answer": "at Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757",
      "score": 0.9419738054275513
    }
  ],
  "11357": [
    {
      "answer": "William Shirley",
      "score": 0.9975709319114685
    }
  ],
  "11358": [
    {
      "answer": "Albany",
      "score": 0.9250122904777527
    }
  ],
  "11359": [],
  "11360": [
    {
      "answer": "Maine district",
      "score": 0.8418938517570496
    }
  ],
  "11361": [
    {
      "answer": "William Shirley",
      "score": 0.9965587854385376
    }
  ],
  "11362": [
    {
      "answer": "William Shirley",
      "score": 0.9956811666488647
    }
  ],
  "11363": [
    {
      "answer": "December 1755",
      "score": 0.9168751239776611
    }
  ],
  "11364": [
    {
      "answer": "Fort Frontenac on the north shore of Lake Ontario",
      "score": 0.7574434280395508
    }
  ],
  "11365": [
    {
      "answer": "Maine district",
      "score": 0.7352155447006226
    }
  ],
  "11366": [
    {
      "answer": "James Abercrombie",
      "score": 0.9816668629646301
    }
  ],
  "11367": [
    {
      "answer": "Louis-Joseph de Montcalm",
      "score": 0.9871788024902344
    }
  ],
  "11368": [
    {
      "answer": "May 18, 1756",
      "score": 0.994583010673523
    }
  ],
  "11369": [
    {
      "answer": "Lord Loudoun",
      "score": 0.8870147466659546
    }
  ],
  "11370": [
    {
      "answer": "James Abercrombie",
      "score": 0.8802582025527954
    }
  ],
  "11371": [
    {
      "answer": "Louis-Joseph de Montcalm",
      "score": 0.8844852447509766
    }
  ],
  "11372": [
    {
      "answer": "Louis-Joseph de Montcalm",
      "score": 0.9629453420639038
    }
  ],
  "11373": [
    {
      "answer": "May 18, 1756",
      "score": 0.9745342135429382
    }
  ],
  "11374": [
    {
      "answer": "Oneida Carry",
      "score": 0.9852185249328613
    }
  ],
  "11375": [
    {
      "answer": "an attack against the forts Shirley had erected at the Oneida Carry",
      "score": 0.904777467250824
    }
  ],
  "11376": [
    {
      "answer": "45,000 pounds",
      "score": 0.9945149421691895
    }
  ],
  "11377": [
    {
      "answer": "campaigns on Lake Ontario",
      "score": 0.9910568594932556
    }
  ],
  "11378": [
    {
      "answer": "Oneida Carry",
      "score": 0.9760239124298096
    }
  ],
  "11379": [
    {
      "answer": "Oneida Carry",
      "score": 0.9816863536834717
    }
  ],
  "11380": [
    {
      "answer": "an attack against the forts Shirley had erected at the Oneida Carry",
      "score": 0.8401879072189331
    },
    {
      "answer": "French forces destroyed the fort and large quantities of supplies, including 45,000 pounds of gunpowder",
      "score": 0.7947710752487183
    }
  ],
  "11381": [
    {
      "answer": "45,000 pounds",
      "score": 0.9900230765342712
    }
  ],
  "11382": [
    {
      "answer": "campaigns on Lake Ontario",
      "score": 0.9910006523132324
    }
  ],
  "11383": [
    {
      "answer": "Abercrombie",
      "score": 0.9883429408073425
    },
    {
      "answer": "Abercrombie",
      "score": 0.7186042666435242
    }
  ],
  "11384": [
    {
      "answer": "Ticonderoga",
      "score": 0.9963625073432922
    }
  ],
  "11385": [
    {
      "answer": "Oswego",
      "score": 0.8747006058692932
    },
    {
      "answer": "Oswego",
      "score": 0.9839510917663574
    }
  ],
  "11386": [
    {
      "answer": "the disposition of prisoners' personal effects",
      "score": 0.9769107699394226
    }
  ],
  "11387": [
    {
      "answer": "Ticonderoga",
      "score": 0.9963510036468506
    }
  ],
  "11388": [
    {
      "answer": "Abercrombie",
      "score": 0.9891945123672485
    },
    {
      "answer": "Abercrombie",
      "score": 0.7185461521148682
    }
  ],
  "11389": [
    {
      "answer": "Abercrombie",
      "score": 0.9905776977539062
    },
    {
      "answer": "Abercrombie",
      "score": 0.7595440745353699
    }
  ],
  "11390": [
    {
      "answer": "Oswego",
      "score": 0.8746932148933411
    },
    {
      "answer": "Oswego",
      "score": 0.9845448732376099
    }
  ],
  "11391": [],
  "11392": [
    {
      "answer": "an attack on New France's capital, Quebec",
      "score": 0.9432849884033203
    }
  ],
  "11393": [
    {
      "answer": "to distract Montcalm",
      "score": 0.99104905128479
    }
  ],
  "11394": [
    {
      "answer": "William Pitt",
      "score": 0.9985050559043884
    }
  ],
  "11395": [
    {
      "answer": "Loudoun returned to New York",
      "score": 0.9716817140579224
    }
  ],
  "11396": [
    {
      "answer": "an attack on New France's capital, Quebec",
      "score": 0.9080744981765747
    }
  ],
  "11397": [
    {
      "answer": "an attack on New France's capital, Quebec",
      "score": 0.8485248684883118
    }
  ],
  "11398": [
    {
      "answer": "to distract Montcalm",
      "score": 0.9743638038635254
    }
  ],
  "11399": [
    {
      "answer": "William Pitt",
      "score": 0.9982526302337646
    }
  ],
  "11400": [
    {
      "answer": "Loudoun returned to New York",
      "score": 0.9594587683677673
    }
  ],
  "11401": [],
  "11402": [
    {
      "answer": "Lake George",
      "score": 0.9869760274887085
    }
  ],
  "11403": [
    {
      "answer": "attacked the British column, killing and capturing several hundred men, women, children, and slaves",
      "score": 0.9723570346832275
    }
  ],
  "11404": [
    {
      "answer": "French irregular forces",
      "score": 0.7237042188644409
    }
  ],
  "11405": [],
  "11406": [
    {
      "answer": "Lake George",
      "score": 0.9842180013656616
    }
  ],
  "11407": [
    {
      "answer": "Lake George",
      "score": 0.9834078550338745
    }
  ],
  "11408": [
    {
      "answer": "attacked the British column, killing and capturing several hundred men, women, children, and slaves",
      "score": 0.9712883830070496
    }
  ],
  "11409": [
    {
      "answer": "British blockade of the French coastline",
      "score": 0.9330281019210815
    },
    {
      "answer": "a poor harvest in 1757",
      "score": 0.7656566500663757
    },
    {
      "answer": "a difficult winter",
      "score": 0.630563497543335
    }
  ],
  "11410": [
    {
      "answer": "poor harvest",
      "score": 0.8559560775756836
    }
  ],
  "11411": [
    {
      "answer": "St. Lawrence",
      "score": 0.9394382238388062
    },
    {
      "answer": "Carillon, Quebec, and Louisbourg",
      "score": 0.7802240252494812
    }
  ],
  "11412": [
    {
      "answer": "British blockade of the French coastline",
      "score": 0.970760703086853
    }
  ],
  "11413": [
    {
      "answer": "British blockade of the French coastline",
      "score": 0.9669286608695984
    }
  ],
  "11414": [
    {
      "answer": "poor harvest",
      "score": 0.9045049548149109
    }
  ],
  "11415": [
    {
      "answer": "the British blockade of the French coastline limited French shipping",
      "score": 0.7390268445014954
    }
  ],
  "11416": [],
  "11417": [
    {
      "answer": "British failures in North America",
      "score": 0.9886676669120789
    }
  ],
  "11418": [
    {
      "answer": "Newcastle",
      "score": 0.6871976256370544
    }
  ],
  "11419": [
    {
      "answer": "three major offensive actions",
      "score": 0.9599210023880005
    }
  ],
  "11420": [
    {
      "answer": "Two",
      "score": 0.9914054870605469
    }
  ],
  "11421": [
    {
      "answer": "British failures in North America",
      "score": 0.9303653836250305
    }
  ],
  "11422": [
    {
      "answer": "British failures in North America",
      "score": 0.9868804812431335
    }
  ],
  "11423": [],
  "11424": [],
  "11425": [
    {
      "answer": "Two",
      "score": 0.9354430437088013
    }
  ],
  "11426": [
    {
      "answer": "3,600",
      "score": 0.996711254119873
    }
  ],
  "11427": [
    {
      "answer": "3,600",
      "score": 0.9915972948074341
    }
  ],
  "11428": [
    {
      "answer": "Abercrombie saved something from the disaster when he sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac",
      "score": 0.7989751696586609
    }
  ],
  "11429": [
    {
      "answer": "Abercrombie was recalled and replaced by Jeffery Amherst, victor at Louisbourg.",
      "score": 0.8602306842803955
    }
  ],
  "11430": [
    {
      "answer": "3,600",
      "score": 0.9951032400131226
    }
  ],
  "11431": [
    {
      "answer": "3,600",
      "score": 0.9928221702575684
    }
  ],
  "11432": [
    {
      "answer": "3,600",
      "score": 0.9814796447753906
    }
  ],
  "11433": [],
  "11434": [
    {
      "answer": "Abercrombie was recalled and replaced by Jeffery Amherst, victor at Louisbourg.",
      "score": 0.8627222180366516
    }
  ],
  "11435": [
    {
      "answer": "an invasion of Britain",
      "score": 0.9686846137046814
    }
  ],
  "11436": [
    {
      "answer": "failed both militarily and politically",
      "score": 0.9140766263008118
    }
  ],
  "11437": [
    {
      "answer": "Quiberon Bay",
      "score": 0.8705226182937622
    }
  ],
  "11438": [
    {
      "answer": "an invasion of Britain",
      "score": 0.9646607637405396
    }
  ],
  "11439": [
    {
      "answer": "an invasion of Britain",
      "score": 0.9572594165802002
    }
  ],
  "11440": [
    {
      "answer": "failed both militarily and politically",
      "score": 0.942818820476532
    }
  ],
  "11441": [
    {
      "answer": "failed both militarily and politically",
      "score": 0.8958258032798767
    }
  ],
  "11442": [],
  "11443": [
    {
      "answer": "James Wolfe",
      "score": 0.9928801655769348
    }
  ],
  "11444": [
    {
      "answer": "cut off the French frontier forts further to the west and south",
      "score": 0.9746677279472351
    }
  ],
  "11445": [],
  "11446": [],
  "11447": [
    {
      "answer": "James Wolfe",
      "score": 0.9793739318847656
    }
  ],
  "11448": [
    {
      "answer": "James Wolfe",
      "score": 0.9903501272201538
    }
  ],
  "11449": [
    {
      "answer": "cut off the French frontier forts further to the west and south",
      "score": 0.9164450168609619
    }
  ],
  "11450": [
    {
      "answer": "Battle of Sainte-Foy",
      "score": 0.7901248931884766
    }
  ],
  "11451": [],
  "11452": [
    {
      "answer": "Governor Vaudreuil",
      "score": 0.9705828428268433
    },
    {
      "answer": "General Amherst",
      "score": 0.6252082586288452
    }
  ],
  "11453": [
    {
      "answer": "any French residents who chose to remain in the colony would be given freedom to continue worshiping in their Roman Catholic tradition",
      "score": 0.8646774291992188
    },
    {
      "answer": "continued ownership of their property",
      "score": 0.9347184300422668
    }
  ],
  "11454": [
    {
      "answer": "Amherst",
      "score": 0.99015873670578
    }
  ],
  "11455": [
    {
      "answer": "Governor Vaudreuil",
      "score": 0.9602208137512207
    }
  ],
  "11456": [
    {
      "answer": "Governor Vaudreuil",
      "score": 0.9707982540130615
    }
  ],
  "11457": [
    {
      "answer": "continued ownership of their property, and the right to remain undisturbed in their homes",
      "score": 0.8668702840805054
    }
  ],
  "11458": [
    {
      "answer": "Amherst",
      "score": 0.9828527569770813
    }
  ],
  "11459": [
    {
      "answer": "Governor Vaudreuil",
      "score": 0.9342107772827148
    }
  ],
  "11460": [
    {
      "answer": "10 February 1763",
      "score": 0.9916394948959351
    }
  ],
  "11461": [
    {
      "answer": "15 February 1763",
      "score": 0.9836606979370117
    }
  ],
  "11462": [
    {
      "answer": "surrendering either its continental North American possessions east of the Mississippi or the Caribbean islands of Guadeloupe and Martinique",
      "score": 0.9533315896987915
    }
  ],
  "11463": [
    {
      "answer": "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent",
      "score": 0.9620631337165833
    }
  ],
  "11464": [
    {
      "answer": "10 February 1763",
      "score": 0.8893779516220093
    },
    {
      "answer": "15 February 1763",
      "score": 0.6092175841331482
    }
  ],
  "11465": [
    {
      "answer": "10 February 1763",
      "score": 0.9907256364822388
    }
  ],
  "11466": [
    {
      "answer": "15 February 1763",
      "score": 0.9832363128662109
    }
  ],
  "11467": [
    {
      "answer": "15 February 1763",
      "score": 0.9840855002403259
    }
  ],
  "11468": [
    {
      "answer": "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent.",
      "score": 0.9667144417762756
    }
  ],
  "11469": [
    {
      "answer": "80,000",
      "score": 0.9522110819816589
    }
  ],
  "11470": [
    {
      "answer": "1755",
      "score": 0.9877205491065979
    }
  ],
  "11471": [
    {
      "answer": "France",
      "score": 0.9710743427276611
    },
    {
      "answer": "New Orleans",
      "score": 0.8454265594482422
    },
    {
      "answer": "New Orleans",
      "score": 0.7379273772239685
    }
  ],
  "11472": [
    {
      "answer": "New Orleans",
      "score": 0.996042013168335
    },
    {
      "answer": "New Orleans",
      "score": 0.9865690469741821
    }
  ],
  "11473": [
    {
      "answer": "80,000",
      "score": 0.8065232038497925
    }
  ],
  "11474": [
    {
      "answer": "80,000",
      "score": 0.6540319919586182
    },
    {
      "answer": "many went to France",
      "score": 0.6676109433174133
    }
  ],
  "11475": [
    {
      "answer": "1755",
      "score": 0.9904845952987671
    }
  ],
  "11476": [
    {
      "answer": "France",
      "score": 0.9538892507553101
    },
    {
      "answer": "New Orleans",
      "score": 0.9270309805870056
    },
    {
      "answer": "New Orleans",
      "score": 0.8618693351745605
    }
  ],
  "11477": [
    {
      "answer": "New Orleans",
      "score": 0.9815045595169067
    },
    {
      "answer": "New Orleans",
      "score": 0.9429584741592407
    }
  ],
  "11478": [
    {
      "answer": "King George III",
      "score": 0.9852136373519897
    }
  ],
  "11479": [
    {
      "answer": "outlined the division and administration of the newly conquered territory",
      "score": 0.9130392074584961
    }
  ],
  "11480": [
    {
      "answer": "west of the Appalachian Mountains",
      "score": 0.9944027066230774
    }
  ],
  "11481": [
    {
      "answer": "King George III",
      "score": 0.971569299697876
    }
  ],
  "11482": [
    {
      "answer": "King George III",
      "score": 0.9439381957054138
    }
  ],
  "11483": [
    {
      "answer": "reservation of lands west of the Appalachian Mountains to its Indian population",
      "score": 0.7797353267669678
    }
  ],
  "11484": [
    {
      "answer": "west of the Appalachian Mountains",
      "score": 0.9860679507255554
    }
  ],
  "11485": [
    {
      "answer": "west of the Appalachian Mountains",
      "score": 0.9923953413963318
    }
  ],
  "11486": [
    {
      "answer": "the elimination of French power in North America",
      "score": 0.690942645072937
    },
    {
      "answer": "the disappearance of a strong ally and counterweight to British expansion",
      "score": 0.8649070262908936
    }
  ],
  "11487": [
    {
      "answer": "construction of military roads to the area by Braddock and Forbes",
      "score": 0.9503850936889648
    }
  ],
  "11488": [
    {
      "answer": "1769",
      "score": 0.9900711178779602
    }
  ],
  "11489": [
    {
      "answer": "Yamasee",
      "score": 0.8022572994232178
    }
  ],
  "11490": [
    {
      "answer": "Cuba",
      "score": 0.9928552508354187
    }
  ],
  "11491": [
    {
      "answer": "Cuba",
      "score": 0.9451946020126343
    }
  ],
  "11492": [
    {
      "answer": "construction of military roads to the area by Braddock and Forbes",
      "score": 0.8889358043670654
    }
  ],
  "11493": [
    {
      "answer": "1769",
      "score": 0.9909877181053162
    }
  ],
  "11494": [
    {
      "answer": "Yamasee",
      "score": 0.6482905745506287
    }
  ],
  "11495": [
    {
      "answer": "the elimination of French power in North America",
      "score": 0.7868446707725525
    },
    {
      "answer": "the disappearance of a strong ally and counterweight to British expansion",
      "score": 0.860912024974823
    }
  ],
  "11496": [],
  "11497": [
    {
      "answer": "force",
      "score": 0.9609573483467102
    }
  ],
  "11498": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9081554412841797
    },
    {
      "answer": "Sir Isaac Newton",
      "score": 0.9260124564170837
    },
    {
      "answer": "Sir Isaac Newton",
      "score": 0.9016630053520203
    }
  ],
  "11499": [
    {
      "answer": "three hundred years",
      "score": 0.9937681555747986
    }
  ],
  "11500": [
    {
      "answer": "Einstein",
      "score": 0.9928668737411499
    }
  ],
  "11501": [
    {
      "answer": "Philosophers",
      "score": 0.8548837304115295
    }
  ],
  "11502": [
    {
      "answer": "motion",
      "score": 0.8505322337150574
    },
    {
      "answer": "motion",
      "score": 0.9886729121208191
    },
    {
      "answer": "motion",
      "score": 0.6420968174934387
    }
  ],
  "11503": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9808560609817505
    },
    {
      "answer": "Sir Isaac Newton",
      "score": 0.9690141677856445
    },
    {
      "answer": "Sir Isaac Newton",
      "score": 0.8450374007225037
    }
  ],
  "11504": [
    {
      "answer": "motion",
      "score": 0.9475473165512085
    },
    {
      "answer": "force",
      "score": 0.9240883588790894
    }
  ],
  "11505": [
    {
      "answer": "Sir Isaac Newton",
      "score": 0.9075677394866943
    },
    {
      "answer": "Sir Isaac Newton",
      "score": 0.9717254042625427
    }
  ],
  "11506": [
    {
      "answer": "Standard Model",
      "score": 0.9866628646850586
    },
    {
      "answer": "Standard Model",
      "score": 0.8332152366638184
    }
  ],
  "11507": [
    {
      "answer": "gauge bosons",
      "score": 0.9457961320877075
    }
  ],
  "11508": [
    {
      "answer": "strong",
      "score": 0.6013080477714539
    },
    {
      "answer": "electromagnetic",
      "score": 0.7293615937232971
    },
    {
      "answer": "electromagnetic",
      "score": 0.6153985857963562
    }
  ],
  "11509": [
    {
      "answer": "weak",
      "score": 0.8179527521133423
    },
    {
      "answer": "weak",
      "score": 0.7086838483810425
    }
  ],
  "11510": [
    {
      "answer": "electroweak interaction",
      "score": 0.9820355176925659
    }
  ],
  "11511": [
    {
      "answer": "technology",
      "score": 0.7061754465103149
    }
  ],
  "11512": [
    {
      "answer": "forces between particles smaller than atoms",
      "score": 0.9852957725524902
    }
  ],
  "11513": [
    {
      "answer": "gauge bosons",
      "score": 0.9829544425010681
    }
  ],
  "11514": [
    {
      "answer": "four",
      "score": 0.9855367541313171
    }
  ],
  "11515": [
    {
      "answer": "Aristotle",
      "score": 0.9788171648979187
    },
    {
      "answer": "Aristotle",
      "score": 0.9312451481819153
    },
    {
      "answer": "Aristotle",
      "score": 0.9109630584716797
    },
    {
      "answer": "Aristotle",
      "score": 0.9403883218765259
    }
  ],
  "11516": [
    {
      "answer": "Aristotelian cosmology",
      "score": 0.9948674440383911
    }
  ],
  "11517": [
    {
      "answer": "four",
      "score": 0.9943615198135376
    }
  ],
  "11518": [
    {
      "answer": "Earth",
      "score": 0.671850860118866
    },
    {
      "answer": "the ground",
      "score": 0.6844434142112732
    }
  ],
  "11519": [
    {
      "answer": "unnatural",
      "score": 0.9910992980003357
    }
  ],
  "11520": [
    {
      "answer": "Aristotle",
      "score": 0.5932796001434326
    },
    {
      "answer": "Aristotle",
      "score": 0.8630144000053406
    },
    {
      "answer": "Aristotle",
      "score": 0.8317759037017822
    },
    {
      "answer": "Aristotle",
      "score": 0.8663865327835083
    }
  ],
  "11521": [
    {
      "answer": "four",
      "score": 0.9896137118339539
    }
  ],
  "11522": [
    {
      "answer": "left alone",
      "score": 0.9792622327804565
    }
  ],
  "11523": [
    {
      "answer": "Aristotle",
      "score": 0.7837612628936768
    },
    {
      "answer": "Aristotle",
      "score": 0.8187795877456665
    },
    {
      "answer": "Aristotle",
      "score": 0.810827910900116
    },
    {
      "answer": "Aristotle",
      "score": 0.973199725151062
    }
  ],
  "11524": [
    {
      "answer": "17th century",
      "score": 0.9754412174224854
    },
    {
      "answer": "17th century",
      "score": 0.9366377592086792
    }
  ],
  "11525": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9949342012405396
    }
  ],
  "11526": [
    {
      "answer": "innate force of impetus",
      "score": 0.9747180938720703
    }
  ],
  "11527": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9261196851730347
    }
  ],
  "11528": [
    {
      "answer": "friction",
      "score": 0.9955874681472778
    }
  ],
  "11529": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9955198764801025
    }
  ],
  "11530": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9963093996047974
    }
  ],
  "11531": [
    {
      "answer": "Galileo Galilei",
      "score": 0.8919621706008911
    },
    {
      "answer": "Galileo",
      "score": 0.527748703956604
    }
  ],
  "11532": [
    {
      "answer": "Galileo Galilei",
      "score": 0.9424375295639038
    }
  ],
  "11533": [
    {
      "answer": "Newton",
      "score": 0.9777833819389343
    },
    {
      "answer": "Newton",
      "score": 0.761651873588562
    },
    {
      "answer": "Newton",
      "score": 0.8483877778053284
    }
  ],
  "11534": [
    {
      "answer": "lack of net force",
      "score": 0.9830448031425476
    }
  ],
  "11535": [
    {
      "answer": "Newton",
      "score": 0.8253228664398193
    },
    {
      "answer": "Newton",
      "score": 0.9672253131866455
    },
    {
      "answer": "Newton",
      "score": 0.8232837915420532
    }
  ],
  "11536": [
    {
      "answer": "Newton's First Law",
      "score": 0.8610916137695312
    }
  ],
  "11537": [],
  "11538": [
    {
      "answer": "objects continue to move in a state of constant velocity",
      "score": 0.9204023480415344
    }
  ],
  "11539": [
    {
      "answer": "Aristotelian belief",
      "score": 0.9343743324279785
    }
  ],
  "11540": [
    {
      "answer": "Newton",
      "score": 0.6394180059432983
    },
    {
      "answer": "Newton",
      "score": 0.926122784614563
    }
  ],
  "11541": [
    {
      "answer": "the laws of physics",
      "score": 0.8557252287864685
    }
  ],
  "11542": [
    {
      "answer": "the laws of physics",
      "score": 0.9843541383743286
    }
  ],
  "11543": [
    {
      "answer": "curving parabolic",
      "score": 0.9693278670310974
    }
  ],
  "11544": [
    {
      "answer": "at rest",
      "score": 0.6883501410484314
    },
    {
      "answer": "at rest",
      "score": 0.975116491317749
    }
  ],
  "11545": [
    {
      "answer": "Inertia",
      "score": 0.8845567107200623
    }
  ],
  "11546": [
    {
      "answer": "moving vehicle",
      "score": 0.8832752704620361
    }
  ],
  "11547": [
    {
      "answer": "person",
      "score": 0.9626681208610535
    }
  ],
  "11548": [],
  "11549": [],
  "11550": [
    {
      "answer": "inertia",
      "score": 0.9591163396835327
    },
    {
      "answer": "inertia",
      "score": 0.9029185175895691
    },
    {
      "answer": "inertia",
      "score": 0.9270068407058716
    },
    {
      "answer": "inertia",
      "score": 0.9384247660636902
    }
  ],
  "11551": [
    {
      "answer": "rotational inertia",
      "score": 0.9811467528343201
    }
  ],
  "11552": [
    {
      "answer": "Albert Einstein",
      "score": 0.9949414730072021
    }
  ],
  "11553": [
    {
      "answer": "weightlessness",
      "score": 0.9958618879318237
    }
  ],
  "11554": [
    {
      "answer": "principle of equivalence",
      "score": 0.9304639101028442
    }
  ],
  "11555": [
    {
      "answer": "constant motion",
      "score": 0.9741672277450562
    }
  ],
  "11556": [
    {
      "answer": "length of a day and the length of a year",
      "score": 0.9581368565559387
    }
  ],
  "11557": [
    {
      "answer": "Albert Einstein",
      "score": 0.9951477646827698
    }
  ],
  "11558": [
    {
      "answer": "weightlessness",
      "score": 0.995816171169281
    }
  ],
  "11559": [
    {
      "answer": "Newton's Second Law",
      "score": 0.9450452923774719
    },
    {
      "answer": "Newton's second law",
      "score": 0.7102603316307068
    }
  ],
  "11560": [
    {
      "answer": "kinematic",
      "score": 0.995453953742981
    }
  ],
  "11561": [
    {
      "answer": "General relativity",
      "score": 0.995540976524353
    }
  ],
  "11562": [
    {
      "answer": "quantum gravity",
      "score": 0.8024252653121948
    }
  ],
  "11563": [
    {
      "answer": "the relative units of force and mass then are fixed",
      "score": 0.8033708930015564
    }
  ],
  "11564": [
    {
      "answer": "force",
      "score": 0.9645784497261047
    },
    {
      "answer": "force",
      "score": 0.7307010889053345
    }
  ],
  "11565": [
    {
      "answer": "mass",
      "score": 0.9826447367668152
    },
    {
      "answer": "mass",
      "score": 0.6233933568000793
    },
    {
      "answer": "mass",
      "score": 0.5844212174415588
    }
  ],
  "11566": [
    {
      "answer": "kinematic measurements",
      "score": 0.9791586399078369
    }
  ],
  "11567": [
    {
      "answer": "space-time and mass",
      "score": 0.9734504222869873
    }
  ],
  "11568": [
    {
      "answer": "Newton's Third Law",
      "score": 0.9298891425132751
    }
  ],
  "11569": [
    {
      "answer": "Third Law",
      "score": 0.9179582595825195
    }
  ],
  "11570": [
    {
      "answer": "unidirectional",
      "score": 0.9933017492294312
    }
  ],
  "11571": [
    {
      "answer": "F and \u2212F are equal in magnitude and opposite in direction",
      "score": 0.9626263380050659
    }
  ],
  "11572": [
    {
      "answer": "situations where forces can be attributed to the presence of different objects",
      "score": 0.9371333122253418
    }
  ],
  "11573": [
    {
      "answer": "bodies",
      "score": 0.9420393705368042
    }
  ],
  "11574": [
    {
      "answer": "the second body exerts a force \u2212F",
      "score": 0.9435268640518188
    }
  ],
  "11575": [
    {
      "answer": "center of mass",
      "score": 0.8402646780014038
    },
    {
      "answer": "center of mass",
      "score": 0.9851876497268677
    }
  ],
  "11576": [
    {
      "answer": "closed",
      "score": 0.9916684627532959
    }
  ],
  "11577": [
    {
      "answer": "mass of the system",
      "score": 0.9739740490913391
    }
  ],
  "11578": [
    {
      "answer": "no internal forces that are unbalanced",
      "score": 0.7185761332511902
    }
  ],
  "11579": [
    {
      "answer": "no internal forces",
      "score": 0.6628161668777466
    }
  ],
  "11580": [
    {
      "answer": "acceleration",
      "score": 0.9648447036743164
    }
  ],
  "11581": [
    {
      "answer": "each other",
      "score": 0.9822013974189758
    }
  ],
  "11582": [
    {
      "answer": "intuitive understanding",
      "score": 0.9534010887145996
    }
  ],
  "11583": [
    {
      "answer": "operational definitions",
      "score": 0.9876903295516968
    }
  ],
  "11584": [
    {
      "answer": "Newtonian mechanics",
      "score": 0.9889798164367676
    }
  ],
  "11585": [
    {
      "answer": "experimentation",
      "score": 0.9914987683296204
    }
  ],
  "11586": [
    {
      "answer": "Newtonian mechanics",
      "score": 0.9735764265060425
    }
  ],
  "11587": [
    {
      "answer": "Newtonian mechanics",
      "score": 0.993545413017273
    }
  ],
  "11588": [
    {
      "answer": "force",
      "score": 0.967930018901825
    }
  ],
  "11589": [],
  "11590": [
    {
      "answer": "vector quantities",
      "score": 0.9908366203308105
    }
  ],
  "11591": [
    {
      "answer": "scalar quantities",
      "score": 0.9681704044342041
    }
  ],
  "11592": [
    {
      "answer": "Associating forces with vectors",
      "score": 0.9926401376724243
    }
  ],
  "11593": [
    {
      "answer": "ambiguous",
      "score": 0.9921489953994751
    }
  ],
  "11594": [
    {
      "answer": "it is necessary to know both the magnitude and the direction of both forces to calculate the result",
      "score": 0.7456944584846497
    },
    {
      "answer": "it is impossible to determine what the acceleration of the rope will be.",
      "score": 0.836703360080719
    }
  ],
  "11595": [],
  "11596": [
    {
      "answer": "Forces",
      "score": 0.8709934949874878
    },
    {
      "answer": "forces",
      "score": 0.5789638757705688
    },
    {
      "answer": "forces",
      "score": 0.5840737819671631
    },
    {
      "answer": "forces",
      "score": 0.5616171956062317
    }
  ],
  "11597": [
    {
      "answer": "forces",
      "score": 0.7106457948684692
    }
  ],
  "11598": [
    {
      "answer": "vector quantities",
      "score": 0.6621100902557373
    },
    {
      "answer": "forces",
      "score": 0.6979489326477051
    }
  ],
  "11599": [
    {
      "answer": "static equilibrium",
      "score": 0.996425211429596
    }
  ],
  "11600": [
    {
      "answer": "magnitude and direction",
      "score": 0.9607516527175903
    }
  ],
  "11601": [
    {
      "answer": "net force",
      "score": 0.955319881439209
    }
  ],
  "11602": [
    {
      "answer": "their respective lines of application must also be specified",
      "score": 0.9582799077033997
    }
  ],
  "11603": [
    {
      "answer": "parallelogram",
      "score": 0.9704334139823914
    },
    {
      "answer": "parallelogram",
      "score": 0.8232846856117249
    },
    {
      "answer": "parallelogram",
      "score": 0.7184652090072632
    }
  ],
  "11604": [
    {
      "answer": "the resulting force, the resultant (also called the net force), can be determined by following the parallelogram rule of vector addition",
      "score": 0.7510144114494324
    }
  ],
  "11605": [
    {
      "answer": "net force",
      "score": 0.8589211702346802
    }
  ],
  "11606": [
    {
      "answer": "difference of the magnitudes of the two forces",
      "score": 0.9718978404998779
    }
  ],
  "11607": [
    {
      "answer": "their respective lines of application",
      "score": 0.9473353624343872
    }
  ],
  "11608": [
    {
      "answer": "independent components",
      "score": 0.7866315841674805
    }
  ],
  "11609": [
    {
      "answer": "two",
      "score": 0.9894696474075317
    },
    {
      "answer": "two",
      "score": 0.758708119392395
    }
  ],
  "11610": [
    {
      "answer": "the original force",
      "score": 0.8296253681182861
    }
  ],
  "11611": [
    {
      "answer": "orthogonal components",
      "score": 0.8263328671455383
    },
    {
      "answer": "Orthogonal components",
      "score": 0.8845713138580322
    }
  ],
  "11612": [
    {
      "answer": "three-dimensional",
      "score": 0.8740890622138977
    }
  ],
  "11613": [
    {
      "answer": "resolved into independent components at right angles to each other",
      "score": 0.9189199805259705
    }
  ],
  "11614": [
    {
      "answer": "two",
      "score": 0.9835339188575745
    },
    {
      "answer": "two",
      "score": 0.7498065233230591
    }
  ],
  "11615": [
    {
      "answer": "Summing these component forces using vector addition",
      "score": 0.9123990535736084
    }
  ],
  "11616": [
    {
      "answer": "third component being at right-angles to the other two",
      "score": 0.947455108165741
    }
  ],
  "11617": [
    {
      "answer": "static friction",
      "score": 0.9912882447242737
    },
    {
      "answer": "static friction",
      "score": 0.8426834344863892
    },
    {
      "answer": "static friction",
      "score": 0.8743202686309814
    }
  ],
  "11618": [
    {
      "answer": "static friction",
      "score": 0.9936966300010681
    },
    {
      "answer": "static friction",
      "score": 0.8382858037948608
    },
    {
      "answer": "static friction",
      "score": 0.9231003522872925
    }
  ],
  "11619": [
    {
      "answer": "applied force",
      "score": 0.9500083923339844
    }
  ],
  "11620": [
    {
      "answer": "static friction",
      "score": 0.6598061919212341
    },
    {
      "answer": "static friction",
      "score": 0.8853336572647095
    }
  ],
  "11621": [
    {
      "answer": "does not move",
      "score": 0.9465650320053101
    }
  ],
  "11622": [
    {
      "answer": "not",
      "score": 0.9127945899963379
    }
  ],
  "11623": [
    {
      "answer": "static friction",
      "score": 0.6098023056983948
    },
    {
      "answer": "static friction",
      "score": 0.7104871869087219
    },
    {
      "answer": "static friction",
      "score": 0.9850759506225586
    }
  ],
  "11624": [
    {
      "answer": "static friction",
      "score": 0.6562256813049316
    },
    {
      "answer": "static friction",
      "score": 0.7580086588859558
    },
    {
      "answer": "static friction",
      "score": 0.9833149909973145
    }
  ],
  "11625": [],
  "11626": [
    {
      "answer": "spring reaction force",
      "score": 0.9952422976493835
    }
  ],
  "11627": [
    {
      "answer": "weight",
      "score": 0.9677382707595825
    }
  ],
  "11628": [
    {
      "answer": "gravity",
      "score": 0.950222373008728
    }
  ],
  "11629": [
    {
      "answer": "Isaac Newton",
      "score": 0.9974377155303955
    }
  ],
  "11630": [
    {
      "answer": "measuring forces",
      "score": 0.9415314197540283
    }
  ],
  "11631": [
    {
      "answer": "forces",
      "score": 0.752669095993042
    }
  ],
  "11632": [
    {
      "answer": "gravity",
      "score": 0.985724687576294
    },
    {
      "answer": "gravity",
      "score": 0.9003134965896606
    }
  ],
  "11633": [
    {
      "answer": "spring balances",
      "score": 0.5640740394592285
    },
    {
      "answer": "such tools",
      "score": 0.5547966361045837
    }
  ],
  "11634": [
    {
      "answer": "Galileo",
      "score": 0.9900184869766235
    },
    {
      "answer": "Galileo",
      "score": 0.7832738757133484
    },
    {
      "answer": "Galileo",
      "score": 0.8166463971138
    },
    {
      "answer": "Galileo",
      "score": 0.8522354364395142
    }
  ],
  "11635": [
    {
      "answer": "rest",
      "score": 0.9844323396682739
    }
  ],
  "11636": [
    {
      "answer": "Aristotle",
      "score": 0.9894803762435913
    }
  ],
  "11637": [
    {
      "answer": "behind the foot of the mast",
      "score": 0.9670512080192566
    }
  ],
  "11638": [
    {
      "answer": "foot of the mast",
      "score": 0.9803057909011841
    }
  ],
  "11639": [
    {
      "answer": "Dynamic",
      "score": 0.9084250926971436
    }
  ],
  "11640": [
    {
      "answer": "Aristotelian physics",
      "score": 0.9079262018203735
    },
    {
      "answer": "Aristotelian physics",
      "score": 0.8040560483932495
    }
  ],
  "11641": [
    {
      "answer": "Aristotelian",
      "score": 0.7828903198242188
    },
    {
      "answer": "Aristotelian",
      "score": 0.6162676811218262
    },
    {
      "answer": "Aristotelian",
      "score": 0.9899693131446838
    }
  ],
  "11642": [
    {
      "answer": "Galileo",
      "score": 0.8034937381744385
    },
    {
      "answer": "Galileo",
      "score": 0.7408707737922668
    },
    {
      "answer": "Galileo",
      "score": 0.9569442868232727
    },
    {
      "answer": "Galileo",
      "score": 0.7629349827766418
    }
  ],
  "11643": [
    {
      "answer": "zero net force",
      "score": 0.6947070956230164
    }
  ],
  "11644": [
    {
      "answer": "kinetic friction",
      "score": 0.9795330762863159
    }
  ],
  "11645": [
    {
      "answer": "kinetic friction",
      "score": 0.7716476321220398
    },
    {
      "answer": "kinetic friction",
      "score": 0.7953566312789917
    },
    {
      "answer": "kinetic friction",
      "score": 0.9585636854171753
    }
  ],
  "11646": [
    {
      "answer": "Aristotle",
      "score": 0.9954719543457031
    }
  ],
  "11647": [
    {
      "answer": "dynamic",
      "score": 0.8940929174423218
    }
  ],
  "11648": [
    {
      "answer": "object",
      "score": 0.9811474084854126
    }
  ],
  "11649": [
    {
      "answer": "object",
      "score": 0.9748924970626831
    }
  ],
  "11650": [
    {
      "answer": "kinetic friction",
      "score": 0.5918436050415039
    }
  ],
  "11651": [
    {
      "answer": "Schr\u00f6dinger equation",
      "score": 0.9811397790908813
    }
  ],
  "11652": [
    {
      "answer": "Newtonian equations",
      "score": 0.9197248220443726
    }
  ],
  "11653": [
    {
      "answer": "classical position variables",
      "score": 0.9928586483001709
    }
  ],
  "11654": [
    {
      "answer": "quantized",
      "score": 0.9841613173484802
    }
  ],
  "11655": [
    {
      "answer": "force",
      "score": 0.973989725112915
    }
  ],
  "11656": [
    {
      "answer": "force",
      "score": 0.6162806153297424
    }
  ],
  "11657": [
    {
      "answer": "force",
      "score": 0.9443801641464233
    }
  ],
  "11658": [
    {
      "answer": "Schr\u00f6dinger equation",
      "score": 0.7857815027236938
    }
  ],
  "11659": [
    {
      "answer": "Newtonian equations",
      "score": 0.7841387987136841
    }
  ],
  "11660": [
    {
      "answer": "spin",
      "score": 0.9702338576316833
    },
    {
      "answer": "spin",
      "score": 0.6723677515983582
    },
    {
      "answer": "spin",
      "score": 0.7423666715621948
    },
    {
      "answer": "spin",
      "score": 0.7231025099754333
    },
    {
      "answer": "spin",
      "score": 0.6752814650535583
    }
  ],
  "11661": [
    {
      "answer": "Pauli principle",
      "score": 0.9938708543777466
    }
  ],
  "11662": [
    {
      "answer": "value of the spin",
      "score": 0.9319624900817871
    }
  ],
  "11663": [
    {
      "answer": "parallel spins",
      "score": 0.8535199761390686
    }
  ],
  "11664": [
    {
      "answer": "parallel spins",
      "score": 0.8775004148483276
    }
  ],
  "11665": [
    {
      "answer": "spin",
      "score": 0.7070693969726562
    },
    {
      "answer": "spin",
      "score": 0.9795362949371338
    }
  ],
  "11666": [
    {
      "answer": "antisymmetric",
      "score": 0.9928011894226074
    }
  ],
  "11667": [
    {
      "answer": "two bosons",
      "score": 0.8038197755813599
    }
  ],
  "11668": [
    {
      "answer": "two fermions",
      "score": 0.918988049030304
    }
  ],
  "11669": [
    {
      "answer": "a mathematical by-product of exchange of momentum-carrying gauge bosons",
      "score": 0.7678256630897522
    }
  ],
  "11670": [
    {
      "answer": "force",
      "score": 0.9551068544387817
    },
    {
      "answer": "force",
      "score": 0.7660678029060364
    },
    {
      "answer": "force",
      "score": 0.7929777503013611
    }
  ],
  "11671": [
    {
      "answer": "conservation of momentum",
      "score": 0.9969545602798462
    }
  ],
  "11672": [
    {
      "answer": "Feynman diagrams",
      "score": 0.9240387678146362
    },
    {
      "answer": "Feynman diagram",
      "score": 0.6642295122146606
    },
    {
      "answer": "Feynman diagram",
      "score": 0.691810131072998
    },
    {
      "answer": "Feynman diagram",
      "score": 0.6470838189125061
    }
  ],
  "11673": [
    {
      "answer": "straight line",
      "score": 0.9532444477081299
    }
  ],
  "11674": [
    {
      "answer": "conservation of momentum",
      "score": 0.9916974902153015
    }
  ],
  "11675": [
    {
      "answer": "conservation of momentum",
      "score": 0.9958950877189636
    }
  ],
  "11676": [
    {
      "answer": "fundamental forces",
      "score": 0.931634783744812
    }
  ],
  "11677": [
    {
      "answer": "Feynman diagram",
      "score": 0.6481642127037048
    }
  ],
  "11678": [
    {
      "answer": "four",
      "score": 0.9906108975410461
    },
    {
      "answer": "four",
      "score": 0.9430691003799438
    }
  ],
  "11679": [
    {
      "answer": "strong and weak forces",
      "score": 0.9800609350204468
    }
  ],
  "11680": [
    {
      "answer": "electromagnetic force",
      "score": 0.9782083034515381
    },
    {
      "answer": "electromagnetic force",
      "score": 0.8808265924453735
    }
  ],
  "11681": [
    {
      "answer": "masses",
      "score": 0.978817880153656
    }
  ],
  "11682": [
    {
      "answer": "Pauli exclusion principle",
      "score": 0.9966543912887573
    }
  ],
  "11683": [
    {
      "answer": "four",
      "score": 0.8579177260398865
    },
    {
      "answer": "four",
      "score": 0.6628090143203735
    }
  ],
  "11684": [
    {
      "answer": "four",
      "score": 0.9899302124977112
    },
    {
      "answer": "four",
      "score": 0.9361073970794678
    }
  ],
  "11685": [
    {
      "answer": "strong and weak forces",
      "score": 0.9502339959144592
    },
    {
      "answer": "nuclear forces",
      "score": 0.7077654600143433
    }
  ],
  "11686": [
    {
      "answer": "strong and weak forces",
      "score": 0.989919900894165
    }
  ],
  "11687": [
    {
      "answer": "Isaac Newton",
      "score": 0.9972983002662659
    }
  ],
  "11688": [
    {
      "answer": "20th",
      "score": 0.9939409494400024
    }
  ],
  "11689": [
    {
      "answer": "string theory",
      "score": 0.8408298492431641
    }
  ],
  "11690": [
    {
      "answer": "self-consistent unification models",
      "score": 0.9614518880844116
    }
  ],
  "11691": [
    {
      "answer": "The development of fundamental theories for forces",
      "score": 0.9548367261886597
    }
  ],
  "11692": [
    {
      "answer": "Isaac Newton",
      "score": 0.9972118735313416
    }
  ],
  "11693": [
    {
      "answer": "Michael Faraday",
      "score": 0.9483340978622437
    },
    {
      "answer": "James Clerk Maxwell",
      "score": 0.940642774105072
    }
  ],
  "11694": [
    {
      "answer": "a modern understanding that the first three fundamental forces (all except gravity) are manifestations of matter (fermions) interacting by exchanging virtual particles called gauge bosons",
      "score": 0.8908550143241882
    }
  ],
  "11695": [
    {
      "answer": "Isaac Newton",
      "score": 0.9971141815185547
    }
  ],
  "11696": [
    {
      "answer": "Galileo",
      "score": 0.9825599789619446
    }
  ],
  "11697": [
    {
      "answer": "9.81 meters per second",
      "score": 0.9832212924957275
    }
  ],
  "11698": [
    {
      "answer": "sea level",
      "score": 0.9309109449386597
    },
    {
      "answer": "center of the Earth",
      "score": 0.5612163543701172
    }
  ],
  "11699": [
    {
      "answer": "force of gravity",
      "score": 0.9059895873069763
    }
  ],
  "11700": [
    {
      "answer": "gravity",
      "score": 0.8561426997184753
    },
    {
      "answer": "gravity",
      "score": 0.8234595656394958
    },
    {
      "answer": "gravity",
      "score": 0.8391005992889404
    }
  ],
  "11701": [
    {
      "answer": "Galileo",
      "score": 0.6031720042228699
    }
  ],
  "11702": [
    {
      "answer": "gravity",
      "score": 0.7791035771369934
    }
  ],
  "11703": [
    {
      "answer": "gravity",
      "score": 0.6113426089286804
    },
    {
      "answer": "gravity",
      "score": 0.73087477684021
    },
    {
      "answer": "gravity",
      "score": 0.753138542175293
    }
  ],
  "11704": [
    {
      "answer": "larger distances",
      "score": 0.8804682493209839
    },
    {
      "answer": "the acceleration of the Moon around the Earth could be ascribed to the same force of gravity if the acceleration due to gravity decreased as an inverse square law",
      "score": 0.6640517115592957
    }
  ],
  "11705": [
    {
      "answer": "acceleration of the Moon",
      "score": 0.918182373046875
    }
  ],
  "11706": [
    {
      "answer": "mass of the attracting body",
      "score": 0.982496440410614
    }
  ],
  "11707": [
    {
      "answer": "radius",
      "score": 0.8023514151573181
    }
  ],
  "11708": [
    {
      "answer": "Newton",
      "score": 0.9729602932929993
    },
    {
      "answer": "Newton",
      "score": 0.8426443338394165
    },
    {
      "answer": "Newton",
      "score": 0.8721399307250977
    }
  ],
  "11709": [
    {
      "answer": "force of gravity",
      "score": 0.8830368518829346
    }
  ],
  "11710": [
    {
      "answer": "Newton",
      "score": 0.8540514707565308
    },
    {
      "answer": "Newton",
      "score": 0.8430341482162476
    },
    {
      "answer": "Newton",
      "score": 0.9665902853012085
    }
  ],
  "11711": [
    {
      "answer": "mass",
      "score": 0.9915852546691895
    }
  ],
  "11712": [
    {
      "answer": "dimensional constant",
      "score": 0.9924172163009644
    }
  ],
  "11713": [
    {
      "answer": "Henry Cavendish",
      "score": 0.997938871383667
    }
  ],
  "11714": [
    {
      "answer": "1798",
      "score": 0.9933536052703857
    }
  ],
  "11715": [
    {
      "answer": "Newton",
      "score": 0.8368811011314392
    },
    {
      "answer": "Newton",
      "score": 0.7996007204055786
    },
    {
      "answer": "Newton",
      "score": 0.98097825050354
    },
    {
      "answer": "Newton",
      "score": 0.7632256150245667
    }
  ],
  "11716": [
    {
      "answer": "dimensional constant",
      "score": 0.9699763059616089
    }
  ],
  "11717": [
    {
      "answer": "Newton's Universal Gravitation Constant",
      "score": 0.92833012342453
    }
  ],
  "11718": [
    {
      "answer": "Newton",
      "score": 0.8060721158981323
    },
    {
      "answer": "Newton",
      "score": 0.7390427589416504
    },
    {
      "answer": "Newton",
      "score": 0.9707249402999878
    },
    {
      "answer": "Newton",
      "score": 0.7447118163108826
    }
  ],
  "11719": [
    {
      "answer": "the force on a spherical object of mass  due to the gravitational pull of mass  is",
      "score": 0.974047064781189
    }
  ],
  "11720": [
    {
      "answer": "Mercury",
      "score": 0.9866026639938354
    },
    {
      "answer": "Mercury",
      "score": 0.8381088376045227
    }
  ],
  "11721": [
    {
      "answer": "Vulcan",
      "score": 0.9849715828895569
    }
  ],
  "11722": [
    {
      "answer": "general relativity",
      "score": 0.994868278503418
    }
  ],
  "11723": [
    {
      "answer": "Albert Einstein",
      "score": 0.9972494840621948
    }
  ],
  "11724": [
    {
      "answer": "Albert Einstein",
      "score": 0.9972646832466125
    }
  ],
  "11725": [
    {
      "answer": "Newton",
      "score": 0.9151096343994141
    }
  ],
  "11726": [
    {
      "answer": "Some astrophysicists",
      "score": 0.725633978843689
    }
  ],
  "11727": [
    {
      "answer": "general relativity",
      "score": 0.9589272737503052
    }
  ],
  "11728": [],
  "11729": [
    {
      "answer": "general relativity",
      "score": 0.9983298182487488
    }
  ],
  "11730": [
    {
      "answer": "ballistic trajectory",
      "score": 0.9743359088897705
    }
  ],
  "11731": [
    {
      "answer": "gravitational force",
      "score": 0.9786869883537292
    }
  ],
  "11732": [
    {
      "answer": "global",
      "score": 0.9892210364341736
    }
  ],
  "11733": [
    {
      "answer": "general relativity",
      "score": 0.9974032640457153
    }
  ],
  "11734": [
    {
      "answer": "gravitation",
      "score": 0.9221386909484863
    },
    {
      "answer": "gravitation",
      "score": 0.7602712512016296
    },
    {
      "answer": "gravitational",
      "score": 0.5670560002326965
    }
  ],
  "11735": [
    {
      "answer": "ballistic trajectory",
      "score": 0.980616569519043
    }
  ],
  "11736": [],
  "11737": [
    {
      "answer": "Lorentz's Law",
      "score": 0.9506955742835999
    }
  ],
  "11738": [],
  "11739": [
    {
      "answer": "electromagnetic force",
      "score": 0.7998538017272949
    },
    {
      "answer": "electrostatic force",
      "score": 0.7902854681015015
    },
    {
      "answer": "magnetic force",
      "score": 0.7920824885368347
    }
  ],
  "11740": [
    {
      "answer": "electrostatic force",
      "score": 0.8323553800582886
    },
    {
      "answer": "magnetic force",
      "score": 0.9396981000900269
    }
  ],
  "11741": [
    {
      "answer": "force on a charge moving in a magnetic field",
      "score": 0.9587227702140808
    }
  ],
  "11742": [
    {
      "answer": "electricity and magnetism",
      "score": 0.9652313590049744
    }
  ],
  "11743": [
    {
      "answer": "magnetic field",
      "score": 0.7289561033248901
    }
  ],
  "11744": [
    {
      "answer": "Lorentz's Law",
      "score": 0.8528583645820618
    }
  ],
  "11745": [
    {
      "answer": "James Clerk Maxwell",
      "score": 0.9976860284805298
    }
  ],
  "11746": [
    {
      "answer": "1864",
      "score": 0.9922975897789001
    }
  ],
  "11747": [
    {
      "answer": "20",
      "score": 0.9926818013191223
    }
  ],
  "11748": [
    {
      "answer": "4",
      "score": 0.9945141077041626
    }
  ],
  "11749": [
    {
      "answer": "James Clerk Maxwell",
      "score": 0.9706940650939941
    }
  ],
  "11750": [
    {
      "answer": "electric and magnetic fields",
      "score": 0.9673358201980591
    },
    {
      "answer": "electric and magnetic fields",
      "score": 0.7848032712936401
    }
  ],
  "11751": [
    {
      "answer": "James Clerk Maxwell",
      "score": 0.9967038631439209
    }
  ],
  "11752": [
    {
      "answer": "scalar equations",
      "score": 0.8759142160415649
    }
  ],
  "11753": [
    {
      "answer": "James Clerk Maxwell",
      "score": 0.8796197772026062
    }
  ],
  "11754": [
    {
      "answer": "nonexistence",
      "score": 0.801995038986206
    }
  ],
  "11755": [
    {
      "answer": "quantum mechanics",
      "score": 0.9912126660346985
    }
  ],
  "11756": [
    {
      "answer": "quantum electrodynamics",
      "score": 0.989409863948822
    }
  ],
  "11757": [
    {
      "answer": "photons",
      "score": 0.98506098985672
    },
    {
      "answer": "photons",
      "score": 0.6406580209732056
    }
  ],
  "11758": [
    {
      "answer": "quantum electrodynamics",
      "score": 0.983515739440918
    }
  ],
  "11759": [
    {
      "answer": "electromagnetism",
      "score": 0.9774616360664368
    }
  ],
  "11760": [
    {
      "answer": "quantum mechanics",
      "score": 0.989651083946228
    }
  ],
  "11761": [
    {
      "answer": "QED",
      "score": 0.8300795555114746
    },
    {
      "answer": "photons",
      "score": 0.6806681752204895
    }
  ],
  "11762": [
    {
      "answer": "electromagnetic",
      "score": 0.5473417043685913
    },
    {
      "answer": "electromagnetism",
      "score": 0.9799903631210327
    },
    {
      "answer": "electromagnetic",
      "score": 0.5573084950447083
    },
    {
      "answer": "electromagnetism",
      "score": 0.6508939266204834
    }
  ],
  "11763": [
    {
      "answer": "repulsion of like charges",
      "score": 0.9428430795669556
    }
  ],
  "11764": [
    {
      "answer": "Pauli exclusion principle",
      "score": 0.9927586913108826
    }
  ],
  "11765": [
    {
      "answer": "energy",
      "score": 0.981373131275177
    }
  ],
  "11766": [
    {
      "answer": "structural force",
      "score": 0.9899208545684814
    }
  ],
  "11767": [
    {
      "answer": "quantum mechanical state",
      "score": 0.9497453570365906
    }
  ],
  "11768": [
    {
      "answer": "lower energy quantum mechanical states",
      "score": 0.9818488359451294
    }
  ],
  "11769": [
    {
      "answer": "energy",
      "score": 0.5911574363708496
    },
    {
      "answer": "energy",
      "score": 0.550746500492096
    },
    {
      "answer": "energy",
      "score": 0.6917505264282227
    }
  ],
  "11770": [],
  "11771": [
    {
      "answer": "elementary particles",
      "score": 0.9869930744171143
    },
    {
      "answer": "elementary particles",
      "score": 0.8409668207168579
    }
  ],
  "11772": [
    {
      "answer": "a residual of the force",
      "score": 0.8412771224975586
    },
    {
      "answer": "the nuclear force",
      "score": 0.6159635782241821
    }
  ],
  "11773": [
    {
      "answer": "nuclear force",
      "score": 0.979293704032898
    },
    {
      "answer": "nuclear force",
      "score": 0.6734968423843384
    }
  ],
  "11774": [
    {
      "answer": "gluons",
      "score": 0.9657089114189148
    }
  ],
  "11775": [
    {
      "answer": "color confinement",
      "score": 0.9882152080535889
    }
  ],
  "11776": [
    {
      "answer": "elementary particles",
      "score": 0.8185223937034607
    },
    {
      "answer": "elementary particles",
      "score": 0.6816966533660889
    }
  ],
  "11777": [
    {
      "answer": "free quarks",
      "score": 0.9953209161758423
    }
  ],
  "11778": [
    {
      "answer": "force",
      "score": 0.951948344707489
    }
  ],
  "11779": [
    {
      "answer": "elementary particles",
      "score": 0.8865758180618286
    },
    {
      "answer": "elementary particles",
      "score": 0.7855452299118042
    }
  ],
  "11780": [
    {
      "answer": "weak force",
      "score": 0.8513575792312622
    },
    {
      "answer": "weak force",
      "score": 0.5803425312042236
    }
  ],
  "11781": [
    {
      "answer": "beta decay",
      "score": 0.9572317004203796
    },
    {
      "answer": "radioactivity",
      "score": 0.7409091591835022
    }
  ],
  "11782": [
    {
      "answer": "radioactivity",
      "score": 0.9017037749290466
    }
  ],
  "11783": [
    {
      "answer": "1013",
      "score": 0.9957798719406128
    }
  ],
  "11784": [
    {
      "answer": "1015 kelvins",
      "score": 0.9539064764976501
    }
  ],
  "11785": [
    {
      "answer": "heavy W and Z bosons",
      "score": 0.8786188364028931
    }
  ],
  "11786": [
    {
      "answer": "weak force",
      "score": 0.7419193983078003
    }
  ],
  "11787": [
    {
      "answer": "weak",
      "score": 0.9843788743019104
    },
    {
      "answer": "weak force",
      "score": 0.9058724045753479
    }
  ],
  "11788": [],
  "11789": [
    {
      "answer": "normal force",
      "score": 0.7782580852508545
    },
    {
      "answer": "Pauli repulsion",
      "score": 0.6853666305541992
    },
    {
      "answer": "normal force",
      "score": 0.7069754004478455
    },
    {
      "answer": "normal force",
      "score": 0.741658091545105
    }
  ],
  "11790": [
    {
      "answer": "Pauli repulsion",
      "score": 0.9851217269897461
    }
  ],
  "11791": [
    {
      "answer": "fermionic nature of electrons",
      "score": 0.5590882301330566
    }
  ],
  "11792": [
    {
      "answer": "normal force",
      "score": 0.9569954872131348
    },
    {
      "answer": "normal force",
      "score": 0.9682507514953613
    },
    {
      "answer": "normal force",
      "score": 0.9439104199409485
    }
  ],
  "11793": [
    {
      "answer": "normal force",
      "score": 0.9587312936782837
    },
    {
      "answer": "normal force",
      "score": 0.8822603821754456
    },
    {
      "answer": "normal force",
      "score": 0.8700903654098511
    }
  ],
  "11794": [
    {
      "answer": "Pauli repulsion",
      "score": 0.9884242415428162
    }
  ],
  "11795": [
    {
      "answer": "impact force on an object crashing into an immobile surface",
      "score": 0.9631673693656921
    }
  ],
  "11796": [
    {
      "answer": "tables and floors",
      "score": 0.9762938022613525
    }
  ],
  "11797": [
    {
      "answer": "ideal strings",
      "score": 0.9762749075889587
    }
  ],
  "11798": [
    {
      "answer": "pulleys",
      "score": 0.9925324320793152
    },
    {
      "answer": "pulleys",
      "score": 0.5776181817054749
    }
  ],
  "11799": [
    {
      "answer": "instantaneously",
      "score": 0.9830358624458313
    }
  ],
  "11800": [
    {
      "answer": "conservation of mechanical energy",
      "score": 0.9476068615913391
    }
  ],
  "11801": [
    {
      "answer": "movable pulleys",
      "score": 0.8941836357116699
    }
  ],
  "11802": [
    {
      "answer": "Tension forces",
      "score": 0.8667551279067993
    }
  ],
  "11803": [
    {
      "answer": "Tension forces",
      "score": 0.8755719065666199
    }
  ],
  "11804": [
    {
      "answer": "tension forces",
      "score": 0.8767550587654114
    }
  ],
  "11805": [
    {
      "answer": "idealized point particles",
      "score": 0.9638127088546753
    }
  ],
  "11806": [
    {
      "answer": "idealized point particles",
      "score": 0.66347336769104
    },
    {
      "answer": "three-dimensional objects",
      "score": 0.8471736311912537
    }
  ],
  "11807": [
    {
      "answer": "extended fluids",
      "score": 0.8681015968322754
    }
  ],
  "11808": [
    {
      "answer": "other parts of an object",
      "score": 0.9783191680908203
    }
  ],
  "11809": [
    {
      "answer": "extended structure",
      "score": 0.9923326969146729
    }
  ],
  "11810": [
    {
      "answer": "matter",
      "score": 0.9401564598083496
    }
  ],
  "11811": [
    {
      "answer": "other parts of an object",
      "score": 0.9500056505203247
    }
  ],
  "11812": [
    {
      "answer": "along the pressure gradients",
      "score": 0.9553806781768799
    }
  ],
  "11813": [
    {
      "answer": "Newton",
      "score": 0.6159917712211609
    },
    {
      "answer": "Newtonian",
      "score": 0.7501497864723206
    }
  ],
  "11814": [
    {
      "answer": "stress tensor",
      "score": 0.7262413501739502
    },
    {
      "answer": "forces",
      "score": 0.7119914889335632
    }
  ],
  "11815": [
    {
      "answer": "stress-tensor",
      "score": 0.8250696063041687
    },
    {
      "answer": "stress tensor",
      "score": 0.6902037858963013
    }
  ],
  "11816": [
    {
      "answer": "pressure",
      "score": 0.9758604764938354
    }
  ],
  "11817": [
    {
      "answer": "pressure terms associated with forces that act normal to the cross-sectional area (the matrix diagonals of the tensor)",
      "score": 0.8669592142105103
    },
    {
      "answer": "shear terms associated with forces that act parallel to the cross-sectional area (the off-diagonal elements)",
      "score": 0.7980031967163086
    }
  ],
  "11818": [
    {
      "answer": "stress tensor",
      "score": 0.632788896560669
    }
  ],
  "11819": [
    {
      "answer": "tensile stresses and compressions",
      "score": 0.7951993346214294
    }
  ],
  "11820": [
    {
      "answer": "pressure",
      "score": 0.8186280727386475
    }
  ],
  "11821": [],
  "11822": [
    {
      "answer": "Torque",
      "score": 0.7142900824546814
    },
    {
      "answer": "rotation",
      "score": 0.6896727681159973
    }
  ],
  "11823": [
    {
      "answer": "unbalanced torque",
      "score": 0.9421206712722778
    }
  ],
  "11824": [
    {
      "answer": "Second Law of Motion",
      "score": 0.9676003456115723
    }
  ],
  "11825": [
    {
      "answer": "rotational",
      "score": 0.982921302318573
    }
  ],
  "11826": [
    {
      "answer": "angular velocity",
      "score": 0.5899096727371216
    }
  ],
  "11827": [
    {
      "answer": "angular velocity",
      "score": 0.6156048774719238
    }
  ],
  "11828": [
    {
      "answer": "First Law of Motion",
      "score": 0.8932818174362183
    },
    {
      "answer": "Second Law of Motion",
      "score": 0.8245421648025513
    }
  ],
  "11829": [
    {
      "answer": "toward the center",
      "score": 0.9289068579673767
    }
  ],
  "11830": [],
  "11831": [
    {
      "answer": "radial (centripetal) force",
      "score": 0.9345380663871765
    }
  ],
  "11832": [
    {
      "answer": "centripetal force",
      "score": 0.769370436668396
    },
    {
      "answer": "radial",
      "score": 0.7664636969566345
    }
  ],
  "11833": [
    {
      "answer": "centripetal force",
      "score": 0.6435282230377197
    },
    {
      "answer": "tangential force",
      "score": 0.9911025762557983
    }
  ],
  "11834": [
    {
      "answer": "radial (centripetal) force",
      "score": 0.9442402720451355
    }
  ],
  "11835": [
    {
      "answer": "radial",
      "score": 0.6092289090156555
    }
  ],
  "11836": [
    {
      "answer": "radial (centripetal) force",
      "score": 0.9266536831855774
    }
  ],
  "11837": [
    {
      "answer": "object",
      "score": 0.6621329188346863
    },
    {
      "answer": "object",
      "score": 0.6350608468055725
    },
    {
      "answer": "object",
      "score": 0.7945206761360168
    },
    {
      "answer": "object",
      "score": 0.6323919296264648
    },
    {
      "answer": "object",
      "score": 0.9583507776260376
    },
    {
      "answer": "object",
      "score": 0.7348812222480774
    }
  ],
  "11838": [
    {
      "answer": "kinetic",
      "score": 0.8719126582145691
    }
  ],
  "11839": [
    {
      "answer": "mechanical work",
      "score": 0.5397032499313354
    },
    {
      "answer": "potential",
      "score": 0.786754310131073
    },
    {
      "answer": "potential",
      "score": 0.6534534692764282
    }
  ],
  "11840": [
    {
      "answer": "net mechanical energy",
      "score": 0.9326406717300415
    }
  ],
  "11841": [
    {
      "answer": "difference in potential energy",
      "score": 0.9725863933563232
    }
  ],
  "11842": [
    {
      "answer": "conservative force",
      "score": 0.9326338768005371
    },
    {
      "answer": "conservative force",
      "score": 0.9136400818824768
    }
  ],
  "11843": [],
  "11844": [
    {
      "answer": "conserved",
      "score": 0.9724026918411255
    }
  ],
  "11845": [
    {
      "answer": "direction and amount of a flow of water",
      "score": 0.6965358257293701
    }
  ],
  "11846": [
    {
      "answer": "contour map",
      "score": 0.9744771718978882
    }
  ],
  "11847": [
    {
      "answer": "forces as being due to gradient of potentials",
      "score": 0.8986881971359253
    }
  ],
  "11848": [
    {
      "answer": "gradient of potentials",
      "score": 0.826323926448822
    },
    {
      "answer": "macrophysical considerations",
      "score": 0.9570292234420776
    }
  ],
  "11849": [
    {
      "answer": "friction",
      "score": 0.9649016857147217
    },
    {
      "answer": "friction",
      "score": 0.6383153796195984
    }
  ],
  "11850": [
    {
      "answer": "Nonconservative forces",
      "score": 0.977432131767273
    }
  ],
  "11851": [
    {
      "answer": "gradient of potentials",
      "score": 0.8863669633865356
    }
  ],
  "11852": [
    {
      "answer": "forces",
      "score": 0.9218495488166809
    }
  ],
  "11853": [
    {
      "answer": "electrostatic potentials",
      "score": 0.9370899200439453
    },
    {
      "answer": "potentials",
      "score": 0.6148461699485779
    }
  ],
  "11854": [
    {
      "answer": "tension, compression, and drag",
      "score": 0.9369957447052002
    }
  ],
  "11855": [
    {
      "answer": "statistical mechanics",
      "score": 0.9897602796554565
    }
  ],
  "11856": [
    {
      "answer": "nonconservative forces",
      "score": 0.7453959584236145
    },
    {
      "answer": "nonconservative forces",
      "score": 0.9849850535392761
    }
  ],
  "11857": [
    {
      "answer": "nonconservative forces",
      "score": 0.5928361415863037
    },
    {
      "answer": "nonconservative forces",
      "score": 0.8876893520355225
    },
    {
      "answer": "transfer of heat",
      "score": 0.6058022975921631
    }
  ],
  "11858": [
    {
      "answer": "Second law of thermodynamics",
      "score": 0.8753610849380493
    }
  ],
  "11859": [
    {
      "answer": "nonconservative forces",
      "score": 0.8997131586074829
    },
    {
      "answer": "nonconservative forces",
      "score": 0.9779044389724731
    },
    {
      "answer": "nonconservative forces",
      "score": 0.8440247774124146
    }
  ],
  "11860": [
    {
      "answer": "change the internal energies of the system",
      "score": 0.978293776512146
    }
  ],
  "11861": [
    {
      "answer": "nonconservative forces",
      "score": 0.8314012289047241
    },
    {
      "answer": "nonconservative forces",
      "score": 0.9751150608062744
    },
    {
      "answer": "nonconservative forces",
      "score": 0.5927443504333496
    }
  ],
  "11862": [
    {
      "answer": "heat",
      "score": 0.9928190112113953
    }
  ],
  "11863": [],
  "11864": [
    {
      "answer": "kilogram-force",
      "score": 0.971221923828125
    },
    {
      "answer": "kilogram-force",
      "score": 0.6241679787635803
    },
    {
      "answer": "kilogram-force",
      "score": 0.7150195837020874
    }
  ],
  "11865": [
    {
      "answer": "kilopond",
      "score": 0.9664927124977112
    }
  ],
  "11866": [
    {
      "answer": "metric slug",
      "score": 0.9714683890342712
    }
  ],
  "11867": [
    {
      "answer": "metric slug",
      "score": 0.8266922235488892
    },
    {
      "answer": "kip",
      "score": 0.6338597536087036
    }
  ],
  "11868": [
    {
      "answer": "metric slug",
      "score": 0.8580448031425476
    }
  ],
  "11869": [],
  "11870": [
    {
      "answer": "kilogram-force",
      "score": 0.9710960388183594
    },
    {
      "answer": "kilogram-force",
      "score": 0.6871460676193237
    },
    {
      "answer": "kilogram-force",
      "score": 0.7081917524337769
    }
  ],
  "11871": [
    {
      "answer": "kilogram-force",
      "score": 0.920200765132904
    },
    {
      "answer": "kilogram-force",
      "score": 0.6735718250274658
    },
    {
      "answer": "kilogram-force",
      "score": 0.6895456314086914
    }
  ],
  "11872": [
    {
      "answer": "kilogram-force",
      "score": 0.6654520034790039
    }
  ]
}